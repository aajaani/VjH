

---------combined_output2.txt--------



---------Loeng 1 - Sissejuhatus ainesse.txt--------

 Tere tulemast siis VB Teehnosti ja hajussüsteemide arenduse ainesse. Minu nimi on Pelle Jakovits. Ma olen siin instituudis hajussüsteemidelektor. Annan seda ained, see on nüüd juba kolmadad korda. Annan pilve tehnoloogia ained, mida me oleme annud, ma ei tea, 10 aastad juba. Tegelen ka praktika korraldusega, nii et te olete võib-olla minuga kokku puutun, siis praktika ained raames. Ja õpetan ka kuberneetes ained, mis on pigem, nagu ma kistritudenkitele sügisse mestriis. Ja see ainegi tegime kuskil kolm aastad tagasi just selled tõttu, et ma olin praktika koordinaatore ja ma nägin, et tegelikult meie pakka tudenkit, kes lähevad praktikale, siis nendale ei prugi olla piisavalt sellised appide arenduse ja üldiselt hajussüsteemide teadmisi, kui nad lähevad praktikale itefirmadesse. Et siis tihti, et meie tudenkit pidi hakkama appisid õppima nagu sellise praktika või töö alguses. Ja kui me vaatasem, mis ained instituusisse eksisteerevad, siis oligi hajussüsteemida ainu oli midagi, mis oli ajalooliselt täiesti pakka ain, aga kuskil viis-kuus aasta tagasi ta muutusa ainult ma kistritasem aineks ja natuke teoreetilse maks. Ja nüüd pakka see olnudki sellist hajussüsteemide teemasid ja veepi-teenuste osa katab sellist appide arendust plus pilvedehtnoloogiat. Et. Midame. Täna räägime ja mis on selline aine üldine eesmärk kongi, siis sel näe, siis sissejuhatus hajussüsteemide olemusse, mis üldse on hajussüsteemid, kudas neid defineerida, kudas neid arendada. Sissejuhatus veepi-teenuste arhitektuuridesse. Veepi-teenuste alma peamaselt mõtlen just veepi-appisid. Sissejuhatus pilvedehnoloogisse me hakkame kasutama sinna aines Microsoft asure pilve. Teil on ligipääs üle teie ülikooli konto, et saate sisse logida, saate aktiveerida oma sellise student subscriptioni, mille abil saate väikse hulga krediiti ja lihtsalt saate ligipääsatelun õigused ülikooli asure kontos siis asi üles seada. Aga see aina on hästi praktiline, ma küll loengus siin räägin tausta teemadest ja tuleb ka eksam, mis on selline tööreetilne eksam, aga pool ainest on täiesti praktiline, kus üks ühelä siis loengu teemadega te praktikumides loote rakendusi. Alkuses siis sellise mitmelõimellised rakendused siis hajussüsteemidele on siis veepi-appid enne ja siis pilverakendust enna. Ja te saategi siis kokemuse selliste mitmelõimelliste progammide loomisest, hajussüsteemide loomisest, kus mituprozessi töötavad koos tööna, et saada oma valges sõnumeid või vahendavad andmeid erine halviisidel ja siis aina teisel poolel peamiselt just veepi-appidega ja pilvepõhiste rakenduste loomisega, nii et õppite, kui kui üles pilves oma loodud rakendused ülesseada efektiivselt. Ja aine kodulest on siis korsesportaalis, nagu kõik meie instituutid teised ained, et selt leiate siis loengu slaidid, loengu salvestused, kõik praktikumiuhendid ja seal hakkab olemasel peamine info näiteks, kuna me plaanime teha eksamid, mis on eelmise aastate eksamite näited, et saada vaatata, millised eksamid tulevad. Loengu ülekandid teeme küll suumi ja tekib ka videosalvestus, mille panen üles paaripäeva jooksel pärast loengut ja praktikumid toimuvad siis samal päeval kell 4 ja järgmisel päeval kell 12, kus meil on õppeassistent, kes teil praktikumis aitab. Aina alguses ma ka olen praktikumis, vaatan, et mis probleemid meil võib-al tekivad ja natuke haitan õppeassistent, aga üldjuhul juhendab teil praktikumis õppeassistent. Aga praktikumi ja materjald on sellised kirjeldavad, mis võib-al küll ei jõtla teile krikki ette ära ja lähevad aine jooksel natuke keerukamaks, aga põhimõttelneid saab iseseisvalt läbida ja otsaselt väga palju nagu õppeassistentilt võib-al ei ole vaja, aga kindlasti on parem neid teha praktikumis kohapeal, et kui vähegi mingi probleemid tekivad, siis saate kohe õppeassistenti küsida ja raiskata vähem aega kodus üksi pusides, kui te proovite neid kodus teha. Väheselt eeldus, et tudenkitel on see, et teil võiks olla pyyton teadmised. Me arendame peame sellest pyytonis oma sellised hajussüsteeme, veepi-teenuseid, pilve-teenuseid ja peame sellest kõik materjald on pyytonipõhimised. Teil võiksid olla mingisugused kit kasutamise baasoskus, et me ei pane teid meeskondades töölet-meris konflikte oma vahel lahendama, aga põhimõttel kitivahepeal kasutame päris mitvas kohas, sest see on üks peamise, et viis ja kudas hästi lihtsasti pilves pyyt on rakendus ülesseada, et sellasele on midagi käsitsi teha, me saame lihtsalt panna kitti ja üelda azurale, et võta sit tarkvarasid kitlist ja pan üles. Sellest operatsioonisisteemide alusteadmised on kõik head, et oleksite operatsioonisisteemide aine läbind, kuna me hakkame Linux käsurida kasutama päris mitvas kohas, me hakkame tokeri asju tegema ja et kui Linuxi teadmised ei lütse, siis natuke keerukam sellel aine läbimine. Päris palju teeme küll teie oma arvutis, aga me paneme teie arvutis ISL ja tokeri ja muud oisad tegelikult ka sellest, et aru saada, mis on dockerfail, siis tegelikult on vaja baasteadmisele, et Linux käsur jaast, sest dockerfail onki põhimselt Linuxi käsur ja käskude kirjeldamine tokerfailis küll teise struktuuris. Loengutes on plaanis siis rääkida pärast tänast loengut hajussisteemide olemusest ja definitsioonist, erinevatest hajusprogrammide, omavaheliste suhtluste viisidest alustatest teadete edastusega. Me siis kaugt protseduuridega ja siis selliste webi protokollidega nagu REST. Peamiselt me kasutame RapidMQ-t jaadet edastuseks ja loome sellist HTTP appisid, et teile näidata RESTi, aga pärast seda tegeleme ka selliste webi teenuste standarditega, et kui te ota kusakil praktika käigus või kuskil mujal projektis kasutanud swaggerit või open appid, siis me loome oma open appi spetsifikatsiooni ja genererime põhimõtteliselt serveri koodi ja implementeerime meetodit seal koodis ära. Vaatame ka pilvetehnoloogite kohta, mis on erinevad pilvetehnoloogimudelid. Räägime, mis on virtualiseerimes ja konteinerite erinevused. Ei ole, et konteinerid on lihtsam virtualiseerimine, vaid need erinevasad väga fundamentaalisad. Räägime natuke ka anmebaasidest pilves ja hajus anmebaasidest üldiselt ja aina viimased teemad on selliste mikro teenuste, nanoteenuste ja tarko arhitektuuridega seotud teemad, kus me lõpuks paneme ka oma loodud rakenduse pilve, täiesti pilvepõiseks rakenduseks, nii et ta kasutab pilve anmebaasi, pilvefailisüsteemed, pilvefailisüsteemed, pilvehoida ja jooksebki täiesti ja on disaniitud täiesti pilve jaoks. Ja viimane selline teema on EXAM-i konsultatsioon, kus EXAM tavaselt toimukas ieteiskymnedal või kueteiskymnedal nädalal. Peame selleks, et tudenkit, kes lõpetavad oma õpingud ja teevad lõputööd kevadel, siis saaksid aine kiiresti arvastatud. Praaktikumide sisu proovib neid teemasid jälgid üks ühele, selletatukat äna, nagu sellel nädalal praaktikumi veel ei ole ja praaktikumid hakkad pihta siis, kui me võtame ette esimese hajussusteemide teema järgmine nädal ja räägime lõimedest ja hajussusteemide processide synchroniseerimisest ja siis praaktikumis proovite läbi, mit me lõimelise püüt on rakenduse loomist. Praaktikumid toimub kohapeal, et suumi meil praaktikumide aegal kasutuses ei ole, et ei saa üle suumi vaatatamist toimub praaktikumis, kuna sa tegelikult segab õppeassistent, et ta peab samal aegel ruumis tudenkit aitame ja siis tekivad küsimused suumis ja siis on raske nagu jälgida, mis mõlemast toimub. Aga me seame üles eraldi sellises Suulipi keskkona või üle kasutamane instituudi Suulip keskkonda ja seal saate küsida abii, et näiteks jäädte pärast praaktikumi kodus midagi lõpetama ja saadute hättas, siis saate Suulipi kaudu abiküsida ja see on selles mõttes hea, saate ka 11 aidata Suulipis, et kui teisel tudenkil on mingi probleem tekib, siis saate ise kiiresti aidata enne kui mina või õppeassistent juab teid aidata. Ja toimud siis tänakel 4 ja omme kell 12. Praaktikumi teemad on üks ühele loengutega. Nii et me alustame lõimmedest püütonis, aga me mida me teeme on me võtame tegelikult ühe kasutuslo, milleks on selline suhtselt lihtne raamatute halduse süsteem või appi ja me võtame selle kasutuslo ja implementeerime selle esimeses praaktikumis osaliselt. Järgmises praaktikumis teeme natukes seda edasi ja kogu praaktikumide käigus me arendame järjest edasi seda ühte kasutuslugu. Et alguses teeme ta lõimmedega selliste raamatut alla tõmbamise, siis teeme ta teatete edastusega selliseks hajussüsteemiks, siis teatete edastusasemel kasutame RPC-d, kauprozeduurne nende kahe hajusa komponenti vahel. Neljandes praaktikumis me teeme ta ümber webi appiks, et siis saab post ja get request saata, et seda meie rakendust kasutada. Pärast seda teeme ta natuke ümber, et ta ei ole nagu nii käsitööna tehtud appi, vaid kasutab open appi spetsifikatsiooni, et märata ära kõik need appi endpointid ja metodid ja metodid ja sisendid ja väljundid, et ta oleks nagu dokumenteeritud appi, nii ajalda. Pärast seda paneme ta meie appi pilve platform üles, siis me paneme ta sellise pyütun rakendusena, aga järgmises praaktikumis me teeme teemast konteineri, võisigi mitu konteinerid, nimut, et me saame konteinerina jooksutada teda oma arutis ja pilves. Ja pärast seda hakkame anmeid oidma pilveanmebaasides, sellasemele, et anmeid oida nagu lokaalsena failidena, siis võtama anmebasid kasutusele asures. Siis teeme ta natuke ümber, et on nagu ühe konteiner asemel teeme temast nagu mitu mikro teenost, mis on ama vahel suhtlevad, saarnastelt tegelikult nendele teadete edastusele ja kaukprotseduuridele. Ja pärast seda teeme ka frontend juurde sellele mikro teenusele. Et see frontend hakkab olema hästi lihtne, lihtsalt nagu selline basic õpetus, kuidas luua JavaScript frontend, mis suhtleb meie loodud appiga. Ja automaatsal, siis kui kasutakse klikki mingi nuppe HTMLis, siis kutsutakse appi meedodeid välja. Ta nii väga ei õpeta teed, kuidas häid frontende luua, vaid pigem õpetab seda, et kuidas frontendid üldse töötavad, et kuidas nad seda appi meedodeid väljakutsuvad tõnaamiliselt ja kuidas nad need appipolt tagastatud anmeid kasutavad siis HTMLis. Ja pärast seda, kui meil frontend on olemas siin, siis hakkame natuke laiendama seda meie rakendust, et lisaks kahele mikrotenusele teeme ühe sellise nanoteenuse juurde, mis konverteerid tekstiilised ramatu fileid ümber PDFideks automaatsal, et iga kord, kui uus ramatu file anmei base lisatakse, siis kutsutakse välja selline asure väike nano funksioon, mis on osaliselt ei sisaltu meie mikrotenuste sees, vaid on nagu välinne selline nano funksioon, mis käivitatakse tõnaamiliselt sünnmustapõhiselt, kui vaja. Ja viimases praktikumis me võtame kõik omal oodud komponentid, kaks appi, konteinerid, frontendi ja selline nano funksiooni ja anme base ja teeme nad kombineerim nat koku nagu üheks selliseks pilve paketiks, mis ongi nagu selline üks pilvepõhine rakendus ja kui me varasemalt oleme testinud, võib-olla nende sellist komponente, siis lõpuks paneme ta täiesti pilves tööle sellise pilve rakendusana või pilvepõhise rakendusana kui ingliskelle sõjata siis cloud native application. Ede ongi sest, et kõikid asi praktikumid, et teed töötame edasi selle sama rakendusega, et siis te näete, et kuidas erinevaid lähenemise anme basi teaks, verinad lähenemisi hajussüsteemide kontekstis kasutada täpselt sama kasutusloo raames. Praktikumid oleks kõige parem lahendada enne järgmislooingud lihtsalt selletõttu, et siis te olete selle teema praktiliselt läbinud enne kui te järgmist ja reetselt teemat kuulama tulete, aga selleks, et nagu 100% punkte saada, siis põhimõttel teie tähtaeg on järgmise praktikumipäev. Ma. Soovi viitesadat kodutööd hakkada hindama mai lõpus või juni alguses, et me ikkagi sunnime teid jooksvalt neid esitama, et kaeguse nii on, et ei saa lubada täiesti lõpus kõike praktikumi järgiteha. Ette sa vika esitada ja et võid kohe praktikumi jooksvõi ära teha ja ära esitada ja kõik, et ei paha kui te koota ma nad alat. Olen, et paridusel kokemust on nende tehnoloogitega, et siis praktikumis jõub täiesti valmis nende ka. Me ei avalda need järgmise nädalab praktikumi materjale enne, kui see praktikum algab, et kuna me ise vaatame näid üle ja parandame uuendama materjale, siis teoreetiliselt saate minna selle sama aine eelmise aasta korslaslehele ja vaatata, mis näid ülesandad eelmine aasta oli, aga ei ole mingid karantiid, et see on täpselt sama aene. Meie midagi muutub. Ja võib juhtud, et te jääte väga hättakuna asures nüüd töötab midagi natukas teistmoodi ja me peame kogu praktikumi ümber tegema. Ainehinde komponentid on siis see, et te saate 50% praktikumidest, kui teete kõik praktikumis ära, esitata ära, saate täispunktid, siis aines on 1% puud, et saada aines läbi. Eksam annab samuti 50% aines, ja see on selline teoreetil eksam. Seal on kolm küsimust, mis on sellised senaariumi põhised küsimused, et ei ole faktiküsimused või ei ole muudlidest, et pigem selline lahtise senaariumiga küsimused. Saate vaadata aine kodulehelt, et mis näite küsimused olid. Mul on mingi 2022 aasta eksamin näite küsimust olemas. Eksamine saamiseks peab esitama vähemalt 75%, ehk vähemalt 10 praktikumilahendused, hakkab olema, kes 13-12 praktikumi peame selled öet, et esimene praktikumi jääb ära. See ei nõua, et te peate saama 75% punktidest, vaid, et te peate esitama 75%-i lahendustest. Nad võib-ead olla ka osallid poolikud. Ja nagu teisteis ainates ka, et siis on vaja 51% kogu ainest, et saada vähemalt tee, ja siis see hindamiskala on täpselt samamis teisteis ainates. See on midagi väga erilisti ole. Praktikumilahendused ei ole krupitöö, ehk te peate iseseta tegema, ei tohi teiste tudenkite koodi kopeerida. Kui te jääte hätt, ei saa lahendatud, siis pigem küsige abisulipi kanalis või küsige õppejult habi vajaduse saama aidata teid koodikirutamisega. Et kui midagi on, et siis saame teile viidata, mida seal teist moodi teha, et lahendada. Mõni korda on mõned tudenkit lihtsalt kui kui kui kui kavandavad väga keerulise lahenduse, lihtse lahenduse jaoks, et saate kindlasti praktikumis habi küsida. Te saate lahenduse ei teid teiste õppilästega üliõpilästega arutada, aga teid tohi anda teisele tudenkile oma koodi, et nad koopeeriksid teie koodi. Kuna ülesende tuleb ise lahendada, see ei tohi olla krupitöö. Esiteks see tuden, kes koopeerib koodi, siis ei õpi selle käegus kõikitead mis ise ja teise problemina, et kui meie märkamajhindamisele ka teise problemine, ja teise problemina, et kui meie märkamajhindamisele kaks tööd on hästi sarnased või täiesti samad, siis mõlematel tudenkitel tegi problem, mitte ainult sellel, kes koopeeris. Põhimõttel tehke töö ise, ärge jaga oma lahenduse koodi teistega, kui teie sõber vaja pabi, siis aidaketa ta andke tale vihjeid, aidaketa progameerida kas või näide, andke tale üldised juhiseid, aga ärge laske tal koodi koopeerida. Kui te kasutate mõnda veebialikat või näiteks chat-cpidid, siis viidake sellele, et muidu tekib sama probleem, et kaks tudenkit leiavad täpselt sama hallika veebist, et midagi implementeerida ja siis kood näib täpselt sama välja ja siis tekib ka probleem, aga kui mõlemad viitavad, et ma leidsin mingisugus osalise lahenduse kusagelt veebist, panate lihtsalt koodi kommentari kus linkiga, et me näeme, et te olete kusagelt muidat lahendus leidnud ja siis ei tegi probleem, et teine tudenk teie pealt koopeeris, vai te mõlemad olete koopeerid kusagelt muidat, et siis seda probleem ei tegi. Ja kui kasutate chat-cpidid, siis on teie endu otsustada. Selle ain eesmärk ei ole teile nii väga programeerimist õpetada. Meie huvi on pigem kõik need erinemad pilvetehnoloogia hausstüsteemide lahendused ja kuidas neid efektiivselt kasutada. Ja kui teine natuke vähem mõppite püütu, onid kuna kasutadat chat-cpidid, siis on teie enda asi, aga ma kindlasti ei soovita kasutada chat-cpidid. Kenerida kõik kood ja siis mängida lihtsalt testijad, kas töötab või mitte, kas töötab või mitte. Et see muutub selleks puzzle mänguks, et proovite ja vaadata, kas see lahendus töötab või mitte. Sela asemel, et ise proovite selle lahenduda ja õpida selle käigus. Palju parem, et õpite ise nullist apisid designima, sest see on tegelikult suhtsev lihtne. See kood, mida me siin ainees loome ei ole väga keeruline kood. Ja sellest apide ja haussystemide loogikast aru saamine on palju tähtsam, kui mingi koodi valmis saamine, mis on keeruline. Et see loogika, mida me oma kasutus loos implementeerimine on suhtsev lihtne. Et ei vaja mingi erilisi. Me ei hakkagi erilise algoritme või erilisi keerukaid anvestruktuur katsutuma. Esialgse tegsemäead on 28. mai ja 4. juuni. Võimalik, et ma liigutan seda 4. juunid natuke hilisemaks, et anda teile rohkem aegat õpida. Aga praeguse seisujärgi jääb ta umbes selliseks. Need on mõlemad tegelikult enne lõpudüöda kaitsimisi. Nii et tudenkit, kes soovad lõpudüöd kaitsistaksele kevadel, saavad valita näiteks lihtsalt 28. mai. Ja siis jääb umbes pooldeist nädalat esimeste kaitsimistene, mis hakkavad vist rähedest pihtu. Eksam toimub koha pealt teltas. Ta on kirjalik, aga ta on avatu draamatu, avatud interneteksam, et saada süljaharvutud samal alal kasutada. Aks kirjutada paveri peale, et ei ole muudlidesse, kus ta muudlise kirjutada. Aga see on huvitav aine, kus see nõuab käsitsi kirjutamist paverile. Saada natuke arjutada. Jah, õnne, nagu siin ei ole koodi kirjutamist, see on pikem nagu selline, et senaariumi põhiselt teoreetsed küsimused. Ja kestvus on siis 9 minuutit eksamil ja 3 küsimust, nii ettele jääb niivadi pooltuindi iga küsimuse kohta. Ja näiteeksami küsimused on see Hanna kodul. Kas teil on korralduse kohta mingit küsimusi? Kõik sealga. Kõik see sama info on ka kodulehel olemas, aine kodulehel, et leedatse selt üles. Kui te märkat, et mingit kuub päevad on teised, siis andke teada, ma ootan üle. Meil toimub niimoodi, et me kooperime elmisevasta kursuse, lähme sinna, muudame kui kuub päevad ära. Ja alati võib mingisugun asi kaha silma vahel jääda, et kusakil on midagi muutmata. Aga kõik aine materjallid ja praktikumid ilmuvad sinna. Järgmise nädalaj praktikumi alguses paneme üles selle linki praktikumi materialidele ja siis saates avada. Ja seda kasutam hakkata, kui te näete, et see linki taga on mingi lehtmis küsivtel parooli. Tegelikult see tähendab, et me oleme ära peitnud selle materialid kuni praktikumi alguse nii, et siis oodakka lihtsalt kuni praktikumi algab ja tehekki refresh ja siis see parool ka parvasalt. Aga väga lühitelt siis ma kirjelda siis need kolme peamist aine teemat. Hajussüsteeme, webi-tenuseid või webitehnoloogid ja appisid ja siis pilvetehnoloogid. Ja nagu siseulisemalt räägime näidest hajussüsteemid olemustest ja omadustest ja definitsioonidest järgmises loengus. Aga mis on siis hajussüsteem? Tänapäeval on võib-olla lihtsam küsida, mis asi ei ole hajussüsteem. Sest peab kõik asjad on tänapäeval vähemalt mingil märral hajussüsteemid. Kas või täiesti tavaline rakendus, mis teie arvutis jookseb, mis tegelikult ei oia ühtiga arvutist väljas pool, võtab ühendust tõenaselt automaatsalt väliste sisteemidega selleks, et näiteks kontrollidega, kas on mingid uuendusiga, kas on mingid sõgused anmeid vaja alla laadida. Tänapäeval tegelikult ongi peab kõik hajussüsteemid. Aga selline huvitav loogika, mida kasutada hajussüsteemi ära tundmiseks on you know you have a distributed system when the crash of a computer you have never heard of stops you from getting any work done. Et kui teie kasutad oma arvutis rakendust, aga kui internet ei ole, siis rakenduse tööta või rakendus töötab, aga mingi et ta katkestab töö, kuna internet siis teda midagi ole kätte saada. Ja tänapäeval ka päris palju rakendusi. Isegi kui nad on hajussüsteemid, siis nad on võimalselt töötama ilma, nagu interneti ühenduseta puhtalt selle töötu, et muidu ei saaksid keegi kasutada arvutis olevad tarkvara, kui internet ei ole. Aga reaaliselt kui interneti ühendust tuleb tagasi siis tegelikult võib päris paljud tegevasi toimuda taustal, mida teie ei näe. Kahjuks ei ole, sest üks asi on replikseeritud hajussüsteem, kui sul on lihtsalt mitu koopjat nendest teenustest, et sul on okei, kui ainult üks nendest on kätkastav, ei kasutatav, aga näiteks kui sul on anmebaas ja sul on api ja sul on frontend, üks kõik, mis nendest ära kasutab kaop, siis sa ei saa seda rakka kasutada. Et see on pigem selisel olukorral, kui sul on hajutatud anmebaas, kui sul on anmebaasi servereid on kolm tükki ja on täitsa okei, kui üks nendest ära kaop. Et sellise liul, ja, aga need on pigem sellised replikseeritud mudel hajussüsteemides, mis onki ehitatud selleks, et olla tõrke kindel, kui üks server ära kaop. Et sul on igast frontendi konteinerist on sul kolm koopjad, igast backendi konteinerist on sul kolm koopjad ja igast anmebaasi noodist on sul kolm koopjad. Ja siis tõesti üks kõik, mis ära kaop jääb tööle, aga kui üks nendest kolmest kihist ära kaop, siis ei tööta. Ja väga üldiselt võib defineerida ka nii, et hajussüsteem on autonomse te arvutite kogu, mis oma vääli ühendatud arvutivõrku ja mis on varustatud integreeritud keskkona loomiseks vaheliku tarkkoraga. See on väga üldistatud kirjaldis, mis tegelikult väga palju jütle. Ja täna päeval me enam ei tegele nii väga arvutitega. Te näete ka kes selles aides, kui me lähme pilvetehnoloogia peal, et näiteks, mis asi on serverless computing. Kas keegi oska vastata, mis on serverless computing? Päris mitte. Seda on väga palju rakendatud just sellistes kaardi rakendustasüsteemides, kus sul tegelikult näiteks, et Google Maps töödabki, JavaScript rakendasik sinu arvutis. Aga serverless on tegelikult natuke midagi muud. Pikemada siis, kui ta töötab serveris, aga sa kunagi seda serverid teine, see tarkkora arendaja, kes selle tarkkora kirjutab ka kunagi serverid teine, et kirjutatud tarkkora niimoodi, mis töötab, mis jookseb kusagil pilves, aga ei ole määratud, kus serverist ta jookseb. Ja ta on serverite vabakood, mis jookseb kusagil pilves, ta füüsiliselt jookseb serveri peal, aga ta on disaanitud niimoodi, et siin kunagi ei huvita, mis serverist ta jookseb. Kunagi ei eksisteeri serverid, kus ta kood asub, vaid sa kood pikem asub näiteks mingisuguses file repositoriumis või natuke isegi ettevalmistatud konteinerina, aga ei ole teada, kus ta jookseb, enne kui teada tegelikult käima panaks. Jah. Ihtsalt on serveri. Jah. Aga kusutaks seda serverless. Aga see on huvitav nimi, mis tegelikult ei ole õige, samamoodi õige mõeliks seda kutsuta function as a service, mis on palju kirjeldavam nimi, et on pyytane funksioon, mis käivitatakse kusagil pilves, aga sa ei tea, mis serveri peal ette, et ta jookseb ühe nende serverite peal, siis kui vaja. Teine näite on NoSQL serverid, või NoSQL anmebasid, millest me ka pilvetenoloogiaosas räägimad. Suur osa NoSQL anmebasidest toetab SQL-li. Mis on ka see huvitav, nagu, definitsioon, et mis on mitte relatsioonilist anmebasid, osa nendest toetavad relatsioone, osa nendest toetavad SQL-li, aga ikkagi neid nimetatakse ja tihti nagu mitte relatsioonilist üks anmebasidiks. Ja siis tegibki tegelikult väga selline keeruline hinat, et mis asi on üldse hajussusteem ja sellised võib-olla rangemad piirid on, et nendel komponentidel, serveridel, nendel processidel, processoridel ja peame seda just riistvaral, neil ei ole ühist kella. See tähem, et nad tegelikult ei jookse sama ema plaadi peal, neil ei ole ühist kella, nad ei ole synkroniseeritud. Ühel processil võib olla ajatempel täitsa teine, kui teisel processil, kui nad samal alal jooksevad ja oma vahel synkroniseerivad. Kui ma näiteks kaks komponenti anmebasil, kus on kaks anmebasi serverid ja te peate otsustama, kui ma panen paraleliselt kaks objekti anmebasi, kumb nendest ennekohale juab. Olukorras, kus kahel serveril tegelikult on täiesti eraldi kellad ja täiesti eraldi arvutatud timestampend, kui kui tagi püüsilises maailmas üks jõudis ennekohale kui teine, aga nende kahel serveri on erinad kellad, siis ta ei saa kui tagi karanteerida või ei saa hästi karanteerida, et kumb siis tegelikult on. Kui kui tegelikult ennekohale jõudis, et pigem mõeldaksik hajussüsteemid ala sellised süsteeme, kus on eraldi sellised masiinad või sõlmed võrgus, kes omavahel koostud teevad ja need sõlmed on täiesti sõltumatud üks teised selles osas, et neil on oma mõlu, oma protsessor, oma loogilinaaeg, mida nad oma püüsilise kella põhjal arvutavad ja sisteemid ei ole ranges synkronis, nii et sa ei saa tegelikult usaldada, sa ei saa usaldada, et kui üks hajussüsteeme, node või sõlm arvutab mingi ajatempli, et see on korrektne globaals ajasuhtes. Hajussüsteem pigem ongi selline kogum sõltumatud sõlmi või arvuteid või riistvara, mis paistavad kasutajale ühe tervikliku süsteemina, et teie lähete mingile veebiaadresile, hostemile kasutada seda, et tegelikult ei tea, kas seal taga on üks konteiner, üks server, 100 konteinerit või 10 000 serverit ja konteinerit, et te seda ei näe, et kasutajal teist ole see täiesti erabeidetud. Teatud olukorrast võib-al näete, et te lähete veebilehele ja siis vaadate kuhk sellest Chromei logist, et kuhu tehti appi värengud ja vaadate, et mida meil IP-adresile appi värengud tehti, aga siist te tegelikult ei tea, mis selle IP-adresi taga on, kas on reale server, kas on lihtsalt router, kas on mingi sugunne appi lüüs või appi gateway, mis tegelikult suuna veda siit 10-le teisele serverile. Et ta küll osa sellest on nähtav, et ta ei ole üks server, aga selle siseminestruktuur on erabeidetud teie. Ja tegelikult ei ole piirangud ristora kogus, et ku palju servered on YouTube'l, mitu servered on YouTube'i taga. Kui teie vaatad YouTube'i videot, kust tõmatakse alla see video? Kui see tõmatakse alla Amerikas suures tanmekeskuses, kas internet elakse lüüle? Kogu internet tegelikult läheks umbe. Ma soovitan sulle otsida Google Age Networki, et see on globaalne infrastruktuur, mille Google on ehitend, Google on ehitend selleks, et oleks üldse võimalik YouTube'i kasutada. Ja teie, kui tõmbate video alla, siis ta võib tulla Amerikast, aga ainult esimest korda, kui keegi tartus vaatab seda videot. Et Google on endal Tallinnas üks yhed serverid, kus kõik käsitaks ja kõik YouTube'i videod, selleks, et Eestist ei peaks Amerika serveredest videosid alla tõmbama. Ja Google ei lupa näiteks telijal käsida Google'i videoid. Et nad tahavad 100% kontrolli selle üle, et kui inimesed vaatavad mingit sisu, et siis ei oleks mingi cash, mingi kolmante osapoole cash, kes otsustaks, kas näha uut videot, vanavideot ja mingid vanu kommentaare ja uusi kommentaare. Sest Google on teinud nagu lepingud kõik maailma suurimate interneti teinuse pakkujatega niimoodi, et neil on õigusad nende anme keskustesse panna Google'i serverid just selleks, et nad saaksid optimeerida YouTube videoatevaatamisi. Ma võib-olla räägin sellest jääregmisel loengus rohkem. Sellest Google'i võib-olla pilvetehnoloogia loengust agelikult. Miks on vaja üldse hajussüsteeme? Miks kõik süssteemid tänapäeval peak on hajussüsteemid? Ongi selleks arvutusresursside koondamine, et palju efektiisem ja odavam tegelikult kasutada, ehitada hästi suuri pilva anme keskuseid ja kasutada neid selleks, et pakkuda resurss firmadele, kes nüüd oma tarkvarasel ülesseavad, kui see, et iga firma seab oma serverid. Et firmadele võib see mõnesmõttes natuke kallis olla, suhtelat kallis olla, aga energia- ja arvutusresursside kokkuhoiju mõttes on tegelikult palju odavam, nagu koguda Riistvarra resursid kokku ja pakkuda seda paljutale kasutatele. Teenusele niimoodi, et sa saad ühe suure füüsilise serveri peal pakkuda hästi palju sellised virtuaalselid väiksemat keskondi ja kasutada kogu selle serveri võimsus ära selleks, et tarkvarasel peal jooksatada, kui see, et sul on üks. Igal rakenduse jaoks on üks suur server ja siis võib-olla 30%-i või 10%-i või 80%-i sellest Riistvarrast ei ole, nagu kasutust leidev, et lihtsalt istub selle ei tee midagi. Ja et on võimalik anmeid ja töid jaotada ära paljude asukohtada vahel, niimoodi, et on palju efektiisem, kui suur hulk lente need anmed allatõmbad, et ei ole pudeli kaelu, et üks server peab siis kõigega hakama saama, vaid saabki anmed lihtsalt hajutada hästi paljude serverite vahel ära. Ja kui meie vaatame YouTube videoid, siis see tuleb Tallinnast, mida ei tule soome anmed keskusest või tule Google Amerika serverist. Ja samamoodi meie rakendusta puhul, et kui meil on start-up Eestis, kes loob rakenduse hästi palju, akatakse Aasias seda rakendust kasutama, siis on parem, kui need anmed ja tarkvarva liigub kuskile Aasi anmed keskusesse ja hakkatakse sealt neid kasutatele kohale toimetama mitte nagu Eestiserveritest või näiteks isegi Saksama anme keskusest. Ja et oleks selline üldine decentraliseeritus, et mis juhtub siis, kui meie lokale anme keskus kokku jookseb, kas me peame siis kudega hakama neid asju liigutama teise anme keskusesse, või need hoitakse juba niimoodi, et kui üks kõik, mis anme keskus kokku jookseb, siis koha on olemas koopjad asendusteenus, et teises anme keskuses ja meie kasutat võib-ale ei märkagi, et midagi kahtki läks. Aga see esimene arutusresursside koondamine ja decentraliseeritus natuke läheb oma vahel vastuollu, sest alati ei ole võimalik või ei taha maksta sellegest, et meie rakendused töötakseid hästi paljudes erinatse anme keskustes. Et on juhtunud, et kui see suur kokutud, anme keskus kokku jookseb, siis väga paljude asutust ja rakendused lihtsalt enam ei tööta. Microsoft Azure-s oli paar aastat tagasi niimoodi, et üks süsteemiadministraator kirjutas ruuterisse vale konfiguratsiooni ja ruuterise enam ei saanud sisselogida. Ja ruuter enam liiklus tõdasi suunanud. Ja tekki siis probleem, et kõik on harjunud üle webi, süsteeme haldama ja ei saanudki midagi teha, pidikohale kõndima ja ruuterisse sisselogima üle Ethernet kaabli ja siis ära parandama. Aga selleks pidi uuksest sisse saama ja uuksel oli turvallisest peal, et suurvalne administraator ei saanud sinna sisse kõndida. Ja see võitis pool päeva aega enne, kui keegi jõudis sinna ruuterisse juurde kõndida, kelle ole ole õiguses, et ruutarit hallata ja siis ära parandada. Ja terve Anme keskus asures ühes Amerika regioonis oligi maas pool päeva. Selle tõttu. Ja kõik nat rakendused, mis ei olnud teesentraliseeritud, siis ei töötanud. Öldse, et oleks võimalik resursse kaug kaugelt kasutada, et oleks võimalik siis tagada selline kõrg käiteldavus või asjade kokku jooks misel automaatne nende asjade parandamine või selline fault tolerant singlis keeles, et kui midagi kokku jooks, siis kasutad ei märkagi seda. Me seamegi Anme basist üles mitu koopjat, me seamegi appist üle mitu koopjat, niimoodi, et kui üks server kokku jooks, siis kasutad seda lihtsalt ei märka, et nad võib-olla üks või kaks või kolm kasutad märkav, kelle sessioon oli sellele hetkel aktiivne ja nemad saavad vea teat, et midagi enam ei toimu, aga põhimõtteliselt tagada sellel olukorrad, meil on hajussiste niimoodi, et kui ükski sõlm või server kokku jooks, siis tegelikult meie kasutajad sellest mitte midagi märka. See on tegelikult rohkem tõrked alus. Ja jõudlus osas, et me saaksime süsteemes kaleerida, et kui meil on tänna 10 kasutajad võib-olla meile ühes servist viisab, omme õhtul on 300 kasutajad, kas meie üks servisarv saab selle kakkama. Et pilves on suhtselt lihtne või siig automaatne skaleerimine, niimoodi et kui meie paneme oma appi üles, Asure App Service teenusene alla ja aktiveerime skaleerimise, siis vastavalt sellele, ku palju sisse tulevad päringud, vastavalt sellele, ku palju ressursse meie rakenduse konteehner kasutab, ja asure pilve teenus automaatselt lisab sinna ressursse juurde lihtsalt selle tõttu, et see kasutusmugavus või päringude latentzus oleks piisavalt väike ja tänapäeval pilves saab seda teha automaatselt ilma, et administraator ise peakski väga selleks midagi tegema. See on toku oleneb, kas te kasutate virtuaalmasinaid, kas te kasutate dockerid või kuperneetes konteehnerid või kasutate pilve põhiseid teenuseid, kus te seda üles ainult oma püütenrakenduse või java rakendused. Igal ühele on natuke erinev selline viis kuda seda skaleerimist defineerida ja kõike keerulisem on virtuaalmasinate puhul, kun on see nõub tegelikult virtuaalmasinaloomist ja see tavast võtab natuke aega põrreldes teiste lähennemistega. Et siis olekski võimalik samast appist ülesseada võib-a tuhat koopjad, mis töötavad 500 erinat serveris ja kogu liiklus nende vahel ära jagada. Hajusarvutitest on ka klasikaliselt teoria põhjal erinevaid tüüppe, et meil võivad olla sellist hajusarvutit, mis me seamegi ülesed väikse klastri arvutitest, aga kui me seame nad üles täiesti eraldi seisvete serveritena, siis nad on suhselt epaeffektiivselt, kui on vaja luua sellist ästi arvutusvõimsaid või ästi suuri arvutusi võimalisi superarvuteid, siis pigem prooviteks natuke rohkem integreerida neid arvuteid ja serverid, et tegaks isegi süsteeme, mis jagavad oma vahel mälusid, niimoodi, et selle aseme, et meil on 10 serverid, mille ligal on 32 gigabaitimälu, me loome hajus klastri, kus on küll 10 serverid, aga neil on 320 gigabaitimälu ja nad saavad nagu tarkvarast adresseerida kogus seda 320 gigabaiti, niimoodi, et nad kirjutavad programmi, mis adresseerib suvalist aadressi sellest suurest 320 gigabaitismälust, aga füüsilist on ta ikkagi serveritevajal peal ära jagatud, et sellised jagatud mäluolukarad, mida tegelikult on natuke lihtsam programe kirjutada, kes lihtsalt kasutavad hästi suurt mälu, kui kirjutada programe, mis peavad nagu arvesse võtma seda, et sul on 10 erine tarvutid, kui sa tahad rohkem mälu kasutada kui 10 gigabaiti või 32 gigabaiti, siis kui on 32 gigabaiti, sa pead hakkama sõnumeid saadma serverite vahel ja pead hoolitsema seda, et kus asuvad andmed, kas nad asuvad andmed, arvutis üks, nad peavad asuma arvutis kaks, selleks, et arvutik kahes asuv protses saaks mingisugust arvutusi teha, et siis võib-olla peab liigutama mälusoloid andmed nende kahe serveri vahel. Need, kus on jagatud mälu, nagu ristvaraliselt või vähemalt loogiliselt, need on nagu jagatud mälusüsteemid ja need, kus me lihtsalt ühendame 10 arvutid oma vahel, et hakkama hajusarvutis tegema, siis need tihti kasutavad sellest teadate edastamist, et me saame näiteks teha suurte maatriksid arvutusi, jagada maatriksid plokkideks ja igale serverile anda siis väike osasest maatriksist, aga siis, kui me tahame, et üks protses näeks mingi teist maatriksiosas, nad teadad neid maatriksid plokka oma vahel jagama. See on sellised klassikalised sellised paralel arvutused, mida tehaks näiteks MPI või teiste sõnumit edastuste, tehnoloogete abil. Me võime ka ülesseada sellised klustrid, kus selle asemele, et me teeme nagu otse hajusarvutusi tegitama sellise tööde järekorrad, et kui meil on arvutusklustrid näiteks haapetse keskuses ja meil on tudenkit, kes soova jõuad mingiselt pildi töötlusi teha näiteks GPU-tega, siis tudenk paneb oma käsu, mida tahab jooksutada järekorda ja siis on kuskil tööde järekora Haldur, kes võtab järekorrast uusi töid, siis otsustab, millise serveri peal see töö käivitada, kus on GPU-t, käivitab need ja paneb tulemused tagasi, kas kuskile anmebaasi või kuskile filesystemi kirjutab need väljundfailina, neid tulemused, siis see tudenksab hiljem vaadata, kas töö on valmis ja läheb, vaatab oma kaustast, kas sinna tekis väljundfail ja saab seda rugeda. See on tukkagi lihtsam viis, et me ei pane kohe nagu 10 arvutid oma val koost, et otse tegema, vaid kasutame need selliste tööde käivitusena. Ja siis, kui mul on suur selline maatriksid arvutuse üle sanna, et ma ei pane 10 protsessi sama aegselt tööle, aga ma jagangi sellel arvutuse 10 väikseks tükiks. Et mul on üks task, mis tööte päras esimesed 10 000 rida maatriksist. Panan selle järekorda, siis tekitan uue task, mis tööte päras järgmised 10 000 rida. Paren ka selle tööte järekorda, et ma jagan nagu oma suure arvutuse selliteks väikesteks tükkideks. Et võib-olla maatriksist tasamele piltide töötlus on natuke aru saada, et me tükkeltame pilti väikesteks tükkideks ja töötame need kõiki tükke eraldi väikeste töödena. Ja kui meil ühe Tartu ülikooli klastrist ei piisa, siis me saame Tartu ülikooli ühendada teiste ülikoolite ka kokku selliseks kriidiks, et meil on paljud ülikoolide oma vaheline klastrite koost kokkulete, et kui minula mingisugune töö, mis võtaks minul kuuaega aega näiteks teha, et ma jagan ta küll 10 000 väikseks tööks, aga nende 10 000 väikse töö tegemine lokaalsest klastrist võtaks kuuaega aega, siis ma saan need tööt saada opis sellises suuremase tööte järekorda, kus sealt tööte järekorast, siis võetaks ja otsustataks, mis ülikooli klastristse töö käivitada. Senne laajäändus, et meil on mitmed klastrid ja siis me saame ka tööd teistest klastrides käivitada, on see, et ajal oliselt olnud ülikoolide superarvutite või suurarvutite keskuste kriidid. Ja tihti on siis kõike arvutid või serverida oma vahel erinevad, võib-olla meil on sellises Intel ja Nvidia serverid ja siis teises ülikoolisena AMD ja AMD CPU-d ja GPU-d. Siis võib-olla hajussüsteemid meil opist tehtud hästi väikestest süsteemidest, et meil on mikrokontrollerid kusagil majas, et siin majas on ka mingisugused 15-20 mikrokontrollerid, mis tegelikult ei ole nii väga väikselt, nad on pikeb sellised, mis kontrollivad seda ventilatsioonisüsteema, mis kontrollivad päiksepaneele katu sell, mis kontrollivad akkusid, mis kontrollivad CO2 tased sinn, nagu uurivad CO2 tased sinn kuskil väljund toru. See on CO2 sensor, mis mõhda palju väljuvasõhus sellest ruumist, et CO2 tase on ja kasutab seda, et seda ventilatorit, kus ta nüüd sinna asub, kireminne tööle panne kuvaelik. Ja on siis sellised sensorvõrgud, et meie majas tegelikult ongi suur hulk sensoreid, kui te oled te näinud seda dashboardi sinna samas seinataga vist üks tubansi vahel, mis natuke visualiseerid need majanmed, siis need majanmed tulevadki siis lokaalsest sensorvõrgust, kus on palju kontrollereid ja palju sensoreid. Autodes tänapäeval on suured kännvõrgud, kus mitmed mikrokontrollerid autode sees oma vahel suhtlevad ja jagavad anmeid sellise car area network kaudu. Ja no seda reaalselt väga ei kasutata, aga sellised võib olla ka, et kui on mingi meditsiini rakendus, siis panaks see inimesi ja külge palju erinele sensoreid ja mikrokontrollerid ja panaks see need oma vahel lühendus, et ühe sensori põhjal siis võib-olla muudetakse mingi teise aktuaatori või sensori käitumist. Neid nimetateks selliseks SART-süsteemideks või ingliskeles embedded system või need on mitu nimed, aga et ingliskeles on kolm või neljinnime nendel. Hajussüsteemidel on palju erinele komponente, aga see peamine on ikkagi need sõilmeld või arvutid, kes teevad viivad läbi mingisugust arvutusi, olgu need mikrokontrollerid, olgu need mingid suured serverid, kus ma ei tea hetkel, mis on SART-ülik oli kõige suurium server, aga mõned aastat tagasi oli server, kus oli 512 tuuma ja vist 4 terabyte mälu, aga võib-olla nüüd on palju rohkem terabyte mälu. Asures võib rentide serveri, mis maksaab kuskil 50 000 eurot kuus selline server, kus on see hint tuleb peame sellest GPU-dest ja hästi paljute ketastest, ketaste kasutamisest. Kus saab kasutada tihti, noh, kas just tihti, ma ei tea palju on, et kasutatakse, aga saab kasutada hiigel suurte SQL-anmebaaside loomiseks, kus mälude maht on 500 terabytei näiteks, ongi arvutis 500 terabytei RAM-i. Ja võib-olla mitte 500 terabytei, vaid saab luua kettasysteeme, kus salvestusruumi on 2 petabytei anmebaasiaks näiteks. Aga lisaks arvuti teendal on ka kõik need võrgud, mida kasutatakse nende omava lühendamiseks. Meie pigem kasutam Eternet võrgke, siin aines Wi-Fi võrgud, kõik need ruutereid sildad. Tänapäeval prooviteks jäärest rohkem arvutusi seostada ka ruuteritega, et ruuterid oleksid targemad, et näiteks Cisco toodab ruutereid, mis on vist iOS-ruutereid, ja sama nimis Apple'il. Aga mille mõte on, et võimalik on jooksutada funksioone, siis ruuteri reistvarab kõrval või peal, selleks, et selle jooksutada näiteks mingisuguselt võrgu funksioona või teha mingiselt anme töötlust ruuteri seadme peal, enne kui need anmed lahkuvad majast või mingisugusest majate kompleksist. Et on võimalik vajadusel ka arvutusi teha ruuterte peal, et seda nimetakse hoog komputinguks, mida ma räägin natuke hiljem pilvetehnoloogia loengus ka. Et kõik need vajaduse sõendused lisaks on tähtsad hajussisteemide puul ka, mis transportiprotokollid on kasutuses, need samad procesid, mis jooksavad ja teevad läbi hajusarvutusi, et meil võib olla kogu hajussisteeme ehitatud riistvara ühendamise peale, kui me loome näiteks sellised jakatud mälusüsteeme või siis me teeme seda ainult procesid etasemel, et riistvara ei teha nagu teistest arvutus, sest pitte midagi ja procesid jagavad, saadavad sõnumeid üks teisele, et siis me teeme seda hajussarvutus ainult procesid etasemel. Et siis meil on hajussisteemis ölmede komponenteid vahel lihtsalt loogilni ühendus, et nemad teavad üksteese IP-aadresse näiteks ja võtad ühendust ja riistvara tasemel ei ole mingisugust hajussisteemi nagu ehitatud otsaselt. Iga suuristed hajussalvestusüsteemid ja annmebaasid, et me soovime hästi suurt mitralatsioonist annmebaas üles seada, kus me saame sadu terapeitte või petapeitte annmeid hoida, või me näiteks tekitame võrguketta oma virtuaalmasinete vahel, niimoodi, et üks kõik, mis proces kettale midagi salvestav, siis kohe teene proces näeb lihtsalt see neid samu file, et üks kõik, mis serveris nad asuvad, saavad päriteks ketta tasemel file, failide tasemel oma vahel nagu hannmeid jagada, et sellase meil, et ülevõrgu sõnumeid saata, siis toimub automaatne ketaste synkroniseerimine, siis filesisteemi tasemel hoopis. See ei ole küll kõige parem viis, kud as annmebaase luua, aga see on üks võimalus, kud as neid luua. Igasugus muud süsteemsed resursid, süsteemi teenused, lõimed, filei pidemed, valdkonna speciifised rakendused ja ka muud teenused. Üks kõige tähtsam muu teenus on just see sama viis, kui ta hajusalt töötavad serverid saavad oma vahel kella synkroniseerida, on siis Network Time protocol serverid, kus server saab minna küsida teise server käest, mis on praegu aeg. Aga see on väga keeruline probleem tegelikult. Okei, ma soovin kahe serveri vahele aega synkroniseerida. Nüüd need kaks serverid lähevad ja küsivad sama välise serveri käest aja. Aga kud as sinna saad olla kindel, et võttes arvesse internetilatentsust saabumise aja arvutamist ikkagi lokaalselt, et mõlemad serverid kolmanda osapoole päringute põhjal ikkagi synkroniseerida oma kella korrektselt, et kud as seda karanteeride saab. Ja kui täpne sellatentsust mõõtmin on? Ja siis on ka küsimus, kui täpne sul kella vaja saad on, et kui täpne, kas millisekonda on piisavalt täpne või mitte? Mõned sistemiid tänab ole kasutad ka nano sekondeid, näiteks InfluxDB default on nano sekondeid kui reaalselt ma ei tea miks, kui peamaselt ülevõrku ikkagi sinna annaid saadetaks. Haajussistemeid on ka erinead mudelid, kud as neid ehitada ja kasutada. Kõige lihtsam on klentserveri mudel, kus meil on mingi server ja meil on klent, kes seda servered kasutab ja võib-olla meil palju klente, kes seda servered kasutab. Muster on siis selline, et klent võtab ühendust serveriga, klendid kõik teavad, kus server asub, aks klendid võib-olla oma vahele teha, kes on teised klendid. Ja klent teab päringuserverile ja server vastab sellele ja server ongi ehitatud selleks, et teenindada mingisugud päringud, mis tulevad klentide käest. Ja klentie ei olema kasutaja, klent võib-olla lised rakendus, klent võib-olla front-endi rakendus, mis teie browserist töötab ja saadab päringud ülevõrku. Ja keerukamad hajussüsteemid saab klentserveri põhja lehitada niimoodi, et kõik klendid on ka serverid. Et sul ongi iga sõlim, kes selle saajussüsteemis osaleb, tema pakub mingis teenus serverina ja teised klendid ühendavad tema ka kui serverisse, aga see sama tarkora võib-olla ka klent teiste serverit vaatest, et võib ka tekida selline server-server mudel, kus kõik on klendid ja kõik on serverid. Meil võivad ole ka selt keerukamad mudelid, kus me kasutame hajus objekte, et pyütanis me tekitame objekti, mida meie kasutame, et võite kujutada ette kui klassi. Ja klassil on oma muut tõed, oma väärtused ja meie pyütan tarkvara saab küsida, mis on selle objekti hetke väärtus. Ja hästi lihtne programeerida, meil on lise klass, klassi objekt ja me küsime selle klassi objekti väärtust ja kutsume välja selle klassi objekti meetodeid. Aga see objekt ei asu meie serveris. See objekte asud tegelikult kusagil muujal pilves teised serveris ja lokaalselt me programeerime tarkvara, kui lihtsalt küsime, et mis on objekti väärtus, aga taustalt toimub objektide vahel synchroniseerimened. Kui mingis teised serveris see väärtus ära muudetakse, siis toimub synchroniseerimined, kõik teised serverid saavad ka teada, et se objekti klassi muutujate väärtus muutus ära. Ja kui meie lokaalselt muudam selle objekti väärtust ära, siis automaatselt synchroniseeritakse selle objekti olek ka teised serverides. Ja siis ei pea nagu mõtlema selle peale, et kus asub server, kelle ka ühendust võtan. Ma lihtsalt programeerin või kasutan selle objekti appid, et mingid meetodeid välja kutsuda, aga ma ei tarkvara kirjutades, ma ei tea, kus sa täpselt asub, ma ei pea mingite teiste serveride ka ühendust võtma. Ja kogu see klentserveri mudel või sõnumite saadmine või ülevõrgu ühenduse, peidetakse siinnago objekti sisse ära. See töötab sellise taustal. Et tema peamine eesmerk on peita ära klentserver mudel või anmedel synchroniseerimine, siis programeeria poolt käest ära, et programeeria ei pea selle ka enam tegelema. Hausobjektide sissemini implementatsioon oskab saanud synchroniseerida, siis on neid natuke lihtsam programeerida. Siis on pigem server-servered, kes omab seda objekti, see käitab sellegu objekti serverina ja teised klendid saavad seda objekti väärtusi muuta, arvatest, et ta on tagilikult lokaalne objekt, aga tagilikult on synchroniseeritud objekt, mis asub teoreetist kusagil muhev. Aga kõige selline tüüpilisem võib-olla rohkem selline klend-klend mudel on hajusarvutustse eriti teadusharvutustse ja kriid arvutustse on selline teadetele orjetne eritas suhtlus, et meil töötavad 16 prozessi soovid hajusarvutusi teha ja selleks et anmed jagad on nad saadaad üksteesele sõnumid. Põhimest peab-u nagu e-mail, et need anmed on nüüd teised ja sa tead, et process 2 tahab need anmed, et sa saadaad processile kahele sõnumi, et need anmed on muutunud. Aga tänapäeval pigem kasutatakse sellist lähenemist, kus meil ei ole nagu otsa teisele processile sõnumide saadmist, vaid kasutatakse selliseid loogilisi huvi grupe või selliseid postkaste. Et selle asemel, et saada sõnum processile 2, te saadate sõnumi postkastie, et näiteks, mis on maatriksite postkastie, saadate oma maatriksina postkastie ja siis üks kõik, mis teene process on huvitatud maatriksite väärtustest, nemad saad kuulad seda postkastia lugeada neid sõnumid. Kuna nende implementatsioon on natuke selline üldisemel lihtsam, siis see on nagu parem, kui otsaselt vaja teadmine, et ma pean saadma sõnumi processile 13, et te lihtsalt saadate sõnumi kuskil aadresil ja teised, kelle on sellele aadresil ligipääs, saavad nende sõnumidele ligi. See on ka esti palju tänaväl kasutuses mobiiltelefonide tarkkoras, et kui teie panete appid tööle oma telefonis, siis selle asemel, et appi ühendub kuhugi, serversi hakkab anmed pollima, ta teeb sellise, kuidas saadada, ta tellib anmedtele ligipääsot, et on huvitatud update sõnumidest või ta on huvitatud, selle kasutajale saabunud sõnumidest on huvitatud mingitest üldistest sõnumidest ja ta subscribeib või tellib teatud postkasti või teema ka seotud sõnumeid ja tekib nagu subscription kuskil serveris ja iga kord, kui anmed tekivad serveris, mis on seotud selle subscriptioniga, siis nad suunateks ja sinna ja siis suunateks seda siin kasutajale või sellele rakendusele, mis sallel telefonis jookseb, et selle asemel, et halatad, mis on need täpselt kliendid, kes hetkel on nagu kuskil jooksamas mingis telefonis, kasutatakse selliseid vahepealse nagu postkasti, et viska sinna sõnum ja see sõnum tuoks see kohales õigele kliendile, kas see kliend ise pollib need sealat või siis jääb kuula ma neid, et kõik need push notificationid ja tänapäeval need mustrid anmedte kohale, et toimetavise mustrid töötavadki sellist postkastide põhjal või sõnumite järekordade põhjal. Ja selle me ka mängime läbi, kas teises või kolmandas praktikumis. Ja suur anmedte töötluse puhul kasutatakse selliseid kuvitavad hajusobjekte, mis kui tavalsed hajusobjektid on ütlema, et ma kasutan hajusobjekti meetodid, et midagi väljakutsuda või mingi tanmed muuta ja see hajusobjekt võib asuda kusakli mujal, siis hajus anmestruktuuride korral on pigem meil nagu anmestruktuur, näiteks mis on list või mis on mingi matrix või mis on mingi tabel ja me ei tea, kus asuvad tabel erinevad read. Et meil on suur tabel, me saame teha mingi tarvutusi tabeli põhjal, aga iga tabelirida võib asuta erineva serveri peal. Et tegelikult nad tavalselt asuvad kõik blokkid enam, aga võite kujutada endale ettesest hiigel suurt hajusad tabelid ja need tabeli blokkid on jagatud täiesti erinevate serverite vahel, aga teie saate teha SQL päringud selle tabeli peal, saate tulemased kätte, aga te ei näe, et kus reaalisalt need anmed asuvad ja kuidas need päringud tegelikult läbi viakse. Et sa oled näiteda nagu Apache Spark RTD, mis on nagu pigem lihtsalt list, Apache Spark DataFrame, mis on nagu Python Pandas DataFrame või siis SQL tabel ja neid on väga saarnast hajusobjektidele, aga nad on nagu sisemiselta ära jagatud ja paraliseeritud. Sellised suuremad hajusobjektid põhimõttel. Ja neid väga palju kasutatakse sellised suurarvutustes ramistikes nagu Hadoop ja Spark ja Big Data anmed teed öödleks. Ja kuna ma ütlesinki, et tänapäeval on pea kõik asjad hajussusteemid, siis lihtsalt näid, et taval internet, World Wide Web minge postime lehekülele või Telfi lehekülele avage webi konsool. Vaadake, mis teile laetakse, kui te seda lehel refresh teate. Eriti hea, kui te seda esimes kord avate, siis ei ole käsitud midagi ja lugega, mitu päringud tehakse, kas Telfi või postime esi lehe laetimisel. Te näet, et neid on tõenest mingi sada või kaksada päringud tehakse taustal. Kõik neid pildid ja kõik neid sisu ära laadida. TNS, E-postid, kõik on hajussusteemid koha algust peale. Igasugust interaktiivselt suhtust programmid, võrgumängud, peer-to-peer võrgud, blockchain võrgud. Ja tänapäeval peab kõik infosusteemid ehitatakse sellist hajussusteemid. Meil on üks või rohkem anmebaasi sõlmeserverid. Meil tihti on back-end-appi konteeenerid või serverid ka palju, et saaks hakkama suure arvu klientidega. Nende ees on tavasalt mingisugune ümper suunaja või liiklusepalanseeria, kes siis otsustab, et millisele serverile päringud edasi saata ja klientide käestu ole västi palju päringud. Ja kogu süsteeme onki ehitatud niimoodi, et meil on ühel tasemel mitu replikaati teatud süsteemist, mis meil vaja on. Ja meil on mitud aset, et eraldada see loogika või arvutuste tegemise anmebaasi moodulist. Et need oida täiesti eraldi, et me võime kõik need appi konteeenerid ära tappa ja anmetega juhtu mitte midagi. Ja me saame suvaliselt muuta nende appi serverite või appi konteeenerid arvu vastavalt vajaduslad, kui palju meil on kasutajad hetkel kasutamads. Öösel võib-olla me jätame ainult ühe elu ja kesed päevavõib pühadajal võib-olla meil on sadatükki neid sadaserverid jookseb. Et selline lihtne mudel, kus on võimalik skaleerida. Ja kui meil on hästi palju anmeid, siis me ka skaleerime siin või vähemalt replitseerime selleks. Me saaksime teha ka samast SQL-anmebasist kolm koopjat saata anmete uuendamise päringud ainult ühtekoopjesse, et karanteerid, et kunagi anmed ei salvestata sama aegselt ei muudata ühtegi väärtust. Aga me saame kõik SQL-päringud, mis anmeid küsivad, ehkä ainult pärjivad, jagada siis kolmeseerver vahel ära, et kiirendada anmetel lukemise kiirust. Et seda tihti tehaksse Postgres puhul näiteks, et kiirendada anmetel lukemise kiirust. Ja, et sellise liul peab aksepteerima, et teil on selline English keeles eventual consistency, et ta on natukes aaja pärast korrekne. Ja see on täitsa okei rakendust jaaks näiteks mingisugune Messages Board või Facebook, et siin väga juhvite, et kui kasutavad, sa aru me ära muudab, et sinu annad koha samal sekondi seda muutust. Siin on oks on okei, kui see tuleb minuute aaja pärast või kahe sekondi pärast. Et sellistest systeemid on seda itse okei. Ja teiste, me nägem selest ka ühes loon, kus Pilvetenoloogia nende hajusannapaised juures, et kuidas siis karanteerida seda, et kui annmed muutetakse, et siis ükski järgmine lukemine ei anna enam vanu annmed. Ja paljemel aeg on. Natuke velan. Üks viimased teemad on siis tegelikult see on teine teema, üks teema on veel. Webiteenused. Mis siis on tänapall webiteenused? Ongi põhimised hajusüsteemid, mida saab suvalisest webiklendist välja kutsuda standartse protokolle standartse rakenduse kaudu. Põhimised kõiki webiteenused saab browserist välja kutsuda. Kül ketmetodeid peamiselt, aga saate ka postmetodeid teha. Tarkvara, mis pakub üle interete ligipäesu erinevatele, tarkvara teenustele ja resursitele läbi standartsete webiprotokollidega. Ehk põhimised tarkvara, mida saab kasutada täpselt sama protokolli kaudu, mida te kasutad teie browser. Ehk ongi standartne Http protokoll ja kui meie teeme mingi hajus rakenduse, me ehitame selles seliselt, et saaks sama Http protokolli kaudu seda kasutada ja ei piaks mingid erilisi protokolle välja mõtlema, et seda kasutada. Ja põhimõttelselt meil võitki olla mingi suure arvutus ja sama moodi, kui me näiteks postimees mingi lehekülj alla laeme või kuskil, ütleme foorumis, uue postituse tekitame, võime sama moodi tekitada uue hajus arvutuse, piltitöötlus arvutuse, siis sama protokolli kaudu. Ja siin ongi näiteks, et Google Translate teie lähete Google Translate lehele ja tõlgite midagi, aga samuti võib teie mobiilis olev rakendus kutsuda välja Google Translate veebiteenust selleks, et samamoodi tõlgimist välja kutsuda. Ja teie saate kirjutada Python rakenduse, mis samuti Google Translate kasutab selleks, et küsida Google Translate, et mis see eestikälne lausa on ingliskeeles. Ja tegelikult ei ole vahet, kas seda teie browser või teie Pythoni rakendused samat protokollite kasutusel ja täpselt samasuguse metodi saate saata sinna oma Python koodist, et ära automatiseerida see sama protsess, mida te teete webi browser ja webi lehekülj ja kaudu. Et see ongi suur osa need asju, mida teise teise browseri kaudu teha, saaks seda ära automatiseerida mingi skriptiga, et tehke sa samasi ära. Või siis piltide väiksemaks tegemise teenus või reditis sõnumikirjutamine, et samamoodi kui teelete rediti lehele ja kirjutad uue sõnumi, saaks seda lua Python skripti, mis kirjutab selle uue sõnumia ja saadab selle sinna. Põhimist sama apimetodi kaudu. Ja. Miks on webi teenuse tähtsad ongi see, et oleks lihtne luua rakendusi, mis oskavad üks teisi välja kutsuda, ükstese metodid välja kutsuda ja ei tekiks seda probleemi, et on meil hästi palju erine protokolle ja kui me loome rakenduse, mis soovib, kas Google Translate teha ja reditis see teises keeles midagi kirjutada, siis sellise tüütun rakenduse kirjutamine hästi lihtne, et kutsume välja Google Translate metod ja kutsume kõik. Kutsume välja Google Translate metod ja kutsume välja Reddit metod ja ongi skript olemas, et seda oleks hästi lihtne teha. Et siis üks peamine eesmärk ongi, et üks kõik, millist rakendusest oleks võimalik neid kasutada ilma, et me peaksime õppima erineva protokolle ja et meil rakendusest oleks sellised platformi neutraalsed, et meil peaks erinevate platformi teaks asju erineval tegema ja et oleks programeerimis keeles sõltumatud, et meil ei ole niimoodi, et tüütan näiteks tuetavüüste protokolli ja siis me ei saa teist programeerimis keelt kasutada, et kui meil ongi selline standaartne hea protokoll nende haussisteemide veepi teenuste metodite väljakutsumiseks, siis on seda võimalik teha üks kõik, mis programeerimis keelest ja üks kõik, mis viisil. On ka sellised standaardid, mis kirjaldavad ära, kuidas need veepi teenuseid kasutada, niimoodi, et oleks nad arvuti loetavad, et oleks võimalik automaatselt genererida tarkk vara ja mis oskaks kohes neid teenused kasutada, et ei peaks olema ainult programeeria, kes läheb ja vaatab, millis need metodit on ja käsitsi programeerib midagi, vaid oleks võimalik ka seda programeerimist ja protokolliit, et kasutamist ära automatiseerida. Siis ajal olised on kasutusel olnud selline asi nagu VSTL enne selliste Http ja Rest Appi populaarseks saamist. Tänapäeval seda kasutatakse ka näiteks Eesti XT puhul päris palju, kun ajal olised seda kasutust on, mis kasutab sellist, kus kasutatakse peamist sellist SILP-protokolli, kus kasutatakse XML sõnumide struktuuri, mis on natuke keerulisem. Aga tänapäeval on palju populaarsem Http protokoll ja selleks on standaard, mille nimena Open Appi, mida me siis ka. Neid standaardeid me vaatame öhes loengus ja on praegu toonlist ühe näiteks Http protokolli kohta. Kes ei tea, mis on Http? Te kõik olete Http'ed mingis ainees kasutan näinud. Http onki selline hästi lihtne viis, kuidas veebis alla tõmata resursse muuta, resursse pärida. Resurs võib olla siis veebileht, resurs võib olla mingi pilt, resurs on põhimõtteliselt mingi tüübi dokument, aga ta võib olla ka tegelikult mingisugune metod, mille välja kutsume. Http on suhvõi vähe operatsioone, mida saab käivitada. On ket mingi resursi alla tõmbamiseks, put resursi loomiseks või muutmiseks, post uue sellise resursi või alam resursi loomist, et näiteks post uus sõnum, post uus image, post uus kasutaja, et uue resursi loomine ja te liitad siis resursi kustutumine. Ja kasutadaks sellist server klientläheneemist, et meil on server, server juba mingisuguna aadress, mis serverid teatud tüübi resurssa, näiteks pildid või HTML-leht või mingisugune üldine resurs ja ketiga saame seda arvussursse alla tõmata putiga muuta, postiga uue luua ja teletiga kustutada. On ka mõned teised metodid, mis on kasutuses, nendest ma räägin siis appi loengus natukka rohkem, aga see ongi sinna lihtne lähemine. Ja tegelikult, kui on ainult nelja metodid, mida kasutada, siis on suhtseb lihtne teada, kuidas tarkora looa, mis oskap need resursse kasutada. Ja see resurs võib tegelikult olla ka midagi natuke abstraksemat, näiteks mingisugune funksionaalsus meie hajussusteemis, et me soovime uut arvutus, vana arvutuses staatust vaadata, siis me saame teha ketpäringu selle arvutuse aadressil, arvutuse aadress võib olla näiteks mingisugune slash arvutuse, slash 617, et see on 617 arvutus ja ketpäringu ka me saame alla tõmbama alla info selle arvutuse kohtad, et arvutuse kohtad, kas arvutus on tehtud, kas arvutus on veel tegemisel, kas arvutus on järjekorras, et ei pea olema nagu selline nii-mell ta ette kujutada füüsiline resurs, võib olla ka selline loogiline või virtuaalne resurs, et mingisugune arvutus, mis kusagel käib, ta võib olla mingisugune kasutaja, et me ketiga saame tõmbama alla selle kasutajainfaaanmebasist. Putiga loome uue kasutaja, postiga muudame kasutajanmed ja te liidiga kustutama kasutajära, et see võib olla üks kõik, mis anmebasiresurs või veebiresurs nagu pilt. Ma rääkin sellest natuke ühes teises loengus, selle vahe on see, et kui meil on näiteks kasutate list, siis uue kasutale listi alla uue kasutaloomine, aga siis me ei saa anmed muuta, siis me kasutame putti olemas oleve kasutaja aadressi peale, et näiteks user slash 312, et saata uued anmed selle kasutajakohta, et ta ümber muuta. Aga teatud olukurras võib ka putti kasutada loomiseks, aga on loodud ka selline natuke täpsem spesifikatsioon või standaarde, et kuidas HTTB-t natuke selgemine kasutada, et mis on lubatud, mis ei ole ja see on restful, mis on põhimselt täpselt sama appi ja protokollis HTTB, aga ta paneme natuke rohkem regleid selle peal, et mida sa võid kasutada, mida ei või kasutada ja ma rääkin sellest ühes järgnevas loengus. Ja siis viimane teema, millest ma tahtsin rääkida, on pilvetehnoloogia, et kui meil on nüüd võimalus luua listasti hajussusteeme webi teenuseid, siis kuhu me paneme nad üles, ne oma hajussusteeme webi teenused, kas me paneme oma server üles siin ülikooli või oma start-up kontari nurgas, või vähem tegelikult taaksime, et oleks lihtsam resurssede hankimist teha, et kui meil öösel või sellel nädalal on ainult 13 klienti, kes meie start-up rakendus kasutavad, mis juhtub siis, kui järgmine kuul meie start-up saab hästi populaarseks ja meil tuleb 10 000 kasutajad, kas me, kui palju meil võtab aega uute serverid ostmine ja kohale toimetamines, ülest panemine, tarkkura sinna instaleerimined, see kõik on nagu aega nõudu tegevus. Palju lihtsamalas, kui me saaksime küsida, et antke meile 10 serverit ja me saaksime ligi pääsu kahe minutikane 10-le serverile ja saaksime oma rakendus sinna instaleerida käima panna, et saaks nagu kiiresti arvutusresursse teile ligi pääsu. Pilvetehnoloogi ongi see idee, mis on täikest kui hästi vana idee aastast 1969, et miks mitte pakkuda arvutusresursse täpselt samamoodi kui elektrit või vett või teore järgmobiiliteenust, mis tegelikult enam ei ole väga selline utiliit-teenus. Me kasutame arvutusresursse ja kuhul lõpus me saame arve selle põhjal, kui palju me mälu kasutasime, kui palju me ketta ruumi kasutasime, kui palju me prozessori aega ära kasutasime ja kuhul lõpus saadab keegi meile arvet, et nii palju peate maksma selle eest. Ja me ei pea selle peale ette mõtlema ja me ei pea ostma arvuteid, servereid ja neid ülesseadma, vaid me saame need lihtsalt kasutamakata ja meil on selline lõpmatute resursside illusioon, et kui ühe aasta pärast on meil 3 miljonid kasutad, siis meil ei oleks vaja nagu liiga palju tööt selleks teha, et võib-olla sadakorda või tuhadkorda või kymmetuhadkordas kaleerida oma resursside vajadust. Ja tihti pilvetehnoloogikaud on võimalik saada ilma ette maksuta arvutusresursse, tihti isegi tasuta, et kui teile on oma start-up, saate minna näiteks Azuresse või Google App Engine või Amazon pilve ja panna mingi prototüp üles ja see ei lähe mitte midagi teile maksma. See hakkab teile maksma siis, kui reaaliselt kasutad, aga teie rakad just kasutama, et testimise ajal või prototüpimise ajal ei prugis üldse mitte midagi kasutada, sest tihti on pilvedes selline päevased või kuused, koutad või märad, et kui te nendest märadest üle ei lähe, siis te ei pea midagi maksma. Et sellised vabatasemad, et alla selle jäädes, et kui ei kasuta piisavalt ketta ruumi, siis ei pea maksma, kui ei kasuta piisavalt interneti, broadbandi, armet allatõmbamise, siis ei pea midagi maksma, aga kui lähete nendest piiridesest üles, hakkab te maksma ja võite päris palju maksma hakkata. Pilved on muutunud ideaaliseks teenuseks selleks, et majutada veepirakendusi, kus teid kasutavad võib tulla üle maailma, et te ei tead, et kõik kasutavad on Eestist, ja te ei tead, nende kasutad arvu ette ära. Et saate lihtsalt elastselt oma rakenduste ülesseada, nii Eestis, no Eestis väga eestis te ei saagi, nii Saksamal, Soomes, Iiris, Amerikas ja siis ka Australias näiteks, et saate täpselt sama rakenduse lihtsalt ülesseada, et muudate läbi apikaudu mõned parametrid ära ja panaks sa teile konteeenerid ka Australiast öelda. Pilved tehnoloogis on mitu sellist mudelid, kõige klassikalis ja mülevaade on, et meil on selline tarkvaratenusena mudel, softwarase servis, kus lõp kasutavad teie rakendust üle browseri ja ei näe midagi nendest serveritest, ei päa midagi tegema, logijad lisse browseri kaudu sisse või tead uue kontoo ja hakkad seda kasutama. Tänapäeval peab kõigist tarkvarast on ka tarkvaratenusena versioon olemas, alates Wordis kasutatud Office 365i, kasutatud Slacki või te Slacki läbi browseri kasutada, kasutatud suulipid või te läbi browseri suulipid kasutada, kasutatud Zoomi või te läbi browseri Zoomi kasutada, et tänapäeval ongi tehtud väga paljudes tarkvarades ka see veebiversioon, et saaks läbi browseri seda lihtsalt kasutada. Pil pakub sellist kahte peamist mudelid, et luua tarkvaratenuseid. Esimene on seline riistvaratenusena või infrastruktuurtenusena, kus teile antakse ligipääs virtuaalmasinatele, et saate minna Amazonist küsida, antke mulle ligipääs 25 suurelle virtuaalmasinale, te saate ülevõrgun nendale ligi, saate kahe minutiga 25 virtuaalmasinat üles, saate üle SSH nendale ligi ja saate neid halda makata ja saate täielik kontrolli nende virtuaalmasinate üle, et saate valida operatsioonisüsteemia, et kasutada makata. Aga selleks on teil vaja siis võibolla selliseid operaatoreid, kes oskavad virtuaalmasinat halata, et võibolla teie start-up ei taha halata virtuaalmasinad, taab lihtsalt oma pyütun rakendust ülespanna. Selleks pakutakse erine platforme rakenduste jaoks, et kui te ei taha tegeleda madalataseme infrastruktuuriga, te tahate lihtsalt, et minu pyüt on rakendusjookseks kusagil, tahate seda esti lihtsalt iskaleerida, tahate, et see efektiivselt jookseb niimoodi on karanteeritud, et kui kasutatav arv 10 korda tõuseb, siis 10 korda rohkem resursse kasutatakse, et kõigil kasutatel on kasutusmugavus enamen sarnane, et siis saab kasutada sellist platforme teenusena, kus pakutakse teile näiteks võimalust, et linkige oma hithaa repositoorium, kui seal on rakendus, millel on veebiserver küljes, näiteks, kas ta on Flask veebiraamistik, kas ta on Vue veebiraamistik, kas ta on Vue, oma pigem mitte, pigem mingi server rakendus, kas ta on mingi sugun fast API rakendus või Java Spring rakendus, et siis pilve platform valmistab ette teile keskonna, mis oskaab neid rakendus jooksutada, skaleerida, halata niimoodi, et ta isegi tõmbab ise sellest hithaap repositoorium starkvar alla, paneb üles, kuski konteinerist panab tööle, teie sate linki, et teie rakendus osub seal jonki tööl. Ja saate konfigureerida, et mis on maksimum konteineritarm, mida te lubate igaks juhuks, et üle eelorvii läheks, ja siis pilva hakkab teil ka seda automaatsa, et skaleerima. Ja kui te loote oma rakendus oma serverite peal, siis te peate ise haldama serverid ostma, haldama võrku, salvestusmahtu, virtualiseerimist, kui te soovid ikkagi virtualiseerimist kasutada, peate ise instaleerima operatsioonisisteemid mingisugust vahepealsed tarkkorad näiteks, kas seata üles püütun 3,9 või püütun 3,12 keskonna, siis oma anmed ja oma rakenduse, kui te pilvekäest võtate infrastruktuuriteenusena, siis pilve teenuspakuja hoolitseb võrku eest, hoolitseb ketasteest, hoolitseb servereteest, hoolitseb virtualiseerimist, et ei saate võibolla valida operatsioonisisteemi, et ma tahan Centos virtualmasinaid, ma tahan U. virtualmasinaid, mis iganes Linux või Windows, veel Windows on ka toetatud, et mis iganes operatsioonisisteemi tahate. Aga ise peate haldama siis operatsioonisisteemi sisu, et näiteks, kui mingisuguses paketis, mida te instaleerite tekib mingi turva viga, siis teie olete vastutav selle eest, et õige laajalne uuendaks ära, et pilve teenuspakuja ei lähe teie virtuaalmasina sisse ja ei hakkak mingit pakete või tarkkora välja vahetama, kui on mingi turva probleemit, võibolla nad panate virtuaalmasin kinni opis. Aga siis te halad ise operatsioonisisteemi, mingisuguses vahevarasid näiteks Python keskondi ja siis on samut, et kui mingi Python teek ei ole turvaline, siis olete teie selle üle vastutav. Aga kui te kasutad näiteks platformi teenusena, selleks võib olla näiteks Google App Engine või Azure App Service või siis Amazonis on see Beanstalk Service näiteks, et siis teie ainult annate anmed info ja rakendusinfod näiteks, mis anmebaaside kasutate ja kus on rakenduse kood ja pilve teenuspakuja siis ise huolitsab nende keskondode eest ja operatsioonisisteemi eest ja nii edasi. Ja lõpuks loote, tarkvarateenus on rakenduse, kus kasutad enam ei tee mitagi. Ja siin see vahe ongi, et palju teil kontrolli on, et mida te tahad ise kontrollida, kas te tahad, eest Riisvara kontrollida, kas te tahad operatsioonisisteemi kontrollida ja keskonda kontrollida, või te annate nagu kõik need haldus ära pilve teenuspakuja le, annate ainult oma koodi ja võib-olla kirjeldata natuke, et kudas see koot peaks jooksma ja kui palju tead, et ka leidete saaks. Ja need vaatame ka siis aina raames läbi ja teete praktikumide raames läbi, et seda, no, enda arvutes võib-olla midagi seata üles, aga pilve kontekstis vaatame nii infrastruktuuriteenuse nagu iga platformiteenuse meile. Ja siis tänapäeval ongi, et pilve ja teenuseb muutunud nagu, te saate kõike teenusena pilvest küsida või teenusest kasutada alates mingite standme baasidest, webi mängude taustasysteemidest, et näiteks webi mängude multiplayer osa pakutakse amas, onist täiesti teenusena, et saate nende mingisugust gaming enginei kasutada niimoodi, et te piha seda ehitama. Firma võib, et näiteks blockchaini teenust võtta pilve teenuse pakuja käest niimoodi, et nad ise ei piha oma blockchain node, et serverite nüleseadma või et lihtsalt amas laanab neile need. Ma asinin õpet, et kui teenuse, nad pakutakse hästi palju tänapäeval, aga igasugust ka kolmde keskkonad näiteks, et te tahate ehitata uue roboti, targvara tahate testida seda robotid väga erineates ruumikonfiguratsioonides, et kas robot saab hakkama mööbli vahel liikumisega ja Amazonis on teenus, mis genererit teile 1000 erineat toak kolmde konfiguratsiooni ja panatate targvara jooksma, et saate tagas, et mitmes tuhandest ruumiste ja robot sai ilma millegile otsasõitmata hakkama. Et on selline teenus lihtsalt, eksist eerib. Igasugust media videoedastust teenused, et näiteks teete video striimi, mist ei soovi ühtegi video striimi, mis platformi kasutada, tahate oma mingisuguse firmale seda teha ja tahate sinna striimi automaalsit injektida mingil reklaame, eksist eerib selleks teenus. Igaid muud väga palju, mida oskate ette kuutata, eksist eerib Amazonis pilve teenus. Näiteks teil on tehas liin, lahedle ka pudelid või midagi muud, mida luakse. Te soovite masinõppe abil tuvastad ära, et misugust tal pudelid on tefektid, siis eksist eerib masinõppe teenus, mis saate töölepanna kaamere striimiga, nii et striimiteks anma, et vist pilve. Teenus vastab teile aja stambi abil vist, et misugune pudel näeb teistmoodi välja, kui teised pudelid, võib-olla selleks mingit efekt. See on valmis teenus selleks, et ära tuvastada natuke teistmoodi välja nägevaid asju, mida toodetakse tehas. Ongi teemat läbi, kõik need kolm teemat, ma räägin rohkem lahtikus näidetega järgmestes loengutes. Tänal idea olik, et ma natuke lihtsalt tutustan, mis sinna aine olema hakkab. See nädal praktikum ei ole, järgmest nädal räägime siis hajussüsteemide loomisest, programeerimisest ja lõimedest ja siis toimub lõimeda põhine praktika. Ja räägime siis natuke mitmelõimeliste rakendastaloomisest pyütonis. Ja miks pyüton on natuke halb nende jaoks, sest tegelikult pyütoni tava lõimeda ei ole üldse paralelisad. Ja järgmestes loengus räägime natuke rohkem hajussüsteemide omadustest, et praegu see või seada liikara, kui selleks kiireks ja lühidaks. Aga siis järgmest kord räägin täpselmalt äneed omadused lahti natuke rohkem nende hajussüsteemide kohta. Eest ka mitmelõimeliste programeerimise loomise kohta. Ja mingi hetk järgmestel nädal on ma lisan teid ka suulippisse, kutsun teid, kui te ei ole juba liikmed. Ja siis selle ka odu saab hakkata ka suhtlema väljaspol praktikumia loengu aega, et saate suulippis abi küsida, kui millegi hakkama ei saa või hättajäete.

---------Loeng 2 - Hajusssteemide omadused.txt--------

 Aga alustame siis pihta tere tulemast teise loengus hajussüsteemide ja webi teenuste arjandusainest, kus ma mõnikord ja vaheta niid järekordasid. Aga täna on siis teine loengus me jätkame hajussüsteemide teemaga, et räägime hajussüsteemide omadustest ja natukka räägime lõimedest, kuna praktikum on konkreetselt lõimede programeerimisega seotud. Ma enne nädal juba natukka alustasin seda teemat, et räägisin teile, mis asjad on hajussüsteemid ja mis on nende omadused. Räägisin natukka hajussüsteemide ja tüüpidest ja näidetest ja ma korraks näitan näid veelkord ja käime natukene detailsemalt sisse selle loengu jooksul üle, et räägime natukene hajussüsteemide kõige tähtsamad omadused, et see võib natukene liiga abstraksseks võib-olla jäeda, aga sellega aine raames näites, kui ma hakkame iljem tegelema pilve, tehnoloogijaga ja pilveplatformidega, siis tegelikult on hea teada neid baasomadusi hajussüsteemidel ka, sest pilved ongi ühed suured hajussüsteemid. Ja räägime siis natukene mitme löömeliste protsessidest ja lõimedest üldiselt teises loengu osas ja põhimõtteliselt, kui te olete seda teemat kattud näiteks operatsioonisüsteemides või Java programeerimise aine samuti, et kui tas Java lõimi programeerida, siis see on suhtelat sarnaane protsess või suhtelat sarnaane teema ka siin. Hajussüsteemid, hajussüsteeme on hästi erinevaid. Tänapäeval, nagu meil minna loeng mainisin, võib väga paljusid rakendusjuvi käsitleda, kui hajussüsteeme. Tavalsed veebirakendusad on üles ehtatud sellised mitme kihilisena, et meil on mingit kliendi päringud sisse tulas meie süsteemi. Sisteemi ees on tavaliselt mingisugune päringute ja autor lüüs, mis jagab sisse tulnud päringud siis kas erinevate regionide vahel ära ja ühe regionisest erinevate serverite vahel ära, et hajutada neid kasutada päringud ja saada hakkama rohkemate kasutada päringude töötledmisega, kui üks server suudab hakkama saada. Siin tavalsed on selline back-end-tyüpi serverid, mis võtavad vastu näiteks Http päringud ja siis vastavad kasutavad päringutele. Ja tihti, kui tegemist on rakendustegmis, mis hoiavad mingit enamisandmed, siis need serverid omakorda siis ühen tuuvad kuskil anmebaasi ja need anmebaasid on tavaliselt eraldi serverit tään ülesseatud, et tekibki kohe selline loomulik hajussusteem, mis võib-olla back-end serverid omavahel ei ühendusti võtada, nad ei suhtel omavahel, nii et nad on pigem nagu selline suur süsteem eraltatud kihtidesse, et igal kihil on oma roil ja sest selle kihi seees replitseeritud, et saaks skaleerida, kui palju serverid tegelev siis ühe ülesandega. Ja kui anmed te mahtunud ohut, siis on vajaga hajutada rohkem seda anmebaasid, et tekitada seda hajus anmebaase, et näiteks seada üles mitu lugemiskoopjad Postgres anmebaasis, niimoodi, et me saame anmed lugeda siis näiteks kolmest serveriks korraga ja nende anmed lugemine hajutada siis kõigi rakendusserverite või back-end koopjate vahel ära, et nad, et anmebaas ise oleks selline pudelik ael. Aga see on omakorda suustelt keeruline tema ja ma räägin sellest võib-olla hiljem. Võib-olla ka tark kodu, kus on igasugused sensorid mingisugused mikrokontrollerid, mingisugused aktuaatorit näiteks, mis teevad uukseluku lahti või mis akna teevad lahti või muudavad kütte võimsust. Need on omakorda mingisuguses lokaalses võrgus, kes suhtelad omal ja nende koostööd võib ka vaadata, kui hajussüsteeme, et saate defineerida, et kui on liikumist selles ruumis, siis lüüdita lamp sisse. Et sellist asju võib sisse ehitada lampi Ristvarasse tarkkars. Ongi lamp ja lampi sees on kohe sensor, mis tuvastab liikumist ja paned tööle lampi, et sellist süsteemi ei oleks hajussüsteem, kuna kõik on ühes Ristvallas sees, ühes rakenduses sees. Aga kui meil on liikumist sensor seinapel ja lamp on siin ja nemad pead ülevõrgu oma vahel rääkima mingi protokolli kasutades ja oma vahel suhtlema, siis on see rohkem juba hajussüsteemi mood ja kui terve maja või korrus või korter on ühendatud niimoodi. Siis on kategoriu juba sellise mikrokontrollerite või väikest arvutete põhise hajussüsteemiga. Ja ma elm, kui träeksin ka näedast igasugust arvutuskriidides, kus võib olla. Siit on natuke raska näedata. Võib olla nagu mitu ülikooli, kellel on oma sellised arvutus klastrid nagu meie ülikoolil ja nad on ülevõrgu ühendatud ja kui meil on teadlased näiteks, võib olla. Teadlased näiteks või tudenkit, kes soovad suuremoodi arvutadesi teha, kui ülikooli arvutuskeskus lubab, siis saab ühendata sellised lokaalsed klastrid globaalsesse kriidi niimoodi, et saab töid saata siis mitme ülikooli arvutuskeskustesse sama aegselt ja kokuda kokuned tulemused paljudes tasukohtubest. Sellised ülevõrgu ühendatavad, kül lokaalsed asuvad klastrid, aga globaalsed ühendatakse ja see tekitab isegi mitme tasemelise hajussüsteemist. Lokaalselt võib-eva, et neid serverid olla ühendatud hajussüsteeme, aga siis näud on nagu ka üle interneti ühendatud siis suuremaks hajussüsteemiks, kus on väiksemat hajussüsteeminik koondamine suuremaks hajussüsteemiks. Ja kõik pilveplatformid on saa-moodi hajussüsteemid, kui teie saate logida sisse näiteks Amazoni webi lehel ja saate sealt kaudu akata põhimõttel küsima endale virtuaalmasinad, siis seal taustal toimub väga palju erinevaid tegevusi. Alate sellest, et luuaks virtuaalmasin, luuaks kuski mujal näiteks webi ketas, ühendatakse see webi ketas virtuaalmasin, aga mis jooksad teises serveris ja konfigureeriteks see kõik keskond ümber selle, et teie tegelikult ei näegi, mis seal taga on. Ja tänapäeval tava kasutad ei näegi. Teie näed ainult seda, et on mingi load balanceri IP-adress ja hostname, aga teie ei näegi, mis seal taga on, kas on üks server, kas on 10 serverid, kas on 100 serverid ja veel vähem näete anmebaasi. Teatud olukordadest võite näha, et te näete erinevata serverid IP-adresse, aga tihtise peidetakse täiest ära. Ja see koormuseaotur, kas seda saab teha väga mitmel tasemel, alate sellest, et Eestist teie küsite, kus asub Facebook, et lähete Facebooki adressile ja TNS vastab teile, mis on selle Facebook-adressile vastav IP-adress. Ja see, millist IP-adressi teile näidata, seda saab TNS tasemel konfigureerida, niimoodi et Eestist tuleolla päringulle näedataks näiteks, ma ei tea, Soomes asuva anme keskus IP-adressi, Saksamalt tuleolla päringul Saksamaanme keskus IP-adressi, et saab juba TNS päringud tasemel jaotada päringud erinata anme keskuste vahel. Enne, kui need teie päring üldseühtik alme keskusesse jõuab, et ka sellist TNS-i tasemel saab jaotada, et kuhu tegelikult liiklus üldse saadatakse. Ja sellisel juhul Facebook'il peab olema erine oma servered siis kõigis nendes anme keskustes. Väga palju põhjusõidav, miks on vaja hajussüsteeme alates sellest, et arvutusresursside koonamina on efektiivsem. Ja see on üks motivatsioon ka pilve arvutuste puhul, et kui iga asutus seab üles endale oma serverid oma kontoris, siis nendel on täis kontroll nende serverid üle, aga kui need kasutad pilve, siis on suur firma, kes hoolitseb suurte arvu Ristvararresurssidest. Ja see on mõnes mõttes efektiivsem ka selletõttu, et siis peab olema ühes asutuses võib-olla suur tiim, inimesi, kes need haldavad neid servered. Aga ka elektrikasutuse mõttes on näiteks efektiivsem jooksutada ühte suurt serverid ja kasutada seda maksimaalselt ära, et sellisil juhul ühe suure serveri elektrikasutus on tõenalselt palju väiksem, kui nüüd 25 väiksema serveri jooksutamine, kelle kõigil on vaja jooksutada siis kõiki Ristvarat, niimoodi Ristvarakoondamine iseenest on juba efektiivsem. Ja anmeti arvutus võib-susud laialjäägamine ka, et arvut saa moodi, et tegelikult kui me koondame ühtekohta, sest see üks koht võib ka natukene problemaatilseks muutuda, sest kui midagi juhtub selle lokaalse võrguga seal, siis meie ei saa kõik kasutad, kes seda ühte serverid kasutavad, siis nende ühendus kaub ära või nad ei saas kasutada, kui selle server kokku jooksud. Siit tegelikult saa moodi koondamine on hea, aga koondamine ainult ühtekohta, mis võib katki minna, ei ole ka kõige paremini, et tegelikult on saa moodi hea, kui need koondatud asukohti on palju ja nad on geografiliselt ära jagatud, niimoodi, et Eesti kasutajad saavad rakendusi kasutada niimoodi, et rakendusid jooksevad Soome, Anme keskuses ja Saksamalt tarid kasutajad saavad kiiresti parema kasutusmugause, kui need hajussistemi komponidi, mida nemad kasutavad, on nendele lähemal, et kui see hajussisteem ise on jagatud sellisteks erinevateks regioonideks, mida saab kasutada, siis lähemal olev kasutajad saavad võib-al sellest kasvu, kui nad ei pea väga kaukel ühenduma. Ja see on põhimustat samamist ees centraliseeritus, et ei oleks olukorda, et kõik Annmed oleks ühes kohas, et kui midagi juhtub, siis Annmed läks kaduma. Eesti ka tegis selle tõttu, ma tegin mitku palju aastat tagasi otsus, et võik Eesti riigi teenused võiksid olla hajutatult ülemaailma, sellase, et natura ainult nagu tegis Tallinnas, et kui keegi ründab Eestit, et siis Eesti riigi teenused jätkuks isegi, et selline konsultatsioonide. Ma isegi unustan ära, mis see täpne Annagas on. Kui meil on konsulaadid välismaal, siis panna konsulaatidesse ka Annmekeskust, väikse Annmekeskused, et saaks hajutatud riigi teenused näedevaale. See päris kunagi nagu käipele ei läinud, aga tehaks ikkagi seda, et meil oleks mitu Annmekeskust, Eesti riigi pilv näiteks ehitati ka kuskil kaheks aastat tagasi. Ja algus oli selle üks Annmekeskust, nüüd on selle kaks Annmekeskust ja tegelikult oleks hea luuga üks Annmekeskust, mis on täitsa Eestist väljas pool, et oleks selline Eesti riigi pilv, kus Annmed oleks ka alles, siis kui Eesti Annmekeskustega midagi juhtub. Resursside kaug kasutus on tähtis, et meil on kaks annemäärg, Resursside kaug kasutus on tähtis, et ei oleks ainult see, et sa saada ainult samast kontorist Annmetelil ligi, vaid saaks üle internet üks kõik kust vajatus on, et rakendusi kasutada. Ja väga tähts on jõudlus, haujusüsteemide see on suhtselt lihtne skaleerida, sest kui meil on monoliitne rakendus, kuidas te resurssijuurde panete. Tavaliselt teete suurema serveri ostat ja panet liigutat oma rakenduse suuremase serverisse. Pilvesmonoliitsele rakenduse saab võib-olla dynaamiliselt suurema virtuaalmasina anda, aga sellised haujusüsteeme, kuna ta on ehitatud niimoodi, et teil on palju komponente, siis sellise veebi haujusüsteemi puhul on lihtne rakendusserverid lihtsalt juurda panna. Öösel näiteks kasutajate ole, panema end ühe app-serveris ja päeval võib siin näiteks viis olla ja nagu pühad ajal, jõulud ajal näiteks meil võib-olla on hästi palju kasutajad ja siis meil võib 25 serverid seal olema. Et see suhtselt lihtne on skaleerida haujusüsteeme, mis onki ehitatud selleks, et seal oleks sellised haujusad komponente ja see natukene suunab sellele pool, et sellised komponente lihtsam lisada ja emaldada, kui hakkata ühtemonellise tarkkora skaleerima. Ja tõrkke taluvus on ka, et kui meil on haujusüsteemis koosad paljudes komponentidest, siis võib-olla ühe komponenti koku jooksmine, mis jooksab ühes serveris, ei mõjuta kogu süsteemi eriti, kui meil on teenused replitseritud, et teenustest ei ole ainult üks koopja kusagil serverisvaid, näitas võib-olla jooksab mitu koopjat ja siis samuti on nagu sisse tulevad sonumid või päringud, nende kolme serveri vahle ära jagatud, siis ühe serveri koku jooksmine ei mõjuta kogu rakenduse tööd. Et mida rohkem on komponenteja, kui need komponenteid on niimoodi kooperitult ülesseatud, niimoodi et kolm koopjat näiteks jooksab erinate serveride peal, siis kahe serveri koku jooksmine tähendab, et meil vähemalt üks koopja neid veel ales. Teatud olukordades ei saa, on vaelik rohkem, kui pooltekoopjate alles jäämist on, selliste hajus algoritmida puhul, kus on vaja, et omaval hajusalt töötavad komponentid valiksid endale näiteks suure pealiku või et sellise lühul on tegelikult vaja, et alles jääks üle poole komponentide, niit kui meil on ainult kolm replikat mingist teenusest, kes oma vahel pealiku valivad, siis on tähtis, et kaks jääksid elu, et kogu süsteeme elu jääks. Aga siis saab näiteks viis jääda üles ja siis on vajad viis-kolm jääks elu. Aga et kui meil on palju erineid komponente, siis võib-olla selles kohaselt ei tekise Törkketaluvus, meil on vaja, et need komponentid oleksid replitseeritud, et samades komponentides tolguse logimisesüsteem või ANME-bass või mingisugused rakendusserverid, et meil onks ka vajad, et oleks replitseeritud, aga häius-süsteemidiga on seda tihti parem võimalik tagata kui monoliitsüsteemidiga. So, ümane-bass jäädud, et viis jääda maha, aga võib-olla sellest rakendusserid, maha ei ole tanda vahel jääda üle, et meil on tohtomasti sühen takas uur, et neid soomeid mulle on, et Euroopa see on ükslades vahel, Amerikas on siis viis teist, ja Asjas on siis neljub, Euroopa jääse ma teist vahe, aga mul sens tõet, et Euroopa on üle asja, kui sa ei või ta, et Iitma ja Sallvea. Sellise liuhtudele on võimalik teha ka ümper suunamisi tene stasemel, et sul reaalselt sul ei suunata kui sinu Tarkvarav, Riisvarav ja sinu arvuti klienti arvut, et näitek laptop teeb päringu, et kus asub see hostname, ja TNS ei leiagi ühtegi serverit, mis sellele vastab, või vähemalt on eelmised päringu terrorid saanud, siis ta võib switchida ümber täiesti teise regioni ja hakkata siin suunamaasjasse, et see on ka võimalik. Aga ka see on tegelikult problemaatilne eriti Amerikas, meil on näiteks olnud, et inimesi läheb Amerikasse konverentsile, ja proovivad Tartu ülikoliserverit ligi pääsada ja ei saa, et jutee.ee ei vasta. Ja mis siis juhtus ongi see, et tegelikult on internet ei ole nii ühendatud üheks internetiks, kui ette kujutada võiks. Reaalselt on tegelikult mitu paraleliselt võrku ja teatad võrkudes ruutimine Amerikast Eestisse ei töötagi, kui vahepeal ei ole cashi loodud ja on vajalik tegelikult näiteks Googlei, Fiber võrkust ümper suunata välis interneti ja ümper suunata Eestisse ja esimest päringu teid prugigi töötada kuni mingisugust vahepealsed. Ma räägin sellest ka natuke ilisemata slaidides, aga võib juhtuda, et täiesti normaalne päring ei saagi vastus, kuna TNS ei oska suunata õigessa kohta ja esimest päringu teid töötagi. Ja, aga esimest päringud võib täitsa fählida, kui ruutereid ei oskagi ruutida orekstsas kohtad. Ühe definitsioonina on hajussusteeem autonoomset arutas elementida kogum, mis paistab kasutale ühe situsa süsteemina. Ta ei ole suvalist arutas elementide kogum, vaid on autonoomsete niimoodi, et need komponentid, mis on neil on, on suhteliselt sõltumadad üksteisest, et nad ei prugigi tegelikult väga teada, mis on teised komponentid ja kudas teised komponentid töötavad. Ehk autonoomsed arutas elementid Eesti keeles võib neid nimetatakse sõlmedeks, Ingliskeles tihti nimetatakse näitek snoodideks. Mis võivad need arutas elementid või sõlmed olla? Nad võivad lihtsalt olla serverid või arutid, kriistvara kusakil, mis oskab jooksutada tarkkura. Nad võivad olla ka processid, et nad ei pea konkreestalt olema terve arvuti, kes on hajussüsteemi osa, vaid selle arvutis jookse üks process on selle arvut või selle hajussüsteemi osa ilma, et server arvuti nagu üldiselt oleks. Teised tarkkura teenuse, mis jooksevad näiteks TNS teenus kusakil jooksevad kolla arvutus serveri osa või mida arvutis serveri või hajussüsteemi osa. Serverid arvutid eriti serverite puhul, mida me eeldame on see, et me saame nendese ühenduda, et me saame neile päringud teha, et neil on mingisugusid IP-aadrisid, neil on mingisugusid portid lahti, et me saame sinna kas sõnumid saata, HTTP päringud teha, aga meil võivad olega sellised, et see on nagu nutitelefonid või sensorit, kuhu tegelikult ei saa otsa ühenduda, et me ei saa temperatuurisensorisse ühendada küsida, mis on temperatuuriväärtus üle lokaalse võrgusin Tartu ülikoolis, et võib-olla saab see mikrokontroller, kes on draadiga ühendatud temperatuurisensorisse saab küsida, mis on temperatuuriväärtus, aga meie peame siis ühendama mingisuguse serverisse, et küsida mingisuguse sensoriväärtus. Sellised sensorid või nutitelefonid ja muud seadmed, kes pigem käituvad sellise klientina, et nemad ise võtavad ühendust teiste hajussüsteemide komponentide, näiteks serveritega, ja saadavad siin anmed või siis küsivad, näiteks, et kas minu ajaks on midagi mingi töö teha, et asjade internetist ihti ehitadakse just sellised seadmed turvalise seda tõttu, mis ise ühenduvad kuskile asjade interneti platformi ja küsivad, kas minu ajaks on mingisugust operatsiooni, et näiteks mulle võib-olla mikrokontroller, kes tegeleb selle lambi sissele ülitamisega, aga ma ei taha võrgust seda kätte saadavaks teha, ma ei tee ühtegi IP-adresse vii porti lahti selle mikrokontroller jaoks, aza mikrokontroller ise ühendub siin majas olavasse IOT-anmebase ja küsib, kas minu ajaks on uut operatsiooni, ja seal, kui ta küsib, kas minu ajaks on operatsiooni, seal on lambi sissele ültamise operatsiooni, seal on lambi välja ültamise operatsiooni ja seal on lambi sissele ültamise operatsiooni ja seda peab võib-olla ise otsustama, kud asjad need kolm operatsiooni siis teha, kas kohe korda ma oledas sissele ülitada või ainult kasutada viimast. Sellised seadmed on pigem nagu kliendid, kes teised sõlmed siin haussysteemist nende ühendust otsa ei saa, aga nad on ikka haussysteemi osad, mis võtavad ise ühendust teiste komponentidega ja suhtlevad nendeega. Et tihti ka asjad interneti platformides, sensori anmed liigutatakse anmebaasi kuhugi, niimoodi et teised haussysteemi komponenti saad anmebasist küsida, et mis on keige viimane temperatuuriväärtus, et ei piaga sensorid otsa olema ühendatud, et keegis sensori käsid otsa küsida. Sellal ma mõtsin autonoomsed, et nad on ise seisvalto otsustavad, kudas nad käituvad, kas nad võtavad ühendust kellegiga või kas nad võtavad vastu mingisuguseid sõnumi teistelt või nad pigem töötavad klientidena. Ei ole et hihti sellist kesksed kontrolerid, kes kõige üle otsustab, vaid nad võivad ka olla sellise mitte keskselt orkestreeritud süsteemina, aga oma vahel koostad tegev haussysteemide süsteem, kus on nagu rohkem korjografia, et iga üks tansib oma moodi, kudest ta soovib ja kokku ehitetakse nendest selline haussysteeme. Ja ühe situsas süsteemina mõeldakse seda, et kui meil nüüd on kasutajad, kasutaks võiks olla selle haussysteemi kasutam lihtne. Ei peaks olema olukorda, kus mina tahan näha temperatuurid, siis ma põnnu ülesotsima, kus on sensor, ülesotsima, mis on selle sensor IP-adress ja küsima selle sensori käest võib-olla mingi speciaalse rakenduse kaudu, et ma nüüd kasutan MQTT rakendust, et nüüd sensorega ühenudust võtta, saata sensorile operatsioon või saata sensorile sõnum või otsa ühenudada sensori MQTT serverisse ja kuulata, et mis on sensoriväärtused. Et selliste rakenduste ehitavalaks suhtseb keerulne, kui me peame teadma kõikides individuaalsades komponentides selle saajussüsteemis ja nende ka oma rakendust ühenudust võtma. Et parem on ehitada selline üks situsas süsteem, millel võib-olla on näiteks anmebaas ja mul on õigus anmebaast anmeid vaadata. Ma saan anmebaasist küsida, mis on sensorid ja vaadata, et sensorides on 40 temperatuurisensorid ja ma küsin anmebaasist, mis on selle temperatuurisensoriväärtus. Ja lõp kasutale võib-olla näeb see välja nagu pikem sellise tavalise veebirakendusena või tavalise mingi tüübi rakendusena ja minu eest on peidetud tegelikult ära, et ku palju sell riistvara komponent on, kus nad asuvad, kui seda infot vaja ei ole ja kuidas ma nagu nende ka ühenudust võtan, et ma ei pea teadma, mis on protokollid, on mikrokontroller ja sensor vahel, kas on Moot Park, kas on NQTT, kas on mingisugune traadi ühenudus ja et klient ei pea sellest mitte midagi teadma. Temaaks on mingisugune lihtsustus tehtud, etteiks veebirakendus, mille kauduma saan nüüd selle hajussüsteemiga suhelda ja tegeleda, et üks nagu eesmärk ongi siis tegelikult ära peitas ja keerukus kasutad eest, sest muidu on nende süsteemide kasutamine väga keeruline. Ja kasutai prugigi aru saada, et tegelikult on hajussüsteemiga tegu, et tema näeb ainult anmebaasi, etteiks. Meil võib olla siis täiesti centraliseeritud rakendus, mis on mingi mononitrakendus või anmebaast plus mingisugune rakendus. Meil võib olla selline hajutatud sõlmeda kogumik, kes teevad oma val koostuda, ka mõned on sellised kesksed kontrollerid või keskkled managerid, kes võib-olla haldaud oma komplekti sensoritest või oma komplekti teistest hajussüsteemide väiksemates komponentidest niimoodi, et võib-olla kasutaja saab ühenudust võtta peamise serveriga ja siin serveri kaudu see server pakub mingisugus liidest olguses haatate pealiid. Meil on siis sellise liides või mingi muu liides, näiteks MQTT, pidame käsina aines vaatame ja sellega autu saab kasutaja kõik infokätte. Võib-olla meil onki, et meil on eraldi sellised väiksemad klustrid, näiteks eraldi kaks kuberneetes klustrid, mis on oma vahel suhtlevad, aga kasutajal näed välja nagu üks kuberneetes kluster, aga tegelikult seal on peidusmitu. Võib-olla täiesti deesentraliseeritud hajussüsteemid, need on näiteks igasugused blockchain lahendused, kus iga sõlm selles võrgus, hajussüsteem võrgus on võrgne olem, et oma vahel ei ole ühtegi pealiku, vaid kõik teavad koostujad ja kõik võib-olla valivad endale, võib-olla nad ei pea esikult pealiku valima, et kõik ongi võrtsad, et sa võid suvalise noodiga ühenduda ja tema kas samasugused päringuid teha ja tema võib-olla suhtelad peistene noodidega, aga otsaselt ei ole pealiku, kellege ühendustaks võtma. Et selliste süsteemide pool võib-olla siin olevad klusterid peavad endale, klusteris olevad komponentid peavad endal pealiku valima ja siis kas teised hajussüsteemide komponentid suhtelad pealikuga või klendiid suhtelad pealikuga, aga selliste peastide etseentraliseeritud hajussüsteemide pool ei peagi pealiku olema. Kas te teate, mis on sellistes Bitcoinis näiteks viis kuidas valiteks see pealiku? Kui on täitsa selline olukord, et meil on kõik omavõls võrtsed, aga üks nendes saab õiguse teha järgmine blockchain, ehk otsustada, mis transaktioonid lähevad järgmise blokki. Põhimiselt ja, aga kõik teevad seda samahaikselt kõik proovioot pealikuks saada. Isegi mitte kõige pikkem, aga konkreets teatud arvu nulle peab olema, et ta ei ole olema kõige pikkem, ta peab olema esimene, kes sinna juuab või esimene, kes raporteerib. Et mõnes mõttes Bitcoinis on loteri. Kes võidab loteri, saab pealikuks ja sellele on õigus. Ei ole nagu, et me valime omaväl, kes pealikuks saab, vaid kõik mängivad loteriid nii kaua, kui üks nendest võidab ja siis see saab pealikuks. Ja mõnes mõttes see väldib seda, et peab kui tege valima, et kui me ei usaldada tegelikult ühtegi node sellest, et kui ta seda teha, siis see hashite arvutamine on selline hästi hajutatud mitte usaldust vaja, loteri, mida saab samahaikselt mängida. Ja võltsida on seda väga raske, sest võltsimiseks on sellal arvutus resurssivaja, siis ei ole isegi vahet, kas sa proovit seda võltsida või mitte, sest nii on sellal arvutus resurssivaja. Et kui oleks suuelne kokum võrdselt node, siis ma oon püks genereerida näiteks pilves endale 10 000 sellist hästi väikest serverid, kes proovivad mängida valijaid, aga kui iga üks nendest vajab tegelikult samal palju arvutus resursse, siis ma väga seda teha ei saa. Ma saan aga sest ei ole mingid kasu. Ja see ongi siis selles definitsioonis olev autonoomsalt arvutusel entidikogumid. Siin meil pigem on ainult üks. Oosaliselt centraliseeritud hajussüsteemides on näite sõlmede tüütä ja mitmesugused ja mõnedel on rohkem õigusi võib-pal ajutuselt, kuna ta on valitud tealikoks, aga teatud süsteemides on kõik siis võrdselt. Ja iga arvutuselement on mõnesmõttes sõltumatu ja peab olema sõltumatu, kuna ikku ja nagu füüsiliselt erinevad seadmed sinne on oma lokaalsed kellad, et mis hetke aeg on. Meil on oma mäluala, neil on oma resursid ja neid on raske niimoodi keskselt juhtida ja üks selline erinoos ongi, et meil ei ole globaalsed kella ja hajusalgoritmid pead selle ka arvestama. Nad saavad seda proovida teha, aga nad ei saa seda nagu 100% paika, et sal alati jääb natuke epa täpseks. Et isegi, kui sa proovid ehitada hajusüsteeme, kus nagu on tähtis, et kui korraga jõuab kohale kolm transaktsiooni, mis nendest ole esimene, näiteks sa tahad, ühest bankakontost tahetakse raha välja võtta ja sul tulub sama aegselt kolm päringud, siis mis nendest tegelikult reaalselt päris elus enne tehti. Seda on väga raske nagu tarkvaratasemel otsustada, kui sul on kolm päringud, mis jõuad kolme erinaate Riistvarasse ja kõigil on oma kellad. Saavad küll kellad synchroniseerinud, aga sa oled teinud seda võrgu päringud ta põhjal ja see ei saa kunagi nagu 100% täpne olema. See on see suhtsalt suur probleem sellistes hajusalgoritmides, kus nagu on tähtis mingite sünnmuste järekord, on hästi tähtis. Mõned hajusrakendustapuul ei ole üldse tähtis. Kes enne modifitseeris mingisugust postitust või on sama kasutamodifitseeris oma postitust kolm korda, see on ka mõnes mõttes oluline, aga vähem oluline, kui mingisugut bankakontot rahaväli võtmene. Sa mõted kellad? Ma ei ole päris kindel, aga see on nagu viga ise võib-olla natuke isegi see, natuke tähtsam, et just see, et kui sul on kolm samal aegsel toimud sünnmust, kas sa saadnad järjestada õigis järekorrad ja siis väga ei ole tähtis võib-olla. Kui sa ajaa sünnmus on väiksem kui täpsus, siis see on nii päris arvutussysteem, aga seda võib-olla isegi nagu rekordida ei olegi võimalik nii täpsult. Ja samas on tähtis, et kogu see systeem sõlmeda kogu, mingi töötaks samamoodi oleneval sellest, kus ja millal toimub kasutaja ja systeemi vahele suhtlusid. Kas kasutaja ühendub siis siia või ühendub opis siia, see haussysteem täks töötama samamoodi või siis siin, et kas kasutaja ühendub siia, ühendab siia, siis kogu selle haussysteemi kasutamine võiks sa olla täpselt samasugun, et ideaalis võib-olla kasutajai tohiks ikkagi aru saada, kuhuda on ühendatud. Ja siis on küsimus, kui läbi paiste peaks olema see hajutadus, kas lõp kasutaja tohiks näha, kus täpselt arvutusse toimuvad, kus on kus, kus läbi paiste peaks olema see hajutadus, kas lõp kasutaja tohiks näha, kus täpselt arvutusse toimuvad või peaks nende eest olla mära peidetud, nangu ideaalises haussysteemis võib-olla kasutajai tohikski midagi näha, aga päris elus ei ole vajalik otsaselt. Ei ole mõte, et ästi palju ressursse ei uurde panna või kui tästi keerulis tarp erahitada selle, agaks et kindlasti kõik asjad ära peita kasutajajast. Ja rakendaseaoks ei tohiks olla olulne, kus anmed täpselt saavlastatakse. Kui meie ühendume, siis küsime mingid anmest sellised haussysteemist. Kui anmed asuad seal, siis kindlasti nende kopeerimine siia võib-olla võta prohkem aega, aga kasutajajaks ei tohiks sellest midagi väga muhtuda, võib-olla väike latentsuse erinevus ja kõik. Kui me tahaksime teha haussysteemi täiesti läbi paistvatuks, et me tahame mingil põhjusel karanteerida, et ei oleks võimalik aru saada, kus anmed asuvad siin võrgus, see olks see suhustselt keeruline, sest kui asuad siin, võib-olla juhavad anmed 10 millisekondiga kohale, kui asuad siin, võib-olla juhavad 40 millisekondiga kohale, nii et vastavad latentsusele me saame kasutada saab teada, et kas anmed on kaugel või lähedal, kas me peame sellel ära peitma. Kui meil on nõu, et selle peaks ära peitma, siis me võib-olla peaksime kogulatentsuse panema automaatsal 50 millisekondi peale ja panema kasutada ootama 50 millisekondi, et enne, kui tanmed saab. Aga mille aaks meil see vajalik on, et kui meil rakendusel tarkvaran mingid sellist nõu, et ei ole, et see ei ole mõted ka lisatöö teha, et tagada sellisid omadusi, kuna teil on rangelt vajalikud. Aga see, ja anmedest on tihitiga peidetud see, kas sellest anmedest on mitu koopete või mitte, see ka ei ole tähtis, nagu kasuta jaaks. Ja see võib mõnikord ka natuke probleemiks tekida, et teie näiteks saadate Facebookile sõnume, et te soovete kõik oma anmed kustutada. Facebook kustutab anmedvaisid ära, ütleb, et teil on kõik anmed kustutatud. Kuidas te teate, et nad on kõik kustutatud? Ei, nad kui teiste kustutavad, aga kuidas nemad saavad kontrollid, et see on kustutatud? Nii on kõva ketas. Nii on virtuaalmasinatest backupid, igasugustest ketastest eraldi backupid, vanakatkilainud kõvaketas kui kõrvale pandud, ära on tead, et uue kõvakettaga, kui keegi tühendad seda kõvakettast. Kuidas sa tead, et anmed on täiesti kustutatud, siesteemides, kus ongi anmed replitseerimine, backupiminine hästi tavalne tegevus. Reasade ongi tegelikult väga raske karanteerid, et mitte üheski serveris ei ole kuskil kooped sellest anmedest. Ja olukorraga, kus meil sellised võrgud järjest suuremaks kasvavad, et kui meil on selline süsteem, mis on tõenalises, et ketas sinn kõrval läheb üks kord näiteks kahe aasta jooksul, läheb üks ketas kõrval. Aga meil on 500 ketast, siis üks ketas, iga ketagohta üks kord kahe aasta jooks läheb ketas katki, ja mida rohkem ketad on, siis seda tõenalises emand ome üks ketas nendest läheb katki. Jah, aga sul tekib juba probleem, kui üks ketas läheb katki, et selle komponentiga tekib koheproblem. Kui sul see komponent on replitseeritud, siis võib-olla mingi probleemi ole, aga... Jah, aga see süsteem, mille see ehitat, peabki olema siis võimelne selliste väikeste viga tege hakkama saama, et sa ei saa ehitada süsteemi, mis jookses kokku, kui üks komponent, üks ketas läheb katki. Jah, nagu sellise läbi paistluse mõttes, et kui meil on ühtne ja samalt situssüsteemis peab olema, nagu kasutel mitte aru saadov, et ta on hajussüsteem, või kasut ei piaks nägema näid resursse, mis seal taga on, siis selliste rikete peitmine kasutajeev, et see on pea võimatu, et kasuta saab vea kasutaja, kui sa vea proovit kasutajast ära peita, siis kasutajal on tegevast, et kasutajal on tegevast, et kasutajal on tegevast, et kasutajal on tegevast, et kasutajal on tegevast, et kasutajal on tegevast, et kasutajal on tegevast, et kasutaj kasutajajab ootele, kuni sa võib-olla uuesti päringu vastusse tale saadad, et nii ta märkab, et midagi on katki, kui asjad hakkavad feilimani, et selliste rikete ja nende taastumise peitmine võib-olla võimatu kasutajast ära peita, sa võid panna kasutajarega viieks minutiks ootele, siis saadad õiget tulemused, aga kasutaja saab aru, et midal eks valesti, miks ta viis minuti tootas. Ja selliste haiussysteemide sellised viis põhiomadust ongi resursside jagamine läbivaistvust, transparensus, millest me praegu rääksime, aga vaatame ka neid tüüp, et mis tüüp peal läbivaistvust meilt võib olla vajalik haiussysteemides tagada. Haiussysteemide avatus, et neid oleks võimalik mugavalt kasutada pea üks kõik, mis rakendusest, erinevalt sellest, mis programeerimist keelt või mis platformist, kas me kasutame Raspberry Pi-bjalt seda haiussysteemi või oma telefonist. Törke kindus, et elaks üle üks kõik, mis vead, mis tekivad süsteemis ja skaleeritavus ja paralelsus, et oleks võimaline skaleerida, et kui meie haiussysteemide kasutajad arv hüppelised kasab, et haiussysteem saaks selle kakkama. Resurssid jagamine, aga mis on siis resursid? Resursid võib oleks kõik, mis haiussysteemil on vajalikud olgun, et kas mingisugud failid, olgun, et arvutas võimsus, olguse salvestusruum. Meil on vaja nagu kõikite kasutata anmed salvestada niimoodi, et need oleks kasutatavad ja mida rohkem pilte salvestaviks, mida rohkem videot salvestataks, meie haiussysteem saaks ikkagi selle ka hakkama. Resursid võib olema anmed, mis on salvestad anmebaasi. Võivad ollagi igasugused failid, näiteks HTML-failid, mida kasutatavad ülleslaadida, nad soovid oma kodulehel näidata seda HTML-faili. Igasugused pildid, videod, et näiteks ma räägin sellest rohkem järgeste slaidipeale sellised anmedte jagamise võrgud, mille eesmärk ongi anmed teha võimalikult lokaalselt kätte saadavaks kasutatele, et näiteks kujutakette YouTube'i, et kui YouTube'i kõik videot täksid Amerikast kohale tõmbama, et kui palju interneti bandwidth'i on vaja, selleks tagada maailma internetiselt, et see võimalik oleks. Ja ka teenused endat, et kui meil on mingisugused teenused, mis on vajalikud selleks, et kõik hajussüsteem töötaks, ja meil vaja, et ka need teenused oleksid jaotatud siis kõiki nende asukohtade vahel, kus meil hajussüsteemide kasutajad on. Ja et ei ole, ei tekiks seda olukord, et teatud teenused on hästi aeglased, kui nad asuvad ainult ühes kohas. Jah, see aeglus sa võiti vaadata, et kust, kes seda aeglust mõõdab, et lõpkasutavadast on aeglene, kui pildi allatõmbane võtab hästi kaua aega, et kas on latentsuse tõttu või se on selle tõttu, et anmeda maht on suur. Jah, aga latentsus on kõululine, et kui anmeda hästi väikse, siis läbilask võime ei progültse tähendada, et ikkagi ootad suusted kaua aega enne, kui nad anmed kohal jõud. Jah, tihti selline sisu kohale toomise võrgud ongi ehitatud selleks, et kui meil on rakendust, mida me näiteks Eestis ehitame, aga meil on kasutad Australiast, et meil ei ole võib-pall kasutada Australiast või kogu üle maailma, et kui nemad kasutavad oma süle arutist, siis meie rakendust, et siis ei peaks anmed tõmbama Saksamaalt või Amerikast, et tekiksid sellised kohalikud anmed nende sisse, et meil on kasutad. Nii, et see on sellist anmed, et mida kõige tehedemid kasutatakse. Tavalliselt on need mingisusvusid pildid, mingisusvusid videod, kas või HTML-failid, et kui kasutaja proovib meie veebilet kasutada, see on kusajag, et vaja alla tõmata näiteks frontend JavaScripti-failid, ja see ei ole hea, kuna tästi kauge lasuvad ja näid tõmatakse eriti olukorras kasutada hästi palju. Ja selleks ongi sellised content delivery networkid, kus automaatselt tuaks anmed, mida kasutatakse sealt asukoast sinna asukoha lähedala. Ja seda tihti tehaakse pilvedes, et nendeiks Amazonis saad defineerida, et kuhu on lubatud teie kaustasasuvad anmed liigutadad, mis regioonidesse, ja kas te tahad, et oleks automaatne selline anmedliigutamine sisse lülitatud. Sest see nõuvab tegelikult mitmekordsed anmedtes alvestamist ja võib teile rohkemaksma minna ka. Et kui teie sojate koopet anmedtes kõikidas anmekeskustes ja need anmekeskus on kuus, siis te peate kuuskord rohkemaksma. Aga kui see toimub tõnaamiliselt, et ainult need anmed liigutadakse, mida reaselt kasutatakse, siis ta ei lähed äle nii palju maksma. Ja üks kõige klassikalis, ja määne näite ongi Google Edge Network, mis osaliselt ehitati YouTube jaaks valmis. Et kui Googlil on anmekeskuseid päris palju, aga põhimst tasu, nad Euroopas, üks Soomes, Amerikas, üks Lõuna, Amerikas, mõned Aasias. Nüüdseks kui te vaatate seda kaarti, siis seal võib olla rohkem, kui te lähete Google Edge Network veibi lähele. Aga need on ainult sellised põhi-Google ehitatud anmekeskused, lisaks asuvad, ma üppal räägin sellest järgmise slaidil. Lisaks asuvad sellised vahejaamad palju rohkemates kohtades, mis on ligi lähedased suurtel riikidele, kus on hästi palju elanikke. Siis Google ehitab sellised oma võrgu ja välis interneti vahel sellised jaamad, kus on ka väiksemad anmekeskused. Ja neid asukohti lisaks nende lülemistel on siis rohkem ja seal ka käsitakse YouTube videosid, niimoodi kui Lõuna Afrikast vist YouTube videosid vaatatakse, siis ei tõmata neid kuskilt Afrikast väljas poolt. Ma aidan üks, vähemalt üks selline vahepealne station. Ja see on nagu teine kiht. Esimene kiht on siis Google anmekeskused, teine kiht on sellised vahepealsed jaamad ja kolmas kiht on partnerfirmad. Siin ma kaegu siin saan sisse suumida, ka üks on Tallinnas. Tõenaselt Teliass, aga ma ei ole 100% kindel. Ja see on nagu kolmas kiht, et Google ise ei lupa näiteks YouTube videosid käsida Teliall. Et lihtsalt ei luba, et kuna nema tahad otsustada, et kuna käsitakse, kuna video eemaltatakse, et kui nema saavad mingisuguse, ma ei tea, take down requesti, siis et neid saaksid kohe selle maha võtta ja ei tekikse seda olukorda, et nüüd ma peavad Teliaga rääkima, et Telia selle käsji maha võtaks. Et nad tavad 100% kontrolli selle üle, et kuidas käsitakse nende sisu. Ja siis nad ongi nii paljutekohalik teenuspakujatega teinud lepingud, et nendes teenuspakujatega Annemekeskustesse on lubatud panna Google serverid. Ehk siis Google ostab ja viib kohale siis Google serverid kõik, keda sa on nende asukohtudesse ja need appid on tihti nagu suurte linnade või väikeste rikide juures. Ja kui teie vaatad YouTube videoid, esimes korda Eestis teie vaatad, siis tõmatakse kuskilt näiteks Soome-Anne keskusest või teisest jaamast, siis Telia serverisse see video ölesse, siis teised, kes pärast teid vaatavad, siis tõmatakse see video Telia keskusest. Aga selliseid võrk, kes saab kasutada üks kõik, mis sugu se sisu jaaks, aga peamiselt oli see vajalik just selle tõtta, et YouTube videoid ja vaatamise maht oli nii suur, et interneti bändvit ei elaks seda ülepõhimõtsult. Või siis läheks liiga kalliks Google'l maksma, või siis Google võtakski interneti üle, et teised teenusid oleks tohutult aeglased. Kõik olema dublitseeritud. Kui teie loota konto, siis tavast ütlet, et kustel ootavalt masina ma loon näiteks virtuaalmasina Soome'es, ma tekitan endale pilve kausta, kus ma panan anmed, ma loon selled näiteks Soome-Anne keskusest. Ja seal saate konfigureerite, kas see asub ainult Soomas, Anne keskusest või autonetiseks. Ja Content Delivery Network'i saab see oleisigi rohkem tünnaamil, et te saate registreerida teatud Anne neteks pildid, et nad oleksid Content Delivery Network'i poolt teie kaustast võetud ja Content Delivery Network'is registreeritud. Ja siis hakkataks automaatsalt neid liigutama, siis kui vaja läheb. Kui kasuta läheb teie veepi lehele ja teil on link, seal selle linkitakse. See link on nagu natuke üldin, aga ta linkib näiteks Soome, siis kasuta läheb selle linkile ja selle hostname'i põhja alt, et teie kaustast võetud. Ja siis on kõik, et teie kaustast võetud, et teie kaustast võetud, et teie kaustast võetud. Ja siis on nagu natuke soome, siis kasuta läheb selle linkile ja selle hostnamei põhja alt suunateks ümber, kus Content Delivery Network isa otsustab, et kuhu suunatakse see bäring, mis tõmbab selle faili alla ja sinna on loogika sisse eidatud, et kuidas see toimub. Ja sellisel juul tegelikult nendel linkidel peavad olema piisavalt üldsed adresid, et nad ei ole IP-specifiliselt. Ja siis on nagu võrgus, interneti võrgus ruuditakse õigesse kohta, kus see IP asub, aga peab olema mingisugune kiht, mis otsustab, et millist IP-et tegelikult kasutada ja kuhud see bäring, faili alla tõmata kuhuda reaalselt suunata. No siis, no siis teed, et siis juulikool saad ülve liga? Jah, aga sa ei taha nagu teha koost, et kõikida ruudritakse mõgailmas, sa tahad ikkagi, et see toimuks nagu sinupold kontrollitavalt asemel ja DNS-issa saab saa teha, et sa saad kirjutada DNS-i kirjad, kus sa mõned sellised reeglid sisse ehitatad, et kudest see suunamine toimub. Ja selled oto pakutakse ka sellised pilve-TNS-teenuseid, et sa saad Amazon pilves ees isedefineerida, et kudest see ruudimne käib ja kui TNS bäring jõub Amazoni, ja siis kontrolliteks ka sinu oma reegleid, mida sinad nagu selle TNS-teenuse eest oled tünnaamise tefineerinud, et sa saad nagu ümber kirjutada need Amazoni-TNS-i reeglit sinu ressurssideaks. See teema on suhtseed keerulline, et ma ei usod, et me seda aines kattame. Läbi paistusest ma natuke rääkisin, miks see üldse tähtis on, on tihti nagu keerulline, hea te näidete ka kirjeldada, aga üldiselt üks põhjus võiks olla näidikse, et me ei taha, et meie kasutad liiga palju teaks päris riistvara adressides, näidiks kus nad asuvad, mis sportid on, mis siipeadressid on, et võib-olla natuke kaistada rönnetavastu reaalselt see väga ei aita. Aga tihti on nagu erinevad põhjused, miks me tahame, et kasutad ei saaks teada täpselt, kus ja ku palju ressursse asuvad meie hajussüsteemis, see on tegelikult hea nagu peita ära kõik hajussüsteemide siseelu ja struktuur ja arhitektuur kasutajad eest. Näiteks juurde pääsu transparentsus või peidab ära nagu anmedes alvestis formaatide juurde pääsu meetodid erinevused. Kui anmebaas kasutab chasenit või kasutab SQL sellasemel või kasutab midagi muud, siis kasut ei toheiks selle pärast oma nagu päringud muud makata. Kui ühes anmebaasi hoiame chasenit, teise anmebase SQL, siis peaks ikkagi olema üks liidestus, mida lõpkasutavad kasutavad, et me oledaks lihtne näiteks mingisugust frontend rakenduse ehitada või et kasut ei peaks nüüd õpima erinevaid formaat, et meil alaks nagu lõpkasutavad üks konkreate formaatia, mis iganes formaadid meil reaalselt hajussüsteemis tegelikult kasutused on, on nüüd ära peidetud. See on hästi loomulik, et kui te infosüsteeme designid, et aga nagu üldiselt vaatates on see tähtis. Asukoha transparentsus, et tegelikult kasutaj ei pea teadma, kus tähtselt asukast asub Soomean me keskuses või Amerikan me keskuses, et tema näeb võib-olla globaalsed aadressi sellele pildile, mida alla tõmataks, et kasutale ei ole tähtis teada, kus asub. Teatud olukorras võib see tähtis olla, näiteks Euroopa nõuab, et anmed asuksid Euroopas, vedid siin anmed, siis võib-olla on hea, kui hajussüsteem näitab, et reaalselt kasut ka Euroopa anme keskuses, et isegurli panevats, et näiteks Soome aadressid, siis kasutad usaldavad seda rohkem võib-olla. Et see on ka sellene mäljakas vaheadus võib-olla. Kas ta reaalselt on või mitte, no võib-olla erinev küsimus. Aga põhimõttel saab ikkagi jälgid, et kuhu paketid lähevad. Võiks ka ära peeta selle, kui mingisugust resursid taustal kolivad teise asukohta, et selled oot ei peaks näiteks serveri aadressi või midagi muutuma, et me kasutame üldist IP-aadressi ja ka taga on serveri lokaalne IP, kuhu ümper suunataks ja see lokaalne IP võib täitsa midagi muud olla. Et igasust replitseerimise transparentsused peita ära see, et ku palju mitu koopjad on resursidest ja et täiesti on võib-olla, et pilv või näiteks hajussüsteem saab isesuunata ühtendendes kolmest koopjast ja kasutaj pea sellest mitte midagi teadma. Et on ka hea peita kõik tõrk, et kasutajat eest ära, muid on jälle hakkavad teiega ühendest võtama, et saad ma teile sõnumeid, et miks midagi katki on, server läks katki, et peita lihtsalt need erorid ära ja kasutajale saata seele pärin kovastus uuesti ja aga mõni kord jälle on hea, et kui midagi katki läheb ja tahad, et piisavalt kiiresti teada saada, et midagi katki läks, millegi pärast teie monitori mõnest ei tööta, siis loodate, et kasutajat teiega ühendest võtavad, et siis mõni kord on jälle hea panna vea teatesse informatsioon, mis oleks kasulik teile, et kui kasutaja teiega ühendest võtab, et seda infot näidata, et näiteks. Üks viis on see, et kui te näitate kasutajale, mis on päringu ID, siis seal võib olla kasutaja teie tõetajatele, teie firma tõetajatele, et neid saad näiteks monitorimisest selle ID-ka kõiks seotud logid ülesotsida. Et kui teie kasutajat, siis tracimist ja panete iga hajussüsteemi komponenti, logis originaalse päringu ID, siis teie töötajad võib olla ei pea kaevama logides nii palju. Et nad ei pea teka ma lisatööd, et okei, mis oli kasutane imi, kas ma tean, kus logides oli, mis aaja perioodisse võis olla, ei pea käsitsakama nagu kaevama logid, vaid lihtsalt saab teha lihtsa päringud. Selle kasutaja päringu ID-ka seotud logid vaadata ja siis võib olla mingile administraatorene palju lihtsam ülesleida probleemid, et sellise juhuse võib olla on hea teatud asju näidata kasutatele. Et kui neid ole mingi probleem, nad võtavad supporti kaud ühendust ja küsida nendat, et palun saadki meile ka teie vea teates olev päringu ID kaasa. Ja mõned muud on ka samaaeksus, et transparentsus ja skaleerimise transparentsus, et kasutate, tegelt, et ei pea sellekohta midagi näge käema, et kui skaleerimisega tekivad mingisugust probleemid või peita ära, et resurssi kasutavad samaks, et mituosa poolt. Et teine kasutaja kasutab ka sama virtuaalmasinat, et kasut ei peaks sellest mitte midagi teadmat peites ära kasutate eest. Ja täieliku läbi paistest peidame kõik kera kasutajat eest ei olegi vajalik, et võib-olla vajaks ka sellest lisaresurssi, et ma rääksin ka ühe näitene sellest, et kasut ei näeb, tegelikult seda latentsuse põhjal või päringu vastuse iiruse põhjal, kui kaugelt nendanme näiteks tulid. Et seda peita tihti oleva vajalik ja ei ole mõte, et nagu lisakulu ja keerukamad süsteemi ehitada selleks, et seda kudagi peita. Ja see on viimast punkti maja just katsin elmise slidipel. Et see transparentsuse võib-olla raska arus oda, mikse see on nii reaalselt vajalik on, aga palju sellise kasulikum omadus on avatus, et süsteemi saks panna kokku suvalisest riistvarast, suvalisest, no mitte päris suvalisest tarkvarast, aga et saks valida erinevaid tarkvarast, et ei oleks te piiratud targvara valikuga. Et oleks hea, kui riistvara on avatud, et lisaseadmete lisamine või komponentide lisamine ei toeks ole rask, et meil ei oleks kasutuses mingi hästi speciaalseid, ma ei tea, kõvaketad, mis ei ole et avakõvaketad või midagi sellist. Et riistvara oleks võimevõi progameerid, et võib-olla ei peaks tellima kogu uusi riistvara komponente või oleks siit nagu üldisemad riistvara komponentid. Ma ei tea, kas see on just hea mõtta, aga näiteks kasutada raspberry piisid või midagi, mis on saadaval kogu aeg ostetav kogu aeg. Ja tegil raspberry pii oligi pahepeal probleem, et mingi aeg, poolteste aastat ei olnudki ostetav, üldse. Kuigis tal on ka sellised alternatiivset seadmendid igas klonid. Ja tähtsam on võib-olla just see tarkvarjan avatus, kuna täna veel riistvara on vahetatav hästi suhtsalt lihtsast, et enam ei tehta väga speciifilist riistvara eriti serveritele. Aga tarkvarjan avatus on ka tähtis või kõige tähtsam, et oleks tähtis, et teil, kui sellise hajussustemi arenda, oleks lihtne uute, lisahomaduste, lisamoodulite arendamine, teenuste lisamine, et kasutadaoks avalik programeerimis liidaseid, näiteks, et appid, mida ehitadakse vastavad võib-olla respetifikatsioonile, on kasutusel näiteks Open Appi või Swagger spesifikatsioonid, mis defineerid ära, kuidas seda appid kasutada. Et kui te annate mingisugus selle parteril ühes, andat teile uus moodul ehitada, et siis oleks hästi lihtne nendale aru saada, kuidas liidestada täie hajussustemiga, et te tekiks seda olukordad, et nende aks näistikeeruline uute moodulite loomine. Aga protokollid võiksid olla midagi sellist, mida te ise välja mõtle, aga avatud protokollid, igasuguset TCP-d ja MQTT-d või AMQP-d, selleks, et sõnumid vahetada, sellase määlet teha mingisugune custom, sõnumite struktuur ja midagi väga unikaalsed väljamõelda, et ei ole mõted tihtijed. Et standaardsed protokollid on tihti piisavad selleks, et peab kõik ära teha. Et selline suhtlus ja annete vahetus teiste teenustega ja süsteemidega oleks hästi lihtne, et tänapäeval tarkkura valimisel vaadateks, et mis suurist integratioonid eksisteerivad, kas on võimalik näiteks integreerida, ma ei tea, Slackisõrumeid saata, kas on võimalik monitorimisega integreerida. Kui on tarkkura, millel on väga vähe välised integratioone, siis võib-olla seda valiteks vähemad. Kui on tarkkura, kasutaja peab liiga palju väli arendusi küsima, et mingisugusel liidestusi teha anmebaaside või anmehallikadega, siis tegelikult see on väga hästi suur lisakulu. Et kui teie lahenduseks on igasugusel avatud protokollid ja programeerimist liidest, et olemas, siis on palju lihtsam liidestuda. Ja kõik süsteemid, mis on siis hajus komponent, hajussüsteemide osalt, peaksid vastama nendele paikapaandud liidestele, mis iganas nad on, kas nad on mingisugud apid, et nad vastaksid selle, nad oleksid võimalised oma vajal koostud tegema üle nende liideste protokollidega ja võiks olla suhtse lihtne liigutada näid hajusrakendusi teistele platformidele, et ei tekiks seda, et te peate rakendust ümber ehitama, kui te lähete näiteks mingile teisele ristora peale, et lähete AMD 64 armi peale, et siis peate kogu sisteemi ümber ehitama, et see olega hea. Ja üldiselt vastavalt teelmistel, et oleks lihtne laiendada uusi moduleid, uusi võimalise juurde ehitada. Ja me katame aines just seda avatud programeerimist liidest ja protokolle, vaatame ja praktiku, mis teeme ka selle läbi open upiga, mis on nagu Swaggeri standard. Swaggerist välja kasv on selline natuke üldiselt standard. Ja paralelisus on tähtis hajussisteemite jaoks, et võimaldada kõrgemad jõudlust ja hakkama saada, kui kasutat arv või päringut arv kasab. Hea või ideaalne oleks, kui N-protsesoriga sisteema annaks, kuni N kord sa jõudluse kasvu, et me saaksime näiteks protsesorid lihtsalt juurda panna kas suuremad virtuaalmasinad, kas lihtsalt rohkem servereid, kus on kokku agregeeritud rohkem protsesoraid. Ja hajussisteem, võib-olla ma natuke seletasin seda valest, mida ma tahitsin, nagu sellest slaidile üldad, et kui meil on sentraliseeritud monoliitne sisteem, siis me tavalt saame selle panna ühel servere tööle ja siis me oleme limiteeritud selle maksimum protsesoreide arvuga, mis üks server on võimaline nagu toetama. Näiteks meil siin Arvuti teaduse instituudis on serverid, kus on 256 tuuma, sellised suuremad serverid ja mitu terapaitimälu ja ka pilves saab serverid, mille on hästi palju tuumasid, aga see on ikkagi limit, et sellest üleminna ei saa. Aga hajussisteemis me saame üks kõik, kui suurta arvu tuumasid tegelikult kasutada, kui me on võimaline lihtsalt kasutama paljuset arvuga, kus igal arvutil on m tuuma, siis me saame n arvutid võtta ja saame mxn tuuma ja kasutada oma hajussisteemis. See võimaldeb me skaleerida rohkem, kui monolitne sisteem võimaldeks, sest monolitne sisteemi jaaks mone limiteeritud rist voraga. Aga hajussisteemis me oleme limiteeritud nagu serverid arvuga. Tihti küll on, et me teaduse sisteemis on kõik, et me saame mõtta arvutid, kus on mitte arvutid, kus on arvutid, kui on arvutid. Ja siis me saame sisteemis, et me teaduse sisteemis on kõik, et me saame sisteemis, kui on arvutid, kus on arvutid, kus on arvutid. Kes me teaduse sisteemis on võimalik, et me teaduse sisteemis on arvutid, kus on arvutid, kus on arvutid. Ja siis me teaduse sisteemis on arvutid, kus on arvutid. Ka teaduse sisteemis on kõik, et me teaduse sisteemis on arvutid. Ma olen oma arvut minu arvut, mis olen oma arvut. Sitemis on kõik, et me teaduse sisteemis on arvut. ja muut probleemid tekivad, mis panavad meil piirit sellele. Superarvutid tänapäeval on ikkagi arvutiklastrid põhimõttel, kus on tohutul arvul, cpu-usid, mälujakp puusid, ikas arvutse on näiteks 1,4 gpu-ud ühendatud. Nääiteks Lumisuperarvutis Oomes on ka midagi sellist, mida meie hapetsekeskus ka heitas koostöösteitega. Ja meil on tavalselt hästi palju kasutad, kes sama aegselt kasutavad seda sisteemi nii, et kui nende arv kasvab, siis meie sisteemi peab olema võimalne sellel üleelama. Palju serveri protsessid töödavad sama aegselt, iga reageerib osadele nendest klientide päringutele ja samas paralelisest tulemad oma probleemid pealmised synkroniseerimisega, et kui meil on 10 000 kasutad, kes kõik anmebaasi midagi kirjutavad, siis selle kirjutamise skaleerimine on üks väga keeruline teema tegelikult. Kui meil on üks anmebaas, siis on lihtne, aga kui meil on anmebes jagatud mitmete noodide vahel ära, siis on suurstseid keerune probleem, kuidas synkroniseerida kirjutamist. Ja skaleerituvast tegelikult tähendab seda, et mitte see, et me saama ainult hakama sellega, ku kasutad arv tõuseb, vaid ka me oleksime võimelised seda tegema tünaamiliselt, et mitte raskama arvotusresursse, näiteks me saame virtuaalmasinat kinni panna, kui need enam vaja ei ole, et me saaksime neid arvotusriistad vajadusele. Ja süsteemi kasvatamine, et kui meil on vaja 10 või sadakorda rohkem kasutajad toetada, siis ei tohiks kaasa tuua targvara muutmise vajadust, mis mõnikord võib täiesti loogiliselt tekida, et kui meil ei ole üks anmebaas enam hakama ei saa, siis me peame oma süsteemi ümber disainima hajusa anmebaas jaoks ja tegelikult see ei ole hea, sa ei võib väga väga kalliks minna. Skaleerimist ongi, skaleerimisel ongi tihti nagu takistavad tegavased, kui meil on mingisuguse teenused, mis peavad töötama sentraalsed, et ainult üks server, siis nad muutuvad pudelikaalaks. Kui meil on mingisugune keskne anmebaas või anme kogu, mida me ei saa mingil põhjusel hajutada, siis ka see tekib pudelikaalaks. Ja kui meil on kalgoritmid, mis vajavad kõikid anmeda kokku kogumist, et teha mingisugus arvutusi, et mis ei ole võimelised nagu hajusalt anmed peale arvutama, niimoodi et mingisugune arvutus teaks kolmest serveris erald ja siis tuvaks see tulemised kokku ja arvutatakse midagi, et kui see ei ole võimalik, siis ka see muutub pudelikaalaks. Ja on ka vajalik, et ükski masine ei sõltuks täielikust infos kogu hajusa süsteemikohta, et see ole hea, kui meil ühe arvutimäru peab olema nii suure, et ta suudaks kõik anmed kõigi hajusüsteemide komponentide kohta kokku koguda, et parem on, et ta sada päringud ja lasad teistel mingit tööd teha, et ei olaks vaja kõik anmed ühte kohta kokku koguda. On hea, et masinat teeksid otsused ainult kohaliku informatsioone alusel, see ole alati võimalik ja tihtis ei ole võimalik, aga sellised süsteemid olev palju skaleeritavamad ja efektiivsemad, kuna teid ei pea palju suhtlema teistega, et lihtsalt päringutel vastata. Ja ühe masinatõrge ei tohiks blokkeerida kogu rakendase algoritmitööd. Ja hajusüsteemide pool tegelikult ei tohiks eeldada globaalse kella olemas olu. See võib parandada seda, et sul ei ole võib olla vajadust kesksete kellaserveretega sünkralliseerida. Aga ma ei ole kindel, kas oleks piisolt täpne, et sul kõik vajadus oleb ära täidetud. Aga võib-olla küll, jah. Põhimõtteliselt niise töötabki, et meil on kella ajaservered, kus sünkralliseeritaks, aga siis ongi see kogu probleem nende täpse ajamõtmisega, ku kõu päringut võtavad aega. Mul ei ole väga aega, et sa tead tänna rääkida. Ma lähen natuke kiiremini, et ma räägin seda skaleerimisest ka veel lohkem pilvetehnoloogia loengus, ja ma jätan näite skaleerimise osa praegu natuke vahele ja lähen lõimete juurde. Ja tõrkkel kindlusest me ka tegelikult siin juba rääkisime, arutasime. Mõned sellised eeldusid, mida ei tohiks teha hajussüsteemide kohta, on see, et võrk on töö kindl, et ükski ruuter, switch maha ei lähe. Võrk on turvalne, et kelle, kelle ei õnnest võrku serverte vahel pealt kuulata. Võrk on homokeen, et meil on alati täpselt samad ruuteri tarkvara kõikida sõlmedes meie hajussüsteemide komponentide vahel. Või et võrkus ei muudeta midagi liigutada ümber, või et võrkuslatentsust puudub, et lokaalsus võrkuslatentsust ei ole, et seda ei tohiks nagu järiti väljas pole lokaalsud võrku. Samut teid ei tohi eeldad, et me võime üks kõikku palju anmeid saata serverte vahel. Ja samut, et kulu anmeidetransportimise puhul on nüll, eriti pilvetehnoloogipuulse ei ole lihtsalt tööne, te peata sellest maksma. Ja et ühel süsteemiadmistraatoril on täielik pilt kogu võrku kõikki teha hajussüsteemid üle, et see tihti ole võimalik, kui see hajussüsteem tõesti olegi täiesti väike. Ei saa eeldada, et üks administraator teab kõike kogu võrku kogu hajussüsteemi kohta, et ei tee kunagi viku või midagi ole muutunud vahel, mida on teinud teine administraator. Ja siis viimane teema, mida te ka praktikumis läbi proovit on, lõimed. Räägime natuke sama asja, mida räägite operatsioonisüsteemid aines. Teil on sa aine ära olnud, ja keval sügisel. Kes ei ole operatsioonisüsteeme võtnud? Kõik on võtnud. Ma eist proovesin ka selle eelduse aineks panna. Ja räägime natuke lõimeda mudelist natuke veel üle ja räägime lõimeda valsi. Nõtukas veel üle ja räägime lõimeda valsi sümproniseerimisest ja kuidas on lõimed implementeeritud. Mis on üldse process? Process on täitmisel olev prográm, et ei ole prográm, mida ei ole veel käivitetud. Pärast programi käivitamist tegi process, mis on hetkel, kas ootel, kuni talle antakse prozessoraega ja reaalselt saab midagi käivitada või ta siis töötab hetkel või ootab näiteks. I.O. taga, et meil kirjutakse mingit file, et ootab, kuni file kirjutame on lõtanud. Ja processil on oma processi hetke olek, mis hoitakse kusagil rekistrites, et näiteks, mis on muutujate hetke väärtus, mis on seotud hetkel toimuvu arvutusega ja mingisugune käsul oendur näiteks, et misuguse koodi instruktsioon juures praegune käivitus hetkel on, mida praegu käivitetuks. Ja lisaks on mälus isu koodiseksioon, kus on selle processi programi kood, anveted seksioon, et mis anvetal mälus hetkel on ja magasin, et mis on hetkel täitmisel käsujärjend, et kui sügavalt on endes programi käskudes hetkel on, et kui üks programa käivitab teise metodi, siis selle programi mäluvajadus kirjutaks magasini ja siis hakkataks järgmis programi järgmiskäsku käivitama. Kui see käsk käivitab teise käsu, siis ka see kirjutaks magasini ja loodakse selle käsuka seotud andmed rekistrisse. Ja kui see käsk väljastab, siis see käsu tagastab mingisuguse tulemuse, siis see käsk sellest käsust väljastataks ja võetakse eelmine täite meetod, siis magasinist ja hakkatakse seda täitma, et see on nagu senne rekursioon, et mis hetkel on täitmisel. Kui mingisuguse meetodi täitmine tagastab, siis tulad tagasi juba teelmisse meetodisse, mis selle meetodi käivitas, nii et seal magasinis hoitakse seda jõud. Ja samast programmist võib olla käivitetu mituprocessi, et kui te näiteks käsurealt käivitat jaava käsu mitukorda, siis iga jaava käske teab jaava processi, mis taustal taetab. Igas protsessori tuumas, et kui meil on arudis neljiprocessori tuuma, siis seal saab juoksida korraga ainult üks protsess. Hyper trading on natuke teine asi, et tegelikult sama aegselt te jookse sama kahta protsessi korraga. Need lihtsalt on niimoodi ettevalmistatud, et nende vahel vahetumina on hästi kiire. Ja kui meil on protsess, mis jookseb hetkel protsessori tuumas ja mingil põhjusel peab vahetuma selle protsessi vahelt teisele protsessile näiteks, see protsess hakkas kirjutama midagi ketale, siis meil ei ole mõtled oodata, kuni ketal kirjutama lõppend, siis me võtame protsessori aja sellest protsessilt ära ja paneme sellest tuumas käima mõne teise protsessi. Või siis meil on vaja käivitada mingisugune operatsioonisüsteemi sisemine käsk, siis me ka paneme hetkel oleva protsessi pausile ja paneme käima opisela operatsioonisüsteemi protsessi, et seda operatsioonisüsteemi protsessori käsku täita. Ja kõik iga kord, kui me peame nimoodi protsesside vahetuma, nende vahel ära muutma, kes hetkel saab protsessoriaaega, et keda hetkel täitetakse, siis kogu see konteksti vahetus võtab aega. Ja see on hästi vähe aega, aga kui seda tehaks hästi tihedalt, siis see on kogu siis on nagu ajakulu, et me peame rekistrites väärtused ära muutma, et mis on hetkel käivitatava protsessirekistri väärtused, peame näed mälukirjutame uue protsessi rekistri anmed mälust siis tagasi või ja tagasi sinna rekistrisse kirjutame, siis ta käimo panem, et see kõik võtab natuk aega. Et kui meil on üks protsess, mille on üks lõimsees, siis ongi, tal on mingisugused mälualas kood, anmed, failid, failid on tavalselt failipidemed, et mis on need avatud failid, mille kaudusab nende failidega selt lugeda või siis sinna kirjutada. Meil on mingid rekistriväärtused ja meil on see stack, et mis on see kood, nagu pointerid ja mis on need eelmiste käskudega seotud, sisendid, väljundid, anmed, kui me saama tagasi hüpata, kui see praegune käsku on täidetud. Aga kui meil on programmis kolm lõime, siis need lõimed saavad iga lõimseb endale unikaas makasini ja unikaased rekistriväärtused, mis hoidakse mälus. Aga nad jagavad omavahel koodi, anmed ja faili, mis tähendab, et nagu on natuke efektiisen, kui teha kolm koopet protsessist, sest me peame oma korda tegema koopet ka koodist anmedest ja failidest. Nema saavad jagada põhimõtteliselt omavahel koodi, faili ja anmed mälus. Muidu, kui me läks kolm koopet, kolm protsessi igal üle on oma koop ja anmedest, me peame kui tegist synkroniseerime need anmed, et teene protsess ei saa esimese protsessi mälus lihtsalt midagi lukeda, aga lõimede puhul saab nad saavad samamälu ala kasutada siin anmedes synkroniseerimiseks. Kui see on implementeeritud, siis see on teatud olguridas võimalik, teatud implementatsioonidus. Aga lõimede puhul on sa automaatsal jagatud ja üks lõim saav kirjutada teise lõime anmed, kui sa ei ole lõime anmed, nad on tegelikult protsessi anmed. Ma magasini kohta juba rääksin, et igal lõimel on oma magasin ja see täitmis järekord, eestikelles tihti pinu mitte magasin. Ja igal lõime täidetaks täpselt samamoodi, aga kui protsessi ja ühtel lõim olaks täidetaks järje pidavalt ja kogu mälu on jagatud lõimeda vahel ja lõimeda vahel, sest mälu kaitsata ei ole, ja protsessi tivaal on defaultina mälu kaitse ja peab siis tõesti luba ma, kui midagi on. Ja kui meil näiteks on, kus meil nagu protsess algas, siis esimene ütleme meetod, mis käivitati, selle anmed on siin, see meetod käivitas teise meetodi, selle anmed on siin, see meetod käivitas kolmanda meetodi, selle anmed on siin ja siis selle praegusel käivitatava ja siis meil on pointter, et kus hetkel selles magasinis on nagu programmi täitmine, et siis võetakse selle hetkekäivituske seotud anmed, aga kõike elmised nagu meetodit ja anmed tuleb ka alles hoida, et me teaksime, et kui see väljupäe tagastab mingi väärtused, siis me saame siia üpata ja siit magasinis laadida mäluvahelikud registriväärtused ja muutjeteväärtused ja et oleks lihtne hästi kiiresti üpata elmiste täitmiste sammudele. Et kui te saate stack trace'i pythonis, et mis on need meetodid, mis käivitad üks see järel, siis põhimiselt see ongi sellest magasinivai stacki nagu logi, et mis oli need käsud, et et ihti saate pythoni väljondis, et näetiks vaadat, et see käs käivitade sealt realt, see koot käivitade sealt realt ja see koot käivitade sealt realt, et saate tagasi vaadat, et mis need kõik elmised meetodite käivitused olid ja ma luulis, hoitakssegi need anmed samamoodi. On erinevad lõimede mudelid, et meil on nagu riistvaralised lõimed, näetiks meil on 4 tuuma või meil on kasutajatasame lõimed, et meil on pythonis loome, siis näetiks, mis siin on 7 lõime ja tuuma lõimed on siis nagu lõimed, mille jaaks on riistvaraline toetus, et need sama aegselt käivitad, et meie protsessor oskap siis sama aegselt 4 tuuma lõime käivitada, et 4 asja korraga juhuksutada. Ja me peame kudagi need kasutajalõimed, mida meil on oma pythonis, siis jagama ära tuuma lõimede vahel, mida siis operatsioonisüsteemi kärnel tead ise, jossu ta ise, kui te sa tead. Et sellise ühe tuuma ka arvutipuhul meil siis ongi näed lõimed jagatud, miks ta ei tööta? Meil ongi siis näed lõimed jagatud ühe tuuma vahel, on sususti tefektiivne, kui meil on täpselt samapalju lõimi kasutada tasemel, kui tuuma lõimesid, et me saameki juhuksutada siis neid neljas erinas tuumas, aga pigem on tavalselt see, et meil on mingisun arv füüsilisilüü lõime, mida meie protsessor toetab sama aegselt juhuksutada ja siis meil on kasutapolt defineeritud, et meil on näiteks 60 lõimeline puul võiks selline krupp lõimesid, ja me lubame oma tarkvaras käivitada siis teatud tegevusi 60 tükki samahaegselt kasutada lõimedes. Lõimede hea küllk on see, et see parandab reageerimeskiirust. Kui me teeme ühe lõimega programmi, siis tegib see probleem, et kui see program võtab ühendust näiteks lokaase võrgukaudu teise protsessiga, siis ta tihti peab jääma ootele, kuni ta saab vastuse või kui ta kirutab file, siis kui ta ei tee seda asukroonselt, siis ta jääb nagu ootele, et kui fileist loodud anmed on käes. Ja see oota aeg on tegelikult hästi halb ja lõimedega saab seda parandada, et kui mingisugune protsessi käsk peab jääma ootele, kuni ta saab anmed failist, siis kui ta on erinev lõim, siis me saame ta pausile panna ja teised lõimed saavad jätkata tegevust. Näiteks me saame igale serverisse sisse tuleva HTTP päringu panna tööle erinas lõimes ja kui mõni neist jäb ootele, kui saab anmed anmebasist kätte, siis see ei mõjuta seda, mida see program saab samal aegel teha. Et suhtel lihtne ongi kogu käivitus, iga erineva sisse tuleva HTTP päringu käivitus teha erinevates lõimedes. Et siis kui ootele jäävad, siis me saame ikkina listat protsessi ootele panna ja käivitate järgvis lõime. See teab paralel programeerimise hästi mugavaks, et me saame maateks jagata 64 plokiks ja panna iga ploki töötluse erinas lõimes tööle. Ja siis me laseme protsessoril või operatsioonisüsteemi Kernelil koolitseda sellest, et kudest on nende lõimede vahel vahetub. Ja me ei pea oma koodist tegema seda, et mis järjekorras me jahat käime panema. Me defineerime lõimede tasemel kuske neli tööd ja laseme protsessoril neil oma aega vahetada nende vahel. Meil on võimalik siis jagada resursse nende vahel nii mälu kui kootiala, et meil ei ole vaja mitut koop, et sellest samas koodist mälus hoida. Me hoiame kokku jagatud resursside osas eritsele mäluala puhel, et me ei ole vaja 64 koopet teha sellest mälust. Tisti küll ütleme, et kui me teeme ühest maatreksist 64 väiksemat protsessid, siis võib-olla iga üks hoiapainud ühte ploki 64-st mälust, niit võib-olla mäluala on nelj vähem, aga meil on ikkagi efektiisem olla või omale üks mäluala ja me ei pea aga koopet tegema siis erineetlast asjadest. Kõik anmed, mis nad peavad olema täpselt samad nende lõimede vahel, siis neid ei pea dubliceerima mitme protsessile. Või vähemalt meil on see automaat, et me peab siis hakkama eraldi luba anma. Ja see võimaldeb ka siis, et meil on võimeline mitut protsessorid ära kasutada ühe progammist, et kui meil oleks ainult selline program siin, siis ilmal lõimed, et ta väga raske panna kahte protsessori tuuma seda sama programmi täitma. Aga me jagamegi oma protsessi lõimed, siis me saamegi kasutada sama programmi, sama protsessi jaoks nelja lõime, kui meil on rohkem, kui meil on rohkem, kui nelja lõime selle protsessi sees. Aga lõimeda vahel lülitemane endised lisakulu. Lõimede silumine, debugging on keerulisem, kuna raskem on aru saada, et mille sa problem tekis, kuna te näete, et problem tekis programmiga mitte, et mis suurlise lõime, kes sa tekis. Ja kaob isolatsioon, et kui mingi lõimd kirjutab vale, et anmed üle ja jakatud mälu alal, siis võib kogu program katki minna, selledatud, et tegelikult ei oleks pidanud seda ala ülekirutama, et teab teise lõimetöö katki, kui ta midagi valesti ülekirutab. Et lõimede kasutamisil on ka mitu viisi, kõige tüüpilisem on jakaja töötaja mudel, et meil on üks lõim, mis käivitud ja see lõim loob teisi lõimesid ja kui lõimede oma töö lõpetavad, siis see sama lõim väljub. Et keegi, kes otsustab, mida teised lõimed teevad ja kuna teisi lõimi lua, et näiteks meil on sisse tulevad 10 pildi töötlus ja see peamine lõim loobki siis 10 teist lõime iga pildi jaoks ja oota, kuni nad töö on lõpetand, ja siis isegi väljub. Et see on selline nagu jakaja töötajad, et ta luaks selle, kui töötaja lõimesid iga kord, kui mingi lisatöö tuleb. Meil on nagu veebi serveri lõim, mis loob iga sisse tuleva päringu töötlemise jaoks uue lõime ja kui see päringu on töödeltud, siis too lõim väljub ja peamine lõim saab uusi lõime juurda teha. Meil on kallameeskonna mudel, et meil ei ole peamist lõime, et me automaatselt tekibki näiteks lõimede hulk ja nad teevad omaval koostööd, aga otsasalt ei... ja kõik lõimeda võrtsad, et ei ole üste peallik lõime, kes teisi loovab ja teisi jälgib, et meil lõimed luvaks iga ainult siis, kui midagi on teha ja otsasalt ei ole pealik, kui nende vahan. Nii, et lõimed võib olla ka nagu... Meil teki piltitöötloss, ongi esimene lõim ja ta tekeleb ka end selle piltitöötlosagi ja väljub ja iga piltikohta teketaks uus lõim, nagu... et meil ei olegi nagu sellest üste lõime, kes teisi lõime loob, et seda saab teha nagu selt lõimede koopeerimise stiilis, et selle asemel, et me tekitame lõime, kes teisi lõime loob, me nagu spoonime ki koha nagu lõime iga kord, kui mingisugune progammikäivitust tekib. See ei ole kõige parem näite, võib olla, et... Ja meil võib olla kor konveijermudel, et me loome viis lõime, iga lõimde täiesti erinaat tööd. Esimene lõim alati tekeleb mingisuguse esimese ülesandega ja meil tekeb selline kas pipeline või konveijer, kus me saadame anmend nagu läbi viiest lõimest ja iga lõimdeb natuke erinevaja ülesande. Seda tihti väga ei kasutata lõimedet asemel pige, siis kui meil on viis erinaat progammia, me striimime nagu anmendnele progammides läbi. Ja selle aseme, et me lõime lõimeed loome kuskult pealiku progammist, me võib olla ei taha, et meil oleks 10 000 lõime. Mis juhtub, kui meil tulebki sisse korra, ka 10 000 kasutada päringut, kus me siin tõesti loome 10 000 koopjad mingisugustest stäkkidest ja asjadest. Võib olla me tahame, et maksimum oleks 20 lõime samaheikse töötavad, siis me saamegi luua sellise tred pooli, kus me defineerime, et maksimum lõimed alv on 20. Ja kui tuleb meil sisse uus töö, siis me külb defineerime, et see on lõim, aga teda ei panda nagu tööle enne, kui meil on nagu vabaresursse sinnd selles tred poolis või lõimede krupis. Et saab piirata, et kui palju lõime, sit ametlikult on nagu selle protsessoripolt järekorras või ootel. Ja tihti, kui meil on vaja koostad teha, et meil ongi siis oma vahel koostad tegevad lõimed, ja oma vahel koostad tegavad lõimed, siis kui meil on vajalik, et nad kirjutaks mingisugust, et alasid mälus üle või et nad oma vahel anmed jagaks, siis tegelikult tekivad palju probleemid, et kuidas seda teha õieti, ilma, et anmed tegiks mingisugust race kondisioneid, et kaks lõiveproojad samal ajaks, et mingit väärtust ümber muuta, et näiteks proovivad teha korrutist või plusoperatsioone, ja et ei tekiks seda olukorda, kus meil olev väärtus sõltub selles, kumb lõim enne kohale jõudis, et seda vältida. Või siis see, et meil on näiteks mälus olev lõim, kes loeb mingi mälu väärtust ja tahab seda plus kaks teha, aga sellel et enne pärast lugemist panaks seda pausile ja jäärimekord, kui ta eluärkeb, siis ta tead plus kaks sinna. Ja nüüd ta panaks se pausile, teine lõim tuleb ja loeb seda väärtust ja ta lõnestab koha see väärtus ära muuta, siis panaks see tema pausile ja panaks see esimene lõim uuesti tööle ja tema lõnestab plus kaks teha. Siis see tulemus ei ole korrekne, sest esimene proovist teha plus kaks, aga vahepeal see väärtus, millel eda plus kaks proovist teha, korrutati kahegi ära ja see tulemus ei ole jälle mõige. Et see tulemus siis sõltub selles, kumb lõim, mis hetkel pausile panaks ja see ei ole hea, kui tulemus sõltub sellistest suvalistest protsessori planeerimise poolt tehtud otsustest, taaks seda vältida. Selleks toetetakse sellised atomaarsed operatsioone, et me loeme väärtustid suurendamada kaks korda ja teine lõim ei ole samal ajal lubatud mitte midagi teha. Me karanteerime, et sama protsessi sees mingisugune lõime tegevus oleks atomaarne, et teiste lõimetele ei õnestuks seda mälu ala näiteks üle kirjutada samal ajal, kui see lõim tegeleb sellega. Selleks saab defineerida igasugused kas kriitised seksioonid, kas kasutada selliseid lukke. Ma järgmise slaidil natuke räägin selle kohta. Et me tahame vältida seda, et mingisuguse väärtuse arvutamine ei sõltuks ajastamise või planeerimise tegevustest. Ja selleks on vaja erinevaid synkroniseermisprinciipe. Erinevaid prinsiivid, mis on kasutus, on näiteks muteks, ehk luk, et ainult üks lõim saab korraga sellest lukust mööd. Meil on koodis selline objekt ja on karanteeritud, et sealt edasi saab ainult üks lõim korraga. Teistid jäävad selle muteksi taga ootama, kuni see üks protsessi alt väljub. Kui meil on olukord, kus me tahame tegelikult lubada mittmel protsessil, näiteks puf, ütleme, meil on ärääi ja mei ärääi pikkus on 4 ja me tahame lubada, et 4 lõime saaks korraga sinna väärtuse panna, aga me ei tohi lubada rohkem kui 4, siis me saame teha sellise semafori, mis lubab näiteks kuni x lõime või kuni 4 lõime sinna ära lelikikorraga, et nad saavad siis kõik appendida sinna listi või äräse uusi väärtusi, aga ei saa rohkem kui 4 appendida, et muidu kirjutateks alakerit mäluala näiteks üle. Meil võib olla ka selline spetsiaanel lugemis ja kirjutusnud luk, et suvalne arv lõimi saab lugeta stava väärtust või muutujad, aga ainult üks saab korraga kirjutuda. Need, kes tahad lugeda, saavad lukust edasi, aga kui keegi tahab muuta, siis ainult üks saab korraga proovida muuta seda muutujad. Monitor on spetsiaanel lukku, saab panna if-else-kondisjon, et kas ootab lukku taga, kuni mingisugune kondisjon on täite, et näiteks ootab kuni list on tühi või ootab kuni list on täis ja jääb ootale kuni list on täis. Ja see võib olla ajatab ka, et kui meil on erinead roolid, et mõned on kirjutad, mõned lugead ja mingi lugea ootab, kuni list saab täis ja jälle siis loeb ja siis teed sellega midagi jätu. Näiteks ootab, kuni maatriksi kõik arvutus on tehtud, maatriks on täis, nüüd ma hakkan arvutus tegemalt ja samal ajal teised saavad kirjutada maatriksisse väärtusi. Ja meil on ka võimalik teha kriitilise region, et mingi block-koodist märkida koodis kriitiliseks. Seda tehaks selle programeerimiskeeltet asemel, et ainult üks lõimsab sinna kriitilise regioni või meetode, et sa siseneda ja teha kogu selle meetode lõpuni ja teistel lõimetele selle laajale ei lubata sinna regioni minna, aga lubataks teha teise asja samaegselt. Et see on selline pikem, siis nagu matalasem programeerimise keeletasemel. Ja on võimalik ka ilmalukkud, et läbi ajada, selleks tuleb kasutada erinevad automaalsed operatsioone, mis on toetatud siis kerneli või procesori poolt. Ehk meil on võimalik teha näiteks test and set, fetch and add või compare and swap. Ma ei ole sadak protsentikindu, et ma õigestine ei tõna määletan, aga test and set on mõte, et me seame mingisuguse väärtuse mälus plus kaheks ja siis... Ei, me seame mingisuguse väärtuse mälus näiteks kaheksaks ja me saame tagasi, mista eelmine väärtus oli. Ja vastal selle me võime midagi edasi teha. Et selle asemel, et me ütleme plus kaks, me näiteks loeme, mis see väärtus oli ja et see oli kaheks. Mission Waffa astupidi, see on järgne operatsioon. Et võimest, et me seame mingisuguse mälu ola väärtuseks ja fetch and add on see, et ma suurendan mingisugust väärtust kahe võrra ja vaatan, mis see väärtus oli. Et see on see õigem, et ma proovisin seda vist valesti selle, et kui me soomem plus kahe teha, kas me ei duvitab, mis see väärtus oli. Et me ei pea ise otsustama, et kui väärtus on kaheks, siis me paneme sinna kymmen. Kui väärtus on ükst, siis me paneme kolmdeest. Et see pigem operatsioon teed plus kahe ja annab meile teada, mis see väärtus enne oli. Et see väldiv seda, et me peame lukema ja suurendama, kunne me tahame lihtsalt suurendada, aga me ka teadaksime teada, et mis see uus väärtus on. Et siis kui me teame plus kaks ja meile tagastadevik väärtus oli kaheks, siis me nüüd teame, et see uus väärtus on kymmen. Et me ei pea ette teadama, mis on uus väärtus. Meile piisab selles, kui me ütleme, mis kui palju seda suurendada, aga me ikkagi tahame teada, mis see uus väärtus on, näiteks oma algoritmi jaaks. Test ja set on, et siis see on selleks, et me seame väärtuse kymmneks, kui ta praegi on kaheks. Ja see on selleks, et me loome, saame teada, et väärtus on seitse. Ja me teadame, et me teadame seda ühekseks seadistada, aga meie operatsioon seadistab ta ühekseks ainult siis, kui tema väärtus oli seitse. See tähendab seda, et see feiliib siis, kui see väärtus, mida me muutu tahame ei ole see, mida me eeldameta oli. Võime luke, et ta oli seitse ja siis automaarnu operatsioon kontrollib, kas ta on seitse, siis muudad ühekseks. Ja me saame siis tagasi tulemuse, kas meil onnestus operatsioon või mitte. Ja seda tähendab, et ühelgi teisel lõimel sama laal ei onnestu seda muutujad mälus ära muuta. Või seda väärtus mälus ära muuta. Kompeerias vätbi ma etkel vist ei mäleta, et palun uurige ise, et mis ta täpselt oli. Ma võin proovit seda mällu või uuesti mäletada, aga praegu hetkelist ei mäleta ja aeg sa potsa. Selle nädala praktikumis siis te hakate praktikumegi piste. Te programeerite ühe sellise väikse kasutusloo ja hakate kasutama pyütonis lõimesid. Esialgu implementeerid seda ilmalõimedeta siis lõimedega ja siis lõimede grupiga. Ja selleks rakenduseks hakkab olema selline raamatute halduse süsteem, kus me kasutame Kutembergi raamatute repositoorimid ja teie kirjutada programmi, mis tõmbab Kutembergist alla raamatuit teatud ID-väärtusega. Et seal on hästi palju avatud vabasid tasuta raamatuid ja esimene meetod, mida ta loote, on lihtsalt tema ülesanani, et raamatut alla tõmata. Ja me loome ka praktikumil lõpus, synchroniseerimis ülesandes ühe teise metodi, mis siis lisaks sellele, et raamatut alla tõmatakse on eraldi meetod, mis loeb raamatutest raamatust, mitukorda mingi sõne eksisteerib ja me jagame sellel sõneotsimise erinate lõimeda vahel ära. Me saame kümbe lõime panne samat raamatut raamatust mingit sõneotsima, nima, et oma vahel tead koostada, et kokku arvutada, ku palju kokku oli neid sõnasid selles raamatus, mida me otsisime, et kas raamatus 211 oli siis sõna Estonia, mitukorda. Ja seda teaks siis lõimedabil. Et esims osas me tõmbame raamatuit alla erindes lõimedes ja viimas osas me synchroniseerime raamatust mingisugus sõneotsimist. Ja järgmestest praktikumides me hakkame seda kasutuslugu, mis on hästi lihtne, nagu edase arendama, tegema sinna rohkem sellest funktsionaalses juurde ja mingi hetk saadistame ta apiks, mingi hetk saadistame ka ta pilves üles, et meil tekib selline hästi lihtne raamatute halduse tarkvara, mida me igas praktikumis natuke edase arendama või teeme teatud asju teist moot, et näiteks kasutame erineid anmebaase või kasutame erineid viise komponentide vahelseks suhtuseks. Ja me teeme ta sellise mikroteenuseks lõpuks, et meil tekib mikroteenuse põhine hajussüsteem. Ja järgmestest loohen, kus ma hakkan siis andmetes rohkem rääkimad, räägid siis andmete vahetusest hajussüsteemides, kus siis pigem lõimeda asemel on program juokseperinevata protsessi täna, kes on oma vahel nagu sõltumadud või rohkem sõltumadud, kui lõimeda. Suumist küsimusi ole, kas kelekil on küsimusi, läksime natuke küll aaja. Tänan.

---------Loeng 3 - Snumite phine suhtlus hajusssteemides.txt--------

 Tere tulemast siis kolmandasse lohen, kus Peepi teenustaja hajussüsteemid arendusaines. Ja täna jätkame hajussüsteemidega. Tänna räägime siis hajussüsteemide komponentide vaalisest suhtlusest. Et kui me seame üles samas arvutis mitu prozessi, siis me soovim ka, et nemad omaval suhtleks. Kui me seame üles mitu prozessi, mis on hajussüsteemi komponentid, mis töötavad siis erinatas arvutides, siis on meil nende prozesside vahelne suhtlus ülevõrgu. Kui me eelne kod rääkisime natuke nagu sellest, et kui meil on lõime, et sama prozessi sees, siis nad jagavad mälu, aga prozesside vahel, mis jooksevad erinevad prozessiden arvutides või ülevõrgu, siis seda võimalust tiht ei ole, et seda on võimalik ainult sellestes hästi suurtes superarvutides või kallites paralel arvutides siis võimaldada, et tekitatakse jagatud mälu. Aga tänna räägime siis pigem nendes prozessides, mille vahel nagu sellist jagatud mälu ei ole. Ja räägime siis erinevatest andmeted edastamise viisidest ja räägime ka täpsemalt natuke nendes protokollides, mida te ise hakkate, siis oma praktikumis kasutama, mis on siis MQTT ja AMQP. Kui me peame otsustama, et kuidas me paneme prozessid oma vahel suhtlema või hausüsteemide komponentid oma vahel suhtlema, siis me peame mõnesmõttes vastama sellistile küsimustel, et kuidas on üldse hausad komponentid oma ühendadud, kas saab teha IP-aadresilt IP-aadresil ühendusi, kas komponentid saab ülesseada serveritena ja nendes saab ühendada ülevõrgu. Ja kuidas meil on võimalik siis seada ülesandme vahetus ja sünkroniseerimene nende komponentide vahel ja mis andme, et meil üldse on vaja sünkroniseerida ja kuidas me siis need vahelsed liidesed protokollid konfigureerime siis ühiseks hausüsteemiks ja kas meil sellised hausüsteemi komponentid, mida me oleme ehitad või mida me tahamme välja asendada, kas need on selget märatetud liidestega, et kui lihtne on meil võimalik vahetada välja mingi hausüsteemil komponentid, kas meil need hausüsteemide suhtlus on disainitud niimoodi, et meil on lihtne vahetada välja üks komponent, et kui meil on näiteks mingisugune tavalne HTTP või REST API kasutuses, siis me saame panna seda teise komponente, mis implementeerib selle sama REST või HTTP API liidese siis. Ja kuidas siis defineerida üldse protsesside vahelise side on see, kui üks protsess saadab mingisugust andmed teisile protsessile, et kui see toimub nagu ühe arvuti sees või ülevõrgu, siis seal suurt vahet ei ole, et me nimetame seda protsesside vaheliseks kommunikatsiooniks või ingliskeles interprocess communication ja see oli üks lühen, mida me elmises loohingus ei mäletanud, mis ei ole. IPC on, et see on interprocess communication, eks see on siis kahe protsessi vaheline kommunikatsioon, et kuidas siis andmed vahetadeks kahe protsesse vahel. Et seda on võimalik teha mitmel viisil. Üldiselt ei looheta jagatud mälu selliseks IPC tüibiks, aga on võimalik lihtsalt jagatud mälu kirjutada andmed, mida teine protsesse on võimaline sest lugema ja selle me jätame nagu tänases loohingus täiesti välja natukene aruts meelmise korral. Aga see läheb pigem nagu paralel arutuste valdkonda. Kõige tavalisem viis on otsa jöhendus soklite kaudu, eht me tekitame kaks soklit mõlemale protsessile, eht protsessid hakkavad oma arvutis või lookaalses arvutis kuulama mingisugus porti ja teine protsess samate kuulab mingisugus porti ja üks nendest ühendub teise protsessi sokli kaudusis ja hakkab andmeid saadma kahe sokli vahel. Me räägime järgmiste slaidile, mida täpselt tähendab sokel ja kuidas see käib. Teine võimalus, et me natuke abstraheerime seda, et mida me saadame, et me defineerime sellised nagu sõnumid või teated ja hakkame saadma teateid kahe protsessi vahel ja see enam ei prugi toimuda sellise otsa jöhenduse kaudu. Teateid võib saada läbi soklite, aga võib ka saada läbi selliste sõnumi vahendajate või selliste brokerite või maaklerite või sõnumi ärekord. Meil tegelikult võib tekida täiesti mingisugune server, kuhu me saadame sõnumeid ja siis teine house systemide komponent ühendub ka sinna serveris ja võtab sealt. Otsa jöhendust on meil võimalik teha siis, kui üks protsess saab kuulata näiteks oma arvutis olaju porti ja teine protsess saab sinna arvutis jöhendada nagu IP ja porti kaudu. Aga alati me ei tahas seda võimaldada, sest sellised portide lahtitegemised on natuke problemaatiselt asjad turvaalises ovaatest. Sest sa võid saata sinna suvalisi pakete ja kui sulle on näiteks sellest tarkvarast, mis ta porti kuuleb mingisugused vead, et ta ei oska korralikult näiteks mingid buffreid hallata, siis võib sinna saata sellised sõnumid vahendad, mis tekitavad näiteks buffer overflow ja siis võimalik tuss selles arvutis mingisuguse suvalise koodi käivitada. Nii et alati ei taha usaldada, et see tarkvara, mis sellest porti kuuleb, see on nii hästi ehitatud, et seal mitte ühtegi viga see seala. Ja kui sa vaad väljas polv portid kinni, siis sa ei saagi IPv6 pakete saata sinna. Kui sinu rakendus on näiteks mikrokontrolleris olev tarkvara, mis ise ühendub näiteks kindlasse kesksese serverisse, aga ise ei luba ühtegi, siis sa tulad ühendust, siis sa saad kaitsta selle vastu, et sinna ei saa midega otsa saata. See küll ei kaitsa 100% võrgueest, sest see rakendus või see mikrokontroller või see arvutimis võrguga ühendust võtab ise kuskil serveriga, siis ta ikkagi paketi peab kuulama, et otsustama, et mis on näit paketid, mis on seotud väliatehtud ühendusega tagas seotud paketidega. Aga üks kõik, mis ühendusta protsesside vahel teed, see ikkagi mingisugus tohud on seal peidetud isegi siis, kui sa ise ühendud anmebaas ja tõmbad dokumenti alla ja kui dokument on disainitud niimood, et see ka tekitat mingisuguse turva olukorra, et samuti dokument on liiga suur või kudagi disainitud niimood, et see parsimistarkvara ei oska seda hästi parside ja tänu sellele on seal mingi väiked security bugi, siis ka sellest tegida problem, et üks kõik mis sugun ühendus on problema niikord. Alati on problem tarkkorras, aga mida vähem port on avatud, seda väiksem, kui sa seda Ingiliskelle sueldaks, et itse on attack surface, seda vähem võimaluse on seda rünnata või sa nagu ei luba kellegil sinu süsteemi ühenduda. Litsad, et portid on alati kõige selline lihtsam viis, kui täst midagi rünnata, et hakkata kas suist scannima, et vaatama, mis tarkvaras sul on, kas sul on sellel SSC-tarkvaraga, sul on mingisugune open SSL-tarkvaraja, siis uurida, et mis bugid võivad selles versioonis tarkvaras olla, et võidi seeegi mis küskile mustale marketile minna otsida, kas selle tarkvaral on bugisid, mida sa osta ja siis on ära kasutada ründajaaks. Seda prooviteks siin tihti karab eet, aga näiteks SSH-tava protokoll ütleb, et ma olen SSH-Versioon ja see on tihti vajalik, selleks, et SSH-tarkvaraga saks oma vahel ühilduvalt ühenduda, et sul on vaja teada, mis protokollid ja mis versioonid kasut sul on, sul on vaja teada, mis krypteerimis protokoll on kasutusels selleks, et võitme krypteerimist, et lihtsalt krypteerimised ei luba, aga sa pead ütlema klientidale, et mida sa lubad, et tihti on vajalik selleks, et tarkvaral üldsetöötakse. Aga selle sa ennest me väga turvalisest ei puuduta, lisama mõtsin idee, et on huvitav, siis selle kohta velda, et teatud stiilida mõnda tüüpi haussüsteemide komponentia teaks natuke paremad, et võib-olla vähendavad natuk sellist ründala, mis on avatud rünnetele. Ja järgmises loengus räägime natuke sellest kaugprotseduurides ja haussuobjektidest, et see ei ole tegelikult nii palju erinev sellest, mis siin on, sest tihti see toimub ka soklite kaudu, kaugprotseduuride või haussuobjektide selline suhtlus, võib ka teadete kaudu toimuda ja meie praktiku, mis tegelikult teemegi kaugprotseduurid teadete edastuse kaudu, et see on pigem nagu veel üks abstrahärimise tase, veel üks abstraktioon, siis elmiste peal, et kuidas sa tead. Soklite jöhendas on kõike madala tasemel, teadete edastuse on natuke kõrgemal tasemel ja kaugprotseduurid ja haussuobjektid on veel kõrgemal tasemel. Aga kui meil on ühes arvutis kaks prosessi, me võime näid ka nagu sellist torude kaudu suhtlama panne. Et üks prosess võtab mingisuguse anmet sisse, töötleb ära ja teine prosess kuulav esimese prosessi väljundid, et selliks Linuxi torud, et on see ülakriips Linuxi käskudas. Et ka seda saaks teoreetselt kasutada kahe prosessi vahel suhtlusele, kui me teame, et ühe prosessi väljund alati lähed teise prosessi sisendiks. Või siis teoreetselt me saame nagu failid et asemel teha, et üks prosess kirjutab kõugi fail ja teine prosess kuulab, kas sinna fail on uue tread tekkinud, et ka selle kaudu. Aga see on tegelikult väga sarna asi, kas sul on toru või sul on failid. Idee on tegelikult täpselt sama, et toru või Linuxis vaadata ku faili, mille see tegib uusi ridasid ja kuiki failid tavalist jääb rea talle, see torust see mingi et kaoplist ära. Ja loogiliselt on selline tehniliselt asemeli prugi olla, et ja, see tavalne toru abstraktion sulle luba tegelikult väga mittmel prosessil seda kuulata, aga failidele on palju lütsem lubada seda, et sul on mitu prosessi kuulata. Ja Linuxid asemel on soklid tegelikult ka väga sarna aset failidele, failipidemetele, millest ma ka natuke räägin täna. Räägimeski natuke soklidest, et mis siis soklid on või ingliskees soket. Sokel on sideots punkt, et kui meil on kaks serverid või kaks prosessi, mis oma val taad suhelda, siis me identifitserime need prosessid, et mis arvutist ta jookseb, et mis selle arvuti IP-aadress on ja mis portida kuuleb. Et me teeme kombinatsiooni siis IP-aadress, call on port ja see defineerib sellisa võrgu asukoha, et kus teine prosess kuulama hakkab või on üppal kuulamas, et see on nagu võrgu asukoha, kuhu saab siis soklite kaudu ühenduda. Tihti on tähtis ka see, et kas ta on TCP või UDP port tüüpi protokoll selleportis kasutusele, et mida kuulatakse, kuna see suhtlus on päris erinevse olenevalt selles, kas sul on TCP või UDP kasutusele. Ja see IP-aadress võib-olla lokaalne IP-aadress samas arvutis olev IP-aadress ehk localhost näiteks, selleks, et kaks prosessi saaksid soklite kaudu lokaalsees masina sõhendada, et seatu öelas näiteks anmebaasi ja paneta anmebaasi kuulama lokaalsed porti 5762 näiteks lokaalses arvutis ja samas arvutis se installeerite püütunprogrammi, mis ühendub siis üle lokaalse võrgu selles anmebaasi. Siis anmebaasi hakkab teatud kombinatsioon IP-aadress ja portist kuulama ja iga klient, kes soovib selle anmebaasi ühenduda, tema peab samuti hakkama ühenduse tegemisel, teeb ühenduse, aga tema peab kuulama mingisugus porti samas arvutis, kui tulevad siis põhimselt vastused sellest soklühenduses tagasi. Ja Linux siis on sokel põhimõttelselt selline speciaalselt tüüpi file pide ehk sinna on samal madalalt asemel võimalik lihtsalt anmeid kirjutada ja lugeada, nagu process kirjutab file ja loovad file-ist, et nagu Linuxi, Kernelii, systeemi operatsioonide või metodide või käskuded asemel on ta põhimõttelselt teatud, speciaalselt tüüpi file pide, aga madalalt asemel käib suhtlus samamoodi nagu file-ist lugemine, file-ist kirjutab, ne lihtsalt sinna anmed jõuavad kohale üle võrgu. Ja põhimõttelselt me saame kirjutada ja lugeada pinaalsed file-e. Sokli ühendused siis võimaltavad processidel oma vahel suhelda, ta on suhtselt madalalt asemel, selledat, et on ka sinna peale erinad abstraktion ehitatud, mis teevad nagu selliste hajustarkkuvara programeerimise lihtsamaks, nagu me ei hakkame ka praktikumist kasutama sõnumite põhist suhtlust. Ja me loome side kahe sokli vahel samas või erinevas arutis ja neil on sellest andartised liidased. Ja me saame kasutada kas paketside, UDP või VOOC side ja TCP-ed, et ka sellest nendest protokollides me selles ainees väga ei räägi, et pigem anmed või operatsioonisjusteemides ja võrgutehnoloogis räägiteks nendest protokollidist. Ja see nõuab natuke madalalmat asemel programeerimist ja saad jälle vastuvat, jolle on oma kohalikud puffrid, mida nemad kasutavad, kui põhimustad failid, kuhu anmed kirjutada ja kust anmed lugeda või kujutad ette, et väliu fail ja sisene fail, kuhu sa kirjutad anmed ja need anmed viaksid kohale sinna servers, ja mis kuulab seda sokliyhendust. Sokliyhenduseapuhul meil on alati nagu klient, kes alustab ühendust ja server, kes kuulab ühendusi ja server tavalsed kuulab ühenduses paljudelt klientidelt. Ja server enne ühenduse võimalda, mis peab server olema tekitanud oma lokaalsa soketi, kuhu saab siis, kas lokaalsest masinast või ülevõrgu ühenduda, ta hakkab kuulama, siis seda soketid lues sellise pand käsu tulemuse na soklisidumise mingisuguse kohaliku aadressiga ja liseng käsu põhjal hakkab kuulama, siis see tulevad ühenduse. Siis see tulevad ühendused võib tulla mitmelt klientilt ja ta peab algatama sellise ühenduste vastuvõtmise kasutada sääks hääpks käsku. Kui server on need nelisamul läbi teinud, siis saavad klientid hakkata ühenduse võtma selle serveri sokliga, siis IP-aadressiga ja portikombinatsiooniga. Ja klient siis samuti loob oma soketi, loob põhimselt soketi ja tekitab siis ühenduse võt, kasutus Connect käsku, et võttes siis serverga ühenduse ja kui server võtab sellise ühenduse vastu, siis tekibki soklijühendus kahe nagu otspunkti vahel, kus on klienti lokaalne port ja IP-aadressi, siis serveri port ja IP-aadressi. Ja pärast seda saab siis näiteks klient kirjutada sinna soklise anmed ja samuti saab siis server vastu kirjutada sinna soklise soklijühendusse mingid anmed. Näiteks ma saadan päringu, et ma soovin mingid metodid väljakutsuda ja siis server saab vastata mulle oma moodi. Ja me saame seda korrata riid ja writei mõne mal poolt ja kui klient saadab close metodi või käivitab close metodi, siis saadateks end of file notifcation, et selle soklijühenduse selle file lõpes või see võimest file ei lõpetu saadateks end of file, mis serveri ütleb, et ühenduse file on nüüd läbi ja siis server loeb seda end of file notifcation ja pärast seda panad ühenduse kinni. Ja see võimalda siis oida sellist ühendus lahti ja saada soklijühenduse kaudu mõlemas suunas siis anmed. Ja te võite ette kujutada, et madalal tasemel on. Siin arutis see process kirjutab sokli file anmed ja sit serveri poolt loetakse sokli file-ist anmed. Ja põhimestel tekitatakse kahe suuran lühendus nende kahe processi vahel. Kas nad on samas arutis ja võinad on täiesti erinevates arutitus? Ta on põhimestel saa-moodi nagu file pide. Sul on file arutis ja kui process tahab seda file kasutada, siis Linux siis tekitatakse nagu file pide. Ja selle file pide me kaududa saab kutsuda välja Linux kerrali meetodeid file-ist anmedte lugemiseks ja file anmedte kirjutamiseks. Et ta nagu otsed ligipäe su file-ile ei saa, et processi on nagu file pide. Siin on saa-moodi, et tegi file pide, et meil on teoreetile file, mis on nagu see sokli adressid ja file pide me kaudu saab processi kirjutada ja saab tugega sellised meetodeid välja kutsuda. Aga nagu file ja otsedlite eksisteerid nagu lokaaselt puffrid, mis on nagu aktiiselt selle sokklyhendus ajal ja selle file pide me pühe. Siin võib-al asjas näites võiks tuua detailsemad näit, et mis näit lokaaselt portid ja IP-adressid on. Sest muidu võib jääta natuke abstrakseks, et kuidas mõlema suunaline liiklus toimub, aga saate näiteks hotsid vaadata, kas seda adressi või natuke lugeta soklite kohta juurde, et kuidas toimud. Siin on oma lokaalne adress, portia ja siin on oma, et võib-mõlemad poole saavad teise poole sokkli adressil saata anmed. Anmeid. Ja kuulata siis oma lokaalses adressis anmeid. Ja see on siis selline otsene suhtluse, aga see on tihti selline natuke madalat aseme, et me ei taha pyütonis alati programeerida sellel tasemel, et me hakkame kirutama file tess lugema. Me tahame näiteks pigem saata sellised JSON-tyübi sõnumeid, kus kõik nagu parametrid ja väärtused on olemased, et oleks rohkem asin loetav, sest proveem on see, et siin olev server pead teadma, mis tüübi anmed saadetakse. Saadetakse küll pinaarsed anmed, aga tema peaks teadma, kuidas need parsidad. Ta peaks teadma, et kas saadetakse XML, kas saadetakse JSON. Ei ole hea teha sest täiesti tünnaamist parsimist, et ma proovim parsida kõigepealt JSONisse, siis XML-le siis aru saad, et mida saadetakse. Tihsti ikkagi selle targvara põheal paneks paik, et mits tüübi anmeid see klendil on lubatud saata, et kui me teame, et me tegeleme mingisuguse serveriga, mis saadab meile näiteks HTML-lehes sisu tagasi, siis klend peab teadma, et see sisu on texti file näiteks UTF-9-as formaadis ja tema saab seda HTML-lehene kasutada. Aga tihti ongi see kerukus, et kuidas me siin lepime kokku, et mis need anmed on, mida saadetakse, või mida kirutatakse ja mida saadetakse serverilt tagasi. Ja sellest tulebki nagu kasab välja selline normaalne või täiesti tavalne aftraktsioon, et defineerime sõnumi tüibid. Kas me saadame JSON-i, kas me saadame integeri, kas me saadame mingisugune listi integeridest, et mis on see sõnumi formaad, mille me kokku lepime, et klend saadab serverile, et näiteks me lubame, et JSON-id saate, siis JSON-i sees on kõik nagu sõnumistruktuurik olev info sisse ära eitatud, et me ei pea eraldi erinevaid metodeid kokku lepima. Ja sellest tulebki selline teadete või sõnumita abstraktsioon, et me lepime kokku, et me saadame teatustruktuuris sõnumeid. Kuigi sõnumid ise võidata olla ka pinaarsed, näiteks meil on pildi file saadame sõnumi, kus on pildi file sees, mis on piraarne pildi file stream, siis näiteks base 64 ka encoditud, kui me tekstina saadame või siis meil olevaja encode, kui me pinaarsena saadame. Ja tead, et edastus ongi, et me lepime kokku, et me saadame teatud struktuuris sõnumeid protsestid vahel ja me peidame ära nagu sellise madalataseme pinaarse sokel-sokkel ühenduse. Kuigi me ei vahet seda välja, et sisemisel tõenaselt ikkagi kasutame sokl ühendust. Ja olukorras, kus sokli ühenduse on liiga madalatasemene ja selleks on kaks peamis tüüpi, kas meil on sõnumi ootse edastuse abstraktsioon, kohe protsessi vahel, et me tekitame iga uuesti näiteks sokl ühendused ja üks protsess saadab teisele protsessile teatust struktuuriga sõnumeid. Ja me lepime kokku, et mis struktuuris sõnumid on, kas see on näiteks MPI's tegelikult võib samutel üks kõik, mis struktuur kas integer või array, aga sõubi puul tavaselt me lepime kokku, et see on XML, HDB või REST-i puul me tavaselt lepime kokku, et kast on XML või JSON, mida saadetakse. Ja RPC puhul on tavaselt XML, RPC JSONi puhul JSON, et me lepime kokku siis teatud sõnumide tühibid. Ja teine peamine erine võimalus on, et kui me ei saada otsa kahe protsessi vahel sõnumeid, vaid me paneme kahe protsessi vahele mingisuguse sõnumide järjekorra või näiteks sõnumid, kui asja hästi nimeda täiesti, kes postkasti. Me ei saada sõnumid protsessilt A, protsessil B, vaid me saadame sõnumi postkasti, ei B, mida kuulab siis protsess B. Me tekitame vahele sellise vahevara või vahetarkkvara, kuhu me saame sõnumid saata ja protsess B võib võta ome ühendust ja küsida, et kas talla on uusi sõnumid. Et see võimalatab teha sellist asymkroonsed ja natukene sellist ühendust, kus mõlemad protsessid, mõlemad osapooled ei pea olema sama aegselt otsa ühenduses soklitegaudu, vaid näiteks me saame panna mingi sensori kogu aga andmeid saadma, aga siis mingisuguse tarkkvara, mis soovid need andmeid kasutada, ta võib ome ühendust võtta küsida, et mis seal järjekorras need sõnumid on ja need sõnumid töödelda. Ja ja ja Linuxis on samamoodi, et sa võid teha IPC niimoodi, et on otsa kahe protsessi vahel võid võid Linuxist tekitada nagu postkasti või mail boxi, et kuhu saata sõnumid, et ka Linuxis on täheelne protsessida vahelne maili box täheelne olemas postkasti, mida saab nagu abstraktsioonina kasutada. Ja selleks kaks peamist on nagu MQTT, mis on tihti nagu IoT-s asjad interetis, aga nagu rohkem on kasutuseliselt Advanced Messaging Queuing Protocols, nagu rapidMQ stiilis, mida tihti kasutatakse mikroteenuste puhul või selliste suurte mauliste anmete ruutimise puhul, kus on vaja nagu otsustada ka, et kuhu edasi suunatakse. Tänna räägime natuke MPI-st ja nendest kahest protokollist. Järgmises loohingus räägime RPC-st ja ülejärgmises loohingus lähme WebI-teenustu juurde ja siis räägime Soopist arrestist. Nii, et järgmised kolm loohingud hakkavadki olema koos tänasega siis nende erineot tüüpi nagu sõnumid te edastamine siis hajusalt töötavate protsesside vahel. Ma vaatan, ega me siin kaamers liiga kaugele ei seisa. Sõnumide põhjine ühendus on siis ingliskeeles message-oriented, et me pigem tegeleme selliste sõnumidega, kui madalat aseme Pinaars anmete striimina ja nagu ma enne mainis, onki, et kas me saadame otsse sõnumid kahe protsessi vahel, aga see võib olla nii synkroone kui asynkroone, et me võime nagu vältida seda, et me saadame otsse sõnumide ka. Võib tegita sellise lokaalse pollimised, kas ma sain sõnumid kohale, kui ei saanud, siis tegelem millega muuga, kas ma sain sõnumid kohale, ma tegelem millega muuga, siis hiljem jälle kontrollin, kas ma sain sõnumid kohale. Või siis synkroon, et ta jääbki ootama, et kuni teine protsessi sõnumi saadab, aga tihtis on problemaatiline. Ja teine võimalus on, et me saadame, tegeleme siis postkastid või teadate järekorad või tööte järekorad või sõnumid järekorad, et järekordasid on erinevaid nimesid nendel ja eesmärkongi siis tekitada selline kõrgema taseme püsi vasukroone suhtlus, et meil protsessid võivadki mingitase järekoradade saanud meid saata ja teiseed hajus protsessid lihtsalt nendeaks vajalikest järekoradadest otsivad sõnumid ja ei kuulavad sealt. Et näiteks meil on mingi kamera, kes tuvastab ära, et on inimese näku pildi peal, aga ei tea, kelle näku tol, kui on näkud, et on sõnumid, et on järekorad, et näiteks meil on mingi kamera, kes tuvastab ära, et on inimese näku pildi peal, aga ei tea, kelle näkud on, aga ta lihtsalt pildist tuvastab ära, et on üks inimene, kellel on näku. Ja ta võtab sellest näpsot ja panab kõugi järekorda ja siis teine protsess, kelle ülesanand, tuvastad ära konkreese, et mis inimese näkus on, et see järekorda võtab sellest file ja proovi pärast tuvastada, kas see on pelle või see on keegi teine näku. Ja siis panab teise järekorda, et see oli pelle, keel 12.30 oli pelle seal toas ja siis mingi teine protsess, kuskit veebiprotsess näiteks järekordast võtab selle ja saadab alerted. Me saame järekordada põhise suhtluse tekitada hajussisteemide komponenteid vahel. Ja see on tihti kasulik, sest see tähendab, et kõik protsessid ei pea oma vaal otsesuhtluses olema, nad võibad ise otsustada, kui tihti nad vaatavad neid järekordi. Ja see võimalda palju paremad skaleerimist, sest me saame tegelikult panna kümme samasugus protsessi kuulama täpselt sama järekorda. Ja kõik pildid, mis järekorda saadatakse, me saame nende kümme protsessi vahel ära jagada, et siis see tekitab väga lihtsam mustri, et kuidas skaleerid arvutusi me lihtsalt paneme palju protsesse sama järekorda kuulama ja nad jagavad oma vaal sõnumid ära. Aga kõik see omadus onki, et saaja ei pea enam ootama ühendust, vaid ta saab lihtsalt vaadata järekordas, kas seal midagi on või mitte. Ja tihti selliste sõnumi järekordade vahevara, see tarkvara, mis implementeerib neid postkastid, see on siis vastutav nagu tõrke taluvuse, anmete püsiva salvestamise eest, et neid sõnumid kaduma ei läheks või et neid sõnumid kiiresti kohale toimetataks või et neid sõnumid oleks nagu vajaliku sellise, kuidas sa räälda, quality of service inglis keeles, et neil oleks vajalik, kas 100% karanteeritud kohale toimetamine või estisuur jõudlus, mis ei karanteeri 100% kohale toimetamist. Ma rääkin sellest natuke iljama. Ja selline kõige klassikalisem hajussusteemide või isegi paralel arutustes, protsesside vahelse sõnumid te kohale toimetamise tarkvara või pigem tarkvara asemel seda nimetada liideeseksest. See on selline liides, mida erinevad tarkvarad implementeerivad, on MPI, Message Passing Interface, implementatsioonid on näiteks OpenMPI ja see on hästi vana tarkvarad, seda kasutatakse 80.-90. sellises suur arvutustes või paralel arvutustes arvutukriidides sellist arvutussimulationide implementeerimiseksis suur arvutust. Ja põhimatselt ta muudab sellise lokaalse protsessid vahelse suhtluse globaalseks, et on võimalik defineerit, et mul on 16 arvutid, kes teevad koostu, et nimiod, et nad jagavad oma vahel sõnumeid, näiteks mingite matriksite arvutuse korral nad jagavad matriksitükkideks, väiksemateks matriksiplokkideks, iga matriksiploka näiteks sõnum, mida siis paralelselt töötavad protsessid oma vahel jagavad. Ja ta ongi nagu selle gruppi suhtluseks paralel arvutuste raames ja. Ja et ma pigem räägin näidete ka. Sõnum ennepjäis võib olla üks kõik, mis sugunne tüüpilline programeerimise objekt programeerimis keele objekt, et see võib näiteks olla integer väärtus üks väärtus, see võib olla mingi int ärei int list, see võib olla ka string, näiteks mille see on json objekt või xml objekt, see võib olla ka lisapinaarne mingisugune objekt, mida hiljem parsime näiteks mingiks java klassiks või puton klassiks. Klassi instants objektiks. Et samuti peab tegelikult klienti ja server omaal kokku lepema, et mida me saadame, et kui üks osapool saadab integeri, siis teine peab põhimõttelselt otsustama, et tema sellel hetkel võta pastu integeri. Et see teeb selle programeerimise päris keerukaks. Kui kirjutada programmet C-s või Fortanaris, siis pidi isegi paika panema, et kui ma saadan ärei, kui pikse ärei on, et kas seal äreis on 16 elementi või seal on 128 elementi. Ja seda tihti pandi paika vastavad näiteks maatriksi või maatriksis suurusel, et kui maatriks 1000x1000 maatriks ja me jagame nüüd 10 processi vahel, et teeme võib olla 10x10 väikselt maatriksiplokid ja jagame nüüd processid vahel ära. Ja siis sanumid olid neid väiksemat plokid. Ta on suhtselt selline madala tasemel programeerimine eriti varasamates programeerimiskeltes nagu Fortran ja C. MPI-t saab kasutada ka Pythonis, on selline openMPI-t ka Pythonile. Siis on natuke lihtsam, sest automaalsed arvutadakse need bufrite suurused ja ei pea käsit siin, et ei ta ole paika panema, kui nagu C-s või Fortanaris pidi panema. On sellised tüüpilised metadid, mida saab välja kutsuda, võite kujutad, et meil on 16 processi, kes nüüd peavad koostööst tegema mingid maatriks arvutusi, et siis nad saavad oma vahel saata MPI send või MPI receive sanumid selleks, et üks osapool siis ütleb, et mina tahan vastu võtta maatriksid ja teine osapool ütleb, mina saada maatriksi ja nad panad üksteisei nagu process ID-t argumentideks, et siis process 1 saadab maatriksi process 2, siis process 2 peab kutsuma välja MPI receive ja process 1 peab saadma MPI sendi ja nad peavad samal ajal nagu mõlemad tegema seda. Ja kui seal läheb cyklist või synkroniseerimist välja, siis võib juhtuda, et program on hästi ebaefektiivne. Et see oli selline madalat aseme, paralel programeerimine, ja IP-adressat asemel kasutati nagu process ID-sid, et kui meil on 16 programmi või 16 processi, mis teavad paralel arvutsi, siis meil on processid 0-15, kes saavad siis oma vahel saata sanumid, et process 1 saadma saata sanumid process 16-le, ütleb 15-le, kui 15 samal ajal kuulab. Aga kuna see oli natuke eba meeldiv, siis tehtiga sellised mitte blokkeerivad sanumidte saadmised, mis olid siis asynkronsed, et ma sain saata sanumi, aga ma ei jää seda ootale. Ja ma saan öelda, et ma olen nõus vastuvõtma maatriksi, aga ma ei jää ootale. Ma ei jää ootale, ma hakkab midagi muut tegema. Ja siis, kui ma taan seda asynkronsed saadetud maatriksid vastuvõtta, siis ma saan kas testida, kas selle muutujal, mille väärtus panaks selle meetadi põhjal, kas selle muutujal on väärtus kohal või mitte, või siis ma võin tõesti ootama jääda, et veit või veit eniga, et ma jään kõiki sanumid ootama. Ja sain imade asynkronsed oodata sanumeid selleks, et vältida sellist olukordagus. Mina küll proovin saata, aga keegi vastu ei võta, et ma ei saagi sanumid saata. Ja lisaks oli sellised kollektiisid operatsioonid, et oli broadcast, et näiteks selline pealik programm võtab maatriks ette, jagab selle 10 blokiks ja saadab skatteri abil iga, et kõigile processi lüüa selles 10 blokist. Et skatter võtab mingi listi objektidest ja saadab iga objekti erineatel processidele. Broadcastiga saab siis näiteks võtta mingi vektori ja saata kõigile processidele täpselt sama koopja vektorist. Ja en peahe ikäteriga saada teha niimoodi, et kui nüüd mina pealik programmina olen jaganud maatriksi 10 blokiks ja saatnud kõigile teistele processidele ja kõik processide oma arvutus ära teid näiteks mingi maatriksikorda vektori korutise. Ma saan en peahe ikäteriga küsida kõikide processide käest, antke mulle tulemus ja koguda 16 tulemus ühte processi kokku ja panna see näiteks arvutatud maatriksi vektori arvutuse tulemus, mis on hajusalt arvutatud, siis tagasi kokku näiteks üheks vektoriks või pealik processis. Aga see oli ka selline suhtselt madalatasemet programeerimine, mis tänapäeva on järjest vähem populaarseks jäänud, kasutatakse peamised sellistes superarvutites ja ästi arvutusmahukate arvutuste pool, kus on hästi tähtis, et optimeerida ästi madalatasemel nagu jõudlust. Pige mingi big data arvutust, siis kasutatakse palju kõrgemataasemeliseid tarkkavaraad. Vältida sellist madalataseme programeerimist, kus me peame tegelema üksikute sõnumite saatmisega. Ja see on ka üks põhjus, miks on kasutusele võetud hajus objektid ja hajus meetodid, millest ma räägin siis järgmise lueng. Võib-olla natuke huvitavam osa teeaks, kuna seda kasutataks ka tänapäeva hästi palju erinevates mikroteenustes ja webitehnoloogite puhul, on pigem need teatate järekordade suhtlused. Idee on siis, et meil on mingisugused protsesid, kes tekitavad anmed, kes saadavad anmeid ja meil on neid mõepall erineva tüüpi ja meil on mingisugused protsesid, kes on huvitatud anmedte kätte saamisest, et näiteks neid panavad selle anmebaasi ja meil on mingit IoT sensori, mis genereriood need anmeid võib-olla mingi mobiil programmiid kasutate telefonides, mis saadavad mingisugused hetke asukohtad, näiteks kus kasutate asub, et demageografist, koordinateid ja midagi. Ja selle aseme, et need anmeded toodjad otsse saadaksid anmed soovietele, me kasutame sellised vahe vara, ingliskelesis message oriented middleware, kus me tekitame postkastid, kuhu saab need anmed saata, et näiteks ühe rakenduse klendiid siis saadavad topik A-se, anmed teise rakenduse klendiid näiteks saadavad topik B-se ja kui on nüüd mingisugused, teised programmid või processid, kes soovivad need anmed kätte saada, siis neimad lihtsalt peavad teadma, millises selle postkasti need anmed saadatakse ja kuulama seda postkasti. Ja siin on erinevad mustrid, kas kui on sellel postkasti nelikuulejad, kas nad saavad kõik samad anmed, kas anmed replitseeritakse, kui on nelikuulejad ja siia saadatakse sõnu maa, kas kõik saavad sõnuma jaa kätte. Või siis, kui me tekitame sellise tööde järjekorrat, me soovime pildi töötlus teha nelja, et meil on kolm klendi, kes saadavad see piltte ja me soovime, et hajutada pildi arvutusi nelja, konteeneri nelja programmi vahel või nelja protsesi vahel, siis me saame tekitada siia, et kui tuleb esimene pilt, see läheb esimesele, kui tuleb teene pilt, läheb teisele, kolmas pilt läheb kolmantele, neljas pilt on neljantele, viies pilt läheb oost esimesele, kas või selline round robin lähenemine anmed hajutamisel. Seda saab tihti defineerida vahevarat asemel, et kui meil on mingisugune topik, mingisugune postkast sinnet, kuidas need anmed jakatakse kuulete vahel, kas kõik saavad koopia või jakatakse vahel ära. Ja siis kohel erine rakendusele meil võibki olla kaks erine topikud ja need isoleeriteks lihtsalt loogiliselt või tarkku arv asemel, et tihti klientid saavad ise otsustada, mis teemat nad kuulavad või mis postkast, mis järekorda nad kuulavad ja see meie klientid, kes toodavad anmed ei peagi tegelikult mitte midagi teadma klientides, kes anmed kuulavad ja üks hea elis on, et siin peavad kõik poordid lahti, olnud et internetis saaks jää ühenduda, aga tegelikult need klientid ei pea nagu luba ma ühtegi välis ühendust, mida nad ise ei ole algatagud, et nemad algataad nagu ühenduses selle vahevaraga. See võimaldeb natuke turvalisemaid lahendusi luua, aga võib-olla see 100% karanteerid. Ma tahan, et kuulaja saaks anmed kätte hästi lühiks aja jooksul, siis tegelikult sul ei ole võimalus kontrollida, kas kuulaja on elus või mitte. Sa saadad selle anmed siia ja loodad, et kuule ja praegu kuulad. Otsesuhdlus, mis on sõnumid otsesaadmene võib-olla võimalda natuke täpsamad kontrollida, kas teine osapool sai sõnumikätt või mitte. Kuigi ikka tihti pakutakse erinevaid võimalusi selle kontrollimiseks selle vahevarapolt. See võib-olla näiteks niimoodi, et saadatakse ainult nendele, kes on hetkel aktiivselt ühenudunud. Et neid on erinevaid mustreid, kudas on. Me nägime natukusest rapid MQ kohta ka, et sul on võimalik tekitada järjekord, kus sõnumid saadatakse kohal ainult nendele hetkel kuulejatele, aga sul on võimalik ka selline püsiv järjekord tekitada järjekord, kes on tegelikult. Ja siis on kõik, et tegelikult on järjekord, kes on tegelikult on järjekord, kes on tegelikult on järjekord, et nendele hetkel kuulejatele, aga sul on võimalik ka selline püsiv järjekord tekida sõnumid peab alles, et kuule ise küsib, et Anna mulle esimene sõnum järjekord, sõna teine, Anna kolmas, ma olen hetkel seitsemante juuras. Et järjekord on seda sõnumid, aga ma ise nagu kerin niöelda järjekordade vahele. See lisati vist suhtselt hiljuti paarast takas rapidis, et seda võimalik teha. Ja see vahevara otsustabki seda, mida ta võimaldeb ja kudas. Ja siin kasutane saad tihti valida, et mis järjekorra või poškasti tüüpise kasutada. M-kütiti puhul sulle seda valik, et tihti väga ei ole, aga rädid või kafka võimalda, et väga sellised keerukad mustreid kasutada sõnumidne kohale toimetamisele. Ma vaatan, kas ma midagi ära omustunud. Ja tihti ütleme, et me soovime teha mingisugust webi tarkvarad, et siit tuleb päring ja siin on mingisugun webi tarkvarad, mis peakse oleva päringul vastava. Kuidas me seda tegime sinna? Seda on suhtselt keeruline teha, aga põhimise, et kuidas sa töötab niimoodi, et meil on klient, kes adab päringu, aga ta tekitab siin järjekorda enda eaks. Ta saadab päringu, mida peaks mingisugun webi server töötlema, aga ta tekitab siin ka enda järjekorda, kui tema nagu selline töö või sõnum jõuab kuhugi töötlejasse ja töötlejab peaks nüüd selle kudagi tagasi saadma originaal sellise klientile. Ja kuidas see töötab, et see protsest tekitab siin enda unikaalse järjekorda ja saadab selle järjekorda aadressi kaasa oma sõnumiga. Kui see sõnum töödelteks ära, siis vaadad ka sõnumise eest, mis on see järjekord, kuhu peaks tulemuse tagasi panema ja siis publiseeriteks see tulemus ja teise järjekorda ja see protsest jääb kuulama seda järjekordad. Ka sellised mustraid on võimalik teha, et tekida sellist aasünkroonsed suhtlus, kus me tahame, et vastus tagasi jõuaks originaal selle klientile. Kõige madalal tasemel teadate järjekordat, et primitiivid on sellised, et me võime järjekorda mingisugus uue sõnumi lisada. Me võime kuulata, kas sõnumi järjekorras on mõni järgmine sõnum ja jääda kuulama niimoodi, et anna mulle sõnum ja kui sõnum tuleb, siis ma käivitam mingisuguse metodi, et see on selline callback-metod, et iga ma jään kuulema, kas on uusi sõnumid, iga sõnumi kohta ma käivitam mingisugus püüta metodi ja see metod on siis vastutav sellest, et mida selle sõnumiga teha. Ma võin ka pollida, lihtsalt käia küsimas, kas hetkel on sõnum, võtas see sõnumid kätte ja siis väljude, ma ei jää kuulama, aga ma isa otsustan, kunama uuesti, siis lähen ja küsin sõnumid järjekorrast. Või siis ma tekitam sellise notify, et mu process võib jääda täiesti magama, aga ma saan signaali ja minu program või process käivitatakse Linux kernel-poled uuesti üles, siis kui sõnum tov järjekordad. Ma defineerin, et ma jään sõnumi tootama, aga ma ei pea jääma aktiivselt tootama, on okei, kui minu process panakse pausile ja ei kävitada enne, kui tuleb mingisugune üles sõratamine sõnumipolt. Et see võimalatab sellist natukene targemad või efektiivsemat processid töötlust, et ma ei taha tegelikult pollima jääda igavesti, et meie process kulutab, processi raega lihtsalt selleks, et kontrollide, kas seal midagi on, või jääb kuulama aktiivselt ja jääb tööle ja aktiivselt kuulama. Ja siis on võimalik ka sellist notify põhist eratamist kasutad, et me lubaame arvuti processoril selle processi magama panna, kuni tuleb uus sõnum ja siis saame notify signaali ja siis eratavadks selle processi uuesti üles. Ja kui me ehitame hajus rakendusi vajus sõsteeme selliste teadate järjekordadega, siis meil on tihti vaja defineerita, mis on sellised lähte järjekordad, kus me anmeid kuulame, mis on siht järjekordad, kuhu me anmeid saadame. Me peame meeles pidama, mis on järjekordade aadresid nimed, kus on see anme paas, kus sa asub. Ja see järjekordade nimed on suhselt keeruline, mida te isepraktikumis ka näet, et kui hästi te aru saata meie praktikumikireldusest, et kuidas need järjekordade nimesid kasutada. Meil on vaja üles jääda kusakil siis see vahe ja vara järjekordahaldurid, mis samuti peab jooksma teenusena kuskil serveris. Mõnikorda on meil vaja nagu mingisugust edasisuunajad, mis kuulavad mingit järjekordaja, otsustavad näiteks, et suunata, sinna tulevad teatud tüüpvisõnumid kuhugi mujal. Näiteks, et meile tulevad sisse pildifailid, aga kui on png-failid, siis me tahame töödelta neid ühe processi poolt ja kui on näiteks jpg-failid, siis me tahame teise tarkvara poolt näid töödeldasime, võib-olla teeme järjekordade vahelselt sellised ümper suunajad. Meil tekelikult tekib selline järjekordade võrk. Selle asemelt ma ainult mõtlem selle peale, mis on neid processid, mis jooksevad ja kuidas nad omavahel ühen tuvad. Me peame ka naku haltama järjekordade võrku, et kas kõik järjekordad on loodud tekelikult sell vahe varas. Muidu meie processid ei prugi töötada, kui midagi on puudu. Ja nagu loogilselt asemel sellise programeerijana, kes on vastutav arhitektuurie, et nemad peavad siis mõtlema ka nende järjekordade võrku peal, et kust kuhu anmeid saadetakse, sest te ka näete praktikumiseb, see on suhtselt selline keeruline olukord, kus te peate kontrolli, et ega kokemat, et mul kaks erinevat processi ei saada samas viis järjekordanmed, et siis seal lähevad need sõnumid, erinaat tüüppi sõnumid sassi ja mina arvan, et selt tulevad ainult sisendanmed, aga millegi päris saadetakse sinna ka alerte ja siis ma proovin töödalt anmed, aga need ei ole sisendanmed, ne on teist tüüppi anmed, siis minu tarko oli tööta, aga koodis mingid probleemi ei ole, probleem on järjekordade nimedes, et valesti on järjekordade nimed konfigureeritud. Ja järjekordade see vahe vara tihti nimetatakse, kas Englis käis näiteks brokeriteks või estikeles makleriteks või halturiteks on sõnumid järjekorad või anmed brokerid. Meil on probleeme anmedte tüüppidega, et SQL anmedbaaside puhul me paneme paika, meil on tabulaardad anmed, meil on anmedtel tulpad, tulpadel on tüüpid ja nimed, aga sõnumides seda tihti nagu paika väga panna ei saa, et me võib-olla paneme paikat. Meie tarkvara saadab Jasoni ja kuule, et teavad ette, et meile tulevad Jasonid seld järjekoras, aga mis siis, kui järjekorad ta tuleb mingisugusid pinaarsed anmed lopiselt? See tuleb tegelikult kokku lepida klientide tasemel ja sellised maklerid ja brokerid tavasti isegi kontrolliseda, et kas järjekoras on Jasoni mitte, nemad lihtsalt vaatad need anmed kui pinaarsete objektidena, mida siis klientid peab parsima Jasoniks enda tarkvara parseritega. Tegelikult sõnumid võivadki sisaldada üks kõik mida ja brokerid tavaltsid seda ei kontrolli. Klientid peavad siis või see tarkvara peab kokku lepima, mis formaate kasutatakse hajussüsteemide komponentide vahel ja arvestama, et kui lubatakse erinele formaate, et kudas seda kontrollitaks. Kui me lubame samas see järjekord saada erinaid tüüpi pildifailid, siis kes kontrollib seda, mida tahaks see PNG-ega ja mida tahaks see JPE-ega formaatika pildidega. Meil võivadki tekida speciaalsed sellised hajussüsteemi komponentid, kelle üle saan ongi valiteerida või kontrollida või ruutida neid sõnumeid vastavalt nende sõnumide struktuuridega. Hea on neid tavalst vältida kui võimalik. Aga isegi, kui me teeme nad, siis hajussüsteemi mõttes on tavalised komponentid, mis kuulavad järjekordasid ja kirjutavad või publiseerivad mingitase järjekordatasse. Kui meil on mingisugused sellised valiteeriat, kes kontrolli, jõudkas sõnuma on õigest formaatise mitte, ja see otsustavad kuus seda edasi saata, siis hajussüsteemi mõttes või süsteeme arhitektuurimõttes on nad tavalised protsesid, kes samuti kuulavad ja saadavad sõnumid järjekordasse. Üks selline lihtsam sõnumid järjekordade põhine protokoll on MQTT, selleks on mituimplementatsiooni, ma näiteks Mosquito on kõige lihtsam MQTT implementatsioon. Pilvedes on erinevad võimsomad implementatsiooni nagu ActiveMQ ja RapidMQ ei ole MQTT. MQTT ja RapidMQ, te MQ on küll väga sarna asja, MessageQ või põhimestel on need erinud asjad, et RapidMQ ei ole MQTT. MQTT kasutab sellist anmete avaldamise ja tellimise mustrit. Meil on anmete loojad, kes publiseerjavad anmeet ja meil on anmete lugead, kes tellivad siis anmete kohale toimetamist. Ja üldjuhul seataks MQTT üles eraldi servelete, nad me ei embedi seda kui tegama tarkkora sisse, vaid me seame üles mingisuguse IP-adressi ja porti peal ja hakkame sinna sõnumeid saadma ja selt sõnumeid kuulama. Me saame siis hajusesteemide komponente panna sinna ühenduma, et kõik IoT sensorid paneme näiteks sinna publiseerima anmeed. Ja kui meil on mingisugun tarkkora, mis soiv visualiseerida anmeed, siis me tegitame tarkkora, mis on võimelne MQTT teemasid või teatete järjekorda siis kuulama ja võib-olla visualiseerib siis JavaScripti abil näit IoT sensoridte poolt saadetud anmeed. Ja ta soovib väga hästi A-sünkronseks suhtluseks. Sünkronset suhtlust ongi raske nagu tegelikult tekitada MQTT abil. Meil on siis mingisuguna hulk sõnumite tootjad, N-sõnumite tootjad ja mingisuguna hulk M-sõnumite kuulejad. Et see võib-olla näiteks 10 000 ja see võib-olla üks, et kui meil on selline IoT elahendus, kus on üks server, mis anmete kuhamisega tegeleb ja 10 000 sensorid, mis saadavad. Ja me saame jagada nend kõik sõnumid, mis tulad siis N-sõnumid, siis M-kuula vahel ja meil ei ole vaja mingisugus keerukad sünkroniseerimist tekitada, et kes saadab mis ajal või kes kuulab mis ajal või kes peab vasta õtma võid. Meil ongi lihtsalt, et mõnevõt ühenduvad MQTT-tise ja kas saadavad või kuulavad anmeid. Lihtsustatud ilustraksioon, kuidas see töötab, on see, et meil peab olema mingisugune anmete saatja, meil peab olema siis see vahevara, kes tegeleb anmete saatmise või vastuvõtmisega ja meil ei pea olema anmete kuulejad. Kuulejab võib olla ilmas aatjada, aga siis ta ei saa mingid anmel käete. Ja anmete publiseeria ei pea eksisteerima ja anmete kuule ei pea eksisteerima, et põhimõtteliselt võib akata tööle siis, kui andüks nendest on. Aga eheldem, et ta saatja on esimene, et tema teb ühenduse brokeriga, et proovib ühendus saada ja siis teeb põhimõtteliselt saab vastu, et jah, ühenduse tegemine õnnestus ja tal tekib ühendus, kus kaududa saab anmete siis saad makata. Siis näiteks meie IoT-sensor teeb ühenduse brokeriga ja siis alustab tööd, aga sensoritelt veel mingida väärtase ei kuula ja ei publiseeri veel anmeid mingi aeg. Ja samal ajal pärast seda võtab siis ühendust mingisugune mingi anmete tahtja, kes samuti võtab ühendust brokeriga, et ma soovin ka ühenduda brokerisse ja saab samuti vastus, et ühendus õnnestus ja tema nüüd saadab teat, et ma sooviksime mingisugust teemat kuulata ja tema võib olla näiteks delta punkt kolmas korrus punkt ruum 3040 punkt temperatuur. Tihti kasutadaks sellise mitmed asemelisi teemasid, kus me kirjaldame ära, et mis anmetega tegu mingi asukoht ja mingit sensori või anmete tüüp. Meil võib siis olla näiteks delta punkt korrus punkt ruum punkt anme tüüp, et ma soovin oma kontoritemperatuuriväärtust siis kuulata. Ja ma ütlen, et ma olen siis kuvitatud sellest teemast ja ma saan vastu nagu kinnitus, et ja, see õnnestus ja siis ma jään nagu kuulama seda teemat. Ja idee on siis see, et mqtidiprooker saadab sellega teemaga seotud anmed tagasi, kui need tekivad siis mqtidisisse. Et ma panen paikse, ma taan delta kolmanda korrus ruumi 340 temperatuuri kuulata. Ja kui see sensor on siis minu toas või ja tal on ühdust sensor, stakab näiteks iga ühe minuti oksu, iga ühe minuti tagant saadma temperatuuri anmed näiteks. Ja siis sensor ise defineerib, et mis teemag anmed ta saadab. Et ta saa võib oppi saata mingit muud anmed, aga eheltev, et meil on sensor siis sama topikuga, et selle korrusse, selle tuatemperatuuri väärtus oli mistas on 22 graadi. Ja kui see topik vastab sellele topikule, siis need anmed, mis siia saadatakse selle teemaga, saadatakse edasi siis nendele klientidele, kes on sellest teemast huvitatud. Ja selline anmedte kohale toimetamise loogika ongi siis teemade põhine. Et mina defineerin, mis teemast ma on huvitatud ja kui selle teemaga seotad anmed tulevad, siis need saadatakse mulle kohale. Ja siin ma ei pea koku panema sellist e-maili postkasti adressi, et kuhu ma soovin sõnumeid kohale toimetada, vaid ma defineerin sellise loogilise patternmatchimise põhise teema, et ma olen teatud anmedest huvitatud. Ja selline subscriber klient võib tegelikult defineerida mitmed teemad, et ta võib olega teistest teemadest huvitatud, vajadusle kasvõi sada teemat. Et ta defineerib, et mis teemadest on huvitatud, et mis teemadel ta nagu subscribib. MQTis pigem mitte rapitis ja, aga rapitis see töötab ka teist moodi. Rapit on suhtse tereinev sellest, kuidas see MQTis töötab. Aga MQTis ma defineeringi niimoodi, et ma saan kasutada selliseid teema, alam, stringid eraldade, mis on kaltkripsud. Ja nendelt asemel ma saan defineerida sellised wildcardid. Näiteks ma olen huvitatud, kas my home ground floor living room temperatureist või ma olen huvitatud my home ground floor üks kõik, mis toa temperatuurist. Või siis ma olen huvitatud kõikidest andmetest, mis on my home ground flooriga seotud. Ma saan kas ühed aseme sese wildcardi kasutada või siis mitmed aseme wildcardi kasutada, niimoodi, et ma defineerin, et minu sensorit sada tundus sellise struktuurikandmeid ja siis ma saan kuulata sellised teemased. Ja see võimaltaab defineerida sellist grupid andmetest, kui ma olen hästi designinud teemadestruktuuri. Aga kas see on siis midagi, mida rakenduse arenda ja päris väljamõtlem hakkama, et mis on see teemadestruktuur, millisugused sellised päringuid ma tahan defineerida nende teemade tasemel, et ma ei saa tegelikult andmebaasi päringuid teha, ma saan lihtsalt kuulata teatud struktuuriga sõnumite teemasid. Is kui ma kuulan my home ground floor, cult creeps ja seda trelle, siis kõik, mis algavad selle prefiksiga, jõuvad kohale. Kui ma seda teemad kuulan, siis mulle saadadks kõik andmed, mis on seotatud teemadega, mille on selline prefiks. Ja tegelikult MQTC's ei olegi nii väga erinevad järjekordi, pigeme nagu üks järjekord ja te partitsioneerida andmeid siis põhimõtsalt nende teemade põhjal. Kuigi loogiliselt tekivad nagu järjekord, et mul on selline järjekord, mul on selline järjekord, mul on selline järjekord, aga siis implementeerimised asemel on nagu üks hiigel sur järjekord ja lihtsalt partid, teemade filtreerimined või andmete filtreerimined nende teemade mustrite põhjal. Ja ma saan ka defineerida nagu quality of service, et kas sõnumid viiakse kohale kõige rohkem üks kord, et karanteerid, et mingisuguna alarm näiteks ei jõua kohale kaks korda, see on nagu nul kvaliteetitase, kvaliteetitase üks on sõnum edastataks alati vähemalt üks kord kohale, et see vahevaras siis karanteerib, et kui ma olen sõnumi saatnud vahevarale ja ühendub sõnumite kuule ja siis ta saab vähemalt ühe korra sõnumi kätte, aga ei karanteeri, et ta ei saa mitukorda seda kätte, et võib-olla korraatakse seda, et näiteks, kui klendi käest ei onestund saada kinnitust, et sõnumi jõudis kohale, siis saadataks uuesti, kuni saab kinnituse. Ja siis on võimalus ka defineerida vahevarad asemel, et ma tahan karanteerida, et sõnumid jõuad kohale täpselt üks kord, et kui ma olen sõnumi saatnud ja hiljem ühendub klient, siis see klient saab sõnumi kätte, et eht kontrolliteks üle, kas ta sai sõnumi kätte ja karanteeriteks, et ta ei saa kunagi rohkem kõikskohal seda sõnumid kätte. Ja see toimub taustal, et vahetatakse paket, et küsiteks kliendid, kas sa oled sõnumi kätte saand, kui klient ütleb, et ei ole, siis saadatakse sõnum ja küsiteks, et tema kas koko aeg kas oled kätte saand. Ja siin on sisse eitada sellised kontrollid ja acknowledgemendid, et karanteerida, kas sõnumid saadatakse vähemalt üks kord kohale, kas sõnumid saadatakse kõige rohkem kõikskord kohale või siis sõnumid saadatakse täpselt üks kord kohale. Ja kui teid huvitab, nagu server jõudlus või selle vahevarajõudlus, siis 0 on kõige lihtsam ja 2 nõuab palju rohkemad võrguliiklust, et karanteerida, et anned tõesti jõudsid täpselt üks kord kohale. Ja vastavalt sellele toimub see protokoll, siis kuidas täpselt need sõnumid kohale toimetatakse. Siin on üks näide, et kui ma tahaksin implementeerida mqtj brokeri abil lampide sisse väljal ülitemist, et kuidas ma saaks saa teha, et ma näiteks tekitan siis mikrokontrolleri, kes on ühendatud lampidega, tema saab saata analoog signaali näiteks lampile, kes lampe sisse või väljal ülitada või on digitannesignaal mis ikanes. Tema on võimelle, siis lampi toas sisse väljal ülitama ja tema subscribib siis, ta hakkab kuulama, kas talle on uusi lampide sisse või väljal ülitamise operatsioone ja ta hakkab kuulama sellist sõnumid teemat nagu home slash office slash lamp, et see on minu kodu officei lamp ja kui siia tuleb sõnum on, siis ta saadab sisse lampile signaali lüüta sisse, kui siia tuleb sõnum off, siis ta lüültab ta välja ja nüüd sel eks, et seda lampi sisse väljal ülitada, peab mingi klienti ühenduma ja mqtitiseja saadma siia selle topiku ka selle teemaga sõnumi, mille sisu on, kas string on või string off. Ja nüüd klient saab seda teha, klient peab teadma, kus asub mqtiti broker, aga klient ei pea teadma, mis on sellega mikrokontroller IP-adress, ei pea teadma, mis on selle mikrokontroller port, tema peab teadma, kus asub mqtiti broker ja mis on see teemade struktuur, et mis on näiteks lubatud asukohad, mis on vajalikud sõnumid, mida saata ja nüüd saavad siia üks kõik, mis klientit nagu põhimõtteliselt spamida näiteks need on ja off operatsioone ja tarku ära mikrokontrolleres võib-e lihtsalt isegi otsustab, et kui siia tead, et mingi mingi mingi mingi mingi näiteks kolm off järjest, mida siis teha. Senna ja sa pautentimise siin peale pan, et on kasvutanimia parooli näiteks ja jagada nendele klientidle siis kasvutanimesest parooli, aga siin peab olema kasvutanimeid paroolid. Sa võid ise seata ilma kasvutanime paroolid ta üles mkittiti broker, kes ei ole hea mõte. Ja rapidis saab rohkem nagu kontrollida, mis suurkust kasvutad ja mis nende roolid on, aga mkittiti siia saab lihtsalt kasvutanimesed ja proole defineerida klientidle. Ja mõlemad on tegelikult klientid, ainuke server ongi siis mkittiti broker ja klientidel siis ei ole vaja portte lahti hoida, et teevad ühenenduse ja selle ühenenduse kaudu põhimistad saavad vastuseid mkittitigest. Jah, aga seal saab kontrollida seda, et sa lubad ainult. Kelelt sa lubad sinna pakete? Jah, sa saad sinna tulemyrii tasemel pana reeglid, kellel on lubatud avaliku portte almet saata. See vahe on see, et sa ei pead seda ette paikka panema saa tarkovaratasemel otsustad, et sellel tarkovaral on lubatud ise teha ühenendusi, aga ühtegi sisse tulad ühenendusti olla lubatud ja sa lubad ainult need ühenendused, mida see tarkovara ise on teinud. Ja sa ei pea tulemyrit tasemel midagi muud konfima, kui panad kõik portit kinni ja lubad ainult need ühenendused, mis on seotud välja minem ühenendusega ja siis rohkem reeglet seal vaja ei ole, et sa ei pea ette teadma, okay, ma luba sellel arvutil Tallinnast ja sellel arvutil Soomeest ühenenduda. Sa lihtsalt lubadki ainult nendel arvutil tüül ühenenduda, kus siit on välja minev ühenendust tehtud ja see on nagu see on hästi lihtne tulemõri reegel, et sa lubad väljavad ühenendused ja selle väljavad ühenendusega seotud tagasi tulevad ühenendused. Vist operatsioonid süsteemid aines ka seda nagu võrgu ruutimise praksis nagu prooviti, et mis on see IPT plus rule, mis lubab selle tagasi tulevad ühenendustega seotud paketid. Et me panime üles ühes projektis anmebaasi ja praeg on lubatud sisse tulevad ühenendused ainult Tartu linnavalitsuse võrgust ja Tartu ülikolivõrgust ja muualt ei ole lubatud ja iga uue regli me lisame sinna pohjumist käsitse, et kui me luba mingi partnerlikasin anmebasi ühenenduda, siis avame näed poordid nende jaoks, et seda on alati võimalik teha lihtsalt lihtsam on turvata, kui peaselis speciaalselt regleid juurda panema. See otsaselt ei karanteeli midagi, et kui keegi proovib männende midale täki teha ja kuulab pealt, mis see sõjandust toimud ja alati on võimalik röönaata. Aga see musta selles mõttes lihtne, et nüüd ei pea enam teadma paljude mingite väikeste seadmete IP-adressi ja me võime sellist hajussüsteemite vahelise ühenenduse ehitada selle mqt-brookerid asemel, et me ei halda serverite komponentide asukohta vai sellise vahevara asukohta on ainult ka vajalik informatsioon meil. Ja natuke võimsam protokoll on siis Advanced Messaging Queuing protocol, mis on siis alkatatud 2006 aasta ja esimene versioon, selline ready to use versioon on 2011. Üks kõige tuntumaid implementatsioon on RapidMQ, aga ka näiteks Apache ActiveMQ ja Pilves on palju erinevad nagu Azure Service Pass, Amazon MQ implementatsioone sellele. Rapidid kasutatakse dihti mikroteenuste puhul, selleks et teha sellist asunkroonsed ja järekordade põhist ühenendust mikroteenuste vahel, et kui meil on hästi keerukad mikroteenuste põhised justiemid, et siis on hea nagu selline anmete buferdamine ja anmete jagamine teha nagu sellise vahevarat asemel mitte panna see nagu protsasside enda kaela, et kudas seda täpselt teha. Ja ta on seda avatud standaard, siis sõnumitele orjenteeritud vahevar ajaks, ta on täiesti asunkroonne kui seal saab natuke nagu asunkroonsed suhtlust teha ja täiesti nagu järekordade põhine. Ja tegelikult te võisite märkata seda ja ma isegal seda ütlesin, et siin nagu mõnes mõttes võib-olla ei tekigi paljusid järekordasid ja meil see subscriber tegelikult ei ühen tou järekordada, aga panep paika sellise anmete partitsioneerimise ja filtreerimise operatsiooniselle nende teemade põhjal. Aga rapidis tekivad tegelikult konkreese järekordad ja klientid saavad ühenud olema järekordad, et anmete kuulata, nad ei saas suvaliselt defineerida, et mis on see anmete päring või niimoodi. Kuigi tegelikult saab saavud tehtseelt sama tulemuse, aga see toimub natuke erineval viisi. Ja seal on nagu anmete krüpteerimine, anmete autentimine või kasutate autentimine ja seal on väga erinevad viisid, kui saab kontrollida, et mis kasutatel on lubahtud teha. Isegi võimalik märjata, et see kasutaja ei saa rahkem saada anmeid kui näiteks 200 megabaiti päevas, midagi sellist, et saab anna isegi sellised piirangud peale kasutatele, et mis on lubahtud korraga saata. Ja IMQB on palju selline keerukam, et meil ei tekki ainult nagu järjekorda, kuhu me saadame anmed, järjekordi, kust me anmed loome. Et mul on täiesti erinevad anme, ütleme anmestruktuurid või olemid, kuhu me anmed saadame, et me saadame saata ainult exchange anmed, mis on sellist ühenudusõlmed serveri sees ja me saame saata näiteks IoT või Delta maja exchange anmed, et siis seal exchangei sees on kõik Delta ka seotud anmed võimõtselt. Ja järjekord on ainult anmed kuhulamiseks, et exchanges on siis anmed saadamiseks ja järjekord on anmed kuhulamiseks. Ja teemad asemel on meil sellised väga sarnaased asjad nagu rootimis võtmed, et kui me saadame mingisugus sõnumi, siis me defineerime, et mis on selles sõnumi nagu rootimis võtti, mis kirjaldab ära, mis anmed tegab tegu. Ja see on põhimõtselt sama asi, mis see teema MQTD sees, et see on selline string võt, mis on mitmed asemelne võt, mis defineerib ära, millega on see anmed seeotud. Ja selle põhjal teaks anmedte rootimis, siis exchanges ja kiuude vahel, ehk anmedte saadjade ja anmedte kuhulete vahel, siis rootitakse anmed, dynamiliselt nende rootimis võtmed põhjal. Aga see võtti võib olla meil saamoodi, et näiteks myfloor.calcgripseasemel on meil nüüd punkt, punkt livingroom, punkt temperature, et see struktuur on põhimõtselt samasuguna. Ja me tekitame nagu rootimistabeli, et misugused sisse tulevad anmed exchangei, me rootime misuguses see järekorda ja selleks kasutatakse sellised asjid nagu bindingud, et nagu rootimistabeli reeglid või rootimisreeglid, mis defineerivad, et misuguse mustriga võtid panna misuguses see järekorda. Ja neid saab dynamiliselt luua, et põhimõtselt sellest exchangesist, selle mustriga rootimis võtimega anmed panna sinna järekorda. Ja sõnum on siis mingisugune sõnum, mis saadatakse exchangei, rootiteks see bindingu põhjal mingisuguses järekorda ja sõnumil on mingisugune sisend anmed, mingisuguseks pinnaase tanmed näiteks, tal on ka heederväärtused nagu HATTP pool, et me saame seadistada, kes oli klient, kes sinna tanmed saadis, mis on objektiis suurus ja siia saab juurde nagu heederväärtusi panna, mingisuguseks võtti väärtustilis meta info ja rooting key on üks meta info, mis on seadud selle sõnumiga. Ja sisu on lihtsalt mingi pinaarna objekt ja samuti klientide tasemelise otsustadaks, et kas meil on JSON, mida me saadame, kas meil on XML, kas meil on mingisugune string väärtus, et klientid isa otsustavad, et kuidas nad parsivad seda pinaarsate objekti ja seda tavast ei panda mitte kuiidagi paikaa, kas exchangei või Q tasemel, et mis objekti on lubatud sinna saata ja see on tehti mõnikad probleem, et kui sinna saadatakse vale tüüpi objekti, et siis JSON või XML parsimine klientis siis feilib võib-olla. Ja peame erinevselt on, et me saadame andmed exchangei ja me kuulame andmed siis järekorrast. Ja peame erinevselt on, et meil on sellised exchangeid või ühendustölmed, et andmed ei saadata otsa järekorda ja meil toimub selline reglite põhine marsrootimine ja enam ei ole, meil on üks muster, mille põhjal me marsruudime, või meil on olla sada reglit, mille põhjal me saadame või kogume mingid andmed kuhugine. Ja järekord on päris erineva asja sellest MQTT teemadest. Ja pigem meil ongi teemad on samad, mis ruutimis võiti ja meil on palju järekordasid ja palju nagu exchange, kuhu andmed saada. Ja meil on ka sellise tüpilid operatsioonid, mida me saame bytonnist näiteks väljakutsuda, et me saame luua ua exchangei, et me looma näiteks delta andmed exchangei ja sinna hakkavad meie klientit delta ka seotud andmed saadma. Me saame tünaamilselt püütonnist luua uusi järekordasid ja me saame järekordadele defineerida, et mis suguste ruutimis võitmedega on, et me tahame sinna järekorda saada. Me saame püütonnist ise defineerida, loome exchangei, loome järekora ja siis loome reglid, kuidas näide järekora ja exchangei pahel andmed ruuditakse. Ja näid bindingud võib luua meie oma tarkvarat tünaamilselt reaal ajas, mis iganes ajal võib neid eemadada, võib neid lisada, et meie tarkvaram võimeline kotsustama selle ruutimis üle, et ei ole administraatoreid, kes ruutimist defineerib, vaid tarkvaravõib isene defineerida. Et kui me mk-tidis puhul pidim panema, et ma kuulan selle mustrig andmed, siis nüüd me võime defineerida, ma kuulan selle mustriga, selle mustriga, selle mustriga, selle mustriga andmed niimoodi, et ma tekitan järekorva ja panan selle järekorval paik, et mis exchangeist, mis andmed kohale juovad ja siis ma hakkan seda järekorda kuulama, et ma saan nagu tünaamilselt tarkvaratasemel selle teha. Ja siis ma võin publiseerida uusi sanumeid, siis ühendus salme näiteks delta exchangei ja siis ma võin resiiviga agata mingisugused järekordased kuulama ja võttaja järekordast järgmised sanumeid. Ja meil on ka erinevad exchangeitypid ja erinevad järekordate tüibid, et neid mustriid tegelikult on päris erinevad. Aga need on nagu sellist baas operatsioonid, mida ma pean tegema, et exchange peab kas eksisteerima või ma päen selle looma, järekord peab kas eksisteerima või ma päen selle looma ja kui järekorda loon, siis ma pean ka panema paik, et mis need routings regli teht, need bindingud on selle järekora jaoks. Sest muidu ühtegi andmed kohale jõua, seal on mõned agad, et teatud tüib järekordat on nagu defineeritud baas binding reglitega. Ja muste rongi, siis selline, et meil on mingisugud publisseerijad, kes saadavad andmed exchangei, meil on mingisugud konsüümerid, kes kuulavad andmed järekordadest ja keegi peab olema paikka pannud, kuidas need routimine toimub. Et kuidas siis exchangei vahel routiteks järekord 1 ja kuidas routiteks järekorda 2 ja selle jaoks on igal järekoral mingisugune hulk binding regleid, mis siis otsustab, et mis mustriga andmed liiguvad siia või siia. Ja neid bindingud võib tegelikult olla ka erine tüüpi, et ma võin rootida mitte ainult nagu rootimis võtme põhjal, aga ma võin rootida ka näiteks nende sõnumi heederväärtuste põhjal. Ma võin näiteks öelda, et mul on siin regel, mis rootib kõik teltandmed siia, aga ainult siis, kui filei või selle sõnumi suurus on suurem kui 10 MB. Ma võin ka sellised regleid teha nagu sõnumite metaandmed heederväärtuste põhjal samuti tekitada nagu sellised rootimis regleid. Mis natuke lihtsustab asi, et ma ei pea defineerima näiteks rootimis võtme see, nagu filei suurustu midegi sellist. Et ma ei pea kõike selle rootimis võtme siis ära peitma. Aga sõnumite marsrootimine toimus saa muudi, et meil on selline, me saame kasutada neid rootimis võtmed, et meil on tartu punkt delta punkt välisvalgustase või tartu punkt delta punkt korrus kolm punkt room 340 punkt temperatuur. Ma ei tea, miks ma siin on tartu, et ta pani nagast olla. Ja siis ma saan nagu defineerid, et ma soovin tartu delta korrus kolm kõikide kontori või kõikide ruumide temperatuuri kuulata, et ma saan tekida sellise bindingu, mis kuulab näiteks tartu delta exchange-i ja kõik sellise struktuuriga andmed siis suunab minu järekorda ja siis ma hakkasin seda järekorda kuulama. Ja samamoodi siis tärna on nagu üks sana ja trellid on siis kogu selline prefix. Trellid tavalselt vist väga pahele panna ei saa, et ta peab viimane väärtus olemat. Ja meil on mitu erinaat ühendustõlmede tüüpi, kolm peamist on selline, et meil on direkt, fan-out ja topic-stilis exchange-id. Topic-stilis exchange on põhimiselt sarja nagu MQTT, kus ma kasutan näid routing-key mustreid. Et kui ma tahan sellise mustreid kasutada, siis ma pean looma topic-stilis exchange-i. Ma saan kool uua direkt exchange-i. Direkt exchange-i mõtta on see, et kui mul on klient, mille nimi on Pelle, siis mis igalne asandmed tulevad routimise võtjaga Pelle saadadaks mulle. Ja see ongi kõik põhimiselt. Et seal, kui on järekord, mille nimi on Pelle, siis sinna järekorda Pelle saadadaks kõik anmed, mis tulevad routimise võtjaga Pelle. Et see on võib-olla natuke parem selgitus. Et kui ma loon, et klendi, mille klendi-i idea on Pelle, siis mulle luaks ka automaalt see järekord, mille nimi on Pelle. Ja tekitatakse binding, et direkt exchange-i, et kui direkt exchange-i saadatakse sõnum routimise võtjaga Pelle, siis see saadatakse järekorda Pelle, mida kuulab klient Pelle. Et see võimalatab saata otsa ja anmed klendidele näide klendi-ide põhjal. Ja sinna saab tekitada uusi kiusid ja uusi binding-ud juurde, aga see põhimiselt võimalatab saata otsa klendile anmed, kui sa tead tema ideed. Ja seal on siis speciaalne direkt tüüpi ühendustsõlmed. Ma saan siis sellest, et ühendustsõlme saata Pelle võitma kanmed, siis Pelle klents saab selle kätte. Ja fan-out on siis natuke speciaalne exchange, et ta põhimõtteliselt saadab anmed kõikides järekordades, mis sinna on tekitatud. Meil on fan-out exchange, sinna tekitan kolm järekorda, mis iganes anmed sinna järekorda saadatakse kõik lähed kõikides järekordades. Mis iganes anmed sinna exchange-i saadatakse, kõik saadatakse kõikides järekordades. Et see on speciaalne viis, kuidas ignoreerida ruutimis regled ja saata kõikile järekordadele kõik samad anmed. Et see võimaldeb repliceerida anmed kõikide järekordade vahel. Et see on kaks aesti lihtsalt mustrit, kuidas anmed kohale toimetada, kas klendi nime põhjal või siis kõikidele järekordadele, mis on loodud ja ignoreerida sellised ruutimis võitmeid üldse. Ja siis topik on, mis mokib natuke saama MQTTid, et ma saan siis võitme põhjal saata edasi. Ja MQP protokoll üks peamele, et implementatsiooni on, kus RapidMQs on vabavaralne, saate minna GitHub'i näha, kuidas on implementeeritud. Seel on palju selliseid plagineid olemas, näiteks MQTT jaoks, et RapidMQ saab otsa kasutada sama protokolliga, mis MQTT saab ajastada sõnumite kohale toimetada. Mis näiteks, sa ei taha sõnumite öösel kohale toimetada, sa paned paika, et sõnumite toimetataks kohale töö ajal näiteks. Et kui sul on mingil põhjas vahelik karanteerida, et mis ajal sõnumite kohale toimetatakse ja neid varem mitte kohale toimetada, sa võid ka defineerida, et sõnumite saadatakse mitte kuulajala või totse e-meeli. Et sa on selline huvita 50 saad e-meeli kohale toimetamist defineerida niimoodi, et sul ei pea olema mingi tarkkuna, mis kuulab sõnumeid ja saadab ise e-meele, vaid RapidMQ enda tasemel on rapid võimelne edastama sõnumite lihtsalt e-meeli. Ja seal on ka teisi blokina, et teiste selliste tüüpide jaoks. Või siis defineerida prioriteesed järjekorrad, et teatuda anmed nendes järjekorrades saadataks kohale enne ja mitte vastavalt saabumis järjekorrale, vaid teatud tüüpi, teatud heteri värtsu näiteks, kui heterkii prioriti võrdub 7 juhab kohale, siis tema saadataks enne, kui heterkii prioriti võrdub 2 näiteks. Lisaks on RapidMQ-d võimalik ülesseada klastrina, et me paname rapidi kolme serveri peale tööle niimoodi, et nad jagavad nagu anmed oma vahel ära. Tal on väga hea selline administreerimis liides, mida te praktikumis vaatate, et saate sellekasutajad luua, saate sellekas virtualseid, servereid luua, et näiteks igale rakendu selle oma virtuaalse rapidi oma rapidi sees. Ja on ka kasutajad aseme juurde pääse kontroolle, et saated defineerid, et sellel kasutajal on lubatud ligi peast sellesse exchangei, sellesse järekorda ja saada defineerid, et millele, mida siis kasutajad teha saab ja mida ei saa. Ja ta töötabks siin umbes niimoodi, et kui meil tekivad klendid, siis klendid loovad ühenuduse ja sinna tekivad nagu ühenuduse sellist kanalid, mille kaudu klend saab saada anmed. Kui klend saadab ühti exchange anmed, siis tekib klendi ja exchangei vahel nagu kanal. Kui klendil on kaks kanalid, kui klend saadab kahti exchange anmed, siis on kaks kanalid. Ja need kanalid on võimalik vaadata reaal ajas administreerimis liidesest ja ei seega need kinni panna, kui vajal läks. Aga põhimselt, kui saada kahti exchange anmed, siis käivad kolme kaks ühenudust ja anmed tuleb and exchangei. Ja kui meil on näiteks kolm klenti, kus või, püüta meil on kaks klenti, üks klent, kes kuulab kolmandast järjekorrast anmed. Ja siis meil on üks klent, kes kuulab näiteks kahest erinevast järjekorrast anmed, et siis ka tekivad, iga klendiaks tekivad sellised channelid ühenudused. Ja ruuti, mis reegljad kasutatakse, siis kuidas ruutida anmed järjekordada ja kiuuda vahel. Kui ma näiteks tahan, siis tekitada video töötluse sellise pipeline või video töötluse selline, et mul on klendid, kes saavad videosid saata üles. Ja meil on siis mingisugused hajus anmedöötluse komponeti, mis tegelevad videoöötlusega. Ja meil on siis anmebaas ja me ehitame nagu sellise vahevaran nende vahele, et nende peaks omavalu otsööhendama. Et me saame ehitada selle niimoodi, et klend saadab mingisuguse videoöötluse sõnumi, et mul oleks vaja video töödelda. Aga sellase, et back-end hakkakse iseneid videosid töötlema, siis back-end panev selle töötluse järjekorda. Siin on nüüd kaks võimalust, et tegelikult esimene võimalus ei ole hea. Ei ole panna hea videosisu järjekorda. Tavallest sa salvestad video sõnumi, et meil on kaks võimalust, et tegelikult esimene võimalus ei ole hea. Ei ole panna hea videosisu järjekorda. Tavallest sa salvestad video kuskil ära, et ta näiteks mingi block story, siis minna joos, või kuhugi salvestatud. Ja sa ei pane videot järjekorda, aga sa näiteks paned selle video asu koha järjekorda, et mis file oleks vaja töödelda. Ja sa defineerid järjekorras nagu videoöötluse sõnmused oleks vaja see video ära töödelda. Ja siis sa annad klendile tead, et video pandi töödlemis järjekorda. Ja siis meil on teime hajussüsteem komponent, kelle ülesanam siin videosid töödelda. Tema kuulab, kas on mulle uusi videoöötluse tööd, võtab selle vastu ja teeb selle töödeluse ära. Võib-olla tõmbab selle video alla kuskil teisest asukohast mingist videosalvestus asukohast näiteks Minna Jo või Amazoni CS3-s. Ja teeb see töötlemis ära ja siis saadab tagasi nagu sünnmuse, kiused nüüd või exchange-i, et nüüd on see videoöötluse ära tehtud. Ja samal ajal meie back-end võib-olla kuulab, kas on uusi videoöötlemise lõpetamise sõnumeid siis väljund järjekorras. Ja kui on, siis võib-olla kirjutab anmebaas, et video on töödelud ja video asub siin asukohas ja saab tagasi vastuse, et video on töödelud. Ja see on üks selline lihtne viis, kuidas me saame kasutada sellist vahe järjekordasid, et vahe, kui saadad vahe, vahendada neid suhtlust mingisuguse back-endi ja näiteks videoöötluse. Kus me ei pea panema, et back-end peab saadma otsa sõnumeid videoöötlusele ja videoöötluse ei pea nagu vastuvõtma sõnumeid, vaid töötab videosid ja siis kui videoöötluse lõpendis, võib-olla läheb ja vaatab, kas järjekorras on veel mingisuguse tegevusi teha veel mingisid videoöötlusi ja tihti, et ta kuulab ühte järjekorda ja saadab sest tulemused exchange-i mingisel teise ruutimise võtma, mis suunatakse mingisuguse väljundi järjekorda, kus saab kuulata, et kas videoöötluse on lõpend või mitte. Meil on näiteks mingisugune uue videoöötluse järjekord ja meil on lõpened videoöötlusti järjekord ja me saame neid kasutada selleks, et sellised asynkroonselt väljakutsuda mingisugust operatsioona. Ja siis ei pea meie back-end, polymame baasia võib-olla see video töötus ka ei pea polymame baasi, vaid lihtsalt kuuleb järjekord, et kas tal on mingisuguse uusi töid. Ja tavalsed seda nimetataks ka tööde järjekorra näed, meil on mingisuguse tööt, kas pildi töötlus, videoöötlus, mingisuguse arvutused ja me paneme näiteks 16 videoöötluse protsessi siis töötama ja paneme näiteks 16 videoöötluse protsessi töötama. Ja paneme nad kuulema sama järjekorda ja nad saavad neid videoöötluse operatsioonid oma vahel ära jagada. Ja see ongi tegelikult hästi lihtne või kõige lihtsam viis, kui täs paraliseerida arvutusi sellistas hajussusteemides, et panna tööd nagu ühti järjekorda ja siis lasta tööde tegiate lihtsalt kuulata selt järjekordas uusi töid ja jagada neid tööd nende vahel ära sellise vahevarat asemel, mitte nagu oleks mingi progamm, kes otsustab okkuma. Kelle andas ja kes peab selle töö käevitama? Ei ole sest orkestraerijad, kes ütleb, et sinu töö on see, sinu töö on see, vaid töötajad ise küsivad järjekords, kas mul on uut tööd või ole, kas mul on uut tööd või ole. Jäävad kuulama, kun uus sonum sinna kohal jõuab ja siis hakkavad seda tegema. Järgmises lainkus on näiteks tegev, et järjekorda on järjekorda, mis on tegev, mis on järjekorda. Järgmises laingus, paljem mulle aega meil on, räägime siis hajus suhtlusest edasi, räägime siis, kuidas protsesid saavad teiste ja protseside meetodeid välja kutsuda ülevõrgu. Kui meil on kaks protsesi, kes töötavad kahes erias arutus, et selle asemel, et nad omavals sõnumeid jagaks või kustile sõnumi järjekorda asja saaks, miks mitte võimaldada ne lihtsalt teises arutus oleva klassimeetodeid välja kutsuda? Üks protses kutsub välja teise, protsesi klassimeetode lihtsalt välja koodi sees. Koodi sees, protses 1 ütleb, et protses 2 käivita see metod ja ongi kõik meie hajusprogrammet. Programmid saad lihtsalt teiste protseside meetodeid välja kutsuda. Teine võimalus seda teha nagu hajusobjektid, tekitama hajusobjekti, mis on täpselt sama objekt, näiteks mingisugune matrix, aga see matrix ei asu meie arutis, asub teises arutis, aga ma saan selle matrixi mingisest operatsiooni välja kutsuda siin arutis ja see operatsioon tegelikult kutsutaks välja seal, kus see hajusobjekt tegelikult asub. Et on võimalik siis teha sellist hajusarvutusi või hajusüsteeme niimoodi, et meil on hajusobjektid, mida ma küll saan adresseerida sellest programmis, aga ta ei asu lokaalselt meie mälus või ta asub kuskil teises serveris teises mälus. Ja on võimalik nagu püütanis või teistes progameerimskeltes kasutavad sellist hajusobjekte või siis otsa teises programmis meetodeid välja kutsuda. Ja ülejärgmises loengus ma siis lähen webiapide rest ja subi juurt ja räägime webi teenustest ja teamesest räägime HTTP ja rest appist, HTTP protokollist ja rest appi sellise spetifikatsioonist või standardeist. Me etan kaks järgmisladi vahele, kuna nad räägivad pigem neid asjad üle, aga ma räägin ki, nendas siis järgmise loengu alguses. Ma mõtsin, et ma panen nad siia vahele, kui ma nad küle aeg jääb. Ja sellene järgmise sellene nädala praktikumist teete sellise hajussusteemi, kus te kasutate rapidMQ'd mitme komponentid vahelise suhtuse vahendamiseks. Ja me tekitame sellise püütanirakenduse, mis kasutab ühte piko teeki siis rapidMQ ka suhtlemiseks. Igal teil on oma rapidMQ server ülesseatud, mis on naljakalt niimoodi, et mul on üks hiigel suur server, kus on hästi palju rapidMQ kontainereid. Vaatame, kas see server elu jääb ja ei jää. Et see on natuke lihtsam mul teha, kui hakkata teile tegema alam selliseid virtuaalsed keskkondi sama rapidi sees, kui kui kas ei oleks võimalik. Eemil aasta see töötas 40, jätu utenki ka, vaatame, kas see aasta 60. aga saab hakkama, et ühes suuramas serveris 60 rapidMQ kontainerid. Esimene üleks on umbes selin, et me teeme ühe programmi, mis publiceerib IoT Unmade, näiteks IoT Device punkt, Jakovits punkt, TempSensor ja teine püütan program, mis siis kuulab Unmade järjekorrast ja tekitame tarkvaratasemelet bindingu, kus see tarkvara panab ise paik ka, et loomule järjekord nimega Jakovits, loosina binding, et kõik annemist tulad siia exchange, millel on mustere IoT Device punkt tärn punkt TempSensor, ma pole seda prosentikinde, kas on kõik õige, aga ja siis me oleme esimene programmi, mis lihtsalt saadab selle mustre kanmeets ja Jakovits exchange. Viimane üles, et teeme natuke midagi keerukamat, et meil on üks program, kes publiceerib sarnase temperatuuri Unmade, meil on üks program, mis kuulab need Unmade ja tekitab alarme, kui temperatuur on kõrgem kui 30°C, ja tähendis kontoris on 30 plus graadi temperatuuri ja kui on, siis ta tekitab uue alarmi uue mustriga ja saadab tagas exchangei, ja siis tekitame kolmanda programmi, kes nüüd kuulab ainult alarme, et teada saada, kas kuskil toas on liiga suur, liiga kõrge temperatuur, ja ma ei tea, mis ta jookseb sinna teha akna lahtu ja midagi. Põhimestel tekitame sest kolm programmi, üks, kes tekitab unmade, üks, kes kuulab alarme ja siis selline hajus rakendus, kes põhimestel kuulab unmade jootsustab, kuna on alarme ja kuna ei ole alarme ja kõik asutavad nagu sama exchangei ja saan me kuule, et ise tekitavad endale järjekorrad ja bindingud tünnaamiseks siis tarkorasees. Ja ma näitan teile ühe asja veel. Ma ei vist ole ikkinda, kas ma saan seda näidata, ma vist saan. Te saate oma rapidi leida üles korslas lähelt, et siin praktikumidi lähealt siia tekib üks selline tabel. Ma vaatan, kas ma saan sisse logida. Mina näen te kõiki kirjeid. Siia hakkavad hiljem ka need hinde tekima. Pärast selle nädalatähta, ega esimese praktikumi täht on, et siis see nädalat pärast nädalatähta hakkab meie õppaesisteneid hindama ja siis vaikselt hakkavad nad siia ilmuma, et see on istalt efektiisem kõik korraga hinata kui üksaval need hinata ja siis eksami hinde tuled siia ja siis see rapidi info on ka siin lõpus. Liselt see, et te peate skrollima sit paremalt, et seda reaalsalt ka näha, et muidu see ei ole sinna näha, et see tabel on väga lai. Ma ei tahnud seda ka ette panna, kuna see on ainult ühe praktikumi info. Ja eelmene aasta ma saad siin suulipi kaudu 40. adressi. See kord mõtsin, ma panendas lihtsalt see tabelisse kirja ja lihtne jagad seda infot. Ja siis proovitegi selle rapidi läbi. See on vist ainuke praks, kus me tegeleme iota anmed tege sellist asjadega. Järgmestest praktikumitse me jätkame selle raamatu kasvatuslooga ja kuni aine lõpunivist. Aga mulle ei õnestund parost tagasi välja mõelda hea tüljesanned, mis on seotud raamatut, aga siia praksini, et ma panin see asjade interneti anmed. Ja ongi siis kõik tänaseks tänan?

---------Loeng 4 - RPC.mp4.txt--------

 Tere tulemas siis neljandasse loengus meie veepi teenuste hajussüsteemid aines. Tänase loengu teemaks on siis kauk protseduurid, et me jätkame sellise hajussüsteemide vahelise suhtluse teemaga, kus seekord räägime viimasest sellisest hajussüsteemide objektid omavalsest suhtlusest ja järgne nädal natuke hüppame üle siis appidele ja veepi teenustele. Kuigime tegelikult räägime täpselt samaste asjast, et kuidas kaukelt mingisuguses serveris asuval tarkkvara meetodid välja kutsuda, mis tegelikult ongi ka samuti appidefinitsioon ja appide mõte ka. Aga alustamegi natuke siis ajalost tagasi. Olem siis selles kohas, kus me elmkord rääkisime siis sõnumite põhisest suhtlusest. Täna räägime remote procedure call, kaug proceduuride välja kutsust, ja siis järgmene nädal hüppame sobia resti ja hddb appide peale. Ja idea on siis sellasemele, et me ehitame kaks processi ja otsustame, et kudas processid oma vahel anmeid vahetavad, mis sõnuminet saadavad. Me defineerime selle sarnaselt nagu programeerimises, et üks klass kutsub teise klassi meetodeid välja, et meil on nagu processid, kes saavad üksteise meetodeid välja kutsuda. Et siis me ei pea defineerime võib-olla väga konkreetselt, mis on need sõnumid, mida me saadame, vaid igal meetodil on oma loomulikud sisendid, mis selle meetodi väljakutsumiseks on vaja, ja need anmed me edastame siis ülevõrgu, kui me kutsume välja mõnes teises serveris asuva processi meetodi või mingi appi meetodi või mingisuguse tarkvara meetodi. Idee on ka, et meid ei huvita väga, et kas see teine process on samas serveris või mõne teises serveris, kas ta asub üle võrgu, üle lokaalsa võrgu, et kas see on lokaalna või kaug võrg, see meieoks ei tohiks väga erinev olla, kui kiireaalselt võib olla suurem latentsuse, see tõltab rohkem aega, kuni meie vastust tagasi tuleb. Ja sana on idee siis ja, programeerimises teise klassi instansi või objekti meetodid väljakutsumiseena. Ja arpet see mõte oli ka programeerimise see, et me saaksime täpselt samamoodi programeerida, et me ei pead teadma programeerimised asemel, et objekt asub kusagil mujal, et me saame ikka oma pyytan koodis lihtsalt objekti meetodid väljakutsuda ja tegelikult see objekt ise asub nagu teises serveris või põhimestelt suunatakse edasi selle objekti väljakutse teises serverisse taustale. Ja osaliselt on see kasutaja või programeerija eest peidetud, aga osaliselt mitte. Te tegelikult peate paar asja tegema ja me vaatame natuke näiteid ka. Ja see on vana idee aastast 1984, ingliskeeles oligi selle nimi Remote Procedure Goal. Jaavast tihti nimetadaks seda Remote Method Invocation, kuna ei ole proceduur, vaidu metodid, et see proceduur ongi selline vanem sõna metoditel. Aga idee on täpselt sama, kas on proceduur, kas on funktsioon, kas on metod. Idee on, et mingiseks meetodi väljakutsumine, mis ei asu samas harvutist samas serveris. Mida tähendab metodi mitte asumine samas serveris, et tema implementatsioon ei asu lokaalselt siin serveris, et implementeeritud on ta kusagi mujal. Ja me ei võib-ole näegi, kuidas ta on implementeeritud ja mis kootel sees on, et seda nagu meie ei näe. Ja see kasutab siis tavalis klient-server-mudelid, et meil on mingisükki server, kes pakkub seda metodid ja klient kutsub selle serveri metodi välja lokaalselt lokaalses programmis. Ja osaliselt põidetakse ära, et server asub kusagil mõjal. Proceduurid tihti toimuvad musta kastina, et lokaalselt meil ei prugigi olla selle metod implementatsioon. Me ei tea, kuidas ta on implementeeritud, et meil ei ole isegi seda sisemist pinaarsed koot, mida käivitatakse selle metodi käivitamisel. Aga mõnikord on see kasulik, vajadus saada lokaalselt käivitada, et mingi pildi töötlus, kui server ei ole kätte saadav. Mõnikord on see täitsa võimalik, et meil on see koot. Aga üldjuhul klient ei tea, kuidas seda implementeeritakse kauad aega võtab, kas ta, ja et kui suurse koodi seegi on. Aga samas meil on vaja täpselt teada, mis on see operatsioon, mille me välja kutsume ja mis on selle operatsiooni sisendid. Ehk täpselt samamoodi, nagu me programeerimeses mingi metodi välja kutsume, et meil on vaja teada metodi nime, metodi argument, et mis on see anmed, mida me siis edase anname sellele metodile ja see peab meile midagi tagastama. Ja tegelikult need ongi täiesti loomulikult sõnumid, mida tegelikult taustas vahetateks kahe serveri vahel, ehk meie sõnumid eks muutuvad need nagu metodite sisendid ja väljundid või nende protseduurite sisendid ja väljundid. Ja sellisel juhul me ei mõtlegi nii väga välja, et mis näb metodid oma, mis meie program siis saad makab teisele programmile, mis jooksab kusagi mõjal, või et me lihtsalt meil ongi kõik sisendid ja väljundid metodide ongi net sõnumid. Ja kauk protseduurite kirjeldus, et kui me programmatiliselt kirjeldame, et mis on kauk protseduur, siis meil ongi vaja ära defineerida protseduurinimi, protseduurisisendid ja tihtiga protseduuri väljundid selleks, et oleks võimalik neid lihtsasti parsida, et ei ole hea, kui me saame üllatuks, et me loodame, et on Jason, aga tegelikult saame tagasi XML näiteks. Meil on tegelikult vaja teada, et mis tüüpise väljundid ka on täpsil nagu programeerimises. Eriti tüüpidega programeerimises. Ja kauk protseduuriteö keskond võib olla täitsa midagi muud, see võib olla teene architektuur arm, AMT 64 asemels, täitsa teine operatsioonis süsteem, oma mälu alla ja nii edas, et ta on täiesti oma hajussüsteemi sõlm, mingist teine serveri keskond ja me ei prugi tegelikult sellest teises keskkondast mitte midagi teada ja meid ei tohikski väga uvitada, et kas ta jookseb Ubuntu Linuxi peal või Windows, siis Python kootina või Java kootina, et tegelikult see ei tohikski väga tähtis olla. Ja parametrid ja tulemuseks, sisendid ja väljundid edastataksegi siis keskkondade vahel sanumitena, et taustalt kasutatakse täpselt samu viise, mida me oleme kattud siis elmistes langutes ja ühenduseks me ei saa eeldad, et meil on mingisugune väga lai riba ühendus, et me saame gigabaiti sekondis anmed saada, vaid pigem on mõeldud nagu väikeste anmed edastamiseks, mitte suurde videode edastamiseks, sinna võivad olla sisse ehitatud sellised maksimum latentsus, et ja kovas aega võtab, et kui meil on vaja videosid edastada, siis pigem tuleks valida mingisugune teine lahendus selle, agaks et me me tüüppeliselt ei tohiks panna video metodi argumentiks või video pinaarsed striimii väärdust metodi argumentiks, et pigem tuleks sellist atmed edastada muul visil. Ja tegeleme pigem nagu väiksete või keskmiste sanumitega kui suur anmedega. Ja üld juhul vähemalt esimestes implementatsioonides oli see täiesti simkronne, et klient kutsus välja metodi, taustal edastadis selle metodi välja kutsume teise serverisse ja klient jäi ootale. Ehk see algne implementatsioon oli täiesti simkronne, aga tähna vaatame ka seda, et kuidas tehaks asynkronset ja kuidas jäävad programeerid, siis saad need tulevikko objektid põhimõtteliselt. Et kutsute välja mingisuguse metodi ja saad teendal tagasi nagu tulevikko objekti ja taustalt käib siis selle metodi välja kutsume serveril, kuni see server tagasi saadab anmed, siis tulevikko objektiil nagu väärtusi ei ole, et teie saada kontrollida või saada defineerida alerti, et mis juhtub siis, kui tulevikko objekt lõpuks väärdustatakse. Ehk jaavast lihtsalt kasvatatakse pigem nagu tulevikko objekte implementeerimiseks. Aga algselt jäi lihtsalt klient ootale, kuni vastusa saab funksioonilt ja siis ei ole tähtis, kas see vastus tuleb samalt arvutist või erinevast arvutist. Ja see onki üks viis, kuidas programeeria eest saab ära peita kõik seda sõnumite vahetust, paralel või seda hajussüsteemide programeerimist, et klenti arva, et ta kutsub välja meetodi ja ta ei tea, kas on lokaalne meetod või kuski mujal hajussüsteemis asub meetod mingis teises serveris jookseb. Ja klendil samas peab olema mingisugune lokaalne meetod või kood, mida ta välja kutsub, et meil ei saa olla niimood, et me pyütunis kutsume, hakkame võtma ühendustis serveriga või et meil tegelikult peakse eksisteerima mingisugune lokaalne meetod, mingisugune lokaalne klass, mille meetodid me välja kutsume. Ja tegelikult meil on vaja mingisugust koodi, kuhu me saame nagu edastada need sisendid ja selle meetodi väljakutse. Ja tihti seda ingliskeeles nimetatist tabiks, eestikilles tüükkaks, et meil on selline väike funktsoon, kuhu me saame selle väljakutse edastada. Ja see funktsoon siis põhimõtteliselt jätab meid ootele ja selle funktsooni implementatsioonis ees on kogu see hajussüsteemis sõnumite vahetus, kuhu ühendust võtta, kuidas sõnumid vahetada ja meie jääme selle tüükka või stabi taga ootel, et see on sarane siis tulevike objektide implementatsioonile näiteks. Ja tegelikult selle asemel, et seda lokaalselt meetodid väljakutsuda või et selle taga oleks mingi loogika, siis sinna tahan peidetas kogu see hajussüsteemi loogikat meetodi otsese väljakutsumise asemel või teel edastatakse sõnumu hoopis sellele serveri, kus selle metod implementatsioon tegelikult eksisteerju, nii et on osaldsead peidetud kasutajaheest või programeerijaheest. Aga siis serveris on täpselt sama metod koost päris implementatsioonina, et meil on nagu selline lokaalne liidesest stiilis tüükas ja siis serveris asub täpselt sama metod samad argumentidega, aga seal juba asub päris implementatsioon. Ja siis kogu see suhtlus klendi ja serveri vahel peidetakse programeerija või meie eest ära, et me ei arva, et me kutsume meetodi välja, aga tegelikult toimub see taustas nagu kahe hajussüsteemi sõlme vahelne suhtlus ja kaugel asuva meetodi väljakutsumine. Ja ma juba seda ütlesin, et mis selle nimi on, et meil peab olema mingisugune lokaalne meetod või klass, midama välja kutsumine. Ja Eesti, kes on selle nimi tüükas, ma usun, et on veel teisi nimesid ka. Inglis, kes on seda, et niimeks on STAB, et mingisuguse meetodi selline võlds implementatsioon mõttes. See on tehtud, seal on implementatsioon, aga see implementatsioon ei ole seotud üldse nagu meetodi enda väljakutsega, vaid ongi seotud kogu selle suhtluse ja anmed ledastamisega. Ja ta ei ole, ütleme, et meil on meetodi interface ja me saame luua selline interfacei põhja, et meil on metodi interface, et meil on metodi interface, et meil on ütleme, et meil on metodi interface ja me saame luua selline interfacei põhja al STABi, mis on nagu mõnes mõttes võlds implementatsioon ja me saame serveris luua selline interfacei päris implementatsiooni, aga me saame siis serveris meetodi väljakutsuda, aga me saame ka siis selle STABi kaudu meetodi väljakutsuda, aga STABi kaudu või tüükakaudu meetodi väljakutsumine siis tegelikult toengub nagu edasi suunamine või selle proksimine. See on nagu proxy põhimõtteliselt, et ta nagu meetodi proxy väljakutsumine, et tegelikult me ei kutsu meetodid lokaalsalt välja, vaid taustal toimub selline suhtlussele asemine, et võib- olad nagu proxy on mõnes mõttes parem eestigelne nimi, kugi proxy ka ei ole eestigelne suna. Aga ja, ta selles mõttes lokaalsed implementatsiooni ei eksisteri. Ja siis võimaladab klendi rakendusele päe seda teenusele ligi nii, et klendi arvatest ta näeb välja nagu kohalik, varjates kogu selle suhtluse üksikasjad kasutajest ära. Ja ta lihtsustab selles mõttes arvendusprotsessi, et me saame toetuda sellele ütleme teegi implementatsioonele, et kuidas RPC implementeeritakse ja me oma koodise ei pea ise välja mõtlema, et kuidas saata sõnumeid, kuidas ühenendustuota serveriga. Mõnes mõttes me isegi võib-olla ei pea teadma, kui me peame seda konfigureerima, et kus need serverid asuad, et kogu see keerukus peidetakse programeerimise hetkel ära, kui ki ta implementeeritakse siis teegi tasemel, kes oskap näid tükkad ja staab ja RPC-t implementeerid. RPC siis teeg võimatsõlsed või see tarkku ora siis implementeerib selle. Ja pakkudes siis arvendal täpselt samasugust liidast, et püüt on lihtsalt mingisuguse klassi mingisuguse meedadi välja kutsumist selle asemete tegeleda sõnumite vahetusega. Ja et on sellesamudse nagu abstraktsioon. Väga kõrgele tasemel toimub see umbes niimoodi, et meil on klient, kes kutsub välja mingisuguse metodi ja pärast selle metodi väljakutsud hakkab toimuma klendi arvutis ümbersuunamise protsess, et selle asemel lokaalsed väljakutsuda, tuleb serveris väljakutsuda ja sisse selleks, et sõnumite tekitada tuleb meil sisend kodeerida, et kui meil on mingid lokaalsed püüt on muutujad, aga serveris on C program näiteks, siis tavaliselt standardiseeriteks need sisendid ja väljondid ära mingiteks RPC protokolli paastüübiteks. See võib tegelikult sisemised olla XMLX, JSONX, see võib sisemised olla mingiteks protopuffiks, kui me räägime Google'i GRPC-st või mingisugus selle RPC protokolli speziifiliseks anme tüübiks ja sõnumi anme tüübiks põhimõtteliselt. Kui teeriteks ära, siis saadatakse sõnum serverisse ja jäätakse ootale, et kuni vastus tuleb tagasi. Serveris võetakse see sõnum vastu, teeritakse vastavalt selle programeerimeskeele, speziifilistele, anme tüüpitele, kas on integer või mingisugune R või midagi muud. Täiditakse funktsioon, tavalselt panaks see ka kaas, mis on selle funktsiooni nimi, mida me tahame serverist käivitada. Täiditakse funktsioon, võetakse funktsiooni väljond, jälle koteeritakse, et RPC protokolliga saaks tulemus anmed tagasi edastada klendile ja klend tekoteerib lahti, võtab vastuuse sealt tekoteeritud seest ja jätkab käivitust, et mis iganesse järgmine käskoli on. See on väga lihtne, et me lihtsalt edastame. Praaktikumis me osaliselt teeme selle läbi, et me teeme seda küll pyytonis ja me implementeerime RPC ise, me implementeerime RPC rabit ja habil, et loomame sellise hästi-hästi lihtsa rabit ja Jasoni põhis ja RPC süsteemi praktikumis. Me teeme saanamise procesi läbi. Kui meie aga see tekoteerimin on suhtel lihtne, et me toetume rabitile, et tekoteerida näid sonumi, et me paname rabit ja saad Jasoni, rabit ise tekoteerib selle ära ja siis rabitist küsime Jasoni ja see tekoteerimine ja koteerime toimub automaalsed rabitipolt. Meil on mingisugune mõlemas arvutis, on meil mingisugused kihid, et klendi kihis on meil see klendi tarkokara näibiks püütane program, mis siis RPC-ed välja kutsub, siis meil on klendi tüigas, kes implementeerib selle võimaluse, et kutsuda välja kauge lasuvad metodid, kui lokaalsed püütoni metodid. Meil on mingisugune RPC-vahevara, mis tegeleb kogu selle tekoteerimise ja koteerimise ja anmet edastamise võrgupaketide teel kuhugi teise serverisse. Selle serverisse on sarane RPC-vahevara, mis oskap RPC-sõnumid vastu võtta ja saata ja siis on serveri tüigas, aga see serveri tüigas juba nüüd põhimõtteliselt, kas sisaldab, võid oskap käivitada juba seda päris koodi, mis on selle sama metodi implementatsioon ja siis täidab selle koodi. Põhimõtteliselt klendi tüigal vastab serveri tüigas, aga serveri tüigas teab, kus on implementatsioon või mis päris püütoni või java metodid väljakutsuda ja serverist täidetakse see. Probleem on ka see, et mis juhu kui viga tekib. Kui me kutsume välja lokaalse metodi, tekib viga, siis me saame uurida, et kus see viga tekis, mis reas koodis. Me saame püütan stack trace või avatsja stack trace uurida, et mis olid need metodid väljakutsujärjestus, et kus viga ta päris tekis, mis reas koodis. Kui meil ei ole lokaalselt koodi, mida me siis teeme? Kui klient näeb, et tekis viga, aga vea tulemus on, et XML sõnumis oli mingisugune väärtus, võitme väärtus vale. Aga meie mõtlasime, me kutsusime välja püüton metodi, miks me tegelem X ja Melliga. Et seal tekivad nagu mitud aset vigaadest, et kas viga tekis serveris asuvavast püüton koodis, kas viga tekis sõnumite struktuuris kodeerimisel, lahtikodeerimisel, et võib-olla ta ei oska teatud UTF-8 ääätähti kodeerida korrektselt ja siis tekis sõnumite konverteerimisel viga. Et vigased võib tekida kas serveri ja klendi vahelises ühenduses, ülevõrgu paketide saadmisel, nii et meil on nüüd palju rohkem erinaid tüüpe vigased, mis võib tekida. Ja kas me üldse tahame klendile anda mingis stack trace, mis võib-olla kogematab prindib välja mingisugused salased väärtused, mis on ühendusega seotud mingisugused võitme. Vigade käsitlemine on siin palju keerulisem, tekivad igasugused hajussüsteemide probleemid, tuleb mõnesmõttes otsustada isegi selle RPC tarkvarja implementeerimiselle, et mis suurvigased edastatakse. Ja sellise tarkvarat e-bagimine võib-olla palju keerukam kui lihtsalt kohaliku meetodi välja kutsumina. Et te võite saada mingisid vigased, millest te mitte midagi aru ei saa, sest seal on üldse seotud selle funktsiooni loogika välja kutsumisega, võid on üldse seotud mingid RPC mehanismide või sõnumide struktuuriga. Ja siis on ka, et kui tekib viga, mis me siis teeme? Kas RPC kutsub selle meetodi uuesti välja? Kas RPC millegi tõttu kutsub selle meetodi kaks korda välja? Me saame tulemused kudagi oma arvutesse kaks korda tagasi, kun nad arvab, et tegelikult käivitas ootab liiga kova aega ja proovib uuesti, kas päringult peab kordama. Mitu peab korda peaks kordama enne, kui kasutale üelda, et server ei ole kätte saadav. Ja kui server saadav vastuseid, kas server peaks ka ülekontrollima, kas klient sai vastuse kätte või mitte. Et kui me elmikord rääkisime sõnumide järjekordata puhul erinevatest nendest strategiatest, kas sõnumide saadadaks üks korda või mitte korda, et karanteerida, et ei tekiks dublikaaata või karanteerida, et tõesti klient sai selle sõnumikätte. Et kas siis selle jaoks on võimalik suhtiselt sarane tase konfigureerida sõnumide kohale toimetamisel, kun nad austal tegelikult me tegelemegi sõnumide kohale toimetamisega RPC-sees. Meil on tähtis ka see viahaldusisse mantika, et kas meil on võib olla meetodi käivitamine ja tulemuse kätte saamine, või me tahame karanteerida mingisuguse pangadussisteemi puhul või hästi kriitiseb sisteemi puhul, et kui meetod väljakutsuti, siis klient kindlasti saab tulemuse ja täpselt ühe kora või ühe tulemuse tagasi kätte. Et siis ongi võimalik valida, kas meil on vähemalt üks kord meetodi käivitamine, et karanteeritakse, et kindlasti meetod käivitatakse või sõnumid juhad kohale. Kas me tahame karanteerida, et vähemalt üks kord käivitatakse ja me ei ole okei, kui seda meetodid proovitakse käivitada mitukorda järjest, et ei tekita mingisugust probleemi anmebaasis, kui me kutsume sama meetodid mitukorda välja, et ei tekik kolme kirjat ühe kirja asemel anmebaasi näiteks. Kas meil peab olema sisseheitada mingisugune duplikatide filtreerimine või astuse kordamine? Või siis me peame karanteerime, et tõesti kui klient saadab meetodi, siis meetod kutsutaks välja täpselt üks kord, aga mitte rohkem kõik kord. Ehk pigem prooviteks implementeerida sest transaktsioon, et karanteerida, et tõesti see käivitus toimus. Ja anmebaasi pandi ainult üks kord mingisuguse tulemused või saadati välja mingisugune SMS ainult üks kord. Saadate tee e-mail välja ainult üks kord ja vältida seda, et duplikaate tekiks. Selles aine, sa me väga seda ei räägi, et räägitakse magistri õppes hajussüsteemid aine seda rohkem, et kudest see taustal toimub ja misugused loogika sellest tagapäepeab olema implementeeritud selleks. Aga täpselt üks kord sellene poliitika prooviv siis tagada, et kindlasti jõuab see meetodi väljakutseda. Aga see võib olla suhselt kerran, et vähemalt üks kord siis põhimõtteliselt näiteks server saadab tulemus tagasi klendile, kuni klent saadab vastu acknowledgemente, et ja, ma sain selle tulemuse kätte. Aga siis ei ole nagu klendipool implementatsiooni selle koht, et duplikaatide mingisugust e-maildamist. Aga need tasemed vähemalt üks kord, ülimalt üks kord või täpselt üks kord on samad, mis AMQP ja MQTT protokollides on kasutuses sellise quality of service moodidena või nende lähenemistena. Ja kauge, proceduuride või kauge meetodide väljakutsa probleemid on see, et need on tavaliselt ja algselt implementeeritud väga synkroonsetena, et klend ei ootale, kuni meetod tagastab midagi. Suurst, et vähe oli võimalik anmeid saada, et me pidime hästi palju meetodide väljakutsid tegema, et rohkem anmeid saada, kuna ühe meetodi väljakutsa oli piiratud esimestis implementatsioonides. Puhudusid sellist voo kontrollid ja puferdamised, et kui klend võtab vastu anmed, siis ta peab võtma vastu neid anmed, mis vastu saad, et ta ei saa nagu lugeda neid anmed, näiteks väikse tükki haval või vastupidi, et iga kord, kui me tahame uusi anmed, siis me peame uue päringu tegema, aga ma ei saa jääda kuulama, et lasta serveril meil avatud ühenuduse kaudu järjest rohkem anmed saada, et näiteks öelda, et ma sooviksin saada kätte kõik viimased mingiseliselt sõnumid anme baasist selle stabilist ja siis ma pean iga kord uuesti pollima, sellasema, et ma teen ühenuduse lahti ja lasen serveril saata mulle selle ühenuduse kaudu järjest rohkem uusi liituvaid mingisuguseid sõnumeid või kirjaid anme baasi. Me vaatame korraks seda, et kui täst GRPC seda tänapäeval tuetab väga hästi ja miks ta populaarskas on saanud. Ja tihti lähevad nend väljakutsa ahelad keerukaks, kui meil on rohkem kui kahes sõlme vahel nagu see RPC-t. Kui mina saadan pärin, kui ühte serverisse RPC kaudu ja see server teab RPC kaudu veel järgmisesse serveris sõhenduse ja siis to server teab veel järgmisesse sõhenduse, tegib see ahel hajussisteemide sõlmed vahel, et siis nende debugimin on isegi keerukam ja kogu see sisteem läheb väga keeruliseks ülesehitada ja jälgide siluda debugid, et kuidas see töötub. Ja ta on suhtselt jäik selline klient-server rool, et kui me tahame, et klient saks serveri meedlade väljakutsuda ja samuti see teine hajussisteemi olem peab saama esimese serveri, esimese klienti meedladev väljakutsuda, siis tava RPC kauduse ta teha ei saanud, siis mõlemad pidid mängima serverit ja eraldi ülesehatma sellised võimalused, et see ei ole, nagu ühe ühenenduse tegemise kaudu ei saanud server, siis klienti remote metodid väljakutsuda niisama, et suhtluspartnerid ei olnud siis võrdsadnud, ei olnud mõlemad serverid. Ja ei olnud võimalik, nagu sellist asynchronous, et callbacki teha, et klient saadab sanumi ja siis server hiljem kutsub välja klienti metod, et seda sanum takastada, et seda esimestes implementatsioonides ei olnud võimalik. Aga hiljem implementeeriti asynkronselt RPC-t ja see töötas niimoodi umbes, et ma kutsun asynkronselt mingisuguse meetodi välja, selle meetodi tulemest kirjutatakse mingisuguse objekti, mida ma saan hiljem pollida, aga ma ei jää ootale, vaid ma jätkan oma koodi käivitamisega ja hiljem käin ja küsin, kas selles objekteis on väärpise, põhimest selline future-objektid, kus ma kontrolli kohe ei eeldagi, et see väärpus kohal on, vaid ma tean, et see võtab kaua aegas, ma teen mingisugus muid tegevusi, et näiteks asynkronselt erinevate. Sisse tulevate päringute töötlus niimoodi, et ma RPC-kaudu kutsun välja mingisugused teiste hajussüsteemi sõlmed ja meetodid, aga ma ei jää nagu ootale, kas et kohe midagi väljastavad, vaid tulem hiljem tagasi ja vaatan, et mis see väärpus hiljem oli, kui see lõpuks kohale juob. Et ja, et selle jääks tihti kasutataksegi näid future-objekte, mis tulevikus avad alles väärtuse. Et me saame testida, kas hiljem kas tulevikus objekti seese on nüüd väärtus tekkinud, või siis me saame defineerida, et käiviteke mingisugune meetod, lokaalne callback-metod, siis kui future-objekte isa vastas kohal. Sana sellest midagi tekite ka rapidMQ praktikumis. Aga me võime ka teha lihtsalt politavad, et me iga natuk saada, kas controli, mingis future-objekte isa on mingisugune väärtuse. See väga kõrgele tasemvisualiseerimisel toeta pumbas niimood, et me kutsume välja ARPETSE-ekoodu serveri meetodi, ja siis tekitame kuskile tuleviku objektit näiteks listi ja esialgun nendel väärtust ei ole, aga me koha kutsume välja kolm ARPETSE-metodid ja ei jää ootale enne teise väljakutse tegemist, kuni esimene saab vastuse, vaid me järjest kutsume kolm välja, ja siis hakkame kontrolli ma näiteks, et kas nende saab mingid väärtuse. Ja siis server kutsub järjest välja ja ARPETSE protokollika autu saadab vastused ja siis ARPETSE tarkvaras siin õtab vastuse vastu ja paned nende väärtused õigesse future-objekti, kus siis hiljem klentsab polides või mingisuguse callback-metodi väljakutse tead, et seal on väärtust olemas. Saab näiteks kontrolli, mõt kas tuleviku objekti siin nüüd on uus väärtuse mitte. See on hästi lihtne visualtioon. Ja see tähendab seda, et me saame siis kolm tükki väljakutsude ja alle siis testi makata ja server saab nende nii kiiresti, kui tema on võimeline käivitada. Server võib nende tegelikult käivitada mingis teises järjekorras näiteks, kui server on ise hajutatud ja seal on mitu paralleelsed töötavad töötajad, kes võtavad näiteks järjekorrast sõnumeid ja võib-olla esimene töö on aeglassem kui teine töö, aga teine töö käivitatakse mingis serveris, mis on vaba ja nii kauku esimest käivitatakse, siis teine server on teise töö juba ära teind ja saadab teise tuleviku objekti vastus enne, kui esimene üldse kätte saadakse. Selleks, et me saaksime kuskil muheal serveris oleva meetodi väljakutsuda, meil on vaja neid kirjeldada, et kus asuvad serverid, mis meetodid seal on, mida saab väljakutsuda, mis on nende meetodite sisendid ja väljundid, et meil oleks vaja mingisuguses standaardeid, mis kirjeldavad seda, et kus asuvad need remote meetodid, mida meie programmist saab väljakutsuda, kas meil on kusagi mingi rekister, kui me saame ühendada ja küsida, et kas kusagi lasub seda tüüpi meetod, et mis on selle server IP-adress, meil hajussisteemide võrgus või üldse internetis näites kusakile, et kui me API siit kasutama näiteks. Siis on väga erinevaid standaardeid selle jaoks, näiteks Open Network Computing Interface, Cobra Common Object Request Broker Architecture, midul on Microsoft Interface Definition Language, JAX RPC on siis Java App for XML-based RPC, puhas XML RPC ja puhas JSON RPC. Need Java XML-i põhised on suhtsealt laialdaselt kasutuses, aga kui nüüd mõeldad, millega me tegeleme, me tegeleme kuskilt ülevõrgu meetodite väljakutsumisega, siis kuidas see tegelikult erineb mingisugust HTTP Appist või kuidas see erineb REST Appist, et tegelikult idea on väga sarnane. HTTP Appi ja REST Appi panad natuke rangemal paikat, mis on need meetodid, mida on võimalik väljakutsuda, aga sellest me räägime ei siis järgmine nädal, mõnesmõttes HTTP Appid ja REST Appid ongi teatud tüüpi RPC-id. Ja tihti kasutataksegi XML-i, kasutat XML-i nende meetodite spetsifikatsioonina ja XML ja JSON-i, lähene mõne on väga lihtne, saadame serverile JSON-i ja JSON-i see, et mis meetodid me saame väljakutsuda, mis on selle meetodid sisendid ja server siis parsib JSON-id, et teada saada, et mis on see meetodi väljakutse. Ja tegelikult midagi sellist me teemegi praktikumis läbi rapidiga, me kasutatame siis rapid JSON RPC põhimõttelis praktikumis implementeerime ise rapidi põhjal. Ja te näete, et see ei ole tegelikult väga keerulne selline JSON RPC implementeerimine. Aga põhimõttelis siin ma taangi natuke rääkida, et kuidas see umbes toimub. Meil on siis vaja ühele sellistele standarditele vastavad kirjeldust. Siin on näide siis Cobra kohta. Meil on Cobra spetsifikatsioonis kirjeldatud siis remote meetodispetsifikatsioon, et mis on see meetodi nimi, mis on selle meetodi sisendid ja väljundid. Põhimus, et lihtsalt näiteks XMLi dokumentina kirjeldatud, et mis on see RPC meetod, mida on võimalik väljakutsuda. Ja siin me kasutame Generator Darkpara, mis on võimeles genererima selle spetsifikatsiooni põhjal serveri poolele skeleton, kus sisemine loogik on implementeerimata ja kliendi poolele tüugas või proksi, mis on implementatsioon, et kuidas seda serveris asuvad meetodid väljakutsuda täisest serverist. Implementeerijad peavad selle skeletoni põhjal implementeerima loogika vastavalt keeleskas jaavas või pyytonis või C-sharpis näiteks. Ja panema selle serveri rakenduse siis üles, kuskil serveris jooksma ja kuskile registreerima, mingisuguse name serverisse või registrisse registreerima, kus see server asub ja misugused meetodeid ta toetab. Jät server implementeerib mõned need ITL-is kirjutatud meetodid ja saada registrisse, et mina asun siin IP-adressil ja mina toetan neid RPC nagu spetsifikatsioon, et minu serveris on need implementeeritud, et nüüd mulle saab üle võrgu saata RPC sõnumid, et neid meetodeid väljakutsuda. Ja klient, kes soovib siis sellist meetod väljakutsuda, ta võtab selle Generated Stab tarkvarad näiteks genereritud pyyton keeles ja siis saab seda tegina kasutada pyytoniselt need meetodeid väljakutsuda lisaks ta peab defineerima või otsima vähemalt, kus need serverid asuvad, mis seda meetodid toetavad ja valjama ühen endast põhimatsalt. Et kui registris on kolm, siis ta valib ühe milline väljakutsu. Et see register või name server võib siis olla meie rakenduse sisemine, aga see võib ole ka globaalne mingisugune kõiki servereid. Põhimatsalt ta ei ole selles mõttes, et kõik serverid ühendast võtavad, aga ta võib olla rohkem kui ainult meie hajussüsteeme osa. Näiteks võime jättekujutada, et siin on mingisugune Twilio meetodi väljakutsumid, et saata Twilio kaudu SMS. Ja siis kui meie rakendus tahab Twilioga ühendast ota, siis ta küsib name serverist, mis on Twilio SMS saatmise sõnumi serveri adress, mille kaud on võimalik Twilio meetodeid väljakutsuda et SMS-i saata. Et siis otsitakse Twilio adresse, kus need metodid on implementeerikud. Ja siis kui klendi rakenduses see meetod väljakutsuda, siis taustal toimub siis RPC implementatsiooni vahel sõnumite saatmine, et se serveris, se server kutsub välja reaalise implementatsiooni, et lõpuks saadad näid tulemused tagasi, et siis see kiht, kus on implementeeritud, siis RPC-se tegeleb siis selle tüükka või proxy ja selle realise implementatsiooni vahelise sõnumite vahetusega. Ja klendi tarkvaraselest midagi tead, ma ei tead, tema arvab, et ta lihtsalt kutsub välja selle püüta metodi ja implementatsioon võib olla teises keeles. Ja see on tegelikult väga sarane, kui täs appid töötavad samamoodi. Java appi XML põise RPC-aks ja karta XML RPC on põhimõtteliselt sarane, aga idea on, et see töötab Java'al, et need implementatsioonid ja klendid on Java'as implementeeritud ja me kasutame soap protokolli, millest ma ka järgmõne kord räägin, et kasutakse soap ja HTTP protokolli selleks, et vahetada siis sõnumite kahe Java virtuaalmasine vahel, üks mis asub serveris ja üks mis asub lokaalsalt. Ja samamoodi on võimalik siis genereerida klendi ja serveri tükkaid või proksisid ja saame siis nii klendiosa kui serverosa genereerida. Alati me peame serveri osas mingisuguse implementatsiooni ka looma, aga see on alati nagu vajalik. Vaatame ühtel näidet, et meil on hästi see Hello World näide, mis on implementeeritud siis selles jaks RPC's, et meil on vaja defineerida config.xml, mis defineerib ära siis, kus asub server. Meil on vaja selle meetodi spetsifikatsioon xmlina, mis kirjalab ära webi teenusti selle parametraid ja meil on vaja ka web.xml, mis kirjatakse ära, et kuidas seda üleseada siis käivitada serveris. Ja siis meil on vaja liides, jaava interface viis liides, mis kirjalab ära selle meetodi sisu, et mis on meetodi nimi, mis on meetodi sisendid ja väljundid. Siis meil on Hello World klient, kes kutsub välja selle meetodist tükka ja meil on Hello implementation, mis implementeerib siis selle meetodi loogika või sisu serveri pool. Liides näb väga lihtne välja, täpsel samamoodi nagu jaavas on, klasside liides, et meil on mingisugune interface, mis siis extendib seda remote ja see remote on siis jaava RMI tegist. Ja me peame ära lihtsalt kirjalama, et mis on selle meetodi nimi, mis on selle meetodi sisend, väärtused ja mis on selle meetodi väljund. Ehk siis saaname stringi ja välja saaname stringi. Ja ta viskap ka siis nagu remote exceptionid, mis võib-olla annavad meile tagasidat ühenduse kohtat, kui ühendus feilib. Ja jaava server on siis meetod, mis implementeerib selle meetodi, mis implementeerib selle liides võib-olla mingi klassi meetodid ja siis implementeerib, et mida see meetod siis selle sisend stringiga tajab, et tagastada siis väljan string. Et ta praegu lihtsalt tagastab hello string, hello pelle, kui string on pelle näiteks. Ja siis klientis, klient peab importima siis sellest jaavaks XML arbetseest staabi. See staab on siis selline üldine staab ja idee on, et seda saab lua siis sellise great proxy meetodiga sealt klassist. Ja et põhimõtteliselt kutsutakse välja sellest klassist, mis extendib siis seda remote. Kutsutakse välja selle remote classy meetod getHelloWorldIf port, getHelloWorldInterface port. Ja selle meetodi tulemus, siis saadakse see klas, mille kaudu saab meetodid välja kutsuda. Ja pärast seda kaastitakse see staab sellesse interfeisi, mida meil on soov, mille meetodid meile on soov välja kutsuda. Ja siis me saame lokaalselt nüüd selle klassi kaudu seda meetodid välja kutsuda. Ja kui meil tekib siis remote exception, siis me printime selle väljat. XMLRPC on palju lihtsam. Nüüd meil ei ole tegelikult enam vaja otsaselt midagi kaastida. Me tegeleme pigem XML-ide parsimidega. Seleks, et me saaksime XMLRPC kaudu välja kutsuda mingi meetodi, me lihtsalt peame õige struktuuriga XML saadma serverisse. Ja me XML-i sees ei ütle ainult, mis on selle meetodi argumentid, vaid me paneme ka selle meetodi nime. Nüüd me serverisse saadame, et me tahame välja kutsuda mingisuguse klassi mingisugust meetodid ja me anname sellised argumentid. Nüüd on see keerukamsest, me ei saa enam mitte metodid püütanis välja kutsuda. Me peame edastama mingisugus XML ja paneme selle meetodi nime argumentid XML-i. Me peame nüüd XML-ige parsima, aga nüüd on ta palju üldisem, et me saame põhimõttel XML-i panna kõik, mis vajalik on. Me saadame serverisse, et me saadame kutsu välja see meetod ja neid argumentidiga. Aga see lähene liigub natuke arpeetseest kaugemale, sest me enam ei tegele lokaase meetodi välja kutsumisega. Vaid me pigem defineerime sõnumi ja ütleme, et selle sõnumi saadame serverisse, et me tegeleme sõnumi edastamisega mõnesmõttes. Aga see sõnum on nagu spetsifikatsioon selle, et mis meetodid me välja kutsume, mis me tegelemme sõnumi. Aga see läheb nüüd kaugemale nüüd nüüd tüübitud progameerimisest, et me teame täpselt, mis on välja tüübit. Aga need tüüpid info panaks ja siis XML sisse, et meil on lihtsalt parametrit, aga meil on üks parameter. Selle on välju ja välju on integer 4 tüüpi, nii et on teatud pikku, aga integer, mis on, mida server peab olema võimene vastuvõtma selle meetodi sisendina. Ja kui meil on siin palet nimed, et siis välju asena on midagi muud, siis me saame servers terrori, et see meetod ei võta selle. Et selle meetodi mingisugune sisend on puudu. Ja vastus näeb saa sugunne välja, et me saame vastuseks näiteks sellis, et kui meil on method getStateName, mille id on 40, siis anvepaisis on 40. state nimis autakoda ja selline välja on, et meie tarkvara peab samuti paletnud. Ja peab aru saama, et see välja kutse või see tule, et see, et ikkse välja, mida me tagasame, on siis seotud selle eelmise päringuga. Ja see läheb natuke apide suunas mõnes mõttes. Kus seda kasutatakse? Ma näitan hiljajame Jason RBC näiteena, et kus see praegusel kasutuses on. Jason RBC teutab täpselt saamoodi, et ikkse mäljas me kasutame lihtsalt Jasonid. Nii et on selle kerge kaalukam RBC, et me ei tegele nii väga enam kliendist tüukaste genereeerimisega, serveri genereeerimisega, ma ei pigem nagu see on nagu sõnumite vahetus, aga sõnumite vahetuse eesmärk on kutsuda välja method serveris. Ja see näeb välja umbes selin, et kui me tahame välja kutsuda mingisugune, et me ei ole kutsuda, et umbes selin, et kui me tahame välja kutsuda mingisugust methodid substraktis, saadetakse Jason, mis sisaldab, et mis on selle methodi nimi substrakt, mis rbc-t me kasutame, et Jason RBC, mis on selle metodi parametrit, me võetakse sellest, mis on täpselt samad, mis metodi välja, kut seal oleks. Ja me paneme tihti kaas, et mis on see päringu ID, et kui me tuleb tagasi vastus, sama ID, kas me teame, et see on selle päringu vastus, nii-alt RBC päringu vastus. Ja väljundis on samud, et mis on see rbc protokolli versioon, mis on see päringu ID, mille vastus on ja mis oli siis result, mis oli selle metodi tulemus. Ja see metodi tulemus peab olema, et Jason ei nad kodeeritav, võib teoreeltiselt olega mingi base 64 kodeeritud, siis mingisuguna pikkem string või mingi pinaarsed väärtused ka näiteks, et me saame aga pildi painaristriimi võtta ja base 64 enkoodida ja panna see stringina põhimõtteliselt sisse, kui me väga tahaksime pilditeutluse teha, aga pilditeutluse sõnumite saadmist ei ole hea teha XMLi või JSONina. Kuigi seda on ajal olnistelt ka tehtud. Mul vist peaks olema üks keerukam näide järgmise slidil, mis siis näiteb, kuidas seda tänapäeval päriselt ka kasutatakse, aga siin võib olnud, et tulemus on saadatakse meile opis erroor, et metodi väljakutsa ei õnestund, kuna on puudu second teene argument sellele päringul, ehk meie, kui me unustame ära substrakti metodi kutsam välja, unustame teist väärtust 23. et siis 42 minus mida, et meil teist väärtus sellel parametrite listisei on, et siis saame erroori, et teine väärtus on puudu. Ja siin on üks näide selle kohta, kuidas seda JSONRPC kasutatakse selliste blockchainide valdkonnas või enda blockchain-appide valdkonnas. Et siin on üks JSONRPC näide, et kuidas küsida, palju transaksioon maksma läheks Ethereumi võrgus, et palju Ethereumi kaasi maksaks mingisugna transaksioon enne, kui seda välja kutsuda, et siis saab saata selle transaksiooninfo, et kui te saadate mingi päringu siit siia, siis saad ja mis on see etke kaas, kui palju trikaasi on, mis on etkev kaasi hindvist ja kui saadate mingisugna sellise data, siis mis see maksma läheks, siis arvet, et see ka autu vastatakse teile, et see reanne hind, mis see praegu siis maksaks. Ja siin on ka, et mis on selle päringu idee, tihti seastatakse see päringu idee konkreetsse kliendiga, et see ole globalne idee vaid selle kliendi 67 päring ja vastus tuleb siis ka, et see vastus on siis selle kliendi 67 päringu vastus ja et mis see vastus on ka oleks. Ma räägin järgune nädal natuke rohkem sellest, et mis on siis RPC-appide vahe, peamine appi ja RPC-de vahe on tegelikult see, et me võime siin panna nagu põhimus, üks kõik, mis meetodi nime, kui haatete peapides tavalselt panaks sa paika, et mis meetodid on lupatud ja kasutatakse pigem, et mis resursi peal me selle meetodi väljakutsume, aga tegelikult see lähene mene on ka väga sõupi, sõup appide protokollis harane, millest me ka järgmine näda räägima. Üks, mis on väga populaarseks hiljuti saanud sellest haatete peapide asendusena, on ka RPC stilis GRPC, mis on loodud projektina pilve põhiste süsteemide foundationi poolt, Cloud Native Computing Foundation, mille raames on ka näiteks kuberneetees, mille raames on dockeri imageid kasutamine nagu konteineristandardina, ja kus on väga palju sellist mitte otsest standardiseerimist vaga selline arendajate best practiceite paika paneme, et mida võiks kasutada tulevikus selleks, et teha süsteemid, mis oleks võimaliselt ka leerima ja tõrkeda aluvalt looma. GRPC üks eesmärk on asendada mikrodeenuste haeusessteemide komponentide vahel tavalisi appi liidesed nagu Http appisid või Soap appisid ja RESTi, et on disainitud efektiisemaks, kui tava veepis kasutatud olev Http ja REST appide. Võib-olla ma natuke liiga palju räägin ette, aga kuna see on otsestelte RPC-ga seotud, siis ma räägin ka sellest, et see tegelikult kasutab täpselt sama Http protokollega kasutab uuemat versiooni, milles on sisse eitatud sellised natuke uued featureid selleks, et saaks paremine anmeid vahetada real ajas ja ei piaks nii palju üksikult päringud saadma serverile, et uusi anmeid küsida. Ja kasutab seda Google-i protokoll pufferid Chession XML asemel, et ei edastada enam nagu pinaaselt kodeeritud stringe ja sellised väga paljude selliste võtmeväärtustega väärtusi, et sellasemmel, et edastada selline string, kus on need võtmed ja igasust komad ja sulud, siis tegelikult, kui on ette teada, mis struktuuriga see oleks, siis me saaksime ainult edastada väärtused, pinaaselt kodeeritud ja eraldatak eraldatud, aga me saaksime välja jätta kõik muu anmed, mida tegelikult meil vaja ei ole, et kui me teame selle Chession struktuuri või noh, me teame, et mis on parametrit järjekord, meil on palju efektiisemalt võimalik need anmeid tegelikult edastada servelite vahel ja see liikluse maht on väiksem puhtalt selle tõttu, et me enam ei saada neid XML ja Chessioniga seotud igasugused kasvenid igasugud muid märke. Et tal on selle tõttukas kompaktsem pinaarnaanme salestus, kiirem parsimine, sest me ei tegele enam XML ja Chessioni teksti põhise, regekside põhise parsimisega kasutada väga paljudes programeerimes keltes, kuna nad on nende jaoks teinud liidesed ja ta on optimeeritud just selleks, et automaased genereerida nii klendi kui server klasse ja põhimised ta on disainitud mitte selleks, et välis maailmas serveriga ühendust võtta, et ei ole see, et klient võtab browserist ühendust ja ta paks gRPC-t rääkima. Et selleks ta ei ole mõeldud, et on ikkagi nägemus, et klendid oma browserist kasutavad täpselt sama Http üks punkt ühtem, mida teie browser räägib, kui ta serveri ühendust võtab, aga pärast sellist frontendi või sellist esimest mikro teenust, mikro teenuste vahelne suhtlus kasutaks efektiisemat suhtlust gRPC kaudu või kasutaks sellist tava Http appisid, et üks teise metodeid väljakutsuda. Et ta on just disainitud hajusüsteemide sõlmede vaheliseks suhtluseks, mitteni väga klentide hajusüsteemi vaheliseks suhtluseks. Ja siis need mikro teenused vahelisüsteemide komponentid, mis töötavad serveritena, nemad pakuvad gRPC-serverid ja lubavad siis enda lokaased metodeid sest selle gRPC kaudu väljakutsuda ja osa mikro teenused, mis isedevad ka päringud, nemad on siis gRPC klientid ja gRPC serverid, kui teised klientid siis nende mingisugust metodeid väljakutsuvad. Ja see on siis efektiivsem, kui selline puhas XML-i või JSON-i põhine RPC, kuna anme mahude väiksemad ja ta toetab sellist anmete striimimist, mis on üks peamine põhjuseid, miks ta on kasvatusluvajatud. Selline tavalne RPC on sellise mudelina, et me kutsume välja metodi ja me saame tulemuse tagasi ja kui me lauama kümmekorda metodid väljakutsutasime, kutsume välja kümmekorda, saadame kümme päringud, saame kümme vastust. Mida see HTTP version 2 lubab ja mida see gRPC lubab on, klient võib öelda, et ma sooviksin kuhulata mingisugust anmebaasi uusi, anna mulle anmebaasi mingisugust kirjed ja ma sooviksin jätkata kuhulata uusi kirjed, mis anmebaasi lisatakse, ühendu siia plaht ja siis server saadab iga kord, kui uus anmebaasi kirja lisatakse, saadab selle ühenduse kaudusis uued metodi tagasi, et me saame siis kutsuda välja mingisugust metodi, mis ei tagasta meile üks kord, vaid jääb tagastama striimina siis anmeid. Teine võimalus, et me on võime, et klient saadab siia servers näiteks kümme ekraani vaadet ja server saadab meile tagasi video, kus ta on need kümme ekraani vaadet kokku pannud, aga me ei pea need ekraani vaadet saadmas ühe päringud, me võime teha näiteks kümme päringud, et saata kümme ekraani vaadet või pilti ja siis lõpuks saame servered nagu ühe tulemuse tagasi, et on võimalik ka sellist mudelet täita. Või siis meil ongi võimalus jäta kahe hajusestemi komponentid vahel ühendus lahti, me saadame järjest päringud ja me ei oota vastusid, ma lihtsalt viskamme torusse uusi metodi väljakutsaid ja server töötab neid ja saadab tagasi meile meil metodi väljakutsaid tulemusi. Me pea uusi appi päringud tegema või teeme ühe päringu ja selle ühenduse kaudu saadame uusi sisendäid funksioonile. Me saame siis järjest uusi sisendäid sellele funksioonile saata ja me ei pea uuesti ühenduse loomist tegema ja siis server jätkab meile vastuste tagasi saadmist. Võimist, et ta on nagu websocket, kui tahate websocketid progameerind, aga mis on nagu hardtab appi teab puhul, ei ole väga uus tehnoloogia, aga gRPC toetab seda siis sellise appi te tasemel või rpc tasemel. Ja kui Jasoni mingisugune näite, Jason võtaks 81 paiti, siis gRPC sõnum, üks näite anad, võib võta peage 3x vähem ruumi lihtsalt selle vähem võrguliklust võrgumahtu. Ei, see ongi see, et kui meil on mingisugune, see on nagu keskminevõrdlus, nagu suvalse näitega, et ta võib umbes 2x-5x vähem võtta, aga see täiesti oleb sellest, et kui telt Jasoni on mingisugused ästi lühikised võtme nimed, et siis võib-olla ta ei võta kaks korda väksel, kui neid võtme nimed on nagu ühetähelised ja põhimesed teemaldab kõik mittevajalikud asjad nagu Jasonist ja proovib edastada ainult need anmed, mis muutuvad. Ja kodeeriteks sene pinaarsalt. No tegelikult Jason ka kodeeriteks pinaarsalt, see olnud tegaks aina pinanesteam, aga ikkagi see võtab, see on päris palju sellist lisa karakterid ja märke, mida tegelikult ei oleks vaja edastada iga Jasoniga. Ja siin on üks näide selle käa RBC kohta, et me saame tekita sellise protofili, mis defineerib, et mis on metodid ja mis on nende metodide sisendid ja väljundid ja mis on nende objektide, tüibid, mida ma edastame nagu sõnumitene. Me saame defineerida, et importida Google Prototype wrappers, kus on väga palju sellist baas tüüppe kirjeldatud, et kui me tahamme integeri saada, et kuidas ta integeri kirjeldatakse. Ja me saame defineerida, et meil on inventory service ja selle serviceil on kolm metodid, mis on RBC tüübi metodid, getItemByName, getItemByID ja getItem. Me defineerime, et mis on nende sisendiks. Sisendiks võib olla meie enda klas, näiteks item, item või items või siis võib olla Google Prototype, protobuf string value või Google Prototype, protobuf pool value või integer value või midagi muud. Ja et siis, kui me saadame string value, siis tagastatakse meile itemite list. Kui me saadame getItemByID ja saadame string value, kus see string on sa ID, siis tagastataks üks item. Ja add item on siis selle post metodid, et paneme uue objekte anme baasi ja tagastatakse meile pooliam välu, et kas see on nende. Ja kui meil on siis selline custom tüüp, et meil on item, me defineerime, et selle item on ID ja name. Ja kui on items, me defineerime, et meil on itemite list. Ja ma ostadesin määleta, mis item desk on, description. See on põhimõtteliselt kaks parametri, mis defineerivad, et kui meil on kuskilt binary string, siis mitu tükki saad lugeda vist. Et kui me saame tagasi väärtused, seal on kaks itemid, siis me võtame ja streamist proovime kahta seda tüüp asja lugeda. Me loome seda ühe string väärtuse, me loome seda ühe name väärtuse ja kuna meid on kaks, me loome ühe korral, loome veel. Ma olen Sarnast asja implementeerinud suur anmete töötluses, et ma pole sada protsentikindal, kas see on korrektne viis. Et siin ei ole nagu nende itemite listi, vaid see põhimise defineerib, et kui meil on puffer, siis mitu objekti seda pufferist lugeda. Aga me loome seda tüüpi objekti seda pufferist ja see objekti defineerib, et pufferist peab olema siis üks string tüüpi väärtus, üks string tüüpi väärtus. Ja tavalselt on seal defineeritud ka nende väärtuste eraldaja. Ja items lihtsalt ütleb, et mitu objekti on seal listis ja vist ühteb ka, kes selle mingisugune kirjeldus ka lisaks, et näiteks, mis tüüpis on, et ta on item või minega muud. Ja ta toetab siis näiteks jaavad, pyytonid, teisi keeli ka. Mis ongi enam vähem kõik. Ma olin natuke vähem slaide. Nii, et võib-olo ma saan midagi juurde rääkida, et ma ei teagi, miks nii kiiresti tänne läks. Et põhimõtteliselt järgmine kord, siis me räägime veel ühes sellisest hajus-anme suhtlusest, mis on hajussüsteevide speciifina, räägime natuke näha hajusobjektidest, et kudas need on kaug protseduuridest erinevad, siis lähme üle veepi-teenustele. Aga samuti räägime sellest, et kudas saab neid veepi-teenuste appisid, mis on ka siis soap või HATTP protokolliga, et kudas neid saab siis hajus. Vabandust, kas keegi saaks suumis öelda, et kui kaua see ühendus maas oli? 30 sekundid, jah. Ma umbes saan aru, et kuna sinna 5 tudenki talle esi jäänud, nad ei ole nagu äralend, et kuiaks pool tündis nad oleks tõenast lahkunud selleks aegs, et ma siis lootsin, et ta koha nagu ühendas. Aga ma loodan, et see salvestus ei lennud kõikki. Tavalliselt sinna internetiga probleeme ei tegi, et selline on uvitav olukord. Järgmene nädal siis hüppame nagu sellistest ajaloolistest hajussüsteemide teemadest natukene veepi-teenuste juurde üle ja räägime siis kudas neid kasutadeks selleks, et defineerida siis appisid. Kas siis saa moodi, et me defineerime appid, mida klendi rakendustest välja kutsutakse? Ma hüppan korraks selle visiooni peale. Kas siin vahel need appisid või ka siis nende hajussüsteemide komponentide vahel? Ja meie praktikumist tegelikult teeme saarnasid asju nagu siin, aga me ikkagi kasutame seda REST ja HATETP-appid mitte, GRBC praktikumides oma komponentide vahel ja seame üles oma rakendusega Azures ühes tuleviku praktikumis. Aga sellest nädalab praktikumis me kasutame rabitid edasi, veel ükskord ja järgmine nädal me enam rabitid ei kasuta, aga see kord kasutame rabitem-q-t, et siis ise üles sehitada JSON sõnumite põhine arpet see, niimoodi, et me kasutame rabitid kahe serveri vaheliseks ühenuduseks, me seame üles kaks püütam programmi, mis küll teiarvutist töödavad samas arvutis, et me ei paned neid serverist tööle, aga nad oma vahel kasutavad remote rabitid, et vahetada sõnumeid ja see sõnumeivahetus toimub umbes niimoodi, et meil on nüüd klient, kes soovib välja kutsuda arpets see metodid, näiteks arpets see, et õmba alla raamat ja otsi sõne sealt, ja me siis serveris implementeerime, et kuidas tõmata alla raamatud ja otsida sõnet sealt, ja klient siis saadab arpetsse sõnumi JSONi struktuuris, mis ütleb, et mis on metodi nimi, mida me soovime välja kutsuda ja mis on selle metodi argumentid, ja meie server hakkab kuulama teatud rabitmq järekorda ja sinna järekorda suunatakse need sõnumid, mille rootimisvõiti on selle metodi nimi ja see serverimplementatsioon, mis seda järekorda kuhu see rootimisvõiti kohal jõuab, siis temal on see implementatsioon, mis seda metodid oskab. Käivitada, nii et siis see serveri kood saab põhimõtteliselt JSON sõnumi, mis ütleb, et käivita otsi tõmba alla raamat ja otsi sõna ja ta teeb selle läbi ja siis ta publiseerib selle tulemuse tagasi rabitisse ja meie klient tegelikult ühendus ajal saab endale oma lokaase postkasti, kuhu server saab iljem rootida tagasi selle sõnumi ja klient saadab siis ühte exchangei, metodi väljakutse ja samal ajal kuulab üste järekorda, kuhu temale tagasi rootitevad sõnumid, siis jõuaad ringiga tagasi. See on see asynkroonne metodid ja väljakutsumine RPC modelis, kui ma selle implementeerime ise rabit ja püütaniga, aga see model on aesti lihtne, et seal midagi keerulist ei ole, et reaalisest elus me peaksime natuke rohkem implementeerima, et sa päriselt nagu tööle saaks üks kõik, mis metodid teaks, aga te saate nagu nägemuse sellest, et kuidas sa RPC, JSON RPC on implementeeritud, kunas sa tegelikult baas loogik on suur, et see on sellest, et see on sellest, et see on sellest, et see on sellest, et see on sellest, et see on sellest, et see on sellest, et see on sellest, et see on sellest, et see on sellest, et see on sellest, aga nüüd on suhtseud lihtne. Slaide pole. Aga õnneks ma väga palju slaidena ei kasutanud ka. Ma siis jagan ka zoomineid slaidid. Või mõtselt mõne oligi paar slaidi, kus ma rääksin lihtsalt sellest, mis on järgmises looingus ja järgmises praksis. Slaide näitega siis veebi lähelt saata allatamata näid. Aga lõpetamist tänakse sara, et oli natuke väiksem loo, enge ei läinud seekord üleaja ja arvasin, et ma selgitan, et näite natuke kauem, aga läks suusad kiiresti. Jah. See oleneb sellest veebi poest. Kui see on Amazon veebi poot, siis see on selline. Aga kui on mingisugun lokaalne Eesti veebi poot, siis ta on pigem monoliitne. Aga reaalselt, kui sul on ikkagi, ma ei tea, miljon kasutajad, kes Temus ööhendub ja asju ostab, siis sa nagu monoliitsa rakendusega väga hakkama ei saa. Et kui seal reaal ajal on ikkagi tohutud palju külastajad, siis sul on vaja nagu skaleeride lahendust ja selle asemel, et skaleeride kogu monoliitsad süsteemi koopjaten on tihti parem. Kui sa tead, et skaleerime näiteks orderite töötlust eraldi, kui product katalog töötlust, võib-olla siin tuleb tohutud palju kasutajad, aga siin on vähem, et me saame specialiseerida selle optimeerimisele, selle asemel, et proovida optimeerida kogu sellist suurst süsteemi. Jägame siis oma suuresüsteemi väikisseimateks mikroteenusteks. Me saame, et iga meeskond arendab oma mikroteenust näiteks. See on jaavas implementeeritud, see võib näiteks mingis teises keeles olla implementeeritud, näiteks ko programeerimeskeeles. Ja me saame ka kõiki eraldi skaleerida, nad töötad eraldi konteinerites ja oma vahel suhtlevad. Siin näites KRPC protokolli kaudu. Ei ole mitte mingisugust reglit. Kui sul on nägemus, et tulevikus ei saa ühe servega nii hakkama, et sa pead algus selle peal mõtlema, et kudas sa seda skaleerimes teed. Ja tänapäeval väga tihti võetakse mikroteenused kasutusale, selleks, et hiljem oleks lihtsam asju tükeldada, asju skaleerida, et sa ei pea ette vära mõtlema, et okei, no mul on monolid, seal on probleemid, et ma akan kasutama mõttes. Ja me saame kõik, et me saame kõik, et me saame kõik, et okei, no mul on monolid, seal on probleemid, et ma akan kasutama pool aastat selleks, et sa monolid väiksemadakse tükkideks designid. Tihti võetakse mikroteenused kohekasutusale, aga see ei pruuki kõige efektiivsema olla, et see võib alguses kallimaks minna. Et kui sa pead ühe virtual machine asemel mingit 16 konteinerid jooksutuma ja... Kui sa mikroteenust teed, siis ei saa. Kui sa ja, otsustada alguses monolidina ja implementeerida, siis saad. See ei ole, et see pole vahetas ja pohalik, kui ei ole see kogu. Jah, nagu virtual machine või serveri mõttes jah, aga konteeneri mõttes mitte, et see on väga halb praktika panna liiga palju asju ühe konteenere sisse. Konteeneres võiks olla üks peamine protsas, mis jookseb ja kõik. Üks Flask server, üks Fast API server ja kõik. Et kui sul on kolm mikroteenust, siis nad tavast jooksevad kolme protsasina ja siis sa ei tohiks väga ühte konteenerse panna kokku. Ja see on halb praktika, kui sa proovid näid ühte konteenerse kokku panna. Sest nad kõik kirutavad erineva striimi logisid näiteks, siis on kõik logid koos. Nad kõik üks jookseb kokku võib terve konteener kokku joosta. Et neid vältida siis tee üks virtual machine ja pane sinna mitu konteenerd sisse. Ja see palju parem seda arendada ja administreerida, kui nad on eraldi konteenerdas. Isegi konteenere ehitamine on sul palju lihtsam, kui sa ei pea mõtlam veel, et mis järekonnastat protsasid peakse selle konteenere. Sest jooksemad sa pigem ütle neid samu asju nagu väljaspol konteenerd panat paikad. Aga muidu idee on küll see sama täpselt jah, et panat üste virtual machine ja kõik kokku. Sest ta nii kaha kui vajadust ei ole, töötab ühes server ja ühes virtual machine. Aga tänan panen praegu ka suumi siis kinni.

---------Loeng 5 - Veebiteenused SOAP REST.txt--------

 Tänase loingu teema on siis webi-teenused. Järgmine nädal me jätkame webi-teenuste teemadega ja räägime sellistest webi-teenuste standaarditest nagu Open App ja Swagger ja mõned ka Soop standaardid. Aga täna räägime pikem, mis asjad on üldse webi-teenused. Räägime, mis on Soop protokoll ja räägime, mis on HTTP protokoll. Nii, natuke räägime ka REST spetsifikatsioonist, mis on selline välja pakutud standaarditest viis, kuidas HTTP appisid kasutada. Kuna HTTP protokoll ise võimalda väga palju erinele viise kasutada, siis REST oli selline viis, kuidas proovida, siis natuke standaardiseerida, kuidas neid appi meetodid välja kutsuda. Varasemast praktikumis olemme rääkinud Soop liuendustest, olemme rääkinud sõnumite vahetusest, olemme rääkinud sõnumite järekordadest ja RPC-st. Täna võtamegi viimase teema, mis on seadud nende suhtlusviisidega, kui ikka järgmikord natukene katame veel webi-teenuste, aga siis lähme juba ka pilve-teenuste poole nad küle. Täna rääkime siis, mis on HTTP ja Soop ja rääkime, mis on REST spetsifikatsioon, et mis on erinevus HTTP ja RESTi vahel, et kui keegi teile räägib REST-appist vahe vahe. Alustame webi-teenuste ülevaateste ja siis lähme nende protokollide juurda. Et mis on üldse webi-teenuse, et kui te täna päeval kasutat VVV-d, World Wide Webi, webi üldiselt siis teie browser läheb kuskile mingisuguse serveri hostneemile ja mingisugusele adressi selle hostneemijalle, mingislash appi, slash raamatud näiteks, ja kutsub välja seal HTTP metodi, et teha ketpäring ja mingisugune resursse alla tõmata. Et webi-teenuste ta valis on alati mingisugun resurss. Browseri puul see võib olla siis HTML-fail koos mingi JavaScript-failiga või siis mingi PILDI-fail, või siis mingi TEXTI-fail, või siis mingit muud tüüpi resursset. Tavalaselt me räägime mingitest resurssidest, mida ülerendi webi-appide siis alla tõmatakse ja teie browseris siis näitab teile, kui te browseri kasutajate olete. Aga vnb-teenuste on natuke üldisemad. Idee on, et kui meil on nii laialtane protokoll kasutuses, et kõik maailma arvutid ja browserid kasutavad samu webi protokolle, miks mitte neid protokolle kasutada, aga siis üks kõik milliste operatsioonide välja kutsumiseks olgu need siis teie poolt, kui te lähete Google Translate lehele ja soovite ingliskeese tegsti ja estigeese tegsti tõlkida, et te lähete browseris, kirjutada sinna teksti sisse ja kutsud selle välja saate tulemuse kätte, või siis te teete pyütun rakenduse, mis vaatab, kus asub Google Translate appi ja teab täpselt sama protsesi läbi, et välja kutsuda siis Google Translate metood üle webi ja täpselt samu protokolle kasutades, kui see lähene minu natuke teine ja seal tulab ka autentida, kui teie rakenduse hakkab Google Translatei välja kutsuma, aga põhimusalt täpselt samade protokolle te vii põhjal on võimalika siis teie püüten rakenduse Google Translatei välja kutsuda. Või siis te teete ise, panate üles mingi eestigels põlkimise appi ühe hajussüsteemi komponentina ja teises komponentist kasutate täpselt sama viisi Http appid, näiteks, et selle teise hajussüsteemi komponenti funktsiooni välja kutsuda ja te kasutate täpselt sama appid, või sama protokolle, mida kasutad teie browser, või siis see püüteni programaks kasutanud, või siis hajussüsteemide komponent ka kasutab täpselt sama protokolle. Ja kui nüüd sellised hajussüsteemid, appid, webi teenused samamoodi ülesheita, siis nad on kõik oma vahel ülduvad. Et siis saabki lihtsast ehitada selliseid komponente, mis on võimalsed teiste komponentide metodeid välja kutsuma, et me ei pea nii väga nagu uurima, et mis sellised protokolle nad toetavad, või me saamegi sellised webi protokolle välja kutsuda. Aga selline ingliskeene definitsioon on, et webi teenused on siis loosely coupled, web services are loosely coupled, standard based reusable software components that systematically encapsulate some discrete functionality and are distributed and programmatically accessible over the standard internet protocols. Et ei peaks mingit erilisi protokolle nendele jaoks välja kutsuma ja tähnapäev väga suur osa webi sasuvatest teenustest, kuskil mingisuguse targvara poolt pakutavad teenused ongi webi apud ja poolt välja kutsutavad. Jah. Jah. Jah, et suvalised webi lehed samuti serveerivad resursse ülesamada protokolle, hattateb ja hattateb essi ja tänapäeval kõik ongi sul pikem nagu webi teenuste peale ülesehtudud. Võib-pal, see vahe on see, et kui see tavalne web on mõeldud HTML lehteda või allatõmvamiseks ja näitamiseks, aga mina tahan nüüd mingis serveres mingisuguse meetodi välja kutsuda, et ta hakkaks piltetöötlema või et ta saadaks mingi alarmi või midagi. Et enam ei ole selleks, et ma soovin mingid webi lehte vaadata või mingisugust ma pikem soovin nüüd täiesti mitte webis oleva kahe komponendi vahel mingisugust meetodi välja kutsuda, et näiteks ma soovin pilves uut virtuaalmasinad luua, ma saan täpselt sama protokolli kasutada, et pilvega 11 võtta ja jäälda talle, et halosta mulle loomul uus virtuaalmasin. Aga ma kasutan täpselt sama protokolli, mida ma kasutaks kuskil HTML lehel läbi vormi uue sõnumis isestamist kuskil foorumisse. Et see protokoll on täpselt sama. Kuigi ma ei soovin mingid webi and-mate muuta, ma pikem soovin, et Amazonis uus virtuaalmasin käivitataks. Et saan asjad protokollid. Mis on vahe webil ja nendel webi teenustel? Et ongi, on tarkvaratenused, mis kasutavad World Wide Webi protokolle. Aga see tarkvaratenus võib üldse mitte webiga olla seotud. Aga tihtin, et webi teenused, neid näheks ikkagi, et nad on webis kätte saadav, kuna tegelikult ma saaksin kas webi browseri või postmaniga minna ja vaadata, et mis on hetkel jooksad virtuaalmasinad. Et ma saaks minna browseriga vaadata, et mis on Amazonis mulle jooksad virtuaalmasinad, et kui seal on toetatud sama ketparing, millega ma mingid webilehti alla tõmban, siis ma saaks samav ketparing ka listida näiteks jooksvaid mingid resursse või Amazoni webiservery. Mane teised näiteks, et me saame, kas läbi browseri üleslaadida mingi pildi, et seda väiksemaks konverteerida või me saame oma appi kaudu või oma tarkvarakaudu näiteks pyytu niist väljakutsuda siis selle pictures.com taostal oleva webi teenuse. Või see redditid, et me saame browseri kaudu redditeese sõnumid, panne sõnumid listida, aga me võime ka otse kasutada nende webi appisid, et seda programmatiliselt teha meie programmis ja ehitada näiteks mingi mobiilirakenduse, mis ise nagu listib neid redditi poste, mida meie kasut on teinud. Kui tänapäeval on minnaks see selles suunas, et need webi appisid limiteeritakse, et limiteerida, kui palju võib üks kasutada näiteks mingisugust pärin, kui redditi vastu jooksutada, et reddit tahab hakkata rahaküsima selleks, kui mingisugused teised firmaad tohutud palju redditi appid kasutavad näiteks selleks, et allatõmata mingeid tekst, et õppetada oma masinope mudeleid või suur keele mudeleid, et siis hakkati nagu järjest kinni keel, et meie webi appisid ei oleks nüüd nii lahtised enam. Põhjemist panaks see neile limitid peale. Ja webi teenuste omadused ongi siis, et nad toetavad täpselt samu protokolle, mida ajaloolised kasutati webis, esimeste webi süsteemide loomiseks. Nii, et meil on mingisugune server, mis serveerib mingisuguseid resursse või võtab vastu mingisuguseid operatsioone üle samade protokollide, ja siis klient ühendub sinna serveris ja kutsub selle serveri mehedoteid välja. Põhimõttel samasugune mude nagu RPC-el. Webi teenuseid saab lihtsalt kasutada rakenduse webi liidese ja taga teenuse vahel, et meil on JavaScript rakendus, mis jookseb kasutaja brousseris. Küll esimest kord, kui me läme mingile webi rakendusaadra, siis tõmadaks JavaScript alla, hatemel alla käivitadakse, aga selleks, et mingi tünamlist infod kätte saada, siis webi teenus, mis jookseb JavaScriptina, siis tõmbab kuskilt appi kaudu teisei anmed alla. Kasutajapraeguseid anmed ühendub kuskil taga liidese appisse ja tõmbab kasutajanmed alla. Aga samamoodi võib neid samu webi teenuste protokolle kasutada ka mikro teenuste vahel või hajussüsteemide komponentide vahel selleks, et meil oleks täpselt samasugune standardne liides, et me ei peaks mäliste klentide ja esiliidese vahel kasutama HTTP-ed ja siis me peaksime oma mingi hajussüsteemide komponentide vahel kasutama teisi liidesed. Tegelikult on võimalik hajussüsteemid ja mikro teenused ülessehita nima, et kõik kasutavad neid webi protokolle. Kuigi täna päeval see ei prugi kõike efektiivsem olla, et näiteks on tihti efektiivsem kasutada mingi teise protokolle nagu gRPC-ed näiteks, et efektiivsemalt suhelda hajussüsteemide komponentide vahel, aga sellest räägime võibolla tuleviku looingutus. Ja miks webi teenused on nagu populaarseks sanud, et see võimalitab sellist erinevalt ehitatud teenuste oma vahelist koostööd, et meil on täelik platformi neutraalsus, et kui me loome rakendused, mis räägivad näite HTTP-ed protokolle, et siis siia olla vahel, et mis keeles nad on implementeeritud, me saame nad oma vahel rääkima panna üksteise meetodeid välja kutsuma panna ja see võimalitab lihtsasti teha nad täiesti programeerimes keeles sõltumatuks, et kui meil jahk jahva ja püüt on oma vahel vahetavad jason sõnumeid läbi HTTP, siis tegelikult ei ole vahet, mis parsjad kasutatakse ja püüt on itse ja mis parsjad kasutatakse jahvalt, et tulemus on ikkagi täpselt sama sugunne. Me saame siis neid appisid välja kutsuta, kas synkroonsalt või asynkroonsalt, et kui meil on vaja näiteks hästi palju anmeid üleslaadida, siis me ei pea ootel jääma, et kas me... kas pilt laeti üles ära ja siis hakkame järgmist pilt üleslaadima või ma asynkroonsalt näiteks 10 pilti samaheikselt üleslaadida erinades lõimedest. Saame näiteks läbi lõimed ja kasutada neid appisid asynkroonsalt või siis, et ei jäägi ootama või... et saab siis nii asynkroonsalt, kui sinkroonsalt kasutada. Ja tavastame kasutama sellist klentserver mudelid. Server on see, kes siis implementeerib, mis operatsioonid on ja mis resursid on serveritud ja mis operatsioonid nende resurside peal võib välja kutsuda. Ja server pakub mingisugust teenust ja meie saame teha päringuid või saata rekveste sina serverisse, et midagi küsida. Ja... Üldjuhul, see on natuke erinev sõnumid nende järekordade systemist, et klents ja server peavad suhtlemise aale olema aktiivselt, et meil ei saa... klient ei saa serverisse, on meid saata, kui server samal ajal ei ole aktiivne. Ja kui meil on synkroone, siis klentavased ka blokkeerib, kuni ta saab vastusa. Ja serveri loogik on tavalselt suhtselt lihtne, et ootab mingid sisse tulaid päringud ja sehera töötleb ja vastab nendale, et alati saab ehitada palju keerulisemad süsteeme, mis töötavad sellise, kui ta saan, lüüsina hajussüsteemi ja klentide vahel. Ja see tarkku ära, mis esimised päringud vastu, ota peale tegelikult see, mis anmeid töötleb ja töötlevad võib olla mingisugused teised komponentid hajussüsteemis, aga see lihtne lähene minna on server lihtsalt võtab päringud vastu, töötleb need ja vastab nendale ja kõik, et ehitada sellised lihtsad lahendusi. Server ja klendisuhtlus saab lihtsalt visualiseerida niimoodi, et klent saadab päringud ja server vastab nendale, see ongi selline request-response model, kus on klendi ja serveri vahel suhtlus. Aga meil võib olla siis neid lähenemisi tavalselt mitu, et tihti on, et meil ei piisa lihtsalt mingisugust ühes monoliitsest rakenduses, kes tegeleb kõike kärad, meil on vaja anmebaasi, meil on vaja siis mingisugust teisi, võib-olla me tahamad serverid skaleeridesi, meil on vaja ka mingisugust sisse tuleva liikluse jaoturid, et tavaliselt, kui just meil ei ole hästi lihtne rakendus, siis me ei kasuta sellised ühetasemile arhietuse. Kui meil on kõik arhitektuur, et meil on ainult klent või server, vaid meil on kas kahe-kolme või sike endasemised arhitektuurid, et selle aseme, et meil on monoliitne server, me paneme anmebaasi erinevasse virtuaalmasinasse või erinevasse asukohta, siis meil tekib selline kahetasemile kiht või siis meil võib-olla ka kolmekasemile kiht, et meil on eraldi frontend mingisugune Javascript HTML põhine lahendumist avaselt jookseb klendi enda arvutis, et kui klenti esimiskorda server raadus läheb, tõmateks alla Javascript-aadiselt arvutis, ja Javascript, ja see käivitub tägelikult klendi arvutis, see on väga hea, et vähendada serveri koormust, et näiteks kõik kaardipõised rakendused nagu Google Maps'i sellised, töötavad pigem tagud klendi arvutis Javascriptina selleks, et mitte koormad üle serverid, siis on tägelikult väga efektiivne viis, kui tähes kasutada klentide arvutide jõudlust ära selleks, mingi tarkkora sellase mõel, et see server peaks kõike renderdama serveri pool ja saadma need anmed. Et siis meil tekeki selline kolmetasemne archituur, et meil on klient, klienti arutis võib-olla mingi front-end, front-end suhtle back-endiga, nii et meil peab serveris mingi tarkkora olema ja siis eraldiga anmebaas, et meil siis ongi tekivad sellised kihilised süsteemid, kus tõmataks alla näiteks mingi Angular Vue, raamistiku Javascripti ja siin onksutatakse klienti arutis, azee oma korda suhtleb näiteks HTTP ka protokolliga siis rakendusserveri back-endingane, mis on võib-olla implementeeritud kas mingis Python Flask raamistikus PHPs või Node.js'is ja siis pärast seda meie rakendusserver ühendub siis anmebaasiga, mis on oma korda näiteks mingis teises virtuaalmasinas, mis suhtleb siis selle rakenduse ja anmebaasi vahel näiteks kasutatakse SQL, et Structured Query Language protokollis siis pärin kuid teha anmebaasi ja seal on mingi Postgres näiteks või MySQL või Misiganas. Jah. Pärast. Seda see neid on nagu meil on tehtud? Pike me ei pead, nagu hea hea praktis hea hea lähenemine on, et ei sai peagi meeles, et sa põhimõttelselt, kui sul tuleb siit hästi palju klientte, siis sa paned siia ühekii veel vahele, et sul see frontend jooksab kasutavarvutis, kasutavarvuti võtab ühendust nagu hostnameiga, mille taga on siis need serverid, aga siia tekib siis jõudlusejaotur või sellne load balancer näiteks seda siin on konfigureeritud, et mis on need serveri adressid, apide serveri adressid ja sul tekib appi serveritas 16 koopjad ja see vahe pealne jõudlusejaotur siis valib nende 16 serveri seast, et kui tuleb ühel klendi päring, et millisele 16 serverist siis päring edasi suunata ja siis tekjad küsimused, et kas ma tahan, et minu rakendusa serverappi hoiaks midagi meeles, kasutajahelmise päringu kohta või mitte, kui ma ei pea meeles oledma, see on hästi lihtne, ma lihtsalt suunan üks kõik millises sellesse 16-sest serverist. Kasutajaga tuleb kaasa kasutajad või mingisugune kasutasessioon või kypsis ja seal kypsises on tavalist infot, mis kasutajaga on tegu ja server kontrollib üle, et see kasutaj on autenditud, tal on õige, et mingisuguse turva taukenid ja kasutajad ei tee põhjal, mis tuleb selle päringu kaasa, selle põhjal siis se server töötlab seda rekwesti ja näiteks paneb või võtab kasutajad anmebaasist ja iga kord, kui tuleb uus rekwest, siis server võtab anmebaasist selle kasutajad anme ja teeb sellega midagi. Mul on kaks slide selle kohta ka, et kas on efektiivne, kui ei hoita meeles kasutajelmise päringute infot, kui meeles hoitakse, siis saab ka siin koormuse auturis või loot balancerist teha sellist sticki ümbersuunamist, et kui tuleb kasutaja IT-värtusega mingisugus konkreetse IT-värtuskanmed, siis meil on seene loogika, mis tavaselt on eteks hashide põhjal, et kasutaja IT hashitud mingisugus algoritmiga selle põhjal jagatakse samalt kasutajalt tulnud päringut alati esimeses serverisse, et lihtsalt hoolistuks sellest, et suunatakse alati sama kasutaja anmed samassa serverisse, et siis on võimalik sellist sessiooni info või stateful töötlus ka teha, et jätta meelde, aga põhimist ja siia panaks see veel üks kicht vahele ja jagatakse need päringut, sisse tullad päringut paljude appi serverite vahele ära. Ja seda me, ma pole kindel, kas me selles ainees vaatame, aga ma räägin selle kohtaga pilvetehnoloogia loengus täpselmalt, et kudas seal pilvetehnoloogisse skaleerimine käib ja nende sisse tulevat päringute jaotumine, paraleliselt töötavate replitseeritud rakenduse koopjate vahel käib. Jah aga to oli natuke keeruisem sisteemed, pikem võib-olla lihtsam, kudas sinul on võimalik luua oma appi rakendus näiteks pyütan flaskis, nagu me praktikumis sisse teeme ja siis tockeris saada seada üles kaks koopjad, sellest kaks tockeri konteinerid ja nende vahel liiklus illust ära jagad, et see on isegi tockeris, see tänab on sisse ehitetud, et see saad niimoodi liiklust jagada mitme tockeri konteineri vahel ära ja kui sa tead tockeris vormis, siis need konteinerid võib-olla olema viis serveris. Et natuke lihtsam läheneme, et lihtsalte tekitame appist mitu koopjad ja jagame sisse tulevad päringut nende vahel ära. Jah aga seal on väga väga aga, et see peamine muster, kudas Postgres nagu paraliseeriteks, see on niimoodi, et sa sead üles ühe peamise serveri ja tema on nagu see right server, et kuhu suunateks kõik right päringud ja sa sead samal ajal üles näiteks nelideist read koopjad ja hoolid seda taustal, et kõik right päringud synkroniseeriteks read koopjadele ja siis sa saad paraleliselt 15 serveris luge tanmeid, aga sa suunad kõik kirjutamised samasse ühteservesse, et see on kõige tavalisem muster, kudas Postgres kasutada saad hästi hea sellise lugemise jõudluse ja kirjutamise jõudluse paraliseerimiseks on palju palju keerulisem Postgres puhul. Ja me räägime ka ühe sannebaaside või piljotehnoloogil looängus natuke sellest, et mis on need alternatiivset, mis oskaad paremini neid kirjutamisega ära paraliseerida. Et ja, et sul on võimalik mõnesmitte see on kõik paraliseeritud, sest see ei avaskeleb jookse kõik, et kõik ka kasutavate arvutite vahel ära, et ta ei ainult tõmatakse põhimised JavaScript alla ja Hatemel alla ja kõik resursid alla. Rakendust seda saab siis paraliseerida ja anmebaside paraliseerimin on natuke keerulisem teema. Selle teutud ihti Postgres SQL ja asemel sa kasutad näiteks mingit Amazon SQL teenust, mis ise oskap sisemiselta asjad ära skaleerida, et siis saab ise selle pärast nii väga muratsamad. Siis olemegi natuke tagasi selle küsimuse juurde, et kas teha synkroonsed suhtlust ja asumkroonsed suhtlust. Synkroonsed suhtluse puhul klientid jäävad ootale, kui nii nad saavad mingisuguse tulemese tagasi jätkuvad ja asumkroonsed suhtluse puhul nagu täpselt esimeses praktiku, mis saaks klient lihtsalt teha lõimed ja erineate lõimed ja ka põhimõtteliselt kutsuda välja erinead HTTP metodid näiteks või API metodid, et sellise juhu nagu anmete saad, mist või kuulamist ei blokkeerita, aga saab teiste tegevuste jätkata. Ja tihti nende see webi apides on sisse heitatud asumkroonsus, et iga kord, kui tulla puhus päring, siis tekitatakse lõim näiteks või panakse päring tööde järjekorda ja siis töödel takkse lõimedega sehära, et oleks kaljeerivam, et ei tekikse seda probleeme, et on ahjad üks töötleja, kes sellega tegeleb, vaid näiteks fast API python rammistike puhus ja python rammistike puhus on hästi tavalne, et iga sisse tulla päring, kui jaoks genereeritakse eralte lõimed, kes tegeleb selle töötlusega. Ja ühendustega ühenduste protokollide ja se serverite puhul on tegelikult atuke keeruline teema, kui te seda hästi seletada, sest üks asi on ühendusega protokollid ise näiteks TCP, kus luaks see kahe osapool sokkalite vahel ühendus, ja selle ühenduse kaudu saab saata pakette, aga meil on ka ühenduseta protokollid näiteks UDP, kus me ei peagi sellist sokkalite otsaselt looma, või tegelikult me peame sokkalite vahel sellise defineerima saatmise, aga me ei peasi püsivad ühendust defineerima, et me peame saata pakette. See võimalda veel rohkem saata on meid ilma, et me peaksime iga uue saatja asu. Sa paketite saaja koku lepima, et me teeme ühenduse, et me saame UDP protokolliga näiteks lihtsalt saata pakette ja saata pakete paljudel adresile korraga või kõikidele hetkel lokaasusvõrgus olevatele seatmetele ilma, et me saame kõikidele nende adresi ja teame, et saame sellist broadcast ja multi-casti teha. Aga ühendusega protokollide puhul on suhtus natuke ebaefektiivsemsest, me peame kõigepealt ühenduse looma ja siis kõik järgmise paketid peavad olema seotud juba tehtud ühendusega, et me peame koku lepima, et see server peab ühenduse vastu võtma ja siis me saame selle ühendusega seotud pakette saata teise otspunkti. Ja mitme partneriga, et kui me kahe serveriga või kahe appiga sama aegis, et ta on ühenduses, peab iga ühe jaoks ühendus olema. Ja samamoodi võib vada, et serveri poolt, et selleks, et TCP protokolli kasutav server paketesaks võtta, siis tal on vaja tegelikult vähemalt ajutiselt luua ühendus ja seda ühendus lahtioida kõigi sisse tulevate klintidega. Aga see võimalda siis meil saata pakete niimoodi, et me saame jagada ühe suure file näiteks, mis üleslaadaks tükkideks ja meil tekib selleks ühenduse raamese paketide saamises paketide õige järjekord, et me panevame selleks pildi niimoodi õiges järjekordust takas kokku, mida UDP puhul on palju keeralsam teha. Ja teine, mida ma mainisin, olisi olekutepõhjised protokollid ja olekutepõhjised serverid, et meil on efektiivse teha kogu sellist ühest appist paljude koopjate, replitseeritud koopjate loomist ja nende vahel liiklus ära jagamist, et kui ükski server ei pea midagi meeld jätma eelmise päringukohta, mida sama kasuta tegi, et meil ei tegi seda vajadest, et me peame alati kasuta saatma täpselt samasse serverisse, et ühelt kasutat tulevad kolm päringud, nad võivad siis olla suvalistesse serveritesse minna meie rakandust töötab ja ei tegi mingiselt probleeme, et see tihti selle eelis on see, et meil ei ole vaja hoolitseda selle äest, et kas üks server saab hakkama kõigi klientidega, kelle päringud peaksid nendele olema alaku eritud, et me saame lihtsalt reaal ajas otsustada ümber, et või ästi labaselt või lihtsalt jagada neid päringud kõikide serverite vahel võrtsalt ära, ilma, et me peaksime arvesse võtma, et võib-olla üks kasutal, seal tuleb 10x rohkem päringud kui teised kasutalt ja kuidas me neid kasutad nende serverite vahel ära jagama, et sellisega asja ka ei pea tegelema. Aga olekult põhised serverid ja protokollid on sellised, et näiteks FTP serveri protokoll on selline, mis protokollis korraks autenditeks kasuta ära ja pärast seda saab kasuta saata nagu päringud, serverilma, et peaks mingisest kontrolli tegema, et kas kasutada. Ja no, autenditud, kas kasutala, on õigusi midagi saata, et saab teha sellise natuke efektiivsema lähenemise, et ei pea nagu igakord ülekontrollima, näiteks kas kasutaja võtgi on, kas kasutale on lubatud midagi teha, et seostatakse kõik sama ühenduseks jäutad asjad. Et server põhvist jätab meeld, et sellel kasutal oli õigus seda kasutada ja siis kasutas adab uue päringu, näiteks uue mingit failide listimise, et FTP on siis nagu file transfer protokoll, et serverist file aladamad üleslaadida, et siis saab natuke efektiivsem suhtlus, kui sama klienter tohutub palju päringud ja me ei pea igakord kontrolli, et kas näiteks appi päringu tegi ala on õigus, kas appi võiti on korrekte, et see on mõnesvõttes võib olla efektiivsem. Et nende jõudlus võib olla selline parem, kui mitte ole kui põhist servete puhul. Ja tihti, et miks me üldse seda teeme, et üks ongi see, et me tahame, et me tegaks meeldie jäted, et selle kasutale on õigus meie rakendust kasutada, samuti võib see FTP server meeldie jäted näiteks, mis failid on avatud, et kui kasutaj hiljuti mingist faili muutis, siis ta saab selle faili pideme lahti jäta Linuxis, et tal on efektiivsem seda faili uuesti avad, siin uuesti kirutada, et kui kasutaj näiteks sama faili uuest laeb, siis server ei pea uuest seda faili lahti, aga võib selle faili lahti jäta ja võib igasugus klendiga seotud info, nagu oma vahe mällu salvestada või mällu salvestada, et see oleks efektiivsem, et server ei pea uuesti otsima klendi anmeid anmebaasist näiteks. Aga selle suur probleem on just töökindlus ja skaleeritavus, et kui meil on hästi palju klente, kui palju mällu, siis selle klendite elmiste päringute kohta server peaks siis meeldie jätma ja see võib tekitada väga suure probleemi just törketa aluusega, et kui server kokku kasvus, me kaotame iguni kogu mällu, kui millegi tõttu suunatakse klendi päringut ühte teise serverse nüüd, siis jälle on see kõik kadund ja skaleeritavus on palju suurem probleem, sest me peame kui kudagi ka balanseerima seda, et kui palju servered haldavad, kui palju hetkel aktiivse klente, sest me ei saa lihtsalt nüüd klente teise serveri peale saata, et meil on efektiisem, et kui need peab samase serverse suunatakse. Aga olekute serverid, need ongi paremad sellise hästi skaleeritavad systeemide puhul ja nende ehitamiseks ja see on tänapäeval muutunud selliseks de facto standaardiks, et pigem kasutada oleku vabasid lahendusi ja protokolle, et näiteks, saadad, et peabapid on ka ülesseidadud niimoodi, et tegelikult nade ei tohiks meelda jäta midagi klendiiga seotud, et igakord kasuta tegelikult peab uuesti autentima, et näiteks heederis uuesti saadma appi võtme, heederis uuesti saadma appi päringuga, põhimselt kaasa saadmas lappi touken igakord, kui see suhtlust käib ja igakord autentitaks, siis kasuta uuesti ära. Ja et designitakse näite appid ja lahendused niimoodi, et nende ei jäta mitte midagi klendiipolt meelda, et ei salvestada siis mällu klendi info, et ei salvestada, kas failid on mingi tavatud, ei jäeta meeles, kas klend oli autentitud või mitte ja pigem kasutatakse näiteks klendi polsad sessioone, mis panakse kaasa siis päringutega mingiselt küpsised või appi toukenid ja sellega, et vältida näiteks, et see server peab ise anmebase, et nende alla tõmbama. Ja kui server soovib mingisugust anme, et salvestada klendi kohta, siis kõik läheb anmevaasi, et ta läheb väljas poole seda rakendust ennast, et ei jäeta rakenduse ja prozesimällu infot sisse tuleva päringu kohta. Ja kui klend koku jookseb, kui server koku jookseb, siis sellest mitte midagi juhtus, sest kõik meil ei olegi midagi mälus, midagi klendiipolt oli mälus, aga põhimest kokuse suhtus on üles ehitetud sellele, et me ei pea midagi meelda jätma, et päringute tegemine töötab niimoodi, aga me ei pea midagi meelda jätma. Ja sellest, et on ka hästi lihtne seda skaleerida, sest me võime lihtsalt suvaliselt sisse tulevat päringut, suvaliste serverite, saata suvaliste serverite vahele ära jagada, et sisse tulevate päringute balanceerimine, see on hästi lihtne, et meil ei olegi mingid tarkkus sisse vaja, loogikat sinna sisse vaja heitada. Aga lähme siis pigem nende protokollidi juurde, kõigevalt ma räägin soapist, mis on selle keerulline ja hästi mõnesmates ka tüütu protokoll, kuna need sõnumid on hästi suure, et mida saadetakse ja tohutab palju sellist mitte vaelik. No mõnesmates vajaliku, aga kasutale mitte vajaliku infot on selli juures, sest kasutatakse sellised x-emeljad dokumente. Et see oli siis selline sõnumi protokoll, ta 1998. aastat, et saada struktureeritud anmed siis selliste webi teenuste vahel, seda siia maani kasutatakse näiteks Eesti XT's, et kui te lähete tööle mingisse firmasse, mis tegeleb Eesti XT ka ja sõnumid vahetusega, siis XT on liikumas soapi pealt, HDTP arresti peal, aga väga paljud vanad asjad võib aga ikkagi soap protokolli peal töötada. Ja idee on, et see oleks siis täiesti platformist ja sõltumatu viis, kuidas välja kutsuda mingisuguseid ARP-C tüüpillisi operatsioone üle webi teenuste protokollid nagu HDTP ja sõnumid saadatakse XML-dokumentid, kuna XML on selline masin loetavad, kus dokument ise kirjalda päramis on dokumentisees. Piisab ainult sellest XML-dokumentist endast, et aru saada, mis infos on dokumentisees. Et see ise selgitav anme struktuur, kus anme tüüpid on tehti linkid enne kasas, et näiteks, kui me tegeleme mingisuguse Eesti riigi teenuse XML-dokumentiga, et seal eksisteerib link, mille kaudu saab allatõmata selle teenuse spetsifikatsiooni, et mida näid väärtused sellel XML-iseest tähendavad ja mis seal lubaadud nimed ja kuidas õieti parsid XML-dokumenti ja mis väärtused seal võivad olla ja või olla, et seal kõik vaelik info on mõnesmõttes XML-dokumentis olemas või vähelalt linkitud. Samas on probleemid sõnumide suurusega, et ei saa väga suuri sõnumid saata, et ei ole väga hästi toetadud pinaarse tanmetse saatmine, kuna XML-ise on tekst, ta on teksti dokument ja kui me soovime näiteks mingi pilti saata läbi XML-dokumenti, mis me tavasalt teeme on see, et me võtame pilti pinaarse tanmet, me tekitame pinaarse jada ja siis enkoodime selle Base64 algoritme abil niimoodi, et ta on string karakterid, ükski ei, põhimiseid ei tegei, nende see ole mingist karakterid, mis teeks mingisuguse XML-i või JSON-i parsimise katki. Ja siis me võtame selle Base64 enkooditud stringi ja paneme selle üheks väärtuseks sinna XML-dokumenti sisse, aga tihti see tähendab, et seal suure pildiaks hoidad olla tohutult suured stringi jadad dokumenti sees, mis hoidad olla suuremult, kui see originaalne pinaarna pilt ja näit fileid isemuutub hästi suureks. Ja HTTP ise toetab saama moodi HTTP protokollile, millest me räägime natuke iljem, aga seda võib ka kasutada teiste protokollidega lihtsalt. HTTP protokoll, et kuidas siis klient ja server oma vahel anmeid ja sõnumid edastavad, on osutunud nagu sellises kõige populaarsemaks, aga tegelikult sõup ei ole HTTP speciifiline, et ta pigem speciifiseeri pärad, mis on need sõnumid, mida saadetakse XML-dokumendid, et kui mingi teise protokolliga sa pigem XML-dokumenda saata, siis see toetab saama moodi. Mis sõupilts on, on simple object access protocol, et kuidas mingi tobekste vahetada nende anmeid allatömata või põhimõtteliselt pigem on ta selline RPC's arna, kudas mingisugust metodid välja kutsuda. Aga selline naljakas kirjeldus võib-pal on, et see, mis laseb Java ja .NET komponentid, et on omavahel suhel, et kudas alguses pandises erinevad selle progameerimiskeeles kirjutatud teenust omavahel rääkima, et kuidas vahetada siis anmeid erinevate skeeles, erinevas platformides kirjutatud tarkkura komponentide või haussisteemide komponentide või webi teenust vahel. Et transporti protokolli on erinevaid, HTTP on üks kõige populaarsemaid, kõik päringudiv vastusad on XML struktuuris ja see, mida need XML-sees olevad sellised tagit tähendavad, on tavaliselt skeemadega defineeritud, kus skeemad on linkitud dokumentid, mille sees on defineeritud. Et kui mul on XML-i sees kirjas näiteks person, siis mida see person tähendab, mis väljataks, et person obekti sees olema, mis tüüpinad on, et anme basis skeemad tohjentsud sama muudi, et anmete skeemad. Et kirjeldatakse sellised nimeruume ja sisu elementide definitsoone linkitud dokumentina, et tõmatakse sellised XML-t data-skeemad alla ja nende põhel saab parsimise ajal vaadata, et kas seal seese olevad väärtsedist vastavad kokkulepidud skeemadele või mitte. Ja Soap sellises webi teenuses defineeriteks põhimõttel tähed selle serveri implementeerijapool, et mis on kokkulepidud operatsioonid, mida Soap server siis toetab. Kui me näen Soap serverilis pakub mingi webi teenuses, me tavaselt paneme paikka, et see toetab sellised operatsioonid nagu product title, order product, update order ja cancel order. Et sa arvaselt RPC-le me defineerime, et mis on need operatsioonid, mida klientid saavad välja kutsuda ja nende operatsioonidele me defineerime sisend ja väljund muutujad XML-ide tasamele. Et sisse peab olema teatud struktuuriga XML sisendiks ja väljundiks on teatud struktuuriga XML. Et kui klient kutsub välja update order, siis ta peab saab ma XMLi, sellel XMLi peab olema õige struktuuris, siis mingisuguse tellimuse, uuendamise anmed ja see webi teenuse kirjaldus siis ütleb, et mis on see operatsioon ja mis on see sisend XML, mis väljas, et see XML peab sisse siseldama. Kui te ajate HTTP-appisid kasutend, siis te näete, et tegelikult see on päris erinev, et HTTP puhul on panutud paikka operatsioonid ja siis pigem defineeriteks, et mis resursside peal need operatsioonid välja kutsutakse, aga soapi tasamele resursse otsaselt ei defineerita, vaid defineeriteks lihtsalt listo operatsioone ja soap protokolli puul võib näiteks neid operatsioonale kaks oda, et mida mingisugune webi teenus toetab. Ja me loengu lopus vaatame ka siis soap versus HTTP nagu erinev. Kõige päris räägime soapist, siis vaatame HTTP-id ja siis võrdleme neid oma vahel. Nüüd on nimeruumide probleem, et kui meil on mingisugune XMLi dokument ja meil on seal seees näiteks mingisugune HTML-podi ja siis meil on mingisugune inimesekeha anmed. Meil on kaks täegi ja podi ja podi. Mis on nende kahe podi erinevas? Üks on HTML-keha ja teena inimesekeha. Meil tuleb kui tegi ära defineerida, et mida need tähendavad. Meil oleks alati võimalik neid nimetada umber. Ümbesad meil on HTML-podi ja human-podi, aga siis meil saanme modelid läha tästi keerukuks, et pigem on ikkagi kasutada sellist lihtsalt nime, podi, aga nüüd me peaks jääma paikka panema, et see on podi, nagu miss nimeruumis, et me saame defineerida, et see on podi, aga see on podi HTML-nime ruumis, see on podi, aga see on podi mingisuguses Eesti, Eesti riigi anmedte nimeruumis, et me saame paikka panna, et see podi tähendab teatate tüüpi podi mingis konkreetses nagu nimeruumis ja nimeruumid eraldavad, nagu ma rääksin ka Tokkeril oengus, meil vist ei ole Tokkeril oengus peale, teises aine sääksin sellest, aga ma rääkin sest ka Tokkeril oengus, mis haisata nimeruumid, aga põhimõtteliselt neda ruumid, kus mingi nimi tähendab teist asja, kui teises nimeruumis mingi nimi, nii et see nagu eraldab nede nimeruumid, kus meil on mingisuguses sihemeesed nimed, nede definitsioonid oma vahel, et meil on näiteks height and weight of podi olla nagu inimesepikkus, inimesekaal, aga näiteks HTML-is podi height või mingisuguses podialamosa height võib olla, et mitu pikselid kõrgedan, saab mingisuguse pilt näiteks, et ne on täitsad erinad asjad. Ja siis XML-is, kui me kasutame suupis, me hakkamegi defineerim, et meil on human podi ja see human defineeriteks mingis webis asuva dokumenti põhjal, et meil on mingisugune skeema, mis defineerib, et mis asi on human ja selle sees on definitsioon, et mida podi tähendab. Saamoodi, et meil on HTML-ikohtad, meil on HTML podi ja see HTML on teatud nimeruum, et selle nimeruumi definitsioon asub kuskil aabresis ja see dokument, mida saab allotamata, siis kirjeldab, mida tähendab HTML ja mida tähendab podi HTML kontekstis. Ja siis tihti me peamegi defineerim nagu nimeruumi ja siis selle oleme, mille onmed me siis paneme, siis siin height ei ole lihtsalt height, vaid ta on human height, kui siin ala võib olla veel mingisugun nimeruum, et ta on mingisugun teine height. Ja niimoodi tekitatakse nagu nende XML dokumentide nagu ise kirjeldatavus, et me defineerime ära, et kus on meie definitsioon, et mis täpselt ütlevad, et mida see väärtus siin tähendab. Ja kui me saadame sõlb sõnumi webiserverele, me tavaselt peame defineerime sellise ümbriku, sellised header-value-ud ja siis podi-value-ud, kus ümbrik ise defineerib ära, et mis versioon sõupi, näiteks me kasutame. Päises või heeteris on igasust lisa info-ud, meta-info-ud ja kehas või podis on siis päringu sisu, et näiteks, mis on me, et me serverile saadame. Ja vastu võib tulla lisaks veel üks vea teate, selne kehaseese olev komponent või siis manus, et näiteks mingid failid, mida me kaasa paneme ja mida me saame vastu serverelt, et meil võib siis eraldi olla manused ka, mingisugusete failid. Ja kui me hakkame saadma sõup teadad serverle, siis ümbrik või envelope näeb pärle niimood, et meil on envelope, mis defineerib ära, et mis XML-version on, et on mis tüüpi sõupenvelope on ja mis sen koodingud kasutatakse ja sellesees on siis heeter-värtused ja podi-värtused ja põmst kõik, et siis se kirja ümbrik defineerib need standaardid ära, mida kasutatakse. Ja heeter võib näha välja lisaks enne heeterisse minekult, et seal envelope-sees võib olla kõikasuguses teised nimeruumide, kirjeldused, näiteks, et me kasutam X-road mingit anmete spetsifikatsiooni, et seal plaetakse siis teatud tüibid, anme tüibid, mida saab hiljem siis kas podi või heeter-seese ära kasutada, et siin on siis näide X-roadi päringust. Ja heeter võib see näha välja selline, et me defineerime näiteks ära, et mis on mingisugune service, mida me kasutam, et see kuulub näiteks Eesti, Riigi, mingisuguse konkreetse riigi-organisationi mingi alamsüsteemi kohta, et siin võib näiteks olla mingi RIA ja siin võib olla mingi RIA webi süsteem, näiteks, ja mingisugune selle webi süsteemi alam teenus, siis mida välja prooja teks kutsuda. Ja siis client defineerib ka, et kest ta on, et client on siis ka Eesti mingisuguse organisatsiooni, teise member one mingi teise Eesti organisatsiooni alamsüsteemist tuleb päring, mingi teise organisatsiooni teise alamsüsteemi tehta päring. Ja lisaks on ka sellel päringu ID, kasutada ID ja mingisuguse teised informatsioon, näiteks, et kui ta on seotud mingisuguse, ma teagi, mis see täpselt issuisin tähendab, aga kui ta on seotud mingisuguse probleemiiga võib olla. Ja ma pole kindel, et ma kujutan, et ta võib ka olla mingisugun õigused, mingisuguse õigust, väljaandust õiguste issu, aga ma ei tea, mis issu võib siin olla. Ta võib ka mingi järjekord toist olla. Ja siis on tavasid sellest ID-spiisab, aga ma ei tea, et ta võib mingisugu teine ID olla näiteks. Authentiminne toimub ka tavalist heedrate põhjal, aga siin seda välja toodud näitena ei ole. Ja podi see, siis võib olla näiteks, et ma kutsun välja example service, mis on siis see, et ma kutsun välja siis example servicei ja see example servicei sisähend on siis värtus fu. Et see on pige mõttes need konkreetne anmed, mida me kaasa anname sest selle funksiooni väljakutsama. Funksioon, mida me väljakutsama on example service ja selle sisendid on fu ja vastu võivad siis tulla meile sama sugun, et meil on mingisugut ennmeloob, mingi heeter, mingi podi. Heeter on sustat sarane, et kes oli klient, kes oli service ja võib-olla natuke nüüd on meil mingisugust teised anmed siin juures, nagu protocol version ja request hash, et kontrollida, kas on täpselt samarequest või mitte, et kas sisu on muutunud, et visak siitele, et kas ka põhimselt, et kogu selle request xml dokumenti hash ja siis ka algoritmi, mis algoritmi kasutad selle hashi loomiseks. Ja siis vastus võib tulla par, ubar. Aga selleks, et me saaksime saata sellest väikest funksiooni nime, siin on vist funksiooni vastuuse nimi ja sest väikest väärtust siis selleks peab see dokument olema päris suur. Et siin mul ühele slaadil ta ei mahtunudki, et ma pene nagu viiele slaadile selle raja ka. Ja agu ta tööta põhimõtteliselt nagu webi arpet see, et me defineerime, et mis on see meetod, mille me välja kutsume ja mis on selle meetodi argumentid ja me lepime kokku, et mis see xml-ides struktuur peab olema siis klientide serverite vahel. Et HTTP API on selles mõttes huvitavam. Et me kasutame siis HTTP protokolli ja see on huvitavan, selled öötat on rohkem nagu, ma ei ütleks aru saadavam, aga vähem infod vajav anmete vahetuse protokolle viis, sest progameeria ei pea nii väga teadma, et mis meetodid on võimalikud. Ma ei pea nagu uurima, et mis on need 200 meetodid, mida see appi-server või webi teenus siis toetab. Meil on operatsioonid paigas. Meil on get-operatsioon, post-operatsioon, put-operatsioon ja delete-operatsioon ja mõnikord me teeme ka head, trace, options, connect või patchi. Aga peaamised kasutame need nelja meetodid. Get, post, put ja delete. Ja selle asemel, et meil algs 200 on ikkasad operatsiooni, me pigem defineerime, mis on resursid, mille peale me teeme need nelja operatsiooni. Resursiks võib meil olla siis html-let, pildi-file, kasutaja, virtual machine, kellegi ma ei tea mingisugune asukoht põhimõtsed. Et siis html-protokollide puhul see on kehitatud nagu webi resurside jaoks pigem. Et see ei ole designitud nagu mingida operatsioonide väljakutsumiseks, aga see on defineeritud, et resurside peal ja resursid võib olla peaga üks kõik mida, aga webist avalstate resursid on siis html-let, pildi-file ja need asi. Ja mis on siis get, post, put ja delete operatsioonid? Get tõmbab alla mingisuguse resursi, post loob mingisuguse alamresursi, put muudab tavalselt võib ka lisab mingisuguse resursi ja delete kustutab selle resursi. Ja ta hästi loogiline aru saada, mida me nende operatsioonidega teeme, kui me jooksutame getto operatsiooni pildi peal me tõmbab mingisuguse alla, kui me jooksutame getto operatsiooni asukoha peal, siis me tõmbab asukoha info alla, kui me teeme post operatsiooni kasutaja asukohtade peal, me paneme anmebasei uue kasutaja asukoha, et kus ta praegu asub. Kui me teeme asukoha peal delete, siis me kustutame sellas asukoha anmebasei ära. Ja see loogilise on viis, kuidas defineerida, mida me soovime tehaad. Me defineerime mingisugust resursid või resurside komplektid, näiteks kõik veebilehed, kõik pildid, kõik kasutajapostitused, kõik kasutajad. Ja me saame nende resurside peal sellised operatsioone väljakutsuda. Ja see loogike tuleb pigem sellest, et mis on nende resurside kogumik, mida see server haldab ja mis operatsioone nende peal on lubatud väljakutsuda ja mis operatsioonid näiteks nõuad autentimist ja nii edasi. Et kui HTTB sellised operatsioonid ei nõua nagu tead, mis niivaga operatsioonides, siis tegelikult sõubibuhul tullab väga palju tead, et mis on siin. Ma panasin ta tagasi, muidu teisedi puhle. Ma loodan, et mind on veel kuulda. Sõubibuhul me peame uurima, mis nendes dokumentides sees asub, et mis on seal defineeritud. HTTB-buhul nagu meil tavalised nii väga sellest spetsifikatsioon ei prugi olla, aga see kogu süsteeme on natukene loomulikum ja loogilisem ja selle tõttu on ka palju palju populaarsemaks saanud ja tänapäeval pigem kasutatakse HTTB appisid ja protokolle selleks, et veebideenuseid ehitada ja isegi suhtlus teha hajusüsteemide komponeetid vahel. Ja serverid teenida võib mingisugused resurssioid ja komplekte, neid võib olla 1, neid võib olla 16 ja nad toetavad neid operatsioone. Nende objektide peal server ei pea kõike operatsioone toetamata võib näiteks implementeerida ainult keti ja delidi, või põl ketje delidi ei ole väga normaalega keti, näiteks ainult toetada ja ei toetakse uuendamist. Või delitimist ongi info ainult, et sa tahad praegust elektri hindu vaadata, et sinul ei ole õigus elektri hindu anmebaasi panna või et sinul ei ole õigus elektri hindu näiteks omset elektri hindu allatõmata. Et server ei pea mingi resursi peal kõiki operatsioone implementeerima. Ja siis klientid saavad välja kutsula neid operatsioone, mida siis see server toetab. Ja siin on näite ket, et ütleme, et meil on asjade internet ja anmebaas, kus on anmed, nede anmed tüübiks on measurement, et see ongi resursid on meil siis measurement ja meil on measurementide selline list või measurementide kollektsioon on siis measurement measurements ja seal all on calcrips ja mingisugune üks konkreetne measurement, mingisugune mõdik, mis on mõõdetud sensori poolt. Siin ta on mingisuguse temperatuur ja meil eksisteerib server, kus me saame teha siis selle slash measurement slash measurements slash mingi ID päringu ja see measurements, seal on see resurside kollektsioon ja see on siis konkreetse resursi ID adres. Ja me saame selle peal teha ketpäringu, et selle resursi anmed siis alla tõmad, et konkreetne mingisugune asjade interneti sensori measurement. Ja oleleb nüüd, kas me saame vastu ainult numbrise värts, et see värts oli 100 või me saame nagu sellise Jasoni, mis samuti proovib masiin loetavalt kirraldada ära, et mis see measurement või mis need anmed on, kus on näiteks saadateks vahegi siis Jason. Jasonis on selle measurement ID, mis seadme pealt see measurement on mõdetud, on sensori ID näiteks, kuna täpselt see mõdik tehti, mõõtmine tehti, mõõtmine tehti oli 2020, mis tüüpi see mõõtmine on, et on kui mulle ostiti steam tüüpi ja siis et mis selle measurementi enda nagu meta anmed on, et on steam, temperature ja seal siis on väärtus 100 ja unit on Celsius, et 100 Celsius oli see hetke väärtus. Proovi kise, et minge näiteks selfie või posti meie adresile ja vaadake, et mitu ketpäringud tehakse. Ja kus F12-nega vaadate, et mitu päringud tehaks ühe lehekülle laadimisel, eriti kui ta allaskrollite ka veel, et siis te näete tegelikult, mina kui ma seda 2021 aasta tegin selle pildi, et siis postimees tehti 166 ketpäringud, et see postimeesel leht alla tõmata, aga see oli siis, kui ma allaskrollisin, siis ta tegelikult rea laajas laeb rohkem neid piltte ja lehtid. Ja täna pala ongi, et kui te lähead veebilehele, see ei toimu ühteketpäringud, kus ta tõmate HTML-faili alla, vaid iga pildi jaoks on eraldi päring. HTML-lehes võib olla 10 linki erinate JavaScript-failidele ja seal võib-a, et igasakust teised JavaScript-failid olla, mis on importitud näidest JavaScript-tidesest ja tegelikult tõmataksegi alla siis hästi palju file ja tegelikult 16 MB oli vaja, sõil läksed kõik asjad alla tõmata selles päringus. Kõik need on siis ketpäringud, mida tege browser automaatsal teeb, kui HTMLis on mingisakun link, veeb iresursile ja see resurs võib olla siis teene HTML-leht, pildi-fail, JavaScript-fail, näiteks mingisugune Chart-Pit, Map ja nii-edasi. Ja siis tege browser automaatsal teebki ketpäringud resurside peal. Kui me sooviksime näiteks uud dokumenti luua hudlet-teja appis, siis me samuti saame panna selle sisu kaasa ja teha näiteks mingisuguse resursi koleksiooni peal postpäringud. Me saadame siis mingisese serverisse adresile alarm alarms ja see adres alarm alarms, see defineeribki, et mis resursiga me tegelemad. Meil need see sisu ise ei defineeri resursityüpi, vai tavalselt resursityüpi defineerib see otspunkt, htp, appi otspunkt, kuhume selle operatsiooni saadame. Mõnes mõttes selasame, et meil tekiks alarm dot alarms, change alarm või modify alarm, meil tekib see, et meil on listalt post, tüüpipäring ja teatud resursityüpi peal, kus otspunkt või appi endpoint defineerib, et mis resursidega on siis tegu. Et kui meil oleks user resursi, saaks juba slash user slash users või slash appi slash users ja me saame postida uue useri. Ja siin tekiks uus alarm ja noh, jasonist sisu on ikkagi samamoodi serveri ja klendi vahel koko lepid, et mida server soovib saada, et seda tüüpid me peame saadma, et muidu saame serverga erorri näiteks, et type pärdus on puudu jasonist ja seda päringud vastavõi võetakuna seal type ja la. Mõnikord saadaks vega, mida tavalsed väga ei teht, aga mõnikord võib ka paika panna sellised samamoodi xml tüüpi spetsifikatsiooni, et mis tüüpid jasonid me vastavõtame, et see on mõnesemalt info kliendil, et kui minna sellele adresil, et seda tüüpid jasonid võimest võetakse vastu, aga seda väga tihti ei kasutatakse. Ja kui meil on mingisugun autentimin, et see panaks heeteritevärdusesse, et mis tüüpi näiteks basic-off või api token või midegi sellist ja content type tavalsed definerib, et mis tüüpi sõnum, et ootatakse, et kas jason või csv või xml või midegi muud. Et hardretel peab, et api tegelikult ei pane paika, et ta peaks olema jason, aga me tulem selle eurde koha ja tagasi. Delete operatsioon, me pane paika, et mis on selle kollektsiooni objekti adres, mida me soovime kustutada, näiteks, slash measurement slash measurement slash 2617 näiteks. Ja tulemus võib olla kas error, näiteks, et meil ei ole autentitutetet anmed kustutada, või siis võib tulemus olla näiteks HTTP 204 kood, mis tähendab, et no content, ma tulem selle eurde tagas, et mida need koodid tähendavad. Delete puhul tihti ei ole koodi vastust, et kustutad ja võib piga seda, et no content, et sisu selle laadrasil enam ei eksisteerimest mõnesmõttes sõitelik, et see on kustutad. Et kustutad järele ja sõeldeks, et seal enam content ei ole no content. Putti näide on näiteks mingisuguse resursi anmedte muutmine, et kui ta on kasutaja, soovite kasutaja imeli muuta, et siis sellase me teeme posti, peaks tavalselt tegema putti. Ma tulem ka selle eurde tagasi ühe slide puhul, et mis see selline standard restful appide puhul on, et kuna kasutada posti, kuna kasutada putti. Aga putparing siis samuti mingisuguse resursi aadresil, kus meil on näiteks rakendused ja se rakaniduse ID ja me saadame selle rakenduse adjationi kas uuesti, või me saadame selle rakenduse adjationi mingida alam, võitmed ja väärtused, ainult need, mida me muuta tahame. See olemb ka sellest, et kuidas see rakendus on eitad, et kas ta tahab kogu selle rakenduse kõiki kirjaid või tahab näiteks ainult alam viite kirjat, mida ta muuta soovib. Lisaks on Hotetepeks ka teised erinevad operatsioonid, mida appide puul alat ei kasutat, aga näiteks head operatsioon tagastab ainult resursi nagu metaanmed, et siis su ei tagastata. Kui tead, et kui see on mingisuguna suur video, taad te teada, kui see on suur video, siis te pead saadma ketto operatsioonid video alatamata, võit saadte, et antke mulle ainult heeter väärtused, et siis saad te teada, et kui suur, mitu pittise video siis on, või pilt ennekude alatamate pildi, et saad te lihtsalt küsida Hotetepekservea käest. Näites soovite teada, kuna mingit pilti muudeti või kuna see loodi, et saad te siis küsida, et mis on selle pilti resursi siis metaanmed ja saad te selt vaadata selle suurust ja loomisaaega, aga ei pea seda pilti alatamu. Options on sarnaan, aga options defineerib tavalsed mingisuguse endpointi otspunkti infot. Mitte enam nii väga resursi info, aga te võib ka resursi info tegelikult anda, aga näites, kui me ei oksutama, siis options sparingu slash appi slash resursikohta, siis me saame teada näiteks, et mis operatsioonid on lubatud sellele otspunktile saata ja kas mingisuguse muu ifoad, kas seal on lubatud näiteks kuskib mujald seda väljakutsuda ja mitte, et kas seal on lubatud alatamada anmed scriptilt, mis ei eksisteeri samas serveris või ta asub kusagi mujal. Lisaks on teised operatsioonid nagu trace, mis kontrollib seda, kui saanmed kohale juuavad, et tihti on sellist ümbersuunamised ja koormuse ja autorid vahel, ja kui ma mõnikord vaja diagnostilise eesmärkida näha, et kui tegelikult nad sparingud liiguvad või kudas neid muutetakse vahe serverite poolt, siis trace on selleks kasulik, et kui näiteks me tavaliselt saksime, see võimalda peaa, et niimoodi lisainformatsiooni saad, et kudas muutetakse näiteks mingisugused heterovärtusi või muid väärtusi. Lisaks on ka connect, metod, kui sooviteteks tunnelid luua, et siit ta tihti kasutatakse just HDFDB-s jaoks, et luua siis turvalne tunnel, kus skripteeriteks ühendus ära, põhjumist, et see tagastab selled kas õnestus turvaliselt ühendusluua või mitte, kui ühendata üle HDDB-s. Ja mis on siis post ja puti vahel, sest mõlema tegelikult on operatsioonid, mis muudavad andmeid. See ei ole nii väga niimoodi paikab andud HDDB protokollis, aga restful spetsifikatsioonis, millest ma järgmisele rääginan, on see tegelikult defineeritud niimoodi, et post peaks lisama uue objekti objektide listi. Uue kasutaja kasutate listi, uue piltide listid. Kui meil on kuskil veepi teenus, mis halda piltide kolleksiooni, siis uue pildi loomine peaks töötama postiga. Ja postiga ei panda kaasa objekti ID-ed, et ma loon uue pildi, selle pildi ID on 316, või tavastatud umbes niimoodi, et ma paneme uue pildi list ja me saame servel tagasi, et mis on selle pildi identifikaatoreneid, et ikka ID-värtus. Put on tavalist resursimuutmine või väga konkreetsed resursi panemine kuhugi konkreetse adressiga või ID-ka, et me soovime näiteks tekitada kasutaja, mille nimi on 16 või mille ID on 16, et me saame teha päringu put-päringu slash users slash 16, et seal tagasi luua infot, et me loome konkreetse resursi kirjat. Kui post on pigem täiesti uue resursi viskamene serverisse, siis put proovib mingisugust olemasolata resursi muuta ja võib-olla on defineerid, kui seda resursi eksisteeris, siis loome selle 0. Et selle tõttu ka puti mõnikord kasutataks uue resursi loomiseks kui kui see on pigem infomuutmiseks mõeldud. Ja lisaks on selline päringute omadus, nagu idempotensus, mis tähendab seda, et mis juhtub siis, kui me kordame täpselt samapäratsiooni, et kui me teeme mingisuguse pildi üleslaadimise postmedia tabil, me loome pildi ja me loome selle pildi uuesti, mis juhtub, kas tekib kaks pildi, minna täpselt sama sisu ja minna erinata alat vessite, erinata idega või kirjutudeks esimene pildi üle teise päringuga. Eidee onki, et post ei ole ülekirjutav funktsioon, vaid ta lihtsalt loob mitu alam objekti, kui me sama pildi mitte korda üleslaadime, aga puti, et put proovib panna selle pildi teadud nimega võib-olla või teadud idega ja put lihtsalt kirjutab selle üle. Ja see onki nende kahe metodi vahe, aga kas ta on selline või mitte, seda täiesti implementeerib servet. Teie kood, kui teie looda appi, siis teie kood otsustab, kuidas see tegelikult on implementeeritud, et ta on pigem nagu sellise loogika tasemel, kui kui kui protokolli poolt kontrollitud. Lisaks ketanud, kui teete, mitu ketpäringud, siis midagi toeks muutuda. Headpäring, optionsparing, traceparing, deleteparing and putparing on ka sellised, et te võite neid mitu korda teha ja kui te kaks korda midagi kustutate, siis see teki tagasi, ta ei ole nagu negatiivsuse, kahekorna negatiivsuse, et panaks see pild tagasi kaks korda kustutada. Kõik need on siis sellised, kus tulemus on sama, kui te sama operatsiooni mitu korda teete. Ja tihtite saate mingisuguse stringi tagasi või jationi tagasi, kui te teete operatsiooni, mis HTTB protokolliga mingi appi vastu ja need jagatakse tavaliselt kolme kruppi. On edukad operatsioonid, mis algavad kahega, on klendi tehtad vead, mis algavad neljaga. Alati ei ole klendi poosed vead, aga vead, mis viitavad, et võib-olla klent tegi midagi valesti. Ja serveri vead, mis algavad viiega ja selle mõte, mikste ta serveri viga, on, et see ei sõltu klendist. Yks kõik, mida klent teeks, ta saaks ikka selle sama viiesaja vea. Nende vahe ei ole alati niid selgelt defineeritud, et pigem neljaga algavad koodid, ütlevad näiteks, valed anmed saadeti, et vale funksiooni, kus jutakse välja, või seda pilt ei eksisteeri. Ja viie puhul on see, et koodist tekis viga. Püütan koodist tekis error. Ta või kui tekida klendi poolt saadetud sisendid tõttu, et näiteks Jasonis oli mingisugune string, mida ei õnestanud parsida korralikult ja siis teie püütan koodist tekis viga. Aga ta pigem ütleb, et midagi on serveris valesti, et midagi on koodis valesti. Ja 400 koodik näiteks ütlevad, et seda rekuesti ei toetata, teil ei ole õigusi päringud saata, seda meedladid ei ole lubatud välja kutsuda näiteks teie õigustega. Seda resursi ei eksisteeri, et näiteks selle aades ka pilt ei ole mida allatõmata. See meetood ei ole küll keelatud teie kasutajal, aga ta ei ole lihtsalt lubatud. Vist 400 koodid mingisugune sisend ei ole acceptable, näiteks ta on liiga suur. Ma pole sada protsindiselis kindel. Räkkues taimatud võtis liiga kaua aega ja see serveri tarkkora otsustas ühendus ärakadkestada. Näiteks proovisite mingid suurt videot üleslaadida, aga oli lubatud ainult 60 sekund et ühendus lahti hoida. Elaks kaua aega. Unsupported media typer näiteks seda tüüpi pilt ei ole lubatud üleslaadida ja tuume nii rekuested, kui on pandud lemiit, et te ei või rediti see rohkem kui 10 korda tunnis sõnumid saata, kui teil on tasuta API võtii. Millis on 418? Mis oli? Ma ei tea. Ma ei tea, ma seda siia ei pannud. Ta näete, et siin on mõetumbrid ka puudu. 510 on lihtsalt, et see oli mingisugun eror. 502 tähendab seda, et ei õnestund õigese kohta ümber suunata. Vistid juhtub seda, et kui server ei ooks ja seal, kuhu prooviti suunata seda serveri päringut, prooviti suunata näiteks ühte 16 serverist, aga ta olis hetkel maas ja siis võib koormuse jatur saada, et seda serveri praegu üle oli ole ja tuleb selline vastus, et asukoht, kuhu prooviti saata, seda ei eksisteeri enam. Server on kadud põhimõttelselt. 503 on pigemsed server eksisteerib, aga ta ei võtnud vastu. Ma saan, et ta porti ka ühendast võtama näen, et keegi seda porti kuulab, aga ta ei võtnud minu päringut vastu. Teehti on ülekohormatud näiteks, või järjekord on täis, või ta on praegu 16 lõime, ta on lubatud 16 lõime korraga jooksutada ja tööde järjekorda ei ole, et ta lihtsalt lükkab tagasi. Praegu ei saa vastuveta. See on tegelikult hea selleks, et võib seda päringut korrata teise serverist, võib lihtsalt uuesti korrata, kuniid seda vastuvetakse, aga bad gateway pigem ötleb, et server on maas, et ei ole keltse serverid. Ja gateway timeout on siis mitte, et server või see webi teenus on maas, vaid näiteks mingi vahe pealne see, ütleme, kormus jaotur on maas. Et ei õnestundki serverise ümber suunata või ei õnestundki proovida serverise suunata, et seal on see natuke vahe vist. Et gateway oli kätte saadav, aga ta andis vastu, et timeout ei õnestunud, kui seda vastu võtta. Siis on mõnesmõttes võib-olla küsimus, et mis on nende kahe vahe. Üks on see, et see on, võib-olla kasuta saadis liiga suure file ja selledut on see timeout. A gateway timeout võib olla, nagu see, keesel vahe vara või kormus jaoturi probleem, et ta millegipäeks tei vasta korraksalt. Et võttis küll päringu vastu võib-olla, aga siis annab tagas, et ei õnestun seda väljakutsuda või. Tihti need koodid tegelikult sellest, kuidas teie ise implementeerite need oma koodis. Kuigi bad gateway võib tulla ümper suunamist. Kui meilatada kihilist arhitektuurid, üks kicht suunab teisele kihile edasi ja gateway amad on kichtide vahele ei õnestunud, aga edasi suunata. Või küll tehti ühendus, aga siis teha ühendus timeoutis. Bad gateway on pigemist seda gateway, et ei ole seda erinam. IP adressi näiteks võib porti enam eksisteri. Või keegi kuulasuda. Lisaks on sellised metodid, nagu safe metodid, mis midagi, mis on defineeritud niimoodi, et nad serveris midagi muda. Nii, et te võite neid väljakutsuda ilma, et almebasis näiteks midagi muutuks. Ei kirjuta serveris uusi almed. Teoreetselt nende päringude tegemine ei tohiks mõjutada, nagu serveri olekut. Alati see ei ole tõene. Praktikas see ei ole karonteeritud. Me võime ketpäringud teha tõmbama pildi alla, anmebasi midagi tohiks muutuda. Aga järsku tarkvara implementeeria on teinud, et ta kaundib, mitte ühendust on olnud, või mitte päringud on tehtud, siis kirjutab anmebasid, on olnud 617 ketpäringud. Nii, et reaalislas elus ei ole kudegi karonteeritud. Et safe-i mõte on selles, et ta on nagu turvalised, et nende tõttu ei tohiks anmebas korrupeeruda või midagi, aga tegelikult võib juhtuda, et nende tegelikult midagi seerele muudad. Ja turvaliselt haatadab ja metodid on ket, head, options ja trace, mis tegelikult ainult infot tagastavad ja teoreetselt ei tohiks midagi, nagu anmebasis muuta, aga olem implementatioonist. Ket protokoll tegelikult ei pane paika, kuidas peaks need ket-appisid kasutama, ket protokoll isegi pane paika täpselt, et me tegeleme resursidega. Tegelikult see, mis pane paika, et me tegeleme resursidega ja kuidas need resursse kasutada ja kuna millised operatsioone kasutada, see tuli tegelikult natuke hiljem. Ja see tuli sellisest, nagu ühes vist oli lõputöö, ma ei mäletagi, kas tal oli magisti või doktoranturi lõputöö, kus pakutid välja selline standard veebi teenustele, mis kasutad HATVP-t ja selle nimi on siis representational state transfer, ehk rest või restful, mõni kui nimetakse restful. Aga see ei ole nagu uus protokoll, kasutadakse täpselt sama HATVP protokolli, kasutadakse sama metodeid, aga lubatakse ainult viis metodid, et ülehand öeldaks, et ülehand ei kasuta, et ülehand ei tegele nagu selle tasemega või selle väebi liidasega. Ja see lihtsustab natuke või paned paikareeglid, kuidas HATVP-appisid ja resursse defineerida. Ja defineeriteks, et igal resursil, mida serveeriteks veebi teenustele, seal peaks olla mu unikaalne adress, unikaalne URI või unified resource identificator. Ehk kui meil on pilt, selle peaks olla mu unikaalne adress, kui meil on mingisid kasutaj, selle peaks olla mu unikaalne adress, et tavaselt teakssegi seda nimod, et meil on mingisid ID-värtused või mingi file niimi sinn, et meil on konkreetne server, seal sisav asuvs resursi-t või path ja siis resursi-id või identifikaator. Ja need siis defineerivad konkreetse resurssi, mida on võimaleks siis lua, vaadata, kustutada ja nii edasi, ja resursside kolleksioon on siis see sama adress enne seda ID-t, et slash kasutajad ja siis on loogine aru saad, et kui ma soovin kasutajad halvata mochi mingisugust slash appi slash users või slash users, seal all võiks olla see kasuta ID, et kui ma soovin nendeks mingid konkreetsi kasutajad, vaadata, et see paned see loogilise standaardi paika, et kuidas need resursse defineerid, et rakenda, rakendus arendad ei mõtleks ise mingisugust suvalisi viise välja, et kuidas need resursse identifitseerida ja kuidas need ue RIsid või linked genererida. Ja rest spetsifikatsioonisest spetsifitserib, et me kasutam posti, putti, keti, daliiti ja patchi ja teisi väga ei kasuta, teised on seotud protokolli endaga, aga mitte nagu webi appidega. Ja kaks asja veel, mis panaks sa paika, et kõik implementatsioonid peaks olema olekuta, et serveri implementatsioonid ei tohiks midagi nagu mällu etta ja teine on, et nad peaksid olema käsitavad. Ja mida tähendab käsitavad, on see, et teie rakendus ise peaks vastama põhimõtsel niimoodi, et ta ütleb, kas te saite tagasi käsitud või rooanmed. Et kui teie vastatab päringkule, siis seal võiks heeteris olla kirja, et kas need olid käsitud anmed, kui nad olid käsitud. Kui on käsitud, siis võib-olla teie peavastama, aga kui anmed olid käsitud, et siis tead, et nad ei võetud anmebasist sellel hetkel, või nad on natukene varem nagu meeldie jätud pahemelus alvestadud anmed, et siis seda tuleb defineerida vastuses. Et see, kes teab päringkud, saaks sellega arvestada, et kas ta või saada vanu anmed, või ta sai kõige viimastada anmed sellel hetkel, kui päringkule vastati. Ja defineeriteks, et siis mis meetodeid võib kasutada kas kogu ressursside koleksiooni peal või siis viimases tulbas konkreetse ressursi peal. Et me teeme neid meetodi päringkud kas siis slash klientide peal, et modifiseerida siis klente või slash klientid slash klienti ide peal, et modifiseerida kindlad klenti või kindla klendi ressursi peal operatsioone väljakutsuda. Ja postmetodid on lubatud siis väljakutsuda kogu kolleksiooni peal, et luua uus kolleksiooni elemente, luua uus klientide kolleksioonis. Postmetodid ei ole lubatud konkreetse klendi või konkreetse ressursi peal väljakutsuda, selleks, et selle ressursi muuta. Et ressursi muuta peaks kutsuma välja putto operatsiooni selle ressursi peal, et me siis muudame juba olemas oleva IT ka eksisteeriva klendi anmeid või sisu. Et mis iganes see ressurs on, kas klent või midagi muud? Ei. Panema on lihtsalt ketmetod selleks liulia. Jah, et kui seda terori, et juba eksisteerib, seda võib juba tähendada seda, et eksisteerib ja 404, siis sa saad, kui ei eksisteerida. Ja siis on siis kõik, et juba on juba kõik, et juba on juba kõik, et juba on kõik, et juba ei eksisteerida. Aga see natuke, ja, ja, kui mingil põhjel selle sa kette ei sa kasutada, siis ja, sa oled posti prood kasutada. Aga siis sa loodad, et implementeerion on higged koodid sina pannud. Muidu sa vaid lihtsalt saada, et tänapäeva apidel on see ka väga raske teha sellet, et järgmises loon, kus me räägime nagu sellest vägerest ja open-upi spetsikatsioonist, ja kui te kasutat open-upi spetsikatsiooni, siis selle spetsikatsioonipool, genereritud koodis, panaks kõrgemalt asemal paika, et need metodid, mida ei eksisteeri või mida ei ole lubatud välja kutsuda, nende kohtada saada lihtsalt tasnauteksist koodi, et mis, kas 404 võib olla, või siis method allowed, võib siis 404 not fa, ja pikem võib olla sellel või, et põhjumselt saate vastus, et seda methodid ei eksisteeri, et pikem saate, et seda ei ole implementeeritud tänapäeval, sest mõnesemalt siiaht ei eeldab, et see method eksisteerib, aga miks ta methodid luua, kui seda ei tohiks luua. Keti saab teha mõlema peal, ketsressursside kolleksiooni peal tagastab mingisuguse nimekirja, näiteks kõikide kasutate listi, ja ketti ühe ressursi peal tagastab selle ressursi sisu, näiteks kasutada enda anmed. Puttis ei ole lubatud kolleksiooni peal jooksutada, sest me ei loo uud kolleksiooni putiga teatud olukordades võibse olla, et te teete mingi ülidünaamilise appi, kus te iseloote uusi user collection, trees collection, clouds collection, et näiteks on mingisugune piltide gruppeloote, teoreetiliselt oleks see võimalik, et tegib mingi kaust ja siin kaustal alla saad uute, näiteks teete loomade kolleksiooni ja siin alla hakkade loomade piltte panema, et teoreetiliselt keegi võiks seda implementeerida, aga üldiselt mõeteks, et putt ei jooksutada kolleksiooni peal ja putti siis ühe objekti peal ühe ressursi peal selle muutmiseks. Ja te liiti ka, et kolleksiooni peal nagu me ei kustuta, me ei kustuta kogu kasutajade ära, või me saame kustutada ühe kasutaja, aga me ei kustuta kasutata kolleksiooni ära, aga teatud olukord, et see keegi võib seda implementeerida, neemad, et kustuta mulle kõik piltid ära, kustuta mulle kõik kasutajade ära, et kui keegi seda implementeerib, siis ta käib küll selle restfuli vastu, aga ta võib loogiliselt olla vaja, nagu huvitav kasutada, et soovite mingid metodid, mis kõik ressursi alam objekti ära kustutab, mingi kolleksiooni alam ressursi ära kustutab. Ja niilt põhimest ongi nagu viis kasutust ja see teab ka sellegi appidest aru saamise naltukul lihtsamaks. Kui te näete ketmetodid ressursid peal, kus see ID ei ole, siis on tavasalt kõikid alamressursid alla tõmbamine. Kui teil on ketmetod mingi konkreetse ID peal, siis ta tavasalt konkreetse ressursi alla tõmbamine ja nagu see on aru saadav, et kui te saate aru, et slice-klientid on klientid, siis te saate väga hästi ette kuutada, midas appi siis toetab, klientide listimist, klientide infok alla tõmbamist või siis klienti kustutamist, et nagu nad on loogiliselt aru saadam ja tavalselt appides, hattate pea appides ongi nelj metodid, aga võib-olla palju end pointe, kuhu vastu näid päringud saab teha. Ja vähemalt minu jaaks on sellistest hattate pea appides nii lihtsam aru saada, sest ma ei pea teadma, mis on need 200 operatsiooni, ma pigem pean aru saama, et mis on võib-olla need 16 või 20 erinele resurssi, mida halatakse seal serveris ja võib-olla siis mina appi võitmed, mida halatakse kasutajad, kasutajada postitused, mingisugused pildid, mingisugused failid, mingisugused muud asjad ja see on nagu loomulikud aru saadav, et ma eeltan, et siis piltiteaks on, kas kõik need operatsioonid lubatud või siis vähemalt get-meedad lubatud, et pilt ei halatamata. Ja kui meil on siis get-paring, siis soobis näeb see get-paring selline välja ja restis näeb selline, kus me soobis peame ütlema, et meil on mingisugud get-product-title operatsioon ja selle argument on siis product-id 21 või selles ketis andale lihtsalt slash get slash product, et me tõmbame alla siis product-koleksiooni andmeid, aga me tõmbame alla siis konkreetse product-koleksiooni 21. objekti id järgi siis andmed ja nagu ketist, nagu HATVB ketidest ja soobi operatsioonilisest aru saamine nagu sellavõra lihtsam ja võib-olla ka see, et meil on lihtsalt vähem andmeid, mida me peame edastama. Aga soobi puul on osa asi nagu masin loetavam, näiteks need tüübid ja muud asjad, mis ketipuhul tegelikult mõnikord lihtsalt tunnustateks ära, et kasutad ihti peab lihtsa asja teadma. Ja siis see vahe soobi ja restivalent soobi puul me siis defineerime konkreetse operatsioonid, et cancel order sellase mene teha delete operation slash orderi peal, update order sellase mene teha put order, et meil peab siis eksisteerima sellised natuke listuni kaasemadest operatsioonidest ja me peame nagu neid listi läbi vaatama, et mis on need operatsioonid nende nimed ja need nimed ei ole nagu standardsed, kus HATVB appid või restful appide puul on nagu see resursikoleksiooni nimi on unikaal, nagu need operatsioonid on alati standardsed, et niimoodi on natuke lihtsam aru saada. Aga mõnikord on raske otsustada, et mis need appi endpointid peab siit olema, kui need on dimetratud peab siit olema ja tegelikult see olema pikkagi implementeeriest, kas ta hästi defineerib, et nad on aru saadavad või mitte, et HATVB appide loomine ei karanteeri, et nad on aru saadavad. Et sõup on nagu kasutaja või implementeerijapuolt määratud operatsioonide kogum ja rest on selline standardsed operatsioonide kogum, mida rakendatakse kasutajapuolt määratud resurside kogumu või komplektile. Ta saab nagu suurematega hakkama, ma ei tea, kas protokolli tasemel on neid sõnumite mahu erinevused. Et sa saad ikkagi ketpärin kogu 30 gigabaitis ja faili alla tõmbamist, et see on sisse ehitatud, kui tead toimub selline stream alla tõmbamine, et su browser jätkab alla tõmbamist, et ta ei saa seda ühe paketine saada ninguneis asjad ta saata, et sa peab olema paketide jada. Et see on nagu sisse ehitatud, aga juba see, et XML raiskab väga palju ruumi, muud asjad jaoks, nagu tekitab ratoca probleeme. Ja sest neid XML sõnumid lihtsalt on suured võrraldes. Ketpärin, kus sul ongi ainult heeter väärdus, et sul podi ei olegi, hatate pea ketpärin, kus sul nagu podi ei olegi väa. Teatud olukordades pannakse mingisugused atribüudid või parametrit siia filtreerimisparameetrid näiteks pannakse, kui sa soovad kõikite kasutade listi, aga sa soovad sadad kasutad korraga ja 7,7-dat lehekülge, et saab siia urli parametriks panna, aga mõnikõrd panaks see ka podisse. Ja järgmine nädal siis vaatame, kuidas need veebiteenuseid kirjeldateks ja niimoodi, et neid on võimalik ka üles leida veebist või hajussisteemide vahel. Ja mis on sellised standaartselt viisid, kuidas kirjeldada hatatepe-appid, siit me vaatame seda open appi ja swagger spetsifikatsiooni. Ja tänases praktikumis või selles nädas praktikumist te ehitate oma appi, hatatepe-appi, mis on siis raamadate-haldussisteemi-appi. Ja järgmine nädal me selle aseme, et me ehitame appi nagu pyytanis valmis. Me ehitame valmis open appi spetsifikatsiooni, mis on see nii jam dokument ja kasutame generaaturid, et genereerida meile server record. Ja siis implementeerime järgmine nädal selle spetsifikatsiooni põhjal serveri koodi loogika, aga selle serveri implementatsioon genereriteks meile webiteenuse kirjelduse põhjal automaatsalt. Ja seda tavalist kasutataksegi sõupi puhul, et eksisteerivad sellised teenuse rekistrid, mis defineerid ära, et mis on need operatsioonid ja webiteenused näiteks mingi sugele weather forecast operatsioon või get weather by zip code result operatsioon ja seal defineeriteks ära nagu rekistrid, et mis näite operatsioonid argumentid on ja selle kirjelduse põhjal on võimalik genereerida nii klienti kui serveri koodi, aga me vaatame järgmikõrge seda, et kud seda saab teha siis HTTP-appi ja rest appi puhul. Ja selle näitele praktikumis te siis lootegi oma rest appi, me kasutame selle hästi lihtsalt byton raamistiku kool bytonflask, et see ei ole kõige parem raamistik, mida kasutat, aga see on üks lihtsamad ja seda tihti pilves kasutatakse, ma ise soovitaks kasutada fast appit flaski asemel, kui te soovite end up mingi projekti luua, kuna ta on efektiivsem, aga nagu praktikumis õpetamiseks on see bytonflask hästi selline lihtne ja selge ja me loomegi siis rest appi ja me loome siis kahte tüüpi resursid raamatud ja sellise specialse resursi nagu raamatud otsimine ja raamatule me loome siis raamatuket, raamatu post tegelikult raamatuket, raamatude listiket ja siis raamatud delete operatsioonid. Raamatu post operatsioon on natuke imeliks, sest me ei laaie üles raamatud, me teeme raamatu üleslaadimise niimoodi, et me saadame Jasoni, mis ütleb, et mis IIDga raamat Kutembergist allatõmbata ja raamatul oomine tegelikult on nagu post operatsioon, mis defineerib, et mis raamatud me tahame, et meie selles raamatude haldusplatformis oleks, aga taustal toimub siis Kutembergist selle raamatu allatõmbamine ja pärast seda luuaks raamatuses meie haldussystemis, aga me ise ei laaie üles nagu raamatu textfaili. Et ta võib-e natuke senal äkast raamatu post meetada, aga ülevend on sellest standaardsed ja siis teeme ka raamatust otsimise, kus postiga saab defineerida, et mis termi, mis raamatust otsida ja siis saame vastuseks, et mis ja võimsed, kui palju mitu korda see term siis raamatuseks isteris. Järgmise loengus räägime siis web-teenosta omadustest natuke rohkem ja siis web-teenosta standaarditest nagu näid WSTL soapi ja open appi, mis kasvus väljas vägerest, siis rest appide jaoks. Ja järgmises praktikumis järgmises nädalal siis genereerime oma appi koodi open appi spetsikatsiooni põhjal ja implementeerime neid samat metodid, mida te see nädal implementeerite. Kus kellegil on küsimusi? See ei ole seotud otsed turvallisusega ja tihti seda enam ei teha serveris, vaid seda teha samuti eraldi kihina. Me tegime, kui ma räägisin enne nagu ühest, kahest, kolmest või enkiilisest, et me saame käsimise teha nagu eraldi kihina. See, kes suunab päringud näiteks appile, siis võetakse päringu vastuus vahe kihist ja see vahe kihist ise otsustab, kas anda tagasi käsitud väärdused või teha päring tegelikus serverist ja siis anda see tuud väärde. See otsustadaks see, et kui vanad anmed hoidas, siis selles vahe kihist, et tekki selline üks kicht veel vahele. Aga turvallisust see on natuke oleme, et kui sa selle alvasti implementeerid ja kasutad see käsimist, asja teaks, mis ei tohiks olla käsitud, siis ta võib turvallisust mõjutada, aga üldjuhul pigem ei tohiks väga. Käsimi niis ja otsaselt turvallist mõjutada. Kui sa tead, et anmed baasid väärin kui kui sa tead, et anmed baasid asemel väga nagu sellist käsimist ei teha, minu teada. Ja et on sellist asjad nagu right ahead logid anmed baasides, et kõigeva, et kirjutudeks ketale ja siis kirjutudeks anmed baasimälu, et karanteerite, kui anmed pasi ensi kokku jookseb, et siis anmed oleks olemas. Sellist asju tehaks, aga need ei ole otsaselt käsimised, need on ko ajutised ledgerid, kus hoitakse veel kirjutamat anmed põhimõtsult. Aga käsimist tehaks just eraldi tasemel, et vältida anmed baasi enda päringot. Selleks, et vältided anmed baasaks ülekoormatud, tead, et asju lihtsalt käsida natuke aega, et siis tehaks vähem päringu otsa anmed baasi. Ja siis kõige rohkemud sellest kasu, kui sa tead selle anmed baasid väljas pool. Muidusul päring ninguni läheb anmed baasi tarkvara, ja siis kui tarkvara ise käsib oma, siis sa ei väldi need päringut anmed baasi. Aga käsimin on üks teema, mida me väga selles aine seid ei kata. Aga tänu on see esime praktikum kahe tunni perast vist ja saate siis oma appi ehitada, kui te varem appisid ehitada, on te ola.

---------Loeng 6 - Veebiteenuste Standardid.txt--------

 Tere tulemast siis kuundasse loengusse. Tänase loengu teemaks on webi teenuste standardid ja jätkame eelmisel nädalal alustatud sellist webi teenuste teemat, kus me eelmikud rääksime peamaselt sellistest appide väljakutsed protokollideste viisidest nii soobi kui HTTB appi näitel. Ja siis tähna rääkin natuke rohkem, et kuidas on standardiseeritud sellist appide ehitamine, ülesleitmine, kasutamine ja vaatame natuke ajalupku, et kuidas varasemad standardid töötasid ja vaatame siis teises loengosas sellist de facto standardid, mida praegu kasutatakse, et kuidas kirjeldada restful appisid ja kuidas neid kasutada ja kuidas neid genereerida ja kuidas neid dokumenteerida niimoodi, et see dokumentatsioon oleks interaktiivne ja klentidel aru saadav. Et siis rääkime natuke sellist vanadest webi teenuste standardid, sest nagu VSTL, UDDI ja ISIL ja siis teises loengosas vaatame open appi standardid, mis kasvas välja Swaggeri standardist või Swaggeri tarkvarast põhimõttel, et standardiseeritud Swagger on siis põhimõttel open appi. Peepi teenuseid, nagu ma eelmikord sisse juhatasin, on tarkvaramist pakub juurde pääsu mingitele resurssidele internetis ja tegelikult näi väga idefineerike ära, mis asjadne resursid võib olla kasutadest standardiseid webi protokolle üle HTTP appide, mida tavasad veebis kasutatakse. Ja näit, et mida meelmikord tõin on, siis näiteks Google Translate, String Pictures või Reddit. Ja täna vaatame mõnda näidet veel, aga põhimõtteliselt see loeng ei ole nii väga näidete põhine see kord. Ja webi teenuste standardid siis tuhetavadki laialdaselt kasutadustandarditele, et näiteks struktureeritud dokumentide jaoks kasutati algselt peamiselt XML-li, tänabäe rohkem JSON-it. VSTL kasutati selleks, et kirjeldad ära, et misse webi teenus üldse on ja mis meedad, et ta võimaldad. Ja siis tavasad suhtluseaks oli HTTP appid kasutuses, aga SOAP toetab lihtsalt SOAP protokolle üle HTTP. Kuigi SOAP ei pane paika, et peab HTTP-t kasutava. Ja need standardid siis määravad, et kuidas kirjeldada need webi teenuseid, niimoodi, et nad oleks aru saadavad kõikidele arendatele, kõikidele kasutatele. Ja määravad ära, et kuidas otsida webi teenused, et kui te lähete ja tahate näiteks mingisugus Twitter või Reddit ja appid kasutada, et kuste saate selle kirjeldus üldse, et kuste selleks leidate. Alguses vanasamate standardides kasutati selleks registreid, et kus kuhu üles laadida, sest selle webi teenuse standardne kirjeldused sai seda allatõmata, tänapäeval need webi teenuste kirjeldused on pigemselt serverisendased. Et seal, kus asub appi, seal asub üks dokumentatsioon või dokument, mida saada allatõmata ja selle põhjal näiteks klendi genererida, klendi koodi genererida omale meelepärases keeles näiteks Pythonis või CS-Sharpis näiteks. Tänapäeval registrid väga enam ei ole kasutusel, aga need algset, VSTL-puhised webi teenuste standardid, needle ehitad ümber, me paneme üles registrid ja klendid, kes on huvitatud mingilte webi teenuste kasutamist, lähevad registrisse, registrist otsivad webi teenuseid ja vaatavad, mis on nende webi teenuste sisendid ja väljundid ja siis saavad neid kasutuma hakkata, aga need standardid eesmerk ongi siis tagada, et jälgides, et kui ehitame webi teenuseid, mis jälgivad neid standardeid, et siis oleks lihtsalt panna need webi teenuseid omal koostud, tegemed webi teenus A saab allatõmata siis webi teenuse B spetifikatsiooni, majaduse lihtsalt isegi genererida klendi, kudas seda webi teenuse metodeid välja kutsuda näiteks Javascriptis, kui kirjaasad need dynaamiselt seda ei tehta ja siis kasutamakata, et oleks siis nii inim, kui masin loetavad standardid webi teenuste kirjeldamiseks. Et nad oleksid platformist sõltamatud, et nad oleksid skaleeritavad ja nad lihtsustaksid üldiselt sellist, lisaks koostulega sellist süsteemide integreerimise ja automatiseerimist, et oleks lihtne tekitada rakendus, mis näiteks oskab Redditi appid kasutada ilma, et peaks nagu programeeria liiga palju tööt tegemad. Täna päeval on väga lihtne tegelikult, nagu näiteks Pythonis mingisuguse suvalise webi teenuse klient genereerida, kus klient on täiesti valmis tarkkora, mida saab kasutada oma Python programmist välja kutsuda. Et kui teile on mingisugune keerulne hard tab appi ja neil on open appi spetifikatsioon, siis teie ei piagi iseimplemeteerima metodeid, kuidas näid open appid metodeid välja kutsuda, vaid saaksid võtta open appi spetifikatsiooni, valida programeerimis keel ja klienti tarkkora valmis genereerida. Ees oma Python koodist võib-olla kutsuta kledi tarkkora metodeid välja, et saata mingit anmed parzida või vastu võtta. Meil selle nädalu praktikumis pigem nende klientidega väga ei tekele, et me genereeerime serveri tarkkora pigem kui klienti tarkkora. Ja see üldiselt näid webi teenused, webi teenuste standaardid võimaldavad siis sellist teenustele orjenteeritud arhitektuurie, et suuremate tarkkora komponendid ongi webi teenused, mis oma vahel suhtlevad, üks teise metodeid välja kutsuvad ja keerukamad susteemid luvakse nende kombinatsioonine, nagu service composition, et ma panen mitmed teenused kokku. Täna päeval selle ase on pigem kasutatakse termi nagu mikro teenused või pilve põhised lahendused, aga enne pilvede tulekud näid pigem nimetati nagu service-oriented arhitektuurideks, et kui kõik suuremad, kõik tähtsamad komponendid osad olid webi teenustena või teenustena üldiselt. Ja need omadused, mis standaardeid jälgivatel webi teenustel täeksid siis olema või on, kuna nad jälgivad standaardeid on taas kasutatav, et oleks lihtne seda sama appid nagu uuesti genereerida näiteks teises keeles, et oleks lihtne nende appid jaoks klente genereerida suvalises progameerimes keeles, mida teie asutuse klendid näiteks soovioad oma rakenduses kasutada, mis teie webi teenuste metodeid välja kutsuvad. Interoperability-t koostalitus võime, et oleks lihtne panna mitmed webi teenused oma vahel rääkima, selle ka on sietud integratsioon, et meil oleks võimalik panna näiteks anmebaasja appi oma vahel rääkima, niimoodi, et anmebaasist oleks lihtne tõmat anmed ja saata näiteks mingis appisse või vastupidi, et mingist appist tula, et anmebasja oleks lihtne panna, et luua sellised anmeintegratsioona. Komponeeritavus, et me saaksime gerukamad süsteeme ehitada, niimoodi, et me kombineerime neid webi teenused, mis on kätes aadavad näide süsteemide poolt ja ehitama gerukad süsteemid pannas neid webi teenused oma vahel suhtlama mingisugus loogikaga. Lisaks veel ka leitavus, sest meil on tegelikult tähtis ka see, et kuidas me üles leian, kus asub näiteks mingisugumne Twitteri appi või kus asub Tartu Ülikooli mingi õisi appi, ja selleks on mitmeid viise, tänapäeval käib see niimoodi, et te lähed appile ja te natuke eeldat, et sellel appi kõrval mingisugus selle alamaadresil on see appi spetsifikatsiooni dokumeet, mida saate allatomata ja mis kirjadab ära, et midas appi toetab varasemalt kasutatud siin rekistreid selleks, et kuidas otsida üles, leida näid webi teenused, mida saab siis välja kutsuda. Webi teenuste sisemine loogika on peidetud, kasutajateist nema näevad ainult seda rakenduse, programeerimisliidest, et appi liidest, ja te teate, mis on sisendid ja väljundid, aga te ei tea täpselt, kuidas see implementeeritud sisemiselt on ja koodi generaatorid ka, et klendiosa oska täiesti genereerida, serveriosa pikem genereerideks niimoodi, et teil on vaja ikkagi sisemine loogika ise implementeerida. Autonoomsus, et iga webi teenus oleks suhteliselt ise seisav, et ta ei sisemise, ta ei tohiks väga nagu sõltuda liiga palju välistest süsteemidest, et põhimõttelselt see tähendab seda, et kui teised webi teenuste kokkujooksevad, siis see webi teenus võiks töötada ilma teistet, aga see ei ole alati võimalik. Pikem see, et iga webi teenus vastutab ise oma sisemise loogika eest ja kui te ta kasutatakse mingite teiste lahendustega komponeeritult või mingit integratsioonid on selleks süsteemi ja teiste vahel, et need kõik lähed katki, kui mõtegi üks osapuole ei tööta tavalselt. Eks see oleneb, et kui meil on näiteks mingisugune süsteemist soovib kasutada ilma teenust ja ta kasutab ilma teenusapid, siis see, et üks ilma teenusapi on maas, võib-ala saab teisi ilma teenusapid kasutada, et mõnikord see olemb, kui üldine sõn, et kas me soovime kindlata oma süsteemi sisest apid kasutada või me soovime suvalist ilma teenusapid kasutada. Nad peakse olema lahtiselt ühendatud, ehk nad võiksid eksisteerida iseseisvalt ja üks veepi teenus kokku jookseb, see ei toeks väga mõjutada teisi veepi teenuseid. See ole alati võimalik näiteks olukorras, kus me loome uue veepi teenuse, mis sõltub kahest veepi teenusest, kutsub välja näiteks ilma teenuse ja kutsub välja mingisuguse bussi sõitmisaegade teenuse. Ja kui üks nendest kahest teenusest ei tööta, siis see komponeeritud teenus ka ei proovi töötada. Näiteks meil on mingisugune delta maja ruumide pukimist teenus, et me saame ruumi kinni panna, aga kui see õisi teenus, mis ütleb, kas ruumist praegu midagi toimub või ei toimu, on kätki, siis eka see teenus ka väga miselmist teenus kasutab, ei oka ei tööta. Alati on, et pigem see räägib nagu nendest sisemistest loogikatest. Ja üldiselt peaksid veepi teenust olema staatuseta, stateless, et iga päringud peaks käsitlema nagu ise seisvana. Et see ei ole nii rangenõue, aga see aitab ehitada skaleeritavad ja törkke talu või teenuse, et kui teenus või tarkvarja ise jätab midagi meeldelmist ja päringute kohta, et siis on lihtsam jaotada, sisse tulad liiklust ja skaleerida süsteeme. Et see staatuseta nõua on natuke nõrgen nõue kui maned teised. Üks esimesi sellised veepi teenuste standaardeid oligi, siis web service description language, ehk VSTL, kus kirjeldad erad, kui meil on veepi teenuse implementatsioon ja meil on veepi teenus kuskilt internetis kätte saadav, mis on protokollid, mis kasutataks, kas näiteks SOAP või HTTP, kus mis on need metodid, mida toetatakse selle veepi teenuseest. Ja meil tekis selline VSTL dokument, kus XML-is kirjeldatakse kõik vajalik ära selle veepi teenuse kohta sarvasad nagu meil SOAPi spetsifikatsioonil ja põhimõttel ongi see enam, et me põhimõttel defineerim ära, et mis on selle veepi teenuse nimi, mis on tema metodid, mis on sisendid ja väljundid ja meil on sen XML-file. Ja see XML-file tavalselt panaks ja kuhugi rekistrisse ja seda saab seda rekistrist alla tõmmate ja siis kui me oleme selle dokumenti alla tõmmates, me saame nagu parsed XML-i ja lugeda sealt, et mis veepi teenuse sellised sisendid, väljundid ja spetsifikatsioon nagu üldiselt on. Lisaks oli meil Universal Description Discovery Integration selline dokumentatsioon või dokumentid, mis olid ka XML-i põhjine standard, mis kirjeldab ära, et kuidas otsida ja leida veepi teenused, mis on nende nagu sellist adressid ja kus nad asuvad. VSTL-i põhjal me kirjeldasime ära, et mis on selle funksionaalsus, aga UDDI põhjal me kirjeldam ära, et mis on näiteks selle veepi teenuse mingisugused täägid, et kas ta on ilmaga seotud, kas ta on millegi muuga seotud ja selle spetsifikatsiooni põhjal sai otsida veepi teenused kuskid rekistrist ja leida see info, kus see veepi teenuse asub, mist tema adress on, kuidas ta välja kutsuda, et mis porti taga ta näiteks on sellist infot. Ja lisaks oli ka selline VSIL, kuna sellist kesksed rekistrit, kus me need dokumentid paneme, me peame teadma, kus need kesksed rekistrit kaasuvad, aga kui me näiteks teame, et me soovime Redditi appid kasutada, me teame, kus asub Redditi adress, aga me ei tea, kus asub rekister, kus asub Redditi sees, ütleme, VSTL dokument, et mis rekistrisse dokument asub, kus me alatõmbame, siis tehti veel eraldi selline spetsifikatsioon nagu web services inspection language, mis võimaldas saata teatud struktuuriga päringu Redditi serverisse, mis ütleb, küsib, et kus asub sinu appi spetsifikatsioon, et kus ma saan selle VSTL dokumeeti alatõmata ja see oli nagu vastupidine lahendus siis rekistril, kui sa ei tea, kus rekister asub, siis sa kasutad seda viisi, et see spetsifikatsioon alatõmatad, et oligi XML puhinspeksifikatsioon, mis siis defineerib, kui tas otseteenuspakku elt, et otseteenuse adressilt hostneimilt küsida siis tema poolt toetatud webi teenuste kirjeldusi. Ja tänapäeval pigem kasutatagi seda lähenämist, kui rekistrite lähenämist, et kui me teame, kus asub Eesti reati asutuse mingisugune aadress, siis me saame tolle serveri käest pigem otsida ja küsida, et kus on sinu appide spetsifikatsiooni fileid ja kas ma saan et alatõmata. Ja põhimõtteliselt, et kui meil on klient ja mingisugune appi pakkuja või appi implementeerija või appi server, siis selle appi implementatsiooni jaoks on meil siis vstl kirjeldus. Tihistise vstl kirjeldus võib eksisteerida enne, kui meil on üldse implementatsioon, sest vstl kirjeldub ära, et mis on neid metodid, mida peaks implementeerima, siis on tihti loogilne teha see vstl enne ja pärast seda siis isegi saab genereerida kogu serveri sellise skeletoni, implementeerida sellise skeletoni ja kui meil see appi on olemas, siis kuskil peab eksisteerida see file, siis see appi pakkuja siis kas hoolitseb sellest, et see vstl on siis VSIL stiilis serveeritud kusagilt samast serverist või vähemalt server ütleb, kust asub. Ja nii, UDDI kui VSIL ka linkivad oma info selle vstliga, et UDDI kaudu me saame siis otsida, kus asuvad serverid, et klient, kes soovib seda appid kasutada, ta saab küsida UDDI rekistritest, et mis webi teenused on olemas, või ta saab siis otsa serverist küsida VSIL speciakatsiooni või lähenämise põhjal, et mis on sinu serveri poolt toetatud appid. Kui ta kus server asub, seda saab otsida serveri, kes kui ta ei tea, kus server asub, seda saab otsida rekistritest. Ja põhimõttel ta saab nende kaudu selle vstl ja plus ta saab ka selle server asukoa ja klient saab nüüd selle vstl põhjal näiteks genereerida nüüd selle koodi, et kuidas need metodeid püüta nis väljakutsuda, kuidas need metodeid C++-is väljakutsuda või siis näiteks mingisugune, mingisugune organisatsiooni arendaja, siis implementeerib selle vstl põhjal selle klienti tarkkuvara ise, et kuidas need metodeid väljakutsuda. Et siis UDDI ja VSIL olid sellised viisid, kuidas nagu neid ülesleida ja vstl on siis kirjeldus. Moneks asjad juba rääksin ette ära, et vstl siis põhimõttel saab vastab küsimustel, et mis operatsioone see webi teenus pakub, misugust on parametrit ja tagastusväärtused, siis sisendid ja väljundid, mis muode and-meid edastatakse, et kas meil on JSON dokumentid, XML dokumentid, raw stringid või mingid pinaarsest striimiid, mida me peame edastama ja mis adressi ja protokolliga ligi pääseb. Ja ligi pääseb tavalselt on kas soap või HTTP ja see on mõnesemate sarane elmekordselt soapi appide kirjeldus ka toimus. Vstl sisu, et see on siis spetsifikatsioon, mis kirjeldab appi olemuse ja standardiseeritud viisil, siis tavalselt koos näeb taipides, ehk and-meid tüüpidest ja tavalselt on XML dokumentide väärtuse tüüpid. Koos näeb sõnumid, et mis on sõnumid, mida edastatakse kas serverissa või server saadab meile, mis on and-meid tüüpid, mis on XML struktuurid, mille see sõnumid on, mis on tagide väärtused ja tüüpide nimed. Lisaks on sellised porti tüüpid ja portid, mis tegelikult defineerivad sellised meetodid, mida saab välja kutsuda teenusest. Ja siis on lisaks sellelega sellised bindingud, mis määravad seosad and-mei vahetuseks, kas me kasutame soapi, kas me kasutas HTTP-ed. Ehk meil on meetod, mida saab välja kutsuda, ja meil on binding, mis ütleb, kuidas seda meetodid saab välja kutsuda, sest meil võib eksisteerita meetod, näiteks get-veter-info, aga meil võib eksisteerita kaks bindingud. Üks ütleb, et sa saad HTTP-abil selle meetodid välja kutsuda ja teine ütleb, et sa saad soap-able meetodid välja kutsuda, et HTTP-s sa peaksid kasutama JSON-id, aga soap-is sa peaksid XML-i kasutama, et see binding paned paika, kuidas need meetodeid või siin definitsioonis portidega suhelda või need meetodid välja kutsuda. Ja see on ka selline üldine kirjeldus, nagu service, mis kirjeldab ära selle webi teenuse nime ja kust ta asub. Ma toon ka mõned näited, kui kui need näited on väga sellised keerulisede XML-puhised. Näiteks, siin on siis selline üldine veestel näite, kus ma olen teatud asjad ära peitnud, et meil on siis üleva sellised XML-i meta-anmed sammut soobi puul, et meil on kirjeldus, et näiteks, mis sukuseid XML-i namespace-i me kasutama, et kui me tegeleme soobi, kõist me peame ka mingit soobityübid ära paika panema, siis meil on veesteli mingisugused namespaces kirjeldatud tüibid, et mis näed põhimõtteliselt tagid tähendad, et kui meil porttab, mida see porttab, siis veestelikontekstis või veestel namespaces siis tähendab. Ja sisameil siin kaks tüüpi sõnumitest, mul on ära peidetud, mis selle C-s on, aga et meil on kaks sõnumit, üks sõnum on get last trade price input ja tein on get last trade price output, et meil on siis mingisugune, vistas siis oli, stock marketi hindade küsimise appi ja meil on siis kaks sõnumit ja meil on üks selline binding ja meil on üks teenus, see teenuse nimija stock quote service, see on selline, et me saame nagu seda stock quotei või stock market hindasest küsida siis selle teenuse kaudu, siis on meil selline metodikireldus, mida me defineerime porttabina, et meil on stock quote porttab ja selle alla on metod get last trade price, et mingisuguse aktiahinna küsimine siis. Ja siis on meil kas, et meil on see metod, aga kuidas seda metodid saab väljakutsuda, kui me ei defineeri, et kas meil on, kas me tovetame soapi või Http appi kaudu väljakutsumist, et me saame defineerida neb bindings, mis ütlevad, et seda get last trade price saab väljakutsuda, siis soap binding-u abil meil on soap üle Http ja siin on see namespace, mis kirjelda pärat, misugused spetsifikatsioonid peab kasutama, et kui sellel viisil ühendust otta, et XML-spetsifikatsioonid on salati igasugused namespace, et siin on mingisagu transporti namespace, et kuidas siis suhelda selle get last trade price metodega. Ja kui me peaksime tovetama veel ühte teist viisi, kuidas suhelda, siis me saaksime veel ühe binding-u luua, aga meil on üks metod, üks binding, aga meil võib selle sama metod ja aga kaks binding-u. Ja siin on siis neid tüüpide definitsioonid, et kui meil on type, on siis stock, code, port type ja get last trade price, siis trade price request. Ma vaatan, kest on siin välja toodud. See on vist mõnes alam osas, mis on praegu peidetud. Et siis me saame tefineerida ka tüüpid, et meil on trade price request-tüüp ja trade price-tüüp. Need on siis nende kahe sonumi alam tüüpid vist, mis on siis get last trade price inputis ja outputis. Et kui me saadame, siis requestis me peame ära defineerima, et mis aktiat me aktia hindame küsim, et meil on siis sellel ticker symbol sees, et meil on nagu kompleks type, milles on all ja siis element name on ticker symbol ja kui me tekitame sellise sõnumis, me peame selle ticker symboli määrava. Ja vastu tuleb meil siis selline vastus, kus me saame lihtsalt price-i. Me isegi ei saa seda ticker symboli tuuesti, me saame lihtsalt price-i, et mis oli siis selle ticker symboli hind praegu selle hetkel. Sõnumid siis defineerivad, et meil on get last trade price input ja get last trade price output ja see määrab, et nende sisu ongi täpselt see ja see, get trade price ja get last price request. Me peame sõnumid defineerima, mille see on sõnumielement ja siis sõnumielement on täpselt see tüüb siin. See on suurselt keeruline, mitmatasemeline ja nüüd me defineerime, ka siis stock port types on siis nagu metod. Metodi nimi on get last trade price ja metodi siis see defineeritakse, et mis on sisend ja mis on väljund sõnumid, mida tuleb saata. Nend sõnumid on küll kirjatatud XMLis, aga need reaalselt peab saata JSONis, et kui meil on binding, mis defineerib siis JSONi. Ja lisaks on meil siis binding, mis panab ka need inputid ja outputid põhimõtteliselt paika, et meil on get last trade price operatsioon ja defineerib siis subactioni, mille nimi on get last trade price ja siin juba defineeriteks, et kus sa asub. Siin bindingu defineeritakse ka see, et kus asub see aadress, kus saab seda välja kutsuda. Siit saab teada, et me kasutame soapi üle HTTP, kun nad CSP-etioon on linkitud, siis transporti allat see määrab, et peab soapi üle HTTP kasutama, kus seda bindigud kasutatakse. Ja... Ja teenus ise on siis selline üldin info, et mis on selle web-teenuse nimi, mis on selle web-teenuse portid ja bindigud, nii et see on nagu lisalt põhimõtteliselt linkib kõik nad asjad kokku, et see teenus toetab seda meetodid ja selle meetodid siis tuleb seda bindigud kasutada ja siis saab määrata, et kus asub see soap-appi server, et siin on veel üks võimalus seda paika panna, kust ta asub. Nii et on suhtselt selline keeruline, aga ta on sellesmatsemas asi loeta ja kõik vajalikud sellised... kõik vajalikud, kus mul see transport siin on, kõik vajalikud, nagu tüibid on ära määratud, et see ka tähendab, et sellised spetsifikatsiooni põhjal on võimalik genereerida, siis kas klient või server, et mis oskeb sellist meetodid siis implementeerida või sellist meetodid väljakutsuda. Toon ka ühe kiire selle uudid.ai näite, et kuidas seda webi teenuste otsimise jaoks kirjeldatakse need webi teenuseid, et võib-seda saa moodi lihtsalt appi, mida saab ülesõuprotokolli väljakutsuda, ehk me saame registrist ülesõuprotokolli siis küsida, et mis webi teenused on sellest registriss kirjeldatud ja saame nende spetsifikatsioon alla tõmata tänapäeval kasutatakse suhtselt vähe, et sellised globaalsid registrid ja alati teadmise vajaduse, et kus need registrid selle meid huvitava appi aaks on, on suhtselt tüutu, nagu klientilad on alati selgitada. Aga see näiteks välja selline, et meil on sellised kiit referentsid, et me saame ära määrata, et mis on sellised tüibid, vstl-taipid, service namespaces ja service local names, et vstl-taipid on service, et on webi teenus, me saame ära, et misugust namespaces kasutab, tal on enda mingisugune xml kirjeldus kusagil, example.com.stockaut, et seal saab alla tõmata siis selle kõik need tüibid spetsifikatsioonid, ehk põhimõtteliselt webi serversi võeldeks, et meil on sellise nime ka teenus, ta on webi teenus ja service type ja tema selline spetsifikatsioon asub siit, et saate selle alla tõmata, et tema xml spetsifikatsioon asub seal ja sellest tema namespace-is kirjeldeks ära tema meetodid asjad ja põhimõtteliselt mõnes mõttes see ongi nagu vaelik. Okei, ma olen natuke selgitas, et seda valesti, et see on pigem nagu otsimisepäring mitte see kirjeldus, et me otsime siis webi teenust, me ütleme, et me otsime webi teenus servisid, me otsime teda sellise nime ka ja kui me teame, siis me saame ka määrata, et kus on tema nagu namespace, et see on pigem nagu otsimisepäring mitte see kirjeldus, mis serveri asub. Et see oleks siis meie soappäring, mida me teeme siis uudeteai rekistrisse, et otsida webi teenust, mille nimi on Stock Code Service. Ja vcl on siis alternatiiv rekistripõhj selle webi teenust otsingule, et kui see uudeteai on sellised centraliseeritud, et me peame teama, kus asub see centraliseeritud rekister, siis vcl on pigem decentraliseeritud, kui me teame, kus asub reddit ja tahame reddit-appid kasutada, siis me saame proovida serverist lihtsalt vaadata, et kas ta toetab vcli. Ja kui ta toetab vcli, siis me saame vcli specialkaudu või protokolli või lähemise kaudu küsida, et mis on sinu serveri webi teenus, et mida selles serveris hostitakse. Ja põhimõttel servelil tootse küsida, ana mulle kõik kirjeldused ja siis ma valin nende seastu või otsin nende seast. Et me põõrtumis otsi teenuse pakkuja poole, kaapi serveri poole ja küsime, mis on sinu pakutavad teenused. Ja me ei pea siis teadma, kus võiksid asuta rekistrid, aga me peame teadma, et kus asub mingisugune organisaatsiooni portaal või serveri aadress, et seda väljakutsuda. Aga see on väga tüüpilne, et me teame seda. Seda saab pigem siis kasutada, kui te teate, mis organisaatsiooni webi te soovite kasutada. Nendeks ilma teenuse puhul te teate, et te soovite tõravere ilma teenust väljakutsuda, siis lähete tõravere ilma jaama aadressil ja küsite tõravere ilma jaama käest. Aga kui te soovite nendeks suvalist tartu ilma jaama kasutada, et siis võib-olla oleks mõistliku mina rekistrisse küsida, mis on tartu ilma jaamad apid. Ja siis saate alla ja valite ühes nendest, et see WCL lähene minu, et te teate konkreetselt api teenus pakkuvad, kelle apite taad väljakutsuda. Ta näeb välja umbes selline, et meil on WCL dokument organisaoni kodulehel. See kirjaldab ära kõik teenused, mida see organisaonime systeem pakub. Ja teenuste kirjaldus üldjuhult jälgib täpselt seda sama WCL standardid, millega me enne defineerisime need stock-out metodid ära. Ja põhimõttiselt kusagil asub selline dokument ja me saame sealt leida, mis on WCL dokumenti asukoht. Et kui meil sellest dokumentis on teenuste list ja meil on üks teenus, siis see teenuse blok kirjaldab ära sellest stock-out service metodi. Siin seeks kirjaldab ära, et kust ta asub, mis serveri aadadesi, mis porti peal, et kust alat omata selled teenuse kirjaldus vest L-file. Ja lisaks, et kuidas seda teenuste ennast väljakutsuda, et mis on sellel appi enda endpointi või appi host aadressed. Kust kuhume need soap sõnumid saadame, et seda teenust väljakutsuda. Ja siis idee on, et kui sellest serveri on 10 teenust, siis siin on laks 10 erinad serviceid. Ja klient peab siis vaatame selle X ja M-l läbi, vaatame need 10 teenust läbi ja ise otsima sealt selle vajaliku teenuse, mida ta soovib kasutada üles. Et kas siis ilma teenuse või midagi muud. Et see WCL on siis palju lihtsam näide selle kohta. Kuna soap on siiamaani kasutuses, siis neid asju tihti kasutatakse just sellist vanametasysteemides, aga ka näiteks VSTXD-s on vanemalt teenused kasutavad siiamaani soap. Ja kül vaikse prooviteks nad üle tuua HAT-TP appide peale, aga sellised... Ma asiin lohetavad kirjaldus on tegelikult väga kasulikud, sest nende puhel, eriti VSTL puhel saab lihtsalt genereerida selle appi väljakusjade klienti tarkko raja, seda kasutam hakkata. Aga pigem tänapäe olen kasutuse, siis Swaggeri või Open Appi spetsifikatsiooniid, et kirjaldada ära HAT-TP ja RESTful appisid. Ja see on ka see, mida me praktikumist kasutam hakkame, et eelmine nädal te ise implementeerisite selle HAT-TP appi kasutades Flaski. See nädal, mis me teeme, me võtame minu poolt valmis tehtud sellise Open Appi spetsifikatsiooni, kus on üks meetod puudu. Ja teie ülesanne on siis võtta see Open Appi spetsifikatsioon, kasutada Open Appi generaatorit, et genereerida täpselt samasuguna appi, Flask appi implementatsioon nagu eelmisest praktikumist ja siis see tööle panna testida seda ja kõik meetodid ära implementeerida ja üks, siis mina takas ja üks puuduole metod sinna spetsifikatsiooni ise lisada ja siis uuesti kõik see asja läbi teha. Elmikord me tegime appi käsit, siis see kord me võtame ette spetsifikatsiooni ja genereerime nagu serveri skeletoni selle spetsifikatsiooni põhjal ja ainult implementeerime meetodite sisu, et me siis enam ei pea muretsama nende serveri üldise logika põhjal ja me saaksime Flaski asema näiteks fast API kasutada või Python aseval mingi teist progameerilis keelt kasutada. Aga open appi spetsifikatsioon muutus standardiks, kui Swagger sa jästi populaarseks ja põhimõttelselt võib üldada open appi spetsifikatsiooni nimi ennali Swagger. Ja põhimõttelselt me loome sellise YAML-i või JSON dokumenti, kus kirjeldatuks ära kõik appi meetodid, kõik appi meetodid sisendid, kõik appi meetodid te väljondid ja põhimõttelselt see ongi mõnesmedes kõik. Natuke sarnaselt nagu eelmised XML-id, aga samas lihtsustatult. Ja ta on rohkem inim loetav võrraldes XML kirjeldustega või spetsifikatsioonidega. Me kirjeldam ära kõik resursid, nende lõppunktid kirjeldused, mis iga mis meetod, hated ja operatsioonid, kas ket, post, delete, put on lubatud nende resurside peal. Me genereeme ära, või kirjeldam ära, mis on sisendid ja väljondid. Open appi specijik on, et see onis me ei pea kirjeldama, mis on sisendid ja väljondid. Me võime tegelikult ka sisendid ja väljondid täiesti kirjeldamatuks jäta. Ja see ei ole küll hea standaard, aga põhimõttelselt me ei pea olema nii ülikirjeldav, kui soupi ja XML-i puhul. Lisaks me saame ära kirjeldada asjad nagu autentimne. Me saame paikapanna, et see meetod, et selleks, et teha ketpäringud või deletepäringud, peab kasutama appi võtmeid. See meetod, et sisse logida peaks kasutama kasutenime ja parole või midagi muud. Me saame isegi määrad, et kus need autentimis info peab olema, et kas on näiteks mingisuses kindlas, Http, header-väärtuses, mille nimi on, appi minus key näiteks. Ja tihti saab seda spetsifikatsiooni kasutada ka lihtsalt rest-appi dokumentatsioonina, et arendaja saab minna ja lugeda jambli ja aru saada, et mis on meetodid, mis tootadakse, mis on sisendid, mis on väljundid. Ja ta on selline suhteliselt inim loetav. Natuke rohkem inim loetav, kui ta on jamblikujul, aga nii jamblikujul, kui Jason on tänapäeval täitsa tavaline anmete kirjeldamise standaard arendatele, nii et ta on suhtselt hästi inimia masin loetav. Ja üks väga suure eliseid, miks swaggerid kasutati on see, et selle open-appi või swagger spetsifikatsiooni põhja saab genereerida täis väärduslikku serveri kodi, et te kirjeldate jambli sõna need meetodid, endpointid, mida soovite ja siis kasutad, annate selle sisse genereerijale, genererijal kirja, implementeerib teile jaava spring-kodi, kus on ainult meetodide sisud puudu ja oleneb sellest, mis keelde, mis raamistikude genereerite, te tihtisaate ka teatud meetodid, nagu kuidas parsida Jasonid, kuidas valiteerida, kas Jasonist on midagi puudu, kuidas autentida näiteks fast-appis, genererib ka sellised autentimise meetodid, mis kontrollivad, kas appi võtja on olemas või mitte. Et see teab tegelikult väga palju tööd arendate ja aks ära, kui seda spetsifikatsiooni kasutada. Sellega on omad nagu sellise puudused ja probleemid, aga ideeliselt väga tohutult kiiresti saab lihtsa prototypid ja me mõnesmõttes mängimegi selle praktikumis läbi. Me kasutame peame Jasonid ja Jamli open-upi puhul, kus XML kõist kasutati pigem nende varasemate standaardite puhul. Ja näid erinevse on põhimselt täpselt samad, et meil on mingisugused tagid, meil on mingisugused, tavaselt iga reapeal on mingisugud üks väärtus. Ja kui Jamli ei ole kasutad, siis Jamli on üks ühele sama, mis Jason, aga sellist sulgutasemel kasutatakse pigem nagu ridasid ja püütanis arnas sellist neid tühikutatud tasemet, et samal tasemel olevad väärtused on põhimõtteliselt sama bloki sees. Kui meil on siin Jason, kus on serverite list ja serverite listis on üks Jason, alam Jason, milles on neliväärtust, siis Jamli näeks sama välja niimoodi, et meil on servers ja siis meil see miinus määrab, et see on list. Et iga miinus on siis järgmine listi element. Et kui me siia paneks miinus, siis me saaksime järgmise listi elementi panna neljaga. Ja kui meil on siin list ja listis on üks miinus ja neliväärtust, siis järgmine list on oma korda üks block, ehk üks mõnesmõttes Jasoni block, mis on ühe listi elementi. Et kui servers on list, siis siin ei ole listi neliväärtust, siin on listi üks väärtust, mille sees on neliväärtust. Et kui te ei ole Jamli väga kasutand, siis ta võib natuke keeruline algustus olla, aga ta on võimõtteliselt üks ühel aru saada, kui Jasoni on mõnikord natuke raska aru saada, mis on miinused tähendavad ja muut sellist asjad. Ja näiteks komasid ei pea kasutama, aga me kasutama täpselt samasugused kooloneid, aga reaal öpu komasid ei pea panema. Et Jasoni saab teha ühereaaliseks dokumentiks, et te võite kõik tühikud äraemaldada, noh tühikud pead jääda, aga kõik reaa vaahetsud saada äraemaldada, et Jason võib olla ühereaaline, aga Jam peab olema mitme reaaline, et Jamlis on see rida siis nagu kirjet eraldaja, kus Jasoni see nagu komad või sulud kirjet eraldajad. Ja see on Open Appi specialkatsioon, näb välja niimoodi, siin on sada rida, rohkem kui sada rida, ütleme, et 110 rida ja ma olen jälle natuke kombineerinud teatud read, aga mis meil põhimõtteliselt siin on, et meil on siis Open Appi versioon, et siin on 3.0, kõige viimana viss 3.1, siis on meil Appi info, et meil on Appi versioon 1, siis Appi peal kirjan Swagger Pet Store, see on selline tüüpiline Swaggeri näide, me võime siin defineerida licensi, et näiteks meil on MIT-licens, täiesti vabavaraline, see nüüd tegelikult natuke oleme, millele see licens on, et kas see saab olla Appi koodile, kui Appi koodi seal avalik, et pigem, et on sellel specialkatsioonil licensi. Ja siis on meil, et kus asub server. Ja see server aadres on tegelikult väga kasulik hiljem, kui ma näitan seda interaktiivse dokumentatsiooni, siis see tegelikult ütleb, et ma saan siin aadresil siis hakkata tegema slash endpoint päringud ja saadma sinna ketvui postpäringud. Siis pääsid alla meil kõik endpointid, et näiteks pets ja pets pet ID ja nende endpointide või otspunktide alla on siis need meetodid, et pets toetab siis ketvui postmetodid ja pets ja siis mingi konkreetse koduluoma IT alla on siis ketvui meetodid, et me ei saa koduluomi kustutada, aga saame uusi koduluomi luua ja allaatamata. Me saame koduluomade. Nüüd kui te siia peale vaatad, et kas keegi oskab mulle vastata, et mis meetodeid see appi toetab? Litsad nende otspunktidele ja meetodid peale vaatades. Mida? Aga mida see ket teab? Et küsib kogu petide nimekirja. Mida teab post? Teab uue koduluoma ja mida teab see ket? Otsib siis koduluoma infoeles. Seda ma elm, et puhtalt ilma teadmata, mis on sisendid väljundid, ilma teadmata, mis on kirjeldused, et ihti saate loomulikult aru, mida need meetodid teevad. Koduluomade. Koduluomade. Võraldes nende soap-metodid, et see on selline hästi kokku pakitult, hästi lihtne, nagu aru saada, mis see on. Aga see oleneb ka sellest, et kas arendaja on siia õiged nimed pannud ja et ta ei ole siia midagi väga segast kirutanud. Et sellisele juhula asjad läheb keeruliseks ja tänapäeva appidel võib siin tegelikult olla. Toys slash transactions võideks sellist ja võib palju-palju keerulisemaks minna. Aga põhimõtteliselt selline lihtne appi on hästi aru saadav, kui me kasutame HTTP ja RESTful lähenemist. Iga selle blokki sees on selle kettikirjeldus, selle postikirjeldus, selle kettikirjeldus. Ja siis meil on komponentid all sellised linkitavad infot, et me saame siis defineerida, mis on kodulooma objekti-alamväärtused. Ja see on hästi selline objekto-orienteeritud lähenemine, et me defineerime ära, mis on kodulooma-alamväärtused. Võite kirjalda seda, et meil on pet-klas, meil on pets-klas ja meil on error-klas. Ja siin defineeriteks ära, et mis on siis tavaliselt kodulooma sellised omadused, midada appi kaudu edastate. Et kui me loome uue postiga uue kodulooma kirja, ja siis siin skeemadal defineeriteks, et kui luoks uus koduloom, mis need alamväärtused peaksid olema. Et kas seal peaks olema kodulooma nimi, vanus, mingi muu infokodulooma kohtad. Mis tüüpi koduloom ta on? Kas ta kass või koer või mingisuguna muu koduloom, et ja mis on tolle kassi omakorda tüüb näiteks. Võimust, et võite mõelda, et näite, nagu Anne Paasi jaaks siin, ega vajalikult, et defineerid ära, et kui meie appi tegele koera, et mis on siis kodulooma kirjed, mis Anne Paasi peaks kirjutama, kui appisse tuleb uus post pairing. Nüüd vaatame natuke lähemalt, mis siin nende igasees võiks natuke olla. See peamine meta on, et block on täpselt samamise enne, aga seal saab olla ka näiteks kontakte, et kui tal on küsimusi selle appi koht, et kelle ka ühendust võtta, kus on mingi dokumentatsioon. Litsens võib ka olla keerulisem, et näiteks saab padse konkreetne litsens koos linkiga. Kui me hakkame serverit alla, vaatame, mis võib meil ei ole ka kolm serverit, näiteks, et meil on development server, staging server ja protraksion server, et me saame need aadres isegi meeldese jäta selle spetsifikatsioonis. Eriti siis on kasulik, nagu developerid teaks, et kui te ojate oma GitHub'is sellist spetsifikatsiooni, siis developer saab arjenda minna vaadata, kus on staging ja kus on development server. Ja päevside all on siis meil kõik sellise resto-info, et kui meil on siis üks endpoint kodspunkt pets koduloomad ja seal on ket, siis keti all kirjaldama tavast ära üldise kirjalduse, et siin onki, et return all pets from the system that the user has access to. Ja tavast on neid partitsioneeritud kasutaja kaupa, et kasutel on teadud õigus, et näiteks enda poolt sisestatud koduloomi näha või siis on vastupite, kõikikoduloomi, et see olema siis implementatsioonist, et kuidas partitsioneeriteks need andmed. Ja siis pärast, kui meil on description, ketipuul meil tavastat sisendad ei ole, meil võivad olla parametrit, aga siin näiteks meil parametrit ei ole, et me siin defineerime, et kui sa saadad ketpäringse hapisse, mida sa vastusena saad ja vastusall on tavastat plokid koodidest. Et kui tuleb kood 200, mis seal all vastu tuleb, kui tuleb kood 404, mis stiilis vea teade, siis on, et kas tagastab sulle mingi chase ödi või ta on täiesti tühi vea teade, aga 200 puhul on see tavalselt, et see on okei kood, ehk päring läks läbi ja siis selle omakorda selle koodil võib olla kirjeldus, et siin sees on list of pets ja siis kontent ja all on, misse list siis sisaldab. Siin kontent ja all on, et meil on jason ja jasoni sees meil on jasoni schema ja see jasoni schema sees, et meil on array, nii et meil on jason, kus on siis list ja sest listis on itemid, kus iga item on selle skeemaga. Ja siin me veel ei ütle, et mis selle kodul oma vääritus, et me lihtsalt linkime eraldi skeemale, mis on selle dokumenti põhjas ja see on ka senne objekto-orienteeritud stiilis, et me ei pea seda kues kohas muutma, et me saame seda ühes kohas muuta ja siis lihtsalt linkida sellele. Ja et meil on lihtsalt põhimõtteliselt jason list jason list jason list jason dokumentid, kus iga jason dokument vastab siis petile ja meil ei ole selle listil nagu võtit, et meil ongi lihtsalt list jasonitest. Põhimõtteliselt põres mõttes me jätame selle jason võtme listi võtme nagu abstraktieks. Ja lisaks, kui meil on nagu, et ket, siin on mis võib-olla väike viga, a, siin ei ole väike viga, see ma olen lihtsalt endpointi ära unustanud, et on selle üksliid ja ülelpohle, et ma olaks võinud seda endpointiga näidata. Et endpointis on siis lisaks petile ka PetID ja seal on siis kirjeldused, et me saame konkreetse kodul oma info ja seda otsib kodul oma ID järgi ja me paneme paikaga ket-pets-paj-ID, et kui siin on, siin seda metodi nime millegi põres lihtsalt ei ole, aga see ket-pets-paj-ID see määrab, et kui genereeritakse selle spetsifikatsiooni põhjal püütan metod, mis on selle püütan metodi nimi? Et see määrab siis nagu koodi metodite nime ära, et meil tekib operatsioon, mis on püütan metod, kui me generin püütoni ja selle metodi nimi on siis tavasalt ket-underskor-pets, underskor-paj, underskor-ID, et tavasalt tehakse selline konverteerimene, et kämel keissist underskor-tybis konverteerteks ümber püütanis. Siin on ka, et mis vastuseks saame, et me saame siis, siin tundub väike viga-ale, et siin tegegütaks üks pet olla mitte ära ennendest, võib-olla ma olen siin kogamata vea teinud. Ja siin sellel metodil saavad olega parametrit, meil onki ID-parameeter ja see ID-parameeter on siis selle URLis, et kui genereeriteks püütan kood, siis püütan kood teab kus seda ID-väärtlust võtta, mis andaks selle ket-pets-paj-ID metodi argumentiks. Mõnesmõttel see info on siin vaelika koodi genererimiseks. Siin on siis kodulooma loomine, et samamoodi, et meil on vaja teada, mis on sellel metod, mis on selle metodi nimi, siin petID. Ja siis me defineerime kärgad, kui postmetod tehaks, et mis Jason ei püaks selle postmetodiga kaasa saadma. Siin tegelikult vist ei öelda, et Jason, pigem me öelda, et see anmed tulevad HTML-vormist, et ta on HTML-form, URLin kooded väärtlust, ja selles vormist oli siis kodulooma nimi ja kodulooma staatus ja need oli kaks vajaliku väärtlust, võib-olla seal on veel midagi, aga põhimeks kodulooma loomiseks ta anma kaasa lihtsalt nime ja staatuse. Ja vist selle postmetodiga nad vist toetavad ka ta staatuse muutmist, et neil vist ei ole eraldi put-metodid, mis väga restful ei ole, aga open up-i spejekatsioon lubab kasutada. Ja see vastu võib tulla kas 200 kodiga vastus, et petupdated, kus needJation kui XML puhul on see vastus nagu tühjad stringid, ja kui te teete postparing on võimalik anda kaasa hetereväärtlust accept, ja selleks saate märd, kas ta tahate Jason sõnumit tagasi või tahate XML sõnumit tagasi. Et see võimalatab nagu mitut stiilis saada anmaid tagasi ja postparingu tegiall ise otsustada, kas ta tahab Jason vastust või XML vastust. Et kui tema rakendus pigem tegeleks XML parsimisega, siis võimest, et on võimalik, et saab mitut tüüpi vastust saata. Vist mitte, et ikkagi üks on seal minu teada. Näiteks, kui me tegeme anmet, tegad, kas ma tahan Jason stiilis anmet või CSV stiilis anmet saata, et näiteks mingid anme kogu alla laadimisel. Aga see on jaa, et lihtsalt mitte aaks. Ma ei ole kindel, et võib-olla saab mitu anda ja sista kudagi prioriteetsalt vali pesimise, mis on võimalik või midegi sellist. Aga ma pole päris kindel. Minu teada on üks, aga võib-olla ma ei ole, ma ei lihtsalt teada nii täpselt. Ja siis siin on errood, et me võime ka saada 405 ja siin on isegi kirjeldus, mida sa 405 täpselt tähendub selle appi kontekstis, et ma etad natta laud ja see ka määrab, et vastus on tühi xml või tühist Jason ja see ka tegelega juttab, et vastus tuleb tõennauselt. Või no, vastus tulebki tühi Jason tagase. Mõnikurv teid pea asiagi saadma tühja Jason, et võib lihtsalt kontenti mitte olla. Ja open appi komponentsi blok al saab olla siis väga palju onnev, et juba on juba, et juba on juba, ja open appi komponentsi blok al saab olla siis väga palju erineid asju, et meil võib olla siis keemad, meil võib olla mingit kategoriad, meil võib olla mingit tagid, meil võib olla mingisugud responside kirjeldused, et see võimaltaab näiteks siia linkida, et konkreet see responsiasemel me võime selle responsi ükskord ära kirjeldada komponentid al ja siis siia pana linki sellele komponentile, et meil võib väga palju erineid asju olla näiteks mingite sõnumide struktuurid skeemas, mingite objektide struktuurid, näiteks mis on user väärtused, mida useri loomisel peaks maärama, operatsioonide parametrid, mingisugud näited, näited on väga kasulikud veepi, interaktiise veepi dokumentatsiooni aaks, me vaatame seda vasti igasugused sisendid ja väljundid, vastused, väisevärtused, mida me mitmes korras kasutame, et näiteks kui me taham ära märata, et nende apide puhul tulub kasutada, api token based, siis me saame seda ükskord kirjeldada komponentid al ja siis meetodid al linnkida sellele heeder tüübile. Ja ka sellised security schemes, mis defineerib ära autentimis info, näiteks, et see meetod peab kasutama api võtit ja tal peab olema mingit teatud lugemise ja kirjutamise õigused, seda meetod läbi välja kutsuda. Ja siis peab kasutama speciaalised api võtit, mille on nii lugemise ja kui kirjutamise õigused, aga sellised asju saab defineerida open appi speciaalised. Siin on mõned näita skeemadest, et meil on petid ja peti al, meil on mitu võimalust, me defineerime need näidete, me defineerime need näidete, meil võib olla näiteks cat näide ja dog näide, kus cat on, et name on fluffy, pet type on cat, color on white, genderized male ja predispersion cat ja siis koeraal on name on puma ja siis on ka frog, aga frog pool on omakorda viide ja mingile teisele frog näitele, mis on omakorda komponentid al ja me saame sellist linkimist kasutada, kui me soovime mingit asja ainult ükskord kirjeldada ja me ei soovime mitmes kohastakirja. Ja neid näiteid, miks on näiteid kasulikud lihtsalt dokumentatsioonina, et kui luakse uus kas, siis millised väärtused võiks olla ja mis neid väärtuste näiteid, nagu aidata kasutajad, aga neid näiteid saab ka kasutada interaktiivses dokumentatsioonis ja mida ma vasti teile näitan, et see lihtsustab selle appi testimist selles dokumentatsiooni veevi lähele. Ja skeemasboksis defineerib ära sellised väljaad, mis siis nendel olemitel või resurssidel on, et skeemade peal mõtlet, et me defineerime siis need appi resursid, mida need appi metodid modifitseerivad ja kui meil on PET resursina, siis PET on objektyp, eht ta näiteks kas XML või JSON dokument, tal on mingisugused deskriminatoreid, mis põhimiseks ütlevad, mille järgime need paika paneme ja siis tal on väljaad, et properties, väljaad on meil name, mis on string-typ, ja PET-type, mis on string-typ ja väge määram, et name ja PET-type peavad olema. Ja see on ääriskasulik, sest kui me genererime koodi, siis siia koodi genereriteks validaatorid. Ja kui keegi proovib meile saata meie appile JSONi, kus need kahteväärtost ei ole, siis genereritud kood kohe vastab kasutale, et teil on see väärtost puudu. Ja meie ise ei pea implementeerime seda loogikat, et kuidas kasutale vastata, kui need väärtost on puudu. Et näiteks Pythonis kasutatakse bytantic teeki selleks, et valiteerida neid sisse tulevad väärtosti JSONis. Ja TEOks on jälle lihtsam implementeerimine, kunade saate skipida selle ise valiteerimise ja isekoodi kirjutamine valiteerimise jaoks. Ja siis see struktuur peav olema kui siis XMLis või JSONis vastavalt sellele, mis dokumentistruktuuris appi nagu nõuab. Ja security skeemad alve, me märat, et meil on näiteks, kas appi võtikasutuses autentimiseks. Juhu ta on appi võtikasutuses, et kust asub, et ta peab heeteris olema ja mis tüüpi ta on, et ta on tava appi võtti ja mist teema neima vist appi alamb krips ki. See on tegelikult väga halb viis, kui te spanna, et reaalselt paljudele webi raamisti, kelle ei meeldja alamb kripsud heeteriväetust. Minul tekis sellega reaalne probleem, mida ma ei oskanud väga deep-hugida. Koot töötas, kõik töötas väga esti, kui ma kasutasin appi alamb krips kiid heeteriväetusena, aga ma kasutasin reverse proxid, selleks, et kui serverse tuleb päring teatud alamb hostil, siis ma suunan selle edasi tocker konteinerisse, kus asud mina appi ja millegi pärast see ei töötanud. Ja tuli välja, et see reverse proxy kustutas ära kõik heeteriväetust, milles oli alamb krips ees. Et kuna need ei vasta standarditele, et heeteriväetust ei tohiks alamb krips olla, siis minu genereritud koodus ja minu implementeeritud koodus kõik oli okei, aga ngenicsile ei meeldinud, et heeteris on alamb krips ja kustutas selle ära. Ja siis mina pidi teepakima, et kus see viga tuleb, et miks ma autentida ei saa oma appisse ja tuligi välja sellest, sõv käid vastuseda HTTP-appid, et heeteriväetust ei tohiks alamb kripsuga olla. Is ma pidin ngenics konfiguratsiooniselle ära muutma, et lubataks alamb krips. Võib ka siis kasutada OAuth, et me defineerim ära, et me kasutame näiteks ülikooli OAuthi oma appis. Me ütleme, et meil on siis tüüp OAuth 2 ja meil peab olemes Authentimis Flu. Seda me palati üst välja kutsuma. Authentimis Urla asub siin, et see on mingi ülikooli OAuth sisteenus pakkuja. Ja siis määramäärad, mis skoopist on, et seda peab olema sisse. Selle kaudu tagasi saadud objektil, mis käib mingi kasutakoht, et selle kasutale peab olema write-õigused ja read-õigused, et seda OAuth edukas oleks selle metodi haaks. Me saame sõeld, et selle metodi haaks on vaja ainult kirjutamisõiguseid, ma selle metodi haaks on vaja lugemiseõiguseid või vastupit, et teatud metodid jaoks lugemiseõiguseid on vaja, et teise metodid haaks on vaja, et OAuthigaudu saame tagasi, et sellel kasutale on lubatud ka muutusi teha. Ja kuidas me siis kasu saame, et teatud tüüpi generaatorit, teatud veebiraamistikele oskavad seda ise automaatsa teeaks valmis genereerida tee, peab siis implementeerima, et kuidas OAuth 2 autentimis teha. Flaaskissa ei tööta, et kui me Flaaski genereerimist, Flaaski generaator ei oska seda teha, aga fast API generaator oskab neid asju teha. Vähemalt ma olen ise ära testinud API võitmedega, et genereeriteks siis kood, et kuidas API võitmed lugele siis heeterist ja ise ei pea selle pärast väga muretsama. Ma vaatan, kas ma olen veel mitte kära unustusinud. Ja basic auh ka, et kasuta nimijaparool. Ja ma olen seda juba mitu korda mainind, et eksisteerivad mitu generaatorit. Üks on selline KitHubis olev open upi generaator projekt. See toetab väga palju keeli. Serverit saab genererida 15. keeles, klente saab genererida kuni 30. keeles. Seal on ka sellised puhtat klendikoodid nagu JavaScript. Aga tegelikult serveris on ka Node.js teesti olemas. Ja serveris on mitte ainult 15. keelt, aga 15. keelt korda mingi arv webi raamistiket. Näiteks Python jaoks on nii Flask kui ka FastAPI jaova jaoks näiteks Spring. Et genereriteks see koot mingisuguse webi raamistiku jaoks. Ja loodud serveri koot siis näiteks Flask jaoks sisaldab kogu selle serveri koodi skeletoni, kus on puudu näiteks metodete loogike. Selline business loogike on lihtsalt puudu, mille teie peate implementeerim. Kui tuleb get planning, mis listib kõik loomad, kuidas siis anmebasist võtta need loomad ja kuidas saad station genererida on siis teie implementeerida. Aga genereriteks siin lisaks kogu serveri kootile ka selline Dockerfile, nii et seda appid on hästi lihtne ülesseada. Lissalt DockerBuild, DockerRun ja kõik. Selleks saad testida. Dihti seda on vajalik fastapi puhul, sest Windowsis fastapi alati ei tööta, kui te kasutate teatud, kui on vaja teatud teke, mis Windowsis millegi päris ei tööta. Ja lisaks, mis on väga huvito, genereriteks see veepi liides appid dokumenteerimiseks ja testimiseks, mille on umbes sama funksionaasus kui Postmanil. Ja teie appi jaoks genereriteks see teie serveris näiteks slash toks või slash UI, kus all on siis selline interaktiivne dokumentatsioon ja liides, et kui sa appid kasutada. Teie klientide on hästi mugav sinna minna ja proovid appid kasutada enne, kuid need midagi implementeerim hakkavad. Eesik kasutaja või arjendeva peab implementeerima ainult nende rest metodide sisu, näiteks putket, postelit ja need asiga endpointi jaoks. Aga näiteks flaskis peavad ka implementeerima mingisugused autentimis asjad, anmebaasisuhlus asjad ja muut sellised peate tihti ise implementeerima. Teatud tegid võib loskad ka anmebaasi osa ära implementeerida. Sellised anmebaasi ühenudust autentimised integratsioonid ja muud asjad tihti jäävad nagu arendele. Ja on võimalik siis genereeta niis klient kui server, kui serverist tuleb midagi implementeerida, klientid on tavalselt täiesti kasutatavad. Leijate mingisugus keerulise appi ja soovite Pythonis metodeid väljakutsuda, siis saate open appi specijokatsioonipohjal selle Pythoni tegi valmis genereerida, mida teie saate omakoodist väljakutsuda, kui sa Python tee kuskap tolla appiga suhelda ja ütleb teile näiteks Python tasemel, et mis need sisendid metodeidle ja mis need väljundid metodeidle täiks olema. Ja ta on selles mõttes palju lihtsam kasutada, kui mul endal tavasalt meiti ise hahatatab appi metodeid kirjutada, aga kui on keeruline appi, siis on mõnesed palju lihtsam klient genereerida teie teiele vaelikus keeles. Ja neid näitet siis, mis keeled on serveri jaoks toetatud ja mis webi appide. Näiteks Ruby jaaks on siis Sinatra ja Rails 5, raamistikud Python jaaks Fast Appi ja Flask, skaala jaaks on erinad, Akka, Finch, Lagorn, Play ja Scalatra, PHP jaaks näiteks Laraveli, serveri koodi Lumeni, Slim, Silek, Symfoni ja nend on päris erinad Java jaaks, Spring ja MS4, 4J ja Underdough ja jaaks ja CXF ja Inflector ja nii edasi, et Java jaaks on päris palju. F jaaks and 1, K jaaks on mitmed, kolm tükki C plus plus jaaks on ka mitmed ja Häskel jaaks on isegi mõned ja Erlang jaaks on vist üks, puhas Erlang vist lihtsalt, Ada jaaks on ka ilma raamistikud. Node.js on ka lihtsalt Node.js, et ei ole konkreetne Node.js alam raamistikud. Klienti jaaks on rohkem, et näites puhas Java script Type scripti, et kui te teete angularirakenduse ja soovite mingisust apid väljakutsuda, siis saate angulari tegi genererid selle appi jaaks, et kui te edasi angularis selle appi meedad, et väljakutsuda, et tegelikult päris mugav. Et angularist soovite Twilio appid kasutada, saate siis Type script klienti Twilio open appi speksiooni põhjal genererida, siis oma Java koodistis seda Twilio appi teeki kasutada. Tihisteliselt Twilio appi klienti teeki eksisteerib ka Twilio enda kuski GitHubis, aga põhjumistelt selle open appi speksiooni põhjal saada ise selle genererida. Ja lisaks tegib siis sellest muga webi dokumentatsioon, mida saate post mani asemel kasutada, ei pea käsurialt ketja postpäringu tegema, oid saate neid teha läbi selle webi liidese. Ja ta lihtsustab teie klientidele, et kui teie starteapile mingi klientid ja soovite, et näidata, kui saapid kasutada, on väga mugav, nad tegelikult saates jo interaktiivsese dokumentatsioon, et saavad proovida neid. Ja näevad, mis andme tüibid on, saavad, vaadate, mis vastus, et appi kauda tulevad, saavad neid proovida ja seda saab suhtseid hästi kasutada. Näiteks open appi generaatoril endal on webi dokumentatsioon, mis võimalda peal üles laadida oma speksiooni ja kasutada open appi webi appid selleks, et genererida pyütun kood, see pyütun kood allat oma ja kasutada, mis on natuke naljahkes, aga põhimõttel, et open appi generaatoril endal open appi speksiooni ja webi liidese, millega autus saate proovida open appi webi liidese meedlade välja kutsuda. Kui ta klienti koodi genererida appi gen clients või serveri koodi appi gen servers koodi genererida või siis konkreesele keeled, et näiteks appi gen clients, Python flask või Python fast API, peate natuke uurima, mida see language tegelikult tähendab, et seal on mitu. Ja siis kui on genereritud, saate sellel allat oma, et saate vastuseks file ID ja kui see on valmis, siis saate siit kaudusele pyütun sipitud allat oma. Meie praktikumis saate kas seda kasutada või saate lihtsalt üste java teekid övanta meiväenist ja Jarriga otse oma arvutes generereeld seda koodi, et teid peastada webi liidest kasutam, et see on natuke eba muga on seda webi liidest kasutada, kuna te vist ei saa hästi üleslaadida jamli, et see jamli peab kuskil webis olema. Ja siis see vastus näeb välja selline, et ma ei tea, kui hästi see siit näha on. Ja võib-olla nii paremini, et ma saan ka siit nüüd proovida seda väljakutsud, et ma klikin seda post appi Gen Client Language peal ja mulle tekib. Ja ma seal on ka Trynup, ma jahütan seda Trynupu. Pärast seda ma saan hakata parametrit ja sisse panu, et mis see language on. Ja siis siin on ka näite, et mis see vastustavalsed tuleb välja. Ja kui ma jahütan seda Try ja Execute nupu, siis ka reaalselt, tehaks see selle päring läbi. See on nagu postman, kus ma defineerin ära, et mis see päring on. Aga see on nagu postman, mille sisse on ehitatud selle appi jaoks selle collection, et mis need metodid on. Et ei pea isegi ise näid collectioneid looma. Ja näite, vastus on ka see, et see on successful 200 koodi, siis on linked, kus see genereritud kood siis alatõmata. Et see on teine appi metod, mis on alatõmavana. Võib-olla konkreetslem näite on selline, mis me ise oleme loonud, mis on see targa linnan anmebaasja appi, kus ma olen loonud sellise appi targkora, mida üks tudenk implementeeris. Ja seal on selline seadmete halduse metodid, get, boost, device, elite, konkreetne device, get, correctne device, ja siis muuda mingis kus device anmed. Ja siis saab evente sündmusi saata, et näiteks bussivaliteerimis event või auto ära tuvastamis event. Ja sit on nagu hea ülevaade saata, et mis on need resursid, mida hallatakse ja mis on see resursiala metodid. Ja seal on ka kirjeldus, ja kui ma soovin, siis midagi välja kutsuda, siis ma saan proovida sinna post metodi peal teha try. Ja siis saan siia panna selle jason sisendi, mis ma selle metodile saadan. Ja saan execute teha sinne, et see reaalne metod läbi proovida ja saan ka autentimis info sit sisse paned, et näiteks appi võtme, kirutan see sisse, et ta ajutiselt jätab meeld, et mis on selle kasutaja appi võtti selles säsjonis. Ja te ise proovitega seda praktikumis läbi selle raamatute halldusappiga, et milline siis teie dokumentatsioon välja näeb ja saate ka testida seda nii veebi liidesest, kuidas teie raamatud appid kasutada. Lisaks on ka selline Sväger editor, mida te praktikumis saate kasutada, et kui mina annan teile selles spetsiokatsiooni, siis te saate minna selle laadresile editor.sväger.io, pasteida se spetsiokatsiooni siia ja see pool genereriteks teile automaatsot. Ja see on nagu live editor, kus te siin midagi muutate, siin automaatsot midagi muutub. Ja te ühes ülesandes peate nagu ühe metodi juurde tegema ja siis te hakkate siin kirjutama seda, et te näete, et mis siin juhtub. Ta üleal näitab vigasid, et kui teile Jamlis on mingid vead, et see on see hästi mugav viis, kui ta siis nagu listasti kirjutada ja näha, mis ne muudatsud kohe teevad. Ja ka siin näidatakse teile vigasid, et näiteks, kui te siia panete midagi valesti või midagi on puudu, siis punasega natuke näidatakse, et olete valesti teinud. Elmiste aastatel me seda ei kasutanud ja siis tudenki natuke sattusid hättada, et nad ei saanud aru, kun nad Jamlis liiga palju tühikud kasutasid või liiga palju tääbe kasutasid, et siis tekisid väga halvasti tepakitavad probleemiid. Ma loodan, et selles väger editori, kes saab selle palju paremini aru saada. Ma isen olen seda kasutanud, et nullist sellised appi spekikatsioone kirjutada, et haad, et appid on suhtsealt lihtsalt, et lihtsalt saab võtta ühe olemasle lappi näite ja seda ümber kirjutada enda appi jaoks, et suhtsealt lihtsalt saab blokke, kopia, beistida ja asja teha. Ja angi, et selled nädalab praktikumis, siis mis me teeme, me võtame siis minupolt ettevalmistatud open appi spekikatsiooni, kus üks maetod on puudu. Te testite seda, genereerite koodi, panete ta tööle lokaalsalt või tokeriga, kui soovite ja siis vaatate, kuidas ta töötab. Siis te implementeerite selle serveri koodis puudu olevad metodide sisu ja siis ka lähete takas ja lisate appi spekikatsiooni ühe puudu oleva metodi ja genereerite selle koodi uuesti ja teete muudatused läbi. Et te näete, et üks tüütuma asi on see, et kui te spekikatsiooni muudate ja koodi uuesti genereerite, seda mõnes mõttes genereerib sinna kaustaned failid üle. Olge ettevaatlikud, ette oma vanu muudatusi üle ei kirjuta, et te teed kas genereerite mingisse teise kausta ja peate mingisseks mergil läbi tegema, et kuidas ta oma varem loodad koodi nagu tagasi vite, et kuidas asendab need failid ära. Olge sellega ettevaatlikud. Praktikum juhendis on selle kohta ka sellene punane tekstet. Ja siis järgmine kord hakkame rääkima siis pilvetehnoloogiast ja praktikumise hakkame natuke asure ja pilvetehnoseid kasutama, millel ilgipäästates oma ülikoolikonto ka. Loodatavasti ei ole kõik oma krediidi elmises semestrid arra kasutand. Elmne kevad on okei, et asures, kui teil on ülikooli tudenegi kontost, te saad iga aasta uuendada seda uue kredidi. Aga nad kalb, on kui pool aasta tagasi kasutasid ära, siis on nad kalb. Aga õnneks me kasutama ainult, me peamiselt kasutama tasutateenuseid ja on teised viisid, kuidas ilgipääst saada ka. Aga eks me vaatama. Ja see ongi tänasüks kõik. Kas kelegi on küsimusi? Põhimiselt teeme täpselt sama asja praktikums läbimise elmnekord ja te saate oma elmise korra koodi kasutada, et ei pea loogikat nullist uuest ehitama, aga te peate natuke ümber tegema sellest. Sisendid ja väljundid on natuke täist sugused võib-al täiste nimedega natuke, aga põhimatselt kogu loogika, raamatu allatõmpavis loogika on sama, raamatu otsingu loogika on sama. Ja tõna vähem kõik asjad on samamoodi nagu elmist praksist ja lihtsalt genererite serveri koodi ja siis täidata need lüngad elmise praktikumi lahendustega. Aga see ongi siis tänasüks kõik. Tänan, tänan.

---------Loeng 7 Pilvetehnoloogia.txt--------

 Tere tulemas 7. loengusse. Tänna alustame pilvetehnoloogideemaga. Järgmised loengud ja praktikumid hakkavad olema mõnes vaate pilvetehnoloogideemaks seotud. Me jätkame appide teemadega, et me pihamised praktikumides kasutame oma restappi raamatute halduse rakendust. Aga me nüüd hakkame seda pilves üles jadma, hiljem hakkame seda konteneeriseerima ja siis lõpupoole panemada täiesti pilve põhise rakendus. Mis kasutab ainult pilvetehnoloogid ja natuke arendame seda edasi ja hiljem teeme ka selliseks väikesteks mitmeks mikrotenuseks, et siis ei ole enam selline mono-liidne rakendus, mis jookseb vaid kasutab erinevaid pilveteenuseid. Aga täna siis tutvustame pilvetehnoloogid, et osa teist võib-olla on võtnud ka seda pilvetehnoloogia ained, nii et see tänane loengu on enam vähem, sava, midame siel pilvetehnoloogia aines, katame esimeses kolmes loengus lihtsalt selline rohkem koncentreeritud ja mitte nii sügavalt. Et mis on pilvetehnoloogia? Üks hästi hästi vana definitsioon, mis ei defineerinud pilvetehnoloogidega, rääks lihtsalt arvutesresurssides, oli üks arpaneti rajajaid Leonard Kleinrockii selline sõnastus. Arpaneti oli siis see võrg, mis eksisteeris enne interneti ja mis arenes põhimistet internetiks üle. Selle, toegi 1999. aastal oli siis praeguse seisugana arvuti võrgud alles lapsa kingades, kui nende kasvades ja kerukamaks muutudes näeme tõenalselt nii nimetatud arvuti kui komunaal teenuse levikut, kus sanase praeguse elektriatelefoni teenusega teenindavad koduside kontraid kõikjale üle riigi. Ja midas tähendab komunaal teenus see, et kasutate mingisugust teenuste, siis kuul lõpus maksate sellest. Kas ta on mahu põhine, et näiteks vastalt kasutatud elektri mahul, et maksate või ta on pigem nagu selline subscription põhin, et tänapäeval telefoni teenused väga ei ole mahu põhis, seda on lihtsalt, et maksate kindla hinna ja siis saate kindla arvud, kindla mahu teenuseid, mida selle kuul jooksul võitte kasutada, aga lõpude lõpuks iga kuul maksate enamäeva sama hinna sellest. Aga idee on siis, et saate lihtsalt subscription stiilis teenused kasutada ja maksate kuul lõpus sellende teenuste mahu või mingisuguse ette otsustatud teenuse mahu eest ja siis ise saate sellest mahus kasutada isegi kui te kogu mahtu ära ei kasuta, siis ikkagi maksata sellest. Nii et idee on siis sama, et ei peaks enam arvudusresurssid kasutamiseks, ei pea ise nagu serverid üles eadma, vaid saate lihtsalt minna teenuspakkusele ühelt, et ma tahan nii palju arvudusresursse ja siis ma, tema ütleb, et kuus maksate nii palju ja siis saate neid kasutada. Natuke modernise definition, Kartneril toon, et pilveteenusid on tehnoloogia, kus massiiliselt skaleeritavad IT-resursse, IT-teenuseid pakutateks see teenusena interetikaudu paljudele välistele klentideled. Kui meil on näiteks haapetse keskus siin instituudis, siis kas see on pilvetehnoloogia või mitte? Tegelikult on. Kui teie vaatad, et tegelikult pakutakse tudejängitele, teadlastele, et on sisemistele, klentitele nii-öelda, aga tegelikult haapetse resursid on kasutuses ka kogu Eesti vaates, et eksisteerib selline etais, veepi liides, mille kaudusavad firmad näiteks, kas või Tartu linnavalitsus tulla, ülessead oma virtuaalmasinad ja maksad Tartu ülikoli sellest, et jooksutatakse virtuaalmasinad meie instituudi haapetse keskuses. Aga põhimiselt see suurem fookus on üst, et on masillises ka eritavad, et ei ole lihtsalt mingisugune firma pakub paarile oma klendile, neid IT-teenuseid, võid pakutakse suurele hulgale välistele klentidele siis IT-ressursse teenusena. Ja mida ma mõtlen teenuse al, siin ongi see, et saab lihtsalt seda teenust kasutada ja siis hiljem saad arve ja maksad sellest. Jah, siin saad minna asuresse ja võtta. Jah, sa saad ka, et kui sa teed seda Tudengina, siis on natuke teised reeglid, et siis ei eeldatad, et Tudeng maksab sellest, võid pigem, kui sa oma Tudengi kontoga sisse logid, siis mis juhtub on, sinu, kes küsid, sinna taad näiteks, et ma soovin virtuaalmasinad, siis küsiteks sinu, kes on sinu jühendaja ja siis jühendaja peab ütlema jah, ja siis juhend jõudab jah, siis institut maksab, et see on sellised sisemised reeglid, agu sa teed näiteks kontu oma ID-kardiga. Sa tead täiesti isikliku kontu, mitte ülikoolikonto ja siis sa saad defineerid seal krediitkaard ja muud info ja saad sellest maksta. Ja ta tuleb tõenalised mingi kolm-nelikorda odavam, kui näiteks Amazonis virtuaalmasinad jooksutada. Lissalt sa ei saa kõiki neid teenused, mis on Amazonis või Arsures kättesaadavad, et põhimõtteliselt infrastructure teenuse, virtuaalmasinad saad jooksutada, kuberneetest saad jooksutada, sellist aks saad jooksutada. Ja pilve teenuseb selline väga üldine definitsioon. Minu arvatus ongi see, et lihtsalt arvutesressurside pakkumine mahu põhiste teenustena. Arvutesressursid võidad väga erinevad asjad olla. Meie räägime täna pigem virtuaalmasinatest, konteineritest, teie praktikumist kakasutate virtuaalmasinad, aga lõpude lõpuks on see üks, kõik, mille pilve teenuse pakka teilt rahakak küsima. Näiteks allatõmmatud anmed mahu eest. Kui teie seate üles virtuaalmasinas oma rakenduse, mis on näiteks pildi kaleri ja kliendid välismaalt või Eestist hakkavad teie rakendust kasutama, siis teie ei maksa ainult virtuaalmasine jooksutamisest, vaid Amazonille peate maksmakamaga iga terapaidiest, mida kliendid teie piltte allatõmbavad. Nii et selline anmed allatõmbamise hind on ka tavaliselt üleslaadimise hinda ei ole, et pilve teenuse pakku, et hea meelega võtavad teie anmed ja hakkavad teie kas küsima hoiustamise tasu või allatõmbamise tasu ja teevad sellise lõksu, et ta võid üks kõik, kui palju anmed üleslaadida, üleslaadimisest ei maksa, aga hoiustamisest hakkata maksma ja allatõmbamisest hakkata maksma. Et seal on väga erinevad need resursid, mis lõpude lõpuks võib olla maksustatavad. Aga idea on, et need saab kasutada, kui komunaal teenuste, nad sarvaselt veel elektriale kaasile mobiil paketideled te lihtsalt kuul lõpus maksate. Ja milline see täpselt see hinastamise mudel on, on hästi hästi erinev vastavalt erinevata resursidele, et ei ole, sest üks ühtselt lihtsalt mudelid, et ma maksaan minutiest või ma maksaan tunniest, teatud olukord, et sa maksate millisekunditeest või millisekund mälu alokeerimise eest või siis teatud olukorras maksate näiteks. Kõikide appi päringute eest, mis on rohkem kui üks miljon kuus näiteks ja siis hakkata iga miljoni päringu eest maksma näiteks. Nende avalike pilvede Riistvara asub seist siigesuurtes anmekeskustes. See on selled ötva, et mida suuremad anmekeskuse tehitada, seda odaavam on nagu arvutusresurside in tühiko kohta. Kui on väike anmekeskus, siis sul on vajab vähemalt ühte administraatorit, aga suunamise administraatorese võib-olla üks administraatore saab halata kaks korda rohkem resursse läbi automatiseerimise ja muude tööristad. Samut, et kui väike firma läheb ostaab hiigel suura arvu mingisuguseid serveri kettaid, siis väike firma võib-olla ostaab tuhat, aga Amazon ostaab läks miljon, et ta saab läbi selle mahu odavama hinna küsida. Suuremad anmekeskuste ehitamine on ühiko kohta odaavam, kui väikest anmekeskuste ehitamine. Aga tänapäeval anmekeskus on veel ja suured pilveteenuse pakkujate oot kohalik anmekeskuste ka koostud, et rendiivad nende, kes resursse, mida pakuvad oma klientidela. Ja klendid saavad pilveteenuses suvaalisele hetke resursse juurde küsida, niimoodi, et nende resurssidele ligi pääsemine on pikkem sekundite või minutite küsimus, et keegi ei pea kellekele e-maili saadma või telefonideel resursse juurde küsima, et kõik on läbi hapid automatiseeritav, et te saate lihtsalt oma püütan programmis kirjutada käsumis näiteks teie enda rakendusele küsiblise resursse juurde. Et kui teil mingil vaadust tekik selle jaoks. Ja pilveteenuses kasvasid välja sellistest arvutus klastritest ja kriididest, et varasemalt näiteks Tartu Ülikoolis oli arvutus klaster kusagil, kunnik arvutid, mis jöhendati üheks klastriks, kusai töid, niimoodi saab mitteida, et jooksutada mingisugusid arvutusi. Aga mingihet 90-tadatel hakkasid tekima sellist arvutus kriidid, kus mitmaorganisatsiooni sellist klastrit hakkati kokku liitma suurematest kriidid. Et kui näiteks Tartu Ülikooli teadlastel oli vaja teha mingit teadustööd, mis nõudis rohkem resursse, kui ühel ülikoolil oli, siis oli võimalik kasutada ülikoolide vahelist kriide, kus näiteks Tartu, Tallinna, Helsingi, Läti ülikoolid arvutid olid ühendatud selliseks suureks kriidid, kus igal öel oli omad klastrid, aga sai töid üleslaadidata tööde järekorda näiteks mingi pilditöötlus rakendused näiteks, kus tööd jakkagi. Tõkki, et kriidid jagati tükkideks ja näiteks tükkit jagati erinevate kriidid vahel ära, siis kriidid jagasid erinevate klastrite vahel ära ja klastrite jagasid erinevate arvutujude vahel ära ja tegisid sellised suured kriidid arvutused. Minge etk sai populaarseks, et hakkame siis välistele klientidele pakkuma teenust utiliidina, et tekisid sellise serverite rentimise keskkonade, et oli firma, kes tahtis oma PHP serverid ülesseada, siis ta ei pidand oma serverid ostma, vaid sai webi serveri lihtsalt rentida endale ja hakkas tegime niimoodi, et sai rentida webi serverid ja nendest maksta ja see oligi selline algus pilve tehnoloogiole põhimatsud. Kuigi need firmaad olid väiksed, kes seda pakkusid, et on teonud hiigel suured veel, oli võimalik seda suvalistele firmadel niimoodi lihtsalt rentima hakata. Sest mingi etk tekisid rakendused, mis olid ainult webi põhised, et kui meil oli varasemalt näiteks mingisuguna meili klient, mida ma oma süle arvutis või arvutis installeerisime, siis mingi etk hakkasid tekime selle Google meili sarnased läbi browseri kasutatavad rakendused. Enne seda oli pigem browserid lihtsalt webi lehtedavaatamiseks, aga mingi etk hakkasid kõik rakendused lihtsalt kolima browseri kaodu kasutatavateks, webi rakendusteks, webi teenusteks ja tekisid selline tarkvaratenuse na rakendused, et tänapäeval te saate Wordi kasutada oma arvutis installeerituna või saate lihtsalt Office 365 lehegilele minna Wordi kasutada läbi browseri. Tänapäeval on hästi tavaline, et kõik rakendused näiteks Slack, Slacki saate kasutada kas arvutirakenduseana või browserirakenduseana, Zoomi saate kasutada browserirakenduseana arvutirakenduseana, et tänapäeval onki hästi tavaline, et on erinevad versioonid nendest rakendustest, aga selle laale hakkasid tekkima sellised suured, globaalsed webi põhiselt rakendused, nagu Gmail oli üks nendest ja sai tästi populaarseks. Ja nende rakenduste jooksutamise jaoks oli vaja hästi palju arvutus resursse. Ja ta hakkasid tegima vajadus, et kui Gmail ja teised saad hästi populaarseks, siis miljonite inimeste serverimiseks läbi webi teenust oli vaja hästi palju arvutus resursse ja samal ajal näiteks tekisid need Amazon webi poed, kus hakkati ka myyma, koupa miljonitele, kümnetele, miljonitele klientidele ja neil oli ka vaja ehita hästi suured arvutusparkid ja Amazon leidis, et nad küll pidid ehitama hästi suure arvutus. Arvutusparkid näiteks selleks, et pühad ajal müüa raamatud, aga väljas palju pühased oli näi hästi palju arvutus resursse vabad. Öösel oli hästi palju arvutus resursse vabad. Siis nad proovisid hakkata neid välja rentima selleks, et rahateenida ja tekisid selleks esimised pilveplatformid, kus suur firmar nagu Amazon hakkasid oma arvutus resursse lihtsalt kolmandatele, klientidele asutustele siis müüma või rentima ja selleks kassasidki väljas selleks pilvetehnoloogiaplatformid. Googleil oli ka sellised igasugused veepindekseerimise klastrid ehitatud ja nendelt hakkas ka mingi hetk tekis lihtsalt mõte, et samamoodi nagu Amazon rendime ka oma arvutus resursse väljalise teenime raha nendest, kun nad hetkeljale kasutused. Siin hakkasid tekima sellised suuremahulised arvutused, siin hakkasid olema selline arvutus resursse teemahupõhinarvelta su tiilite arvutustes. Tarkkuvara teenustena siin hakkasid tekima hästi palju sellised globaalselt rakendused, mida inimesed üle maailma said kasutada läbi browserite, mis vajasid rohkemiseks back-end teenuseid, mis jookses kusagil pilves. Täname jooksud kogu loogika inimeste arvutis ja pilvede analoogis tegisid sellised suured andmekeskused, tegis selline vajadus automaatses ka leerimise ja automatiseerimise vastu, mida suuremaks sellised rakendused kasvasid. Esimised suured pilved olidki Amazon oli üks nendest 2006 aastal ja tänu nende webi poodid ja populaarse kasvule näil tekis väga suur vajadus arvutusriistvara järgi ja ne tegisid suuri klastrat selle jaoks. Ja siis mingi, et kakkasid pakkuma välja arvutusresursse ja hakkasid lihtsalt rentima virtuaalmasinaid, et sai siis Amazonist rentida virtuaalmasinaid infrastruktuuri kui teenusena. Ja põhimiselt täpselt saam moodi nagu varasemalt olid need webi serverid, mida sai oma PHP rakenduste või anmebasid jooksutamist kasutada. Amazonist saa moodi. Ja üks suuremalt vahesid oli see, et kui webi serverides valmistati ette teile selline virtuaalmasine või virtuaalkeskond, kus oli teatud PHP versioon, teatud MySQL versioon olemas, et teie saite seda asutusena natuke konfide kasutada, siis Amazon pigemandis teile kogu virtuaalmasina ja teie saite virtuaalmasina seees üks kõik mida teha. Ja saite ise installeerida, saite ise valida operatsioonisisteemi ja pigem hakkasid nagu asutuse, asutused hakkasid ise aldama need virtuaalmasinaid. Ja virtuaaliseerimine oligi selline põhi pilvetehnoloogiat võimaldav tehnoloogia, et selleks, et üldse oleks pilvetehnoloogia võimalik, pidi virtuaaliseerimine arenema piisavalt, et oleks võimalik suhtselt efektiiselt jagada üks suur server väikesteks virtuaalmasinataks ja need väikset virtuaalmasinat siis välja rentida. Meil oli vaja mingit serveri riistvara, selle peal tavaliselt oli mingisugun operatsioonisisteem ja mingi hästi lihtne Linux, selle peale mingisugune virtuaaliseeria, kes tegeleb siis virtuaalmasinata loomisega ja kui meil on siis klendid, kes soovivad teatud suurlusiga virtuaalmasinad, siis iga ühe jaksab ülesseada nagu virtuaalmasinat täpselt samuti nagu teie operatsioonisisteemid ainees näiteks tekite. Lissalt idee on, et meil on suuremad serverid ja me tekitame klendidele täpselt nii suured virtuaalmasinad, kui nema on valmis maksma nende eest ja klendid siis jooksatada oma rakendust nende sees. Miks virtuaaliseerimin on tähtis? Pilveteenus pakkuajatele, et see võimalatab pakkuda sellest isoleeritud keskkonda kasute rakendusteaks, et kui üks firma virtuaalmasin jooksab siin teise firma virtuaalmasinakõrval, et siis näil oleks täiesti oma operatsioonisisteem. Et kui operatsioonisisteemisees on mingisugune paki või võimalus nagu midagi katki teha või nagu põhimõttel hakkida, siis ei ole võimalik lihtsalt rakendustel teise virtuaalmasinaga midagi teise virtuaalmasinasees midagi katki teha. Ja virtuaalmasinast võimaldasid väga rangelt paikapa nagu palju resursse sellele virtuaalmasinale anda, kui palju mälu, kui palju ketaruumi, kui palju CPU-aega või tuumasid. Ja see võimaldas nagu pakkuda rangelt isoleeritud ja väljalõigat, nagu virtuaalmasinat mahujärgi, et kui palju mälu ja kui palju CPU-t anda siis sellele virtuaalmasinale. Ja alguses need virtuaalmasinate ja virtuaaliseerijade olnud väga efektiivset. Et tegelikult oli aeglasem jooksutada rakendusi virtuaalmasinatesees, kui ilma virtuaalmasinateta, nii et oli selline natukene efektiisem jooksutada ostse Ristvarabe rakendusi, aga tänapäeval koos pilvetehnoloogia arenguga on see virtuaaliseerimise tehnoloogia väga palju edasi liikunud, et palju efektiisem on tänapäeval kui varasemalt. Kui teie operatsioonisisteemis kasutatud virtuaalboksi, siis te ka näed, et susteda aeglased jooksevad natukene rakendusi virtuaalboksiese, aga kui te kasutaksite virtuaalboksi asemeks Senni v. KVM, siis see jookseks palju efektiivsemal. Ja tänapäeval te pigem kasutate, näiteks, VSL-i, et jooksutate virtuaalmasinat omal sülarutite peal ja tegelikult see jookseb sama efektiivselt, kui teie enda Windows. Ja teil põhimõtsed Windowsid võib ka vaadalita tänapäeval kui virtuaalmasinat, mis jooksub teie läpakal VSL-i peal või VSL-i kõrval, nii olnud, teise virtuaalmasinana. Tänapäeval kui te jooksutate VSL-iga Windowsid ja Linuxid sama aegselt, siis Linux ei jookse Windowsi see, ta jookseb Windowsi kõrval. Ja ma vaatan, kes ma midagi äraunustasin. Neid lahendusin paljusid. Tänapäeval on hästi populaarsed konteinerid, et oma korda vähendada seda vajadust, et igal virtuaalmasinalla oleks oma koop ja operatsioonisüsteemist. Sest kui te kujutad et, et meil on hästi suur riistvara ja sest riistvara peal jooksab 16 virtuaalmasinat, siis tegelikult 16 operatsioonisüsteemi koop ja jooksutamine on suhtsealt epäefektiivne. Tänapäeval kui ei ole väga ranged vajadust täielikku isoleerimesi ja oks virtuaalmasinatega, siis pigema mõistlik mitut rakendust jooksutada samas Linux operatsioonisüsteemis konteinerid. Ja siis järgmine nädal räägime pigem konteinerid, et enam konteinerid väga palju ei puuduta. Räägime sellest, et ta on lihtsalt sarane virtuaaliseerimisele, aga mitte sama ja järgmine nädal siis ma räägin täpsemal, et mis need erinevast on ja siis võib-olla saate aru, et kui erinevad need on. Mina ei nimetaks konteinerid üldse virtuaaliseerimiseks, kui ki nad on natuke sarane. Natuke sarane lähenemine. Aga virtuaaliseerimise motivatsioon oligi, et võimalikult efektiivselt pakkuda siis pilvetehnoloogia teenuseid ja üldse, et kui me virtuaalmasinat kasut, sõle võtame, et see olks efektiivne. Et kui meil Amazonis näiteks olid alakasutatud riist- või tarkvararesursid, et mõned serverid ei ole kasutatavad või mõned rakendused ainult kasutavad ära pool serveri võimsusest, siis me võime sinna samase serverisse tekitada lihtsalt kaks virtuaalmasinat ja ühe väljarentida, et saame siis neid resursse, mida hetkel ei kasutata, välja rentida siis ja lisad rahaa või lihtsalt neid riistvaraa efektiisemud kasutada. Ja virtualiseerime lihtsalt hakkakeskondade kohandamist rakenduste jaoks, et me saame iga rakenduse jaoks tekitada täpselt selle keskkonna, mis on vaja. Mondade rakendustel Windowsi, mõndade rakendustel Linuxi, erinead jaava versioonid, erinead tüütan versioonid, et me saame keskkonna valmistada ette rakendusele täpselt sellise vaja, et igas virtuaalmasinas võib täiesti erinev tarkvarajoosta erinead versioonid ja kohandada seda väga hästi. Lihtsam oli ka valmist tehtud virtuaalse keskkondi teisaldada ja taas kasutada, et me saime näiteks ette valmistada virtuaalmasina, kus oli kõik vajalik PHP ja MySQL-i jooksutamiseks ja sellest lihtsalt iga kord, kui uus virtuaalmasin vaja on, luua, et peha sellest lihtsalt koopjad. Teha virtuaalmasin valmis, mis kus kõik vajalik on olemas ja salvestada sellest snapshoti failina ja me saame nüüd sellest failist teha koopjad nii palju, kui meil vaja on, et me ei pea uuesti instaleerima, me ei pea skripti jooksutama, me saame lihtsalt selle virtuaalmasinam valmist teha ja teha sellest virtuaalmasinakettast põhimõttelselt koopja ja pärast seda teha sellest koopjast 16 koopjad, et 16 virtuaalmasinad jooksutada ja näid virtuaalmasinakoopjad on ka lihtne, et paillina teise serverisse ületösta või koopjad ülevõrgu, et saab lihtsalt saavmoodi, nagu teie koopjad teise faili, kahe masina vahel saab ka virtuaalmasinad koopjada. Ja tänapäev võib teha ka virtuaalmasinate live koopjad niimoodi, et te näiteks, et teil jooksub virtuaalmasin, te soovite selle virtuaalmasinast nüüd jooksutada selle tarkvarakaks korda suuremas virtuaalmasinas. Mis sa teha, on teha sellest ketast snapshot, teha sellest mälust snapshot, liikutada need failid ja mälukoopja teise arvutisse või näiteks suurema virtuaalmasina peale, et konfigureerida sellele kaks korda rohkem mälu, kaks korda rohkem CPU-d ja kui see on valmis ja jooksuma, siis lihtsalt switchida liiklus sellest virtuaalmasinast sellesse ja see virtuaalmasin, nagu seisuma panne, et on võimalik lihtsalt sellist live migreerimist teha, et virtuaalmasin suuremaks muuta, et see on ka HPC-s meil ja Amazonist võimalik, et saate lihtsalt oma virtuaalmasina peal parem kliki teha ja ühelt, et ma soovin suurendada näid resursse, mille peal see virtuaalmasin jooksub, et näiteks soovit oma SQL-annebaasi teha kaks korda suuremaks. Ja lihtsalt teab ka haldust, et me saame nagu arvuti riistvara välja vahetada, et kui me vahetame siin mingi riistvara komponeti välja, siis need virtuaalmasinad ei pea sellest mitte midagi teadmasest. Nendejaks on nagu riistvaraidseadmed virtualiseeritud. Nema teavad, et neil on mingi võrku kaart, nema teavad, et neil on mingi tüüpi ketas, mida nad saad kasutada, aga kui realne füüsilne ketas välja vahetadaks ja annmedes koope liigutataks üles, siis nendejaks ei muutu mitte midagi. On suustse et lihtsam siin riistvarelisi muudatusi teha või virtuaalmasinad täiesti teise riistvara peale üleliigutada, kui midagi riistvaraga juhtub, et on lihtsam, kui ei pea väga muretsema selle pärast. Te võid isega märgata, et kui te näiteks oma kodu arvutis liiga palju riistvar ära muudatus, Windows hakkab teie vastu võitlama ja teie licentsi ei ole enam palidne, et te liiga palju riistvar ära muudnud. Sellist asju pilves muidugi juhtu, aga idea on sama, et me ei pea muretsema väga sellest, kui riistvara välja asjadatakse. Ta on ka turvalisem, sest me saame eraldada rakendused suhtsevalt rangel, üksteisest pannes nad erinevtes virtuaalmasinades jooksma, sest kõik nende operatsioonis isemised anme struktuurid on erinevad. Isekõiku rakendusele õnestub kui kärnelis mingisugust mitte lubatud koodi jooksutada, siis selle koodi kaudume ei saa ligipääsu teise virtuaalmasinas oleva rakendusmäel. Kui siin rakendusele õnestub ligipääsata mingitele mäelualadele, siis need mälualad on rangemalte eraldatud üksteisest kui samas füüsilises masinas ja on võimalik kaitsta rakenduse üksteise eest. Ja kui üks rakendus hakkab tohutult palju näiteks, määlu võrku kasutamas on võimalik virtualiseerimised tasemel panna limiid, et kuid palju sellel virtuaalmasinad on lubatud võrku pännvitti kasutada. Samu asi on ka konteinerides võimalik teha, et saate limiteerida, et üks konteiner saab ainult teatud mahus võrkuliiklust ära kasutada ja siis ta ei hakkab teisi nagu ülekoorma, kui ta liiga palju võrku kasutab. Konteinerid, millest ma räägin, see järgmine nädal on kergema kaalullisemad, saab otse kasutada operatsioonisüsteemi kernelit ja meil ei ole vaja eraldi virtuaalmasinad iga konteiner jaoks, et pigem kasutatakse täpselt sama kernelid ja siis isoleeriteks kernelid tasemel kaks rakendust üksteisest ära ja ei lubata üksteise resursse kasutada, aga ei teki sinna sellest põhimaselt nende operatsioonisüsteemide kooppead ja kernelite kooppead, vaid kasutatakse üste sama Linux operatsioonisüsteemi kõigi samas ristvaras, samas arvutise oksvate konteinerid teha. Selleks kasutatakse Linux nimeruume ja muid sellised Linux kernelse sisse ei teadud võimalusi, et konteinerid üksteisest isoleerida ja see, mis on täpselt nimeruumid ja mis need tehnoloogid sille kasutused, sellest räägime konteinerite lohingus. Konteinerid on kiirem ülesseada kui virtuaalmasinad, sest me ei pea kopeerima virtuaalmasinad, me ei pea puutima virtuaalmasinad ja operatsioonisüsteemisest. See kernel juba jooks, jahe paneme lihtsalt uue protsassi samas Linuxist tööle lihtsalt kõvasti kiirem kui virtuaalmasinad ja loomina. Jõudlus võib olla lähetasem tavaservele jõudlusele, kui virtuaalmasinad ja puhul sest tegelikult ei ole sellest virtuaaliseerimise kisti ristvara ja konteineris jooksad protsassi vahel ja konteineris jooksad protsassid on lihtsalt tegelikult Linux protsassid ja näitse konteineriseerine väga palju ei mõjuta, kui just valesti ole konfigureeritud liiga vähe resurssele antud protsassile. Ja eksisteerid väga erinevat konteinerid raamistikult, ei tõenest ootet tokerid kasutanud, kuigi tänapäeval toker on pigem nagu liides konteiner-D peal, kui ta ise ei implementeeri enam konteineride loomist, vaid see on afrahritud ära konteiner-D tarkvarasse ja toker isa nagu kasutaja liides võimalt oliselt tänapäeval kui konteineriseerimise implementatsioon. Kui me kasutame siis virtuaalmasinaid, kui me kasutame konteinerid, sest suur vahe on selles, et meil on mingis künn server, meil on vaja ühte operatsioonisüsteemi selleks, et hallata nagu Riisvara-haldust. See võib-olo on natuke erinev type-1 virtualiseerimeses, kus type-1 virtualiseerija ise mängib operatsioonisüsteemi siin, et sellise lihule eraldi operatsioonisüsteemi siin ei ole vaja, et eksisterev kahta tüpvi hypervisoreid, ehk virtualiseerijaid. Kui näiteks võrtaalboxi kasutateks, siis teil on server, ningisugune Linux operatsioonisüsteem või Windows operatsioonisüsteem ja siis näiteks võrtaalbox siin. Aga näiteks KVMI puhul teil seda ei ole niimoodi, et teil ei ole eraldi operatsioonisüsteemi vaja. Ega virtuaalmasina jaoks on meil on eraldi virtuaalmasina operatsioonisüsteem ja siis iga rakenduse jaoks meil on oma koopa näiteks Java tarkvarast ja siis see meie rakendus, mis jookseb selle Java virtuaalmasinas ja mingid Java tegid on selli juures. Kui me kasutame konteenereid, siis meil on samuti server, seal peale on mingisugune Linux operatsioonisüsteem. Tavalliselt me jooksutame selleks tockerit, et hallata virtuaalmasinaid, aga tocker ei ole nagu kiht riistvara ja konteenerite vahel. Me jooksutame näiteks kahte konteenerit või ütleme, me jooksutame kuute konteenerid siin. Kaks on ühtedupi konteener, mis kasutavad kõik näiteks mingit upuntu konteener imidžit ja nelj on siin, mis kasutavad näiteks mingi Alpine, ma ei tea mingid Python imidžit ja see vahe on see, et meil ei ole iga konteener jaoks eralte operatsioonisüsteemi vaja, nad kõik jagavad seda sama Linux kernelid, neil on omal on koopi onendest tarkku arast, mis seal konteenereid peab jooksuma, näiteks kui nad vajavad Java virtuaalmasinad võib mingit Python 3.9 teekke selleks, aga see vahe on ka selles, et kui meil virtuaalmasinad iga rakenduse jaoks peaks olema oma koopi ja nendest Java teekidest, siis konteenerite puhul, nend konteenerid saavad neid teekke jagada oma vahel ja nendest ei pea olema nelja konteeneri jaoks nelj koopjat, vaid nad on niialda read only koopjat, kus tarkkvara lihtsalt loeb neid faile ja ei muuda neid failed, neid vahepeas, et konteener kiht ei tohi nagu muuta, aga ma räägin sellest, siis konteenerite luangust natuk rohkem. Et siis konteenerite puhul saab jagada operatsioonisisteemi ja saab jagada kõik neid vahepeaset faile, mida konteenerite vahele ei muudeta. Sellised üks veel definitsioon pilvetehnoloogekoht on Amerikast NISTist, mis on siis National Institute of Standards and Technology, nemad defineerivad pilvetehnoloogi mitte nagu sellise tekstilse definitsioonina vaid omaadustena, et pilvetehnoloogial, pilveplatformidel peab olema täiellik ise teenindus, peab olema laia ulatuslik interneti ligipäe, peab olema arvutusressursside koondamine, peab olema kiire lastus ja peab olema selline mõõdetav mahu põhine kasutus. Et mida siis tähendab ise teenindus on põhimist, et suvalisel ajal peab olema võimalik lendil arvutusressursse tellida, nagu isegi automatiseeritud viisil, ilma, et peaks suhtlama sellel teenuse pakkuja töötajatega. Võimest on ise teenindus, lähete ise valite, mida soovite ja tellite ja maksata nende. Ja ressurssidele saab ligi siis jooksvalt, nii et kohegu on vajasate ligi ja tünaamiliselt, et ei pea ette tellima või pea nagu kaua ootama enne, kui saada vastus. Kui te sellite mingisugust, näiteks, sellite 100 uud GPU-virtualmasinat, et saate kohe vastuseks, kas on võimalik või mitte. Võib-olla Amazon ütleb, et selles regioonis ei ole nii palju virtuaalmasinaid, virtuaalmasinate tüüppe, kus on GPU-d, et siis peab te valima mingi teise regioni, aga ta saate nagu vastusek koheselt. Te saate ka ligipäesu koheselt, ei ole kasutusel selline inimene inimest liidest, et ei pea telefoni või e-maili kasutuma. Siin on mõned agad, kui te teete uue Amazon konto näiteks oma start-upile, siis tavalselt teil on alguses limiteeritud, et teil on lubatud näiteks kuni 100 virtuaalmasinat korraga jooksutada. Selleks, et saaksid üle 100 kasutada korraga, et peate saad ma e-mailik. Et teatud asjad on ikkagi sellise inimene inimese liidesega, et teatud ästi kallid virtuaalmasinate tüübide, ei ole teile aktiveeritud või virtuaalmasinat arve ei ole teile aktiveeritud. Et see on siis kaitsta selle vastu, et kui keegi varastad näidis krediitkaart ja proovib mingi Bitcoin mainimist teha pilves, et see oleks siis limiteeritud ja oleeks ikkagi mingi sukune filter, kes ülekontrolliib, et kui mingi konto tahab kasutada hästi palju resursset, nad siis kontrollivad üle, et kas näile anda lisaresursse ja mitte. Aga pigem on kasutada selline inimene pilveplatform, ehk inimene appi või tarkvarve pilveplatform, ehk tarkvarve appi läheneemine, et te saate ise, määteks Ansible-is konfigureerid, et ma soovin uud virtuaalmasinat, mille konfiguratsioon on see ja panna selle tööle ühe Ansible käsu jooksutamisega ja kohetegib teile virtuaalmasin ja Ansible Command vastab teile näiteks siip agressiga, et kus see virtuaalmasinat siis jookseb, et saab siis ära automatiseerida uute resursside rentimise, uute resursside küsimise ja nende ümber konfigureerimise ka, et saate need kreal ajas mingi käsure ja käsuga, appi käsuga ümber konfigureerid, et mis on teie virtuaalmasina suurust, et kus see vaja oleks, et teoreetselt saaksid ise oma rakkenduse seest küsida oma rakkendusele rohkem resursse. Ja tavalsest on kasutal suhtselt suur kontrolli resurssid üle, aga see alati oleneb, millist pilvetehnoloogia mudelite kasutate, kui te rendite virtuaalmasinat, siis te saate ise valita operatsioonisisteemi, saate ise valita operatsioonisisteemi versiooni, saate ise installeerida operatsioonisisteemi sisse, mis iganeste tahate, saate täis root õiguset sinna Linux virtuaalmasinasse ja kui kokematta ümber konfigureerite võrgu konfiguratsiooni, mis keelab interneti likkus ära, siis te enam ligisle saa. Et teil on lubaga kõik katti teha võimõtsalt, kui te administreerite seda alvasti. Ja kõiki siis resurssid hankimist on võimalik automatiseerid appi kaudu. Et siis see siis defineerib selle ise teeninduse omaduse pilvetehnoloogite jaoks. Teine omadus oli laia ulatuslik ligi peas üle interneti, et need resurssid, mida te üles jätte peaks olema kasutatavad siis üle võrgu ja üks kõik kust alati on mingisugud limitatsioonid, et te saate kõik kinni pannat ei taha, et kõik oleks ligi peasatav. Aga põhjavõtsalt kõik peaks olema kasutatav, siis üle võrgu ei toeks olla vahe, et mis siiaadmattel te kasutata need resursse, kas on browser, mobiiltelefoneid või tahval arutud ja nii edasi. Ja kõik peaks olema appi kaudu juhitav ja et saaksid näiteks ligi peasu anda või keelata ligi peasu teadud regioonidest või teadud IP adressidelt üle appi, siis et saate defineerida, et nüüd peks port 80 kinni olema või nüüd peks port 80 lahti olema. Kolmas omandus ongi selline resursside koondamine, et pilved platform peaks pakkuma võimalust hästi palju resursse kasutada, et nendel on alati suur klientitarv ja tavaselt ehitatakse sinna, kus näiteks on oda elektri ind, näiteks soome, üks suuremaid super arutid on lumii, mis ei teadud soome just selleks, et ta oleks ühe elektri aama lähedal ja et ta oleks kohas, kus on hästi palju vett ja talvel hea, madal temperatuur, et oda vahe natuke jahutada. Ja kui ühest nagu anmekeskusti piisa, siis saab jagada klientirakenduse anmeid mitmed anmekeskuste vahele, et suuremalt teenust pakkada on hästi palju anmekeskuseid. Mul peakski üks pilt selle kohta olema. Järgmineomadus on kiire elastus, et idea on siis selles, et lisaks sellel, et Amazon saab müüa vastavalt vajaduse resursse, kui neil tekib vaburesurssejuurde, siis täpselt samuti teil, kui klientil peaks olema võimalik resurssejuurde võtta ja eemaldada vastavalt vajadusele, et kesed ööd, kui teil klient ei ole, siis võiks olla võimalus resursse vähendada, et siin oksutate väiksemad virtuaalmasinad, vii oksutate vähem virtuaalmasinaid ja te saaksite oma resursside kasutust ja selle ka rahakokkada, et te saaksite võimalik kasutada resursse täpselt siis, kui vaja ja siis, kui teil öösele ei ole, vaja näiteks, teil on mingisugune office rakendus, teil tööta ja töösele ei ole, et te saaksite põhimised kõik virtuaalmasinad kinni panna ja sellest siis mitte maksta, kui te öösele kasutate vähem resursse. Ja ta peaks võimaldama siis järgmineomaduse kasutada, et te teusuke hakka mõn saada, et saate kasutada vähem resursse, et te teiseks teiseks teiseks teiseks teiseks teiseks Otam derenes하하, et polvist vähem meie pas um Mrs Gold Knapp features. Ja me järrias kus teiste emalisele kasutamisele, me saasameunun huhalt manumustز verdutuni. It الأ kass stained monoma selle threatened ja schedules, ta on andis m takie ilmi toolkit kuhijunahim enuCan袋el, me ma aastudissions nebías, see on teile lihtsam tupp kus kui on näha, et korra ka tuleb hästi veel kasutada, et ei rakendust kasutama. Mida võiks siis ka näiteks Eesti riigisüsteemides rohkem kasutada, kui mingisuguse avalduste tegemise ja omikul kogu systemioks kokku, kuna inimes tootavad seda hetki, kunis avaneb. Tegel tegelikult Eestil on ka oma riigi pelv, mis võimalitab kuperneetest ja virtuaalmasineet niimoodi skaleerida. Ja teile kui klientile teoreetiliselt on olemas olete resursside maht näiliselt lõpmatu. Teie praktiku, mis näete, et see ole niimoodi, sest meie kasutame kõige matala prioriteetsema, et tasuta resursse põhimest tasures ja meie võime suusselt kiiresti jooksta mingi limiidiootsa, et selles regioonis, mida me proovime kasutada, tudenkitel enam ei ole resursse ja peate mingid regiooni switchima. Puhtel tõttel, et meie kasutame tasuta resursse, aga tasuliste resursside maht võiks näha kasutatele kui lõpmatu, et kui teil on vaja lihtsalt Amazonist 100 või 1000 virtuaalmasineet juurde küsida, siis firma jaoks see peaks olema võimalik. Et on masiiselt skaleeritavad resursid klientide jaoks. Ja viiman on siis mõõdetav mahu põhine kasutus, et kui teie kasutatad, siis pilvetenuseid, siis te peaksite saama väga konkreetse nagu tagasi side selle kohta, et kui palju teate resursse kasutan, kui palju see maks malle heb, et asutusel peaks olema võimalik siis analyysida, et kus nad kasutasid liiga palju resursse, mille eest nad täpselt maksid ja et teile oleks võimalik ette enustada, et kui nüüd jääregmine kuu tuleb viiskorda rohkem kasuta, et minu rakendust kasutame, et kas see läheb siis viiskorda rohkem maksma või kolmkorda rohkem maksma, et palju see rohkem maksma läheb. Et kõik teenused, mida te kasutatad, need pead olema täpselt mõõdetud, et kas sa olnudki siis mingi prozessori aeg, mida virtuaalmasineet kasutasid, kas on salvestusruumi maht mingis aja ühikus, mis on tüüppiliselt suhtsilt suur aja ühiked kuus, et interneti riba laius, kui paljude mingit bandwidth jäära kasutate, kui paljude kuus almeid alla tõmbate või isegi mitte teie tõmbate või teie klientid tõmbavad teie pilve kontost almeid alla. Ja tavalselt on need monitoringud, mis tegelevad just nende mahu kauntimise ja arvetetegemisega on suhtsilt keeruliselt. Ja ka erinead mudelid, mida kasutatakse hinastamisel, võivad olla suhtsilt keeruliselt. Samas te saate tavalselt ligipäesu pilve teenustele ilma ette maksuta, palju teenused on ka tasuta, et te saate näiteks mingi prototybi Amazoni või Asuresse ülesseada ilma nagu maksimata isegi ja teil on tihti sellised mingisugust väikse koodad, et te võitte kuus nii palju appi päringud teha, te võite kuus viis gigabit unmade hoidapilves, te võite kuus teatsud tunni virtuaalmasid, et jooksutada enne, kui te maksuma pead hakkama. Et tihti saab teatud teenused tasuta kasutada, näiteks Google App Engineis saab jooksutada, püütan hakkasud siis tasuta, aga nüüd võib kasutama krediitkaartid kontot teha, varasemalt sai nii sama ka kontosite ja ilmakrediitkaartita. Heroku on võimalik lihtsalt oma hobi projekte tasuta jooksutada, kui väga palju kasutust neid ei tekita, aga mõned teenused näiteks Asures static website. Mis on mõnesmõttes suhtsalt saarane kit hab website'idele? Mida? Peidses, ja. See on suhtsalt saarane, aga me vaatame seda Asures static website'iga praktikumis, paneme ka lõpuks oma raamatu, haltuse, appile front-tendi tulevikupraktikumis Asures static website üles. Ja te saate nagu kasutama hakkata ja siis pigema hakkata maksma siis, kui te reaase kliendid tulevad ja lähete üle kuoutada, siis kas kuus või päevas. Ja ei tee, nend kliendid pead saama täpse ülevaata kasutusest ja saab kontrollidei aga piirata, et te peate kliendina saama piirata, et näiteks, ku arve läheb üle mingi perioodi või mingi virtuaalmasinate kasutus läheb üle perioodis, pandakse kinnin, et selle, kei saab natuke kaitsta sellise Tenal of Service rünnete kohtad, kui kõik hakkab spämmima teie rakendust, et teie arved siis lõpmatus ei läheks. Ja väga erineva kranu naarsusega arveldas ühikult pilvas, et kunagi olid Amazoni virtuaalmasinate hinnad mingit tolaritunnis, isegi kui te jooksutasite virtuaalmasina üks minut, pidite maksuma ikkagi terve tunni eest. Tänapäevas enam nii ei ole õnneks, et nüüd on ta pike minutites ja virtuaalmasinate eest maksate võib-ale viis minutid miinimum ja siis ikka minutiest. Aga päris palju aastait oli tunnitasu miinimum, nagu Amazoni virtuaalmasinate puhul. Ja pilvefunktsioonid, millest me ka räägime ja mida me ka proovime praktikumis, nende eest te maksate millisekundites, et ku palju mitu millisekundit võtab teie püütan funksiooni käivites pilves ja siis maksate sellest. Ja sellest me räägime kahest tuleviku praktikumis, kus me räägime nanoteenustast. Lisaks on pilve teenuste platformides alati eraldatud keskkonnad, et pilve teenuse pakku, et peavad karanteerium, et kui teie rakendus savestab kui ka andmed, et teine rakendus nendele almatele ligi ei pääse. Kõik andmebaasid, kõik jooksmis keskkonad on üksteiselt eraldatud, kas virtuaalmasinate või konteineride tasemel vähemalt, tavalised virtuaalmasinate tasemel isegi ja ka andmebaasid, kui on isegi hallatud andmebaasid, siis ka seal tehaks eraldi keskkonad, et karanteerid, et teie andme teile legiks mõne teise asutuse rakenduse protsessidele. Ja te võite eeldada, et pilve teenuse pakku ja oskavad efektiisevalt resursse ära kasutada, sest kui teie, kui asutus üles jate mingit virtuaalmasinat, siis teie põhimast olete vastutav nende virtuaalmasinate halduseest, et efektiivselt väljavahetada mingit teekide versioonid näiteks, kui tulevad uued sellised või nende rabilitid välja, et mingisuguna OpenSSL teegis on mingisugune viga, siis teie olete vastutav nende halduseest. Aga kui te annate nende virtuaalmasinate halduse üle pilve teenuse pakku ettele, siis te saate tegelikult eeldada, et nemad ise uuendavad neid versioone, sest kui hiljem tekib probleem, siis teie saate neid näidada, et see oli nende viga, siis nemad on sellest vastutavad ja neil on tohutult palju klientte ja nad peavad olema efektiivset nende resursside kasutamises. Lisak nemad on need, kellel on 10 000 klientid, kes kasutavad neid virtuaalmasinait, neid resursse ja nendel on kõike parem nagu info, mille põhjal nad saavad optimeerida, et kas need ristvaralised resurssid on hästi ära efektiivselt kasutatud ja mitte. Eks neil ole motivatsioon hinda all oida, aga samas on neil ka motivatsioon, et näidatad nende resurssid kasutad kui see on efektiivselt. Nii et. Seal on teatud teatud otsused, mida teil on hiljem vaja teha. Ma räägin sellest ühes teise slide juures rohkem, aga põhimõttel, et te saate valite, kas te ise haldate virtuaalmasinait. Instaleerite siinne näiteks Python 3.9 ja oksudat oma Flask rakendust seal. Võite kasutate platform teenusena, kus pilve teenuse pakkuja ise halda virtuaalmasinait teie aaks ja teie virtuaalmasinait mitte kunagi ei näe. Miks pilve teenuse platforme või pilve teenus ei hakkatud pakkuma enne 2009-2006 aastat oligi see, et enne seda ei ehitatud väga suuri anmekeskuseid. Oli pigem väikselt firmad, kes rentisid välja virtuaalmasinait oma serverite peale ja osjid uusi serverid. Ei ole suurtma staapi, et tõesti pakkuda lõpmatu arv arvutusressurssa klientidele. Internet sai palju laiemaks põhimõttel, et kasutada pilve tehnoloogia, et peab olema võimalik, võimaldada 10-tel miljonitel klientidel üle maailma kasutada, siis virtuaalmasinait, mis jooksevad Amazoni, anmekeskustas, et lihtsalt internet pidi olema piisavalt kiire, et saaks neid tarkkuvarateenusena rakkujendusi, nagu G-Mail kasutada, kus saadatakse videoid ja pilte ükstisel edasi. Ja virtuaaliseerimise tehnoloogia pidi saama küpseks enne, kui oli võimalik virtuaaliseerimist nii kasutada. Aga olid ka ääriliselt tegurid lihtsalt enne seda ei olnud nõudlust arvutusressurssid järgi, nii suurta arvutusressurssid järgi, et pigem kasutatagi ülikoolides neid arvutusressurssid, suuri arvutusi teha näiteks simuleerimisel, aga ei olnud nagu business case selle jaoks. Ja siis tarkkura tehnuste tulekuga siis see muutus põhimõttel. Ja hästi kallis on Anne Keskus tehitamine, et see on tohutult kallis ja lihtsalt kuni tekisid suur firma nagu Google ja Amazon ja Azure ja IBM, siis teistel ei olnudki raha tehitada hiigel suuri Anne Keskused ja ei olnud vajadus kohe selle jaoks. Et pilved siis elavad ka Anne Keskustes ja globaalsete pilvedeinuste serveerimiseks on väga hästi suurt arvutusvõimsust ja eeldab siis üli suurte ja kallite Anne Keskus tehitamist, mis vajavad mitte ainult servereid, võrguk, seadmid ja ketad, vaid ka hooneid, vajavad massiivse jautussüsteemi, süsteemisid ja jaamasid, elektri, et peab olema piisavad elektrit, et see Anne Keskus ära toita nii-öelda. Google näiteks ehite sooma Anne Keskuse vanasse puidutöötlemist tehasesse selle töötud, seal oli hydroelektriaam kõrval, mis kunagi ehitete ainult selle puidu teha seaks põhimõttel. Ja siis Google sai lisaks tehasostmisega, sai ka endale hydroelektriaama põhimõttel ja said seal siis odavad elektrit ja sinna oli oda vehitada. Et need Anne Keskus tehitadeks sinna, kus on hästi odavad elektri ja jahutamine odav ja ka seal, kus on hästi palju päikest näiteks, kus saad päikse jaamase tehitada. Et siin on siis üks näite Google Anne Keskusest pelgas, et siin on siis näite päikese paneelid, et lisa odavad elektrit, toota eraldi elektrijaotuskeskus ainult sellega maja jaaks põhimõttelised. Ja siin on ka maja kõrval, on näha sellised jahutusseadmed, mis on põhimõtteliselt kõrgemad, kui maja ise ja kaks sellist maja, kus hoitakse siis serverid sees. Serverid iset avasid näovad välja sellised, et meil on lihtsalt rida haavad räkid, kus iga server on sellise sahtlina siin sees ja suur osasel üleval onki seotad siis jahutusega, mis on nende räkide peal. Anne Keskusi on täenabal hästi paljusid, et siin on näite siis Amazoni, Facebooki, Google ja Microsofti pea Anne Keskustest. Suurem osanist asuvad siis Põhja-Amerikas ja Euroopas, Aasias on mõned, Lõun-Astraaljasa mõned, aga nende ümber on tegelikult väga palju sellist väiksemad Anne Keskusi, mis lokaalselt pakuvad sellist väiksemadas mahus pilve ja Anne Keskusi teenuseid ja tihti need samad suur firmad kasutavad ka väiksemad Anne Keskusi, mis on teiste kolmaldosa pole partnerite poolt ehitatud. Ja Google on lisaks ehitanud globaalse interneti oma Anne Keskusta vahel, et neil on nagu fiber kaablid üle ookeanide ja nad ühendavad kõik Anne Keskused oma interneti, et nad saaksid seda interneti nagu ainu oma nikuna kasutada ilma, et peaks globaalselt interneti kasutamasest. Kui inimesed youtube videosid vaatavad, et võib-olla selles ka räägime, et natuke rohkem tuleikus. Ja üks mõjutekured, kus pan Anne Keskused on, kui elektrihinn näiteks, et kui Amerikas vaadata, et Idaho osa riigis on elektrihinn 10 centi, kuna seal on hydroset, see on 10 cm, see on 60 cm, et näiteks, et neid on saanud olemas. ongis elektrihinne, et kui Amerikas vaadat, et Idaho osa riigis on elektrihind 10 senti, kuna seal on hydroelektri aamad, siis Kalifornias on sustselt kallis 2,5 korda kallim ja tihti Kalifornias transportiteks elektriit kaugelt ja alati on need ülekandevõrgud piratud, et ei saa lihtsalt ehitada juurde isegi näiteks päikse paneele. Samuti Eestis on probleem ülekandevõimsusega, et ei saa tohutult palju päikse paneele ehitada, kuna võrg ei kanna seda ära, aga näiteks Hawais oleks veel utsam ehitada Anne Keskus, kuna sinna vietakse kütust kohale, selleks, et elektri aamu juoksutada, et laevadega tuvaks, LNG laevadega tuvaks kütust kohale, et kaasiga juoksutada elektri aamasid siin Hawail, et seal oleks veel nelikorda kallim elekter, et juoksutada virtuaalmasi, no, Anne Keskusi. Pige mehi teateks ega jahutuse tottu jõukete lähetale, et saada vett, kasutada, et tartus on ka krenni jahutusjaam ema ja jääres seal tigutorni juures, kus pumbatakse vett jõest ja niikau kui see vesi on kuskil alla kuue kraadi, siis pumbatakse lihtsalt teltasse ja ka täistesse keskustesse nagu vist tasku ja kasutatakse seda maja jahutamiseks, et lihtsalt võetakse jõest kuue või madalama temperatuuriga vett ja siis pumbatakse siia maja, et kui see veetemperatuur on kõrgem kui kus temperatuurine tegis suvel, siis see jahutusjaam ka jahutab seda vett enne, kui see pumbatakse siia maja, et saa moodi saab kasutada jõgede vett, et jahutada siis neid Anne Keskusi, et tegis Soomes või Amerikas. Ja see on kõvasti ota, kui lihtsalt elektrit kasutada jahutamiseks ja see haitab ka nagu balanceerid seda elektri vajadust, kuna saab kasutada sellist jõe energetpõhimiselt madalat energiet. Ja siis on naljakas, et näiteks, teltas me maksame sellest, et me paneme, me genereerime energiad veetoru, et me maksame nagu miinus energiaest, et selle eest, et me paneme energiad veetoru, me maksame, et me ei maksa energi võtmisest, me maksame energi panemisest jahutusveetorrusis. Ja Soomes ka lumisuperarut ei ehitata just selled, et sinna, et seal nodaam jahutumine ja energi. Ja pilve-Anme töötlus või no, ütleme, et Anne Keskusi kokku siis tegelikult tarpijad väga palju energet juba, et aasta energetarpimine erineate uuringute hinna, kui 2018 oli kuskil 200 teravati, 2020 oli kuskil 500 teravati ja 2020 samal ajal ainult üheksa riiki oma energetarpimisest kasutus rohkem kui 500 teravati, et pilvede hõrli nagu 10 riksis. Kuigi nüüd te võite natuke uurid, et teelasest Praeg on see kõvasti suurem, aga samas võite kuurida näiteks palju Bitcoini mainimine kasutab energet või Bitcoini nertvord küldse, et tegelikult on suhtselt sarna pilve-Anme Keskusite tarpimisele kokku, et nii palju kui see Bitcoini isekasutab. Et 2022, no tegelikult oli natuke vähem, aga 2022 oli see 200 teravati aastasest, mis oli samamist kogu Anne Keskusid 2018. Ja nüüd on see, võib ka sa kõrge malla. Aga tegelikult pilve-tehnoloogi nüüd kasutab rohkem kui Bitcoin. Kuigi Bitcoin on lihtsalt üks rakendus põhimastult. Suurime Anne Keskus paltiku, mis näb selline välja. See on siis Green Energy Data Center, mis on... Mis veel nagu väga suuri ei ole, et meil on ostukeskused, mis on suuramad. Ja selle kogu võimsus on siis 31 megawatti energi kasutust. Meie majas on Suurime Anne Keskus selline, mis on, mida olete näinud kindlasti. Tartutu ülikoolis on kaks Anne Keskusid, üks siin ja üks lochi tänavale. Tegelikult saab tohutult palju arvutusresursse rääkides ära mahutuda. See on küll väike tuba. Ei näe suur tuba välja, aga tegelikult kogu vajaduse mahutab siin ära. Meil on veel ruumi ülegi, et siia veel juurdu panna. Pilve-tehnoloogite kasutusel võtuga on ka asjad natuke muutunud rakendustarenduses. Nüüd on lihtsam, sest lihtsalt rakenduse prototüüpide ülespanna. Ja skaleerida siis, kui kasutajad jäsku tuleb. Enam ei pea nagu nii palju ette mõtlema, et palju me serverid ostame oma start-up jaaks. Võib-al mõned ostame testimiseaks, aga oma rakenduse valmis saame, siis paname pigem pilve ja siis peame mõtlema selle peale, et kas meil rahastust on, et seda skaleerida, kui ka reaalselt klendid meile tulevad. Meil peab olema mingi rahastus valmis selleks, et skaleerida, aga põhjelist me ei pea nagu ette ostma palju arvutusresursse või servereid, et skaleerida oma start-upi rakendust, kui mingisuguse ürituse tõttu aga pästi peal klendite korra aga tulemad. Kui me ehitame selle hästi, siis meil on pilves võimalik seda automaatsa skaleerida vastavalt vajadusele. Me saame ka lihtsalt, kui meil on mingisugust ajutised ülesand, et see oli suhtselt vanar rakendus, aga 280. aastal oli New York Times pidi konverteerima kõik oma artiklit PDF-formaatiat, neid arhiweerida ja nad arvutused, et neil võtakse 7 nädalat aega, et kõik oma 11 miljonit dokumenti PDF-ideks genereerida, kui nad seda oma serverite peal teevad. Aga kui nad lähevad Amazonia, võtavad korra aga kasutusse 100 virtuaalmasinad, siis sa võtasid neid 24 tundi, need said 49 korda kiiremini selle tehtud siis, kui et proovid oma serverite peal teha. Ja tegelikult ei olegi vahed, kas me kasutame kahte virtuaalmasinad 7 nädalat või 100 virtuaalmasinad, üks päev see hinn tuleb meil tõenastat sama Amazonis. Et kas me kasutame vähe virtuaalmasinad rohkem aega või palju virtuaalmasinad sama aega, et ma maksam ikkagi kokkus oma hinna. Meil on tegelikult suhtel odav teha asju kiiresti, kui meil see vajadus tekib, et me ei pea sellest rohkem maksma. Aga kui meil seda tegiksime oma serverite peal, siis me peaksime nagu serverid juurde ostma, et seda kiiremini teha, aga pilves on me lihtsalt maksame rohkem lühjaajaliselt, aga ülepikaajase tasu võib täpselt sama olla. Ja on väga tavalne, et meil on rakendused sellised, et öösel meil on vähem kasutajad, päeval on meil rohkem kasutajad ja kui me oma serverid ostame, siis me teame neid, planeerime niimoodi, et nende maksimum võimsuse palju kõrgem, kui kogu aeg need vaja on, või isegi maksimum vaja on. Aga kui me teame, et nädala keskel meil on nii palju kasutajad, siis me peame ikkagi planeerime natukele rohkem, et igaks juugs, kui tuleb rohkem kasutajad. Ja siis kogu see hall alla on tegelikult ära raisatud vajatus ja see on ka üks põhjus, miks ammas on hakkas pilveteenuseid pakkum, et saada müüa seda halli aega virtuaalmasinate välja. Aga siis pilves me saame kasutada need resursse niimoodi, et me öösel võtame resursside mahtu vähemaks, kasutame väiksemad virtuaalmasinad või kasutame vähem virtuaalmasinad või üldselt paneme teatud virtuaalmasinad kinni ja ei kasuta neid, kui vajadust ei ole. Kui me seda ei teeks, kui me kasutaks sellist lähenevist, siis meil tekivad teatud riskid. Kui me hakkame oma rakenduseks planeerima, et kuid palju meil, siis serverid vaja on, et see vajadust ärakatta, siis meil tekib näiteks üle varustamise oht. Kui me liiga palju serverid ostame ja me kunagi nii pea ära ei kasuta, siis see kogu lisaa resurssid on meil kulu, mida me ära ei kasuta, et me lihtsalt raskesime liiga palju roha ära ja me lihtsalt viskesime rahaa mineva. Või vastupidi, et kui meil on ala varustamine ja meil tegelikult kasutus on rohke, kui me vaja on, siis meil tekivad probleemid, sest mis siis juhtub, näiteks teatud aegad ja kesed päeva, meil on liiga palju klente, siis klendi kokemus hakkab halvaks minema, et sellase med nad saaksid kohemeeja rakenduseld vastuse hakkab nende päringute aeglustuma, et nad saavad poole sekundi või kahe sekundi kolme sekundi pikused vastus, et sellase med kohevastus saada. Ja siis, mis meil juhtub, me võime mõnesmõttes selle ka arvestada, et me saame siis vähem rahaa klentidelt, kui osa klente ei saa meil rakendus kasutada, aga meil on potentsiaal, et meie rakendusele oleks nii palju klente, mis tegelikult juhtub, on need klendid, kellele ei meeld, et meie rakendus on aegle lahkuma ja meie rakendust enam ei kasuta, et meie selline kasutad arv väheneb ja võib-olla ongi vastavalt meie resursside mahule, mis mõnesmõttes on okei, et me saame siis normaalse kasutakokemusega rakenduse, aga siis me kaotasime osa klente, kes meie rakendust muidu oleks kasutanud. Sest see ei ole niimoodi, et ainult nendele klentidele, kes siia halli alasse kulud, on halb kasutus mugavus, või kõigil on halb kasutus mugavus samal ajal, kui need klentid arv on kõvasti rohkem, kui meie rakendus hakkama saab. Siin muidu, kui me saame ka Riisvara juurda osta, ka selle peab aega, enne, et pilves me saame lihtsalt uue virtuaalmasine jooksutada, virtuaalmasine suuris äravahetada ja me saame näku dünaamiliselt ja elastselt vastavalt vajadusele resursse siin muuta. Ja üks asja, mida ma mainisin enne, oli ka see, et suurte anmekeskust eidamine oda on, kui väikest anmekeskust eidamine. Oli ka üks vanemuuring 2008-mis suuris, et palju maksma läks erinevate suurlust anmekeskust eidamine. Ja nemad leidsid, et kui me on keskmise suurse ka anmekeskused versus hästi suured anmekeskused, siis võrgu riistvarraostmine võib olla kuni 7 korda odavam hästi suurtas anmekeskustes saamoodi administreerimine, et kui suurtas anmekeskustes on 1000 serveri kohta, siis väiksemates võib olla 140 serveri kohta, üksad minn. Ja nende palgatasu väga erine võib-olla, et 7 korda efektiise olaks alati, et kui 7 korda efektiise olaks admin sellistes anmekeskustes. Kui ta on huvitatud, siis slideid lõpus peaks olemas viide sellel arktiklile, kui ei ole, siis küsige minu käest, et kui soovitid selle kohta rohkem teada. See on sama, mis ma jätan natuke vahele. Unne see slide vist oli juba, mul otsin seda jemaldada. Pilve tehnoloogia kasutamisel on sellist kolm ästi kõrgetasemist mudelid, mis ei ole väga tehnilised. Meil on tarkkora teenusena läheneimed, kus meil lõp kasutavad, kasutavad mingisugust veebi rakendust, mis ooksab pilves. Nemad ei näe virtual masinatest midagi. Nemad kasutavad lihtsalt neid pilverakendusi, nagi tegist Gmail või Slack üle browseri või Office 365. Ja ülejäänud kaks mudelid, mis siin on, on platformasaservice ja infrastruktusaservice, on pigem selle, aga sa tehitada neid tarkkora teenusena rakendusi. Meie koma praktikumis ehitame lõpuks, aine lõpuks, selle raamatu haldustarkkora täiesti saas teenusena ja paneme selle üles. Täna oleme pigem rääkinud infrastruktuuri kui teenusena, et me rendime põhimeselt arvudustresursi otsa välja klientidele virtuaal masinatena või konteineritena. Ja need tüüpi pilved on näiteks Amazon Elastic Cloud või VMware Cloud või Azure Cloud, et kus klientid saavad lihtsalt rentide virtuaalmasineid. Aga vahepeal on ka sellised kõrgemataaseme võimaluselt platformasaservice, mis on siis ei vaja virtuaalmasineta haldust ja selledõttu on targetitud rohkem sellist arvendat jaoks, et teie saaks seda lihtsalt püütan rakendus üleslaadida, kas teil on vajadust virtuaalmasineid halata. Et siis tekitatakse nende sanaste ja teiste teenuspakujate poolt, sellise specialiseeritud keskkonad veebi rakenduste ülesseadmiseks. Ehk üks esimesi oli Heroku, aga on ka OpenShift, mis põhimest on kuberneetes IBM selline flavor. Aga ka Cloud Foundry ja Flynn on mõned teised ja tegelikult Docker ka kasvas väljub eest platformasaservice pilve projektist. Järgmise enam peamiselt siis vaatame, kas ta platformasaserviceid. Jah, aga ei prugi. Heroku, kus hakkad hindasid võrdlema Amazoniga, Heroku on nagu kaks-kolm korda kaljim. Aga sa põhimõtteliselt sulle ei ole vaja võib-olla administraatorit. Sa võib-olla ei pea maksma alla tõmmatud andmet eest. Sul hakkavad sellised nagu erinevad hinnastamis modelid olema, et kas sa maksad Amazonile iga liigutuse eest või sa saad Heroku keskuutasu ja maksad kuutasu. Aga sa pead ikkagi arvestama, et kui sina haldad kõik optimeerid kõike võib-olla Amazoni on ta Adamkui Heroku. Aga sa tead üks ühele võrdlus, et Heroku konteiner vs. sama suur virtuaalmasin, siis Amazon tavaselt on kaks-kolm korda oda. Üks põhjas on ka see, et Heroku ei ole oma infrastruktuuri. Heroku jooksutab oma asja Amazonis virtuaalmasin. Aga see ongi põhimõtteliselt platformaservice omadus, et seda jooksutab siin infrastruktuuri peal, aga pakutakse nagu sellist mugavan platform, et sa saad lihtsalt oma püütan hakkab sa üleslaadida ja ei pea haldama virtuaalmasinad. Tarkvarateenuse ongi, et me kasutame mingit tarkvara, mis jooksab pilvees üle browseri, ei nõua klientidel mingit tarkvara installeerimist, lihtsalt läheb släki veebilehele ja hakkad kasutama seda ja teiste pilveteenuste mudelit eesmerk ongi sellised asju nagu ehitada. Üks näite on Gmail, mis Google avalikustas 2004 aastal, et pärast seda ei pidanud enam installeerima e-maili rakenduse oma arvutisse. Palju teil on e-maili arvutirakendus oma sülearvutus? Teoski käis üles. Telefonis saaks ka läbi browseris, aga siis see integratsioon ja sõnumite teavituste saad mene võib-olla nii tealseti töötat. Aga jaa, üks käsi tõusis üles. Mina isega enam väga ei kasutam, ma kikem kasutan browserist, Office-it. Nii, mõned ka kasutavad seda, et võtavad Gmaili kasutusel ja siis suunavad kõik oma outlooki e-maili Gmaili ja siis tegib mingi saasside oma vahelne selline tõmbamene ja see on ka natuke uuitu. Aga see idee tekki siis Google töötajatele, et näil jäi üle 300 Pentium 3 arvutid, pärast seda, kun nad upgradeid oma tööarvutid ja mõtlesid, milleks seda tööarvuteid hakata kasutama. Ja ehitasid sellise webi põesi e-maili klendi, et saaks browserist seda kasutama, ja kasutasid seda alguses Google'is ees, aga siis leidsid, et see oli päris hea rakendus ja hakkasid seda välja pakkuma. Tänusena väljas pool, et alguses oli see siia maanensad täiesti tasuline, aga alguses ei saanud lihtsalt kontot teha, nad hakkasid välja saadma kutseid, niimoodi, et saadsid tuhandele ajakirjanikule ja teistele kutsed ja iga kutse saaja, sai edasi saada kaks-kolm kutsed oma sõpradele ja niimoodi saakas laienema. See oli ka selled tõtted, et nad ei tahtud korra ka, nagu miljonit inimesed saad, et nad asi üleaja inimesed aru kasvaks, et see on hea selline ramped up testing, et järjest rohkem kasutajad, aga see elab üle. Ja keegi hakkasid seib e-base samal ajal müüma need kutseid, et saad 150 dollariest minu kutse endale ja siis saad ka seda proovida, et see oli selline trajal. See oli üks selline esimesi täielike tarkvaradeenuse na rakendusi. Aga tänapäeval saab lihtsalt Office 365 kvit ja kasutada, et võördi muuta või slide teha, mina ka slide dihtid on seal, aga näites, kui ma tahan slide'idel futterid muuta või teatud funksionaalsus lihtsalt ei tööta Office 365-el ja ma pean mõni kord allatõmbama, muutma ära, et suuesti üleslaudima, mis on natuke tüutu. Kuigi sisse on nähitatud ka võördi integratioonet, nagu saad lihtsalt avada selle faili ja automaatselt salvestab Office 365-e. See on lisavõimalused, et kui te teete endale Excel tabeli 365-es, kui te kasutate Excelit oma arutis, te saate makrosid kirjutada. Aga nagu Webi Excelist te saate automaatselid päesti kui teha, et kui mingisugune väärtus muutub tabelis, saada need anmed anmebaasi. Ta saada sellist asju teha, et sa saaksid isegi frontendi oma anmebaasile teha, et mis iganes te oma selles Google Sheetsis muudate, et anmebaasis muudateks nad almed ära. Et sellised automaatselt integratioone saab siis teha, mis on nagu lisavõimalused, mida nagu väga ei saa teha. No, nende makrotte põhjal te saate teha, aga nende ei saa igavaseks tööle jäeta ja nende ei ole nagu veebist kätte saadavad. Saate ka teha vastupide, et kui anmebaasis midagi muutub, et see muutub teie nagu selles Google Sheetsis ka, et te saate sellist asju nagu teha sellest. Nende on ka mõnesmõttel sellised Webi platformide elised, et saab sellised automaatselt anmeti integratioone luo sellel. Infrastruktuur teenusele sellest, ma tänal olen päris palju rääkind, on siis virtuaalmasinate ja konteeenerite rentimine üle interneti. Meie hapete sees on siis kasutusile OpenStack vabatarkkora selle jaoks. Kui teie olete mõnes aines kasutand etaisid, siis etaisi tagapeidus on OpenStack, kus etais on nagu Webi liides OpenStacki peal, mida teie OpenStacki liides te tegelikult ei näe, aga pilvetehnoloogi aines on kasutamasida OpenStacki otsa. Ja ammas on edsel kaks ongi üks nendest infrastruktuuriteenuse pakkujate. Meie praktikumis kasutavad pigem asured, kuna te saate oma ülikolekonto ka asurele ligi ja saate krediti sealt. Sealt saab kasutada kaks väikset virtuaalmasinavad või hiigel suuri virtuaalmasinavad GPU-tega, et te võite ise uurida asures, et mis on kõige kallim virtuaalmasinahind. Ja see on peameselt mõeldud ka hästi suurte ketastega virtuaalmasinata loomisega loomiseks andmebaasidega, et teil on võimalus võtta kõige kallim virtuaalmasin ja siinna panna 50 kuhus hästi kallid Webi ketast juurde, kus iga ketas võib maksta 2000 eurad kus. Ja te võite leidak, et selline kõige kallim virtuaalmasin, mida saad ehitada on ühe Betabyte ketta ruumiga virtuaalmasin, mis läheb kuskil 100-150 000 eurad kus maksma. Ja kui keegi tahab mingi hiigel suureskul ennebaasie ehitada, siis saaks Betabyte-se ennebaasie ehitada, aga see on mõnuselt kallis. Ja mis seal saab teha, seal saab monitorida oma resursse, seal saab koormust jagata virtuaalmasinata vahel, seal saab automaatsed panna virtuaalmasinat skaleerima, et kui näiteks keskmine CPU kasutus virtuaalmasinat, see on rohkem kui 60%, panna üks virtuaalmasin juurde, kui on matalam kui 10% võta üks virtuaalmasinama maha, et saab selleid automaatsed skaleerimist seal konfigureerida. Ja see on üks kõige laialdasemalt kasutata platform, isegi Euroopas kasutatakse seda rohkem kui mingit Euroopa pilvasid. Kuigi Asura vist nüüd ehitab suurt sellist Euroopaspezifilist pilve just Euroopa riikide jaoks, kus karanteeriteks, et annmed ei liigu Euroopast välja. Nüüd midagi, millest ma täna väga ei rääkinud, ongi platform, teenusena, mis ongi mõeldud sellise täis platformina veepirakenduste jaoks. Kui saate üles oma pyütoni rakenduse, mitse te peate virtuaalmasinat haldama? Sellase mitte saate minna ja küsida Amazonist või Googlilt pyüton keskkonna, öelda, et kus teie rakendus asub kitis ja teenuspakku tõmbab teie rakenduse kitis talla panab tööle ja teie maksad sellest, et ta jooksad. Teie peate võib-olla requirements-faili tekitamad, kus on kõik tegid, mis pead olla meistale eritud, aga see on ka põhimest kõik. Ja selle me käe mängimööse tulevikupraktikumis läbi, mitte veel selles nädalas, aga põhimestalt see võimaldeb siis automatiseerida kitis asuvate rakendust ülesseadmist, aga te ei pea kiti kasutamada, saate ka mänuaalsalt pushida koodi üles. Aga põhimestalt see teed pakkuse tegitab teile pyüton keskkonna ja jääva keskkonna, mis iganes keskkona, mis on vajalik webi rakenduste jaoks ja saab lihtsalt vahel jäta kogu selle virtuaalmasinatehalduse konfigureerimise paketid uuendamise, et näiteks ei peab pyüton keskkonna ise uuendama, vaid uuendadaks selle teie jaoks. See võib vähendada esialgselt kulusid, et ei pea nagu aega kulutama näiteks virtuaalmasinat ülesseadmiseks ja sellised, kui ressursside kasutus on väike, siis ta võib alvuselt odavam, aga hiljem võib palju-palju kallimaks minna eriti herokku puhul. Sinna on sisseheitatud skaleeritavus, et ei pea isegi isemõtlemat, kuidas ma panen virtuaalmasinat skaleerima, et saate lihtsalt öelda, et viimum virtuaalmasinatel konteeleerit arvan 1, maksimum 50. Ja siis vastavalt vajadusele, et skaleeriteks seda teie jaoks, et panaks saad lihtsalt keskkondi juurde ja agatakse sisse tula päringud nende keskkondadevahel ära. Et ihti on näite integreeritud teiste pilvedenuste ja anmebaasidega, et saate suhtsalt lihtsalt oma püütun koodist agat anmed hoidma näiteks Google File Storages või Google mänest SQL anmebaasis või kasutada Google loginid, selleks, et kontrollide, kas Googli kasutaan Google e-mailiga sisselogind ja mitte. Et ei piisegi tihti Google App Engineis ei piisegi tihti kasutate paroolide haldamise pärast muretsama, et kasutate lihtsalt Google kontosid ja kõik. Et saate vahel jäta püütanis sisselogimise implementeerimise põhimõtsult. Ja näited ongi, et Heroku oli üks esimesi. Google App Engine sai väga populaarseks. Me ka kasutasime seda ainetes, aga mingi hetk pandi kinni, et enam ei saanud tasutada ilma krediitkaardida kontot teha, et nüüd peab krediitkaardi kasutama. Aga saab ikkagi tasutada kasutada, lihtsalt peab krediitkaardi ka autentimete ole tunikaalne kasutaja. Ja põhimise teemaldab sellise RISD ja Tarkku raja ostmisevalimise, konfigureerimise haldamise keerukuse ja virtuaalmasinote haldamise keerukuse. Azure staatised webileid on üks näite. Ta ei ole kõige parem näite, sest seal puudub selline tünaamiline keskkond, kus te jooksutate koodi nagu püütanid või PHP koodi. Ta väga sarna neid kitha peidjidega. Et lihtsalt avaselt jooksutate seal HTML javaskripti. Mitte seige jooksutat seal või klientid tõmbavad selle alla ja jooksutavad seda oma browseris. Et ta võimaldaab sellist HTML javaskriptidelehte sit luua tasuta. Et Azure staatised webileid ei maksava midagi, sarna selt kitha peidjile, et kuna tegelikult ei ole vaja mingit serverid seal taga, siis on selline pigem frontend keskkond. Ja et asuta isiklikuks kasutamiseks, vist võite peate maksmagu te asutse, aga muidu saate ise et asutakasutada. Google App Engine on selline huvita keskkond, mis pakub täiesti valmis platformi, aesti paljude pilveteenaloogete ka integreeritud keskkondaseläks oma rakendus luua. Rakenduse on lihtne ehitada, hooltada ja skaleerida. Pole vaja ise halata servereid, toetav palju set keeli nagu pyütuni ava PHP, aga tänapäeva saab platformides tavaselt kasutatakaad Docker-konteineri, et isepalmistata keskkond. Kui te kasutate pyüton keskkondade, siis nõmad valmistavad teile pyüton keskkondette, aga kui teil on vaja mingit speciaalsed pyüton keskkond, kus on mingit pilditöötrus, teegid, mis vajavad mingit speciaalsed teeg, mida ei ole väga kerg installeerida, siis võib olla saada ise selle Dockeris üles. Ja tal on ette konfigureeritud integraatsioon teiste teenustega. See tähendab seda, et kui te soovite kasutada pyüton App Engineis üleslaadu ja pyüton akendus anme baasi, te ei pea konfigureerida anme baasi. Pea üleslaaduma anme baasi teenust, te ei pea konfigureerida anme baasi, pääsu teenuse autentimis infot, vaid te oma rakendusest importite Google anme baasi appi, hakkad seda kasutama ja taustal loodi connection nende vahel, automaalselt genereerite teile kredentialid ja põhjumast, põhjumast, see on huvita viis, et te ei pea nagu mitte midagi tegema, et näiteks Google User Authentication appid kasutada või Google Database appid kasutada, et kõik teaks nagu vett ära. Ja ta on automaalsest skaleeritav ja kui on mitu kope teie rakendusest, siis lihtsalt kasutateks ka 3. autorit selleks, et jagada sisse tuleb liiklus siis kõikide replikaatide vahel automaalselt ära, et te ei piisagi mulleksama sellest, et kuidas ma skaleerin oma rakendust, kui te ehitate Flask rakenduses, et te tegime, et Flask rakenduses on automaalsest skaleeritav ja põhjums kõik. Ja nad tekitavad teile sellise konteneriseeritud keskkonna, kus eraldatakse siis protsessid ükst esit ära, et minimaalselt sellist eraldatast pakud, et mitte nii tugev kui virtuallmasinata puhul, aga piisav tavaldat. Ja see näeb välja minupalt ilustreeritana selliselt, et teile pakutakse keskkonda, kui saate sissepanna oma rakenduse, selle rakenduse seesta saaksite hakkata näiteks otsa kasutama uuse rauf appid ilmaseda konfigureerimata, cloud file storage appid ilmaseda konfigureerimata, SQL anmebaasi ilma, et te peaksid ütlema, kus sa anmebaas asub, et need info panakse teile ette, nagu valmis ette konfigureerituks, et teie rakendus lihtsalt peab need appid importime kasutama hakkama. Ja teed teete sisse valmis oma rakenduse näiteks Pythonis, panetas selle kitti ja Google App Engineis ütlete, kus sa kitta asub, kus ta peaks koodi tõmbama ja kus selle tööle panema, ja lõpuks lihtsalt jookseb niimoodi ja iga kord, kui kittis kood muutub, siis Google App Engine saab isegi automaaltselt tõmmata selle muudetud koodi ja tõsta sinna ja pana tööle. See oli selline enne, kui sellised continuous integration and continuous deployment sai populaarseks, et pilvetenoloogid pakkusid seda nagu automaaltselt tavalsed enne hõbasada. Ja platforma sa platform teenusena nende pilve ja pilve ja muudelie elis ongi see, et ise ei pea enam halda, ma madalataseme resursse, teenuseid, virtuaalmasinaid, võrgukonfiguratsioone, palju teenused on nagu kasutamiseks valmis, ilma üles jaatmise konfigureerimete, aga see on pigenud. Google pilves asures tavaselt peab ise natukene rohkem tegema, natuke ise rohkem konfigureerima. Teenus pakku ise huolisib enam mittefunktsioonaalisete nõueteest, et kunas ka leeruda ja te saate et ihtiseda konfigureerida, aga selle minimum konfiguratsioon on olemas, et ta pakkub sellist automaaltselt tõrked aluvust, minimaalselt latentsust ja teenuse kättesaadavust. Pilveteenuse pakku elab väga hea motivatsioon teile pakkuda võimalikult väigest latentsust. Kes keegi oskab arvata miks? Kui nemad skaleerio teerakendust, siis panaks rohkem resursse üles ja teemaksete rohkem nende resurssideest. Kui nemad oiavad täistimadard latentsust, siis see vajab rohkem resursse ja teemaksete rohkem üles. Nene on mõnele võites. Nene ei ole väga nagu sellised tagas hoidlikud nende mittefunktsioonsete nõuete tagamise osas, siis see tegelikult toob näile natuke rohkem rahavõib olla. Aga põhjumõtteliselt see on kõik konfigureeritav. Herokkust ja saate ise märate, et mis on selline 95%... Mis on 5% kõike suuremalt latentsus ja ka päringute keskmine latentsus ja siis vastavalt sellele otsustada, et see on võib-sõrmiseks, et on kõik, et on võib-sõrmiseks lisada uusi konteeleerid või emaldada uusi konteeleerid, et selline 95%-i meetrik on seal. Ja see saab lihtsustada prototüibimist ja rakenduste ülesseadmisesest. On suurselt lihtna lihtsalt panna koot üles kitti seda muutajas automaatsil, seda seataks üles see näidik Google App Engineis või Azure-s teile. Ja teil on põhimõtteliselt lootust, et platformi pakkule on parimad teadmised, teenuse te targpara jooksmiseks, et nemad oskavad näid keskkondi konfigureerida ülesseada hästi, sest nad teevad seda 10 000. kasutate jaoks või vähemalt 10 000. rakenduste jaoks. Ja nemad soovivad, et võimalikult hästi efektiivselt neid resursse ära kasutada selleks, et nad põhimõtteliselt oma rahakoku hoida, aga samas neil on võib-olla motivatsioon, et neid paljusid, neil on motivatsioon, nii et täilt rahe saada, aga samas ka resursse koku hoida ja oma rahakoku hoida, mitte teie rahakoku hoida. Ja siin on üks visuoleltsioon, sellest, et kui te panete oma riistvora üles ja oma rakendus oma riistvora peal, siis te peate holitsema võrguseatmete konfiguratsiooni eest salvestusrumi ketast ostmise, serverit ostmise, mis virtualiseerimste serverite peal ja kas kasutate, mis operatsioonisisteemid seal instaleerite, mis keskonnad ülesseada, kas püütan 3.9 või 3.13, kudas hallatat anmeid, kus neid hoida anmebaasid ülesseada ja siis rakendus ülesseada. Kui te hakkate infrastruktuuriplatsformei kasutama, seda osa asju annate pilveteenuse pakkoele halatad. Nema haldavad siis servereid, salvestusrumi, kettaid, SSD'id, võrguseatmeid ja nemad saavad üles virtualiseerimise, kas on KVM või Xen või VMware või midagi muud. Operatsioonisisteeme on selline, mida te ise valite, ise hallate, ehk põhimisete saate valite, kas on CentOS 9 või U.24 ja saate ise halata kogu selle operatsioonisisteemis isu. Kuigi tihti nemad valmistavad selle baas operatsioonisisteemi koopiehetnaga, tihti saate ka ise sellega, et ta valmistada. Aga ise hallad keskondanmeid ja rakendusi. Kui te need platformi teenosine kasutate, seda annate operatsioonisisteemi hallduse ja keskonna hallduse pilveteenuse pakkoele ette valmistada, aga tihtide saate keskonda ka ise valmistada tocker konteinerina ette, et kui te ei taha nende pool valmistad, et piiton keskonda kasutada, saaksid ise piiton konteineri üles jada. See on ka senne natuke hallala, kes selle ette valmistavad. Aga see on default kasutasena, et nemad valmistavad teile ette piiton 13 näiteks. Ja kui nüüd klientid kasutavad teie rakendus, siis nemad põhimatsalt selle eest üldse ei vastuta, aga alati natuke oleneb, et näiteks Facebookis oli võimalus, et kasutajad laevad üles Facebooki sisse, et Facebooki platformi oma mängu koodi, et teistele kasutajatele lasta oma tarkvara kasutada ja selle seda kui rahaküsida. Et osad sellised platformi või sellite tarkvara teenusena võimaldavad selle tarkvara seeese jooksutada ka. Tarkvara, et see on mõnigalt selline hybridne lahetnus ka. Et näiteks IoT platformis on võimalik jooksutada anme töötlusrakendusi platformi sees konteineritena, siis ta on ka selline vahepealne, et see platform pakub ka platformase servisteenusted selle platformi sees või kõrval jooksutada rakendusi. Aga üldjuhel see ei ole võimalik. Et selline peamise teelised pilveteenuste puhul on, et me saame real ajatsressursse juurde küsida ja resursside kasutust vähendada, kas seda automatiseerida või üle appi või üle webi lide se ümber konfigureerida. Tihti puudub ette maks, et kui me teeme oma startapis, me saame kohe kasutama hakkata ja loota, et kuua jäävaks mingi raha saame. Lihtime seda niimoodi tee, aga meil mõnikur on isegi võimalus teatud prototüüpid asuta ja jooksutada, kui me reaalise klient ei ole, et kui me seda testime või esimised väikse klientid on, et siis võib-olla väga kalliks ta ei lähe. Et on lihtend asuta koodid, et saab kas virtuaalmasinaid mingi tuindide aarb näiteks 750 tuindi asures viss kasutada, kui meil on trajal akound. Meil võib olla vähem halduskoormust vastavalt sellele, millist pilvedenuse modelid me kasutame. Vähemalt ei pea riistvara haldama, me ei pea võrguseadmeid ruutereid ülesseadma, me ei pea tulemyöre ülesseadma, et teha meie serverides jookse tarkvara interjets kasutatavaks, et vähemalt selle üle me ei pea muretsama visi platformel. Teenuse puhul siis isegi rohkem, et me anname vastutuse teenuspaku äle, me ei pea sellest ise hoolitsemat jälle natukene lihtsam kasutada. Paljud kohandatud teenused on kohandatud kasutus valmis, saate minna asuresse ja küsida asuresse Postgres Anme baasi teatud suurusega ja ühe minuutin jooksele on ta kasutatav teieoks. Et te peaa uurima, et kuidas ma Postgresi hästi ülesjan Tokkar Konteineris või isegi Virtuaalmasina peal. Te ei pea isegi näende installeerimisega tegelema, et te lihtsalt ütle, et mul on vaja Virtuaalmasinud, kus on Postgres ja see seateks, et teile paar minuutik üles ongi tehtud. Tänapäeval see ole raske, et saate iseminna Tokkar Habe ja Postgres Virtuaalmasin, Postgres Konteineri võtta, vaadata, mis näid parametri peaks olema, aga te peate ise tegelikult ikkagi natuke mõtlem, et okei, mul on server, kas seal serveris on kõik konfitud, selleks, et ei tekiks mingiselt probleem, et palju file võib olla avatud, või kas ketas on piisavalt kiire, midegi sellist, et pilves saate natuke vähem selle peale mõelda. Ja lihtne on ülesseada automaatised skaleeritavust, Virtuaalmasinata puhul on natuke raskem, platformi puhul on ta üli lihtne, sest see on sisse ehitatud, et saakelib teenuse pakku ise, hoolitsib selleest. Ja te saate teenuseid viia lähemale sinna, kus teil on kasutajad, et kui teil on palju kasutajad Amerikas, saate Amerika, Anne Keskusestsele ülesseada, kui teil on palju kasutajad Euroopas, siis seate näiteks Frankfurtis ülesseada või Soomes või Rootsis ülesseada neid Virtuaalmasinat või. Et te saate oma tarkku arvasurssid lihtsasti kohale viia sinna, kus teie klientid on. Ja tihti on ka sisse ehitatud. Teenused, mis automaatised proovivad, leida, et kus teie kasutajad tulevad ja need teenused sinna ülesseada, et mõnikord teie peasugi sellest isega hoolitsema. Aga puudus on võib-olla, puudusid on sellised, et teil on nüüd jälle piiratud ligi-pääse nendel arvutusresurssidel, et kui teil on vajadus instaleerida näiteks mingisugusid AMD-speciifilise teegid või Intel-speciifiliselt teegid, et hakkas kiirendada mingisugusid pilditeötlusasju või algebra mingisugus teekide arvutusi masinapemudelete jaaks, et siis teile ei prugi lihtsalt olla ligi-pääse, et seda teha. Samas pilveteenuse pakuvad, mõnikord pakuvad teile ka täist teenust, et te saate kogu riistvara endale ja maksata rahkem sellest, et ka sellised teenuseid pakutaks. Et virtuaalmasin, kus teile on karanteeritud, et ühtegi teist virtuaalmasinad selle serveri peale jookse. Kulusid võib olla palju-palju raske mitte hindata, kui te ostate serveriste teate, ja palju selle servo maksma te läks, ja te maksad elektriest ja muud asjadeest, aga te ei saa üllatus arveid endale, et Amazon saata teile 10 000 euras arve, kuna keegist tegi teile, et te näele servistatakki teie platform, teenus on rakendusevastu ja Amazon skaleerist seda öösel kuni 100 replikaadi ja jäi tööle paariks päevaks ja hiljem tuleb hiigesur arve. Et te peate palju rohkem muretsama sellest, et palju asjad maksma teile lähevad ja te peate ettesed arvestama, mis võib olla suhtselt keeruline. Kui teil on mingisugused suured pilve kontod ja teil on asutusest hästi palju kasutajad, siis nende kasutate ligi pääsuda haldamine võib olla päris keeruline Amazonis. Et seal on väga granulaaset reeglid, et kes saab millele ligi ja kui te kasutate laanate valed õigused, kui te aanate rakendusele valed õigused ja keegi varastab teie kredentialid, nad saavad jälle mingit bitcoin mainimist teha teie pilves ja teie maksad sellest. Ja kui te ei märka seda, siis hiljem jälle saate mingi arve. Üks probleem tekib sellega, et kui te ehitate rakenduse Google App Engineisse, kus te kasutate Google sisselogimist, kus te kasutate Google SQL-i, kasutatada mingit Google monitorimist, kui lihtne on teil võtna oma püüta rakenduse ja see panna Azure-s tööle või oma serveri palj tööle, siis te peate ümber ehitama näiteks, kuidas sisselogime toimub, et enam ei saa Google Authentication logi otsa kasutada. Reaalselt tegelikult saab, et te saate mingi OAuth teegi kasutada, et samuti lupaada teatud Google kontotel teie rakenduse sisselogida ja kasutades Google Authentication 3. osapoola OAuth teenusena, aga te peate ikkagi selle osaa täiesti ümber ehitama. Teil mida rohkem te ehitate omad rakenduse pilve teenuste speciifilseks, seda suurema risk, et teil on hiljem raske, nagu lõpetada selle pilve teenuse kasutamist. Te peate osaa oma rakenduses ümber ehitama, et tegib selle vendor lock-in, kus teatud teenused on nii speciifilselt selle pilve teenuspakku jälle. Selle vältimiseks on hea ehitada konteinerite või kube näitele põhist rakendust, kus on suhtselt lihtne konteinerit tõsta ühes pilve teenuspakku teisele, et ei pea nagu nii palju asju ümber ehitama. Aga platform teenusele puhul Heroku asja ehitades või Google App Engine asja ehitades võib olla suhtselt raske nagu teise platformi liikumine hiljem, et peate päris palju ümber teha. Ja kui te kasutad pilve teenuseid, siis mis juhtub, kui keegi varastud teie kredentialid? Kuidas ta sellest hoolitsed, et neid turvalseena hoitakse eriti, kui neid konfigurereeriteks rakendustes või mingitad siia CD-pipeline'ides? Et näiteks Amazon scaniib kõike avalike GitHubi projekte ja saadab e-mailed, kui ta avastab, et keegi on Amazon kredentialid pushind üles kuhugi. Ja kõik pilve teenuse pakku, et tegelikult scanivad veebi, et leida üles, et kas keegi on kokematame, et kredentialid kuhugi pannud. Et see on väga tüüpilline, et mingi arendaja lihtsalt unustab ära, et neid kredentialid ei tohiks kuskis kootis hoida ja et neid ei tohi kuskis repositoorimise minna. Et kui need ei ole avalikus repositoorimise, siis veel, aga ka privaatses repositoorimise on tegelikult probleem, et kui näiteks kokematan, et saadatakse klendile ja siis klendi tööta ja keegi pääseb ligi ja siis lahkub töölt ja võtab kredentialid endale, et igast asi võib juhtuda. Pilve teenuseid on mõnesmattes kujunanud majanduse selgrooksest väga paljud asjad jooksavad tänapall pilves. Kui mingi hetk asures Euroopa regioonis läks, üks administraator ja kirjutas ruuterisse vale konfiguratsiooni sisse, niimoodi, et ruuter ei saanud enam interneti ühendust, siis oli mingi kuus tundi, oli teenused maas. Ja kõik, kes hoidsid oma rakendusi selles sama sanmekeskuses, nende rakendused ei ole kasutatavad. Kui nende rakendused ole ka teiste sanmekeskuste, siis nende olid kasutatavad, aga nad on nagu sellise pudelikaelad või üks kohted, mis kaidki läheb, siis võib tegelikult väga palju asju kaidki minna. Aga näiteks start-upide mingi prototüüpide loomine on palju lihtsam eriti just see skaleeritavas osa, et kui näiteks start-up saab hästi populaarseks, siis on suhtselt lihtne skaleerita seda rakendust. 10 kasute alt 1000 kasutate peale või rohkemate peale ja lihtsutab ki seda globaalsata rakenduste loomist, kus klendiid on tegelikult ülemaailmad, kui me ehitame asja üles Eesti, Teli- ja Ammekeskuses ja meil tegib tohutult palju klienti Amerikas, siis me veame ikkagi teisid eidnustpakkojad vaatama, et Amerikast, Eesti, interneti selline leitavusele atentsust tegelikult ei ole üldse hea. hea. Teie kujutad maailmas nagu üks internet, kõik on leitav, kõik on kasutatav, aga tegelikult see nii väga ei ole, võib juhtuda, et kui meie mingisuguna töötajala, läheb Amerikas konverentsile ja proovib Tartu ülikooli veebilehte ligi pääsadad, siis ta tegelikult esialgu ei saagi ligi. Et ka Googlil on endale internet võimsed lootuma anmekeskustavahel, et just vältidad seda, et nad toetavad liiga palju interneti peala. Ja pilveteenuste tulek on siis võimalda on luua väga sellised specialiseeritud ja halata, ja lihtsalt ja halatavad teenused. Te saate näiteks minna Amazoni ja vaadata palju on Amazonis pilveteenused. Neid on reaalsalt üles haja unikaalse pilveteenuse. Existeerib teenus robotid automaatseks testimiseks. Niimoodi, et teie loote roboti algoritmi, mis sõidab nagu tuas ringi ja ümber mööbli, Amazonsis leidub pilveteenus, mis genererib teile sada erinevat tuba erinevate toolid asukohtudega ja vaatab, kas teie roboti algoritmi juhab nagu üheskuhas teise, mis annab teile raporti, et mitmes genererib tuas jõudis ja mitmes jõudnud võib kui palju saajaka vettis ja saate mingi keskmise roboti kohal jõudmise haja. Et selline teenus mis genererib 3D maailmasi roboti teaks, et eksisteerib. Amazon põhimõtteliselt on ka võtnud vastu sellise otsuse, et nemad pilves implementeerid üks kõik, mis teenuse, mida klientid küsivad ja siis vaatad, kas see teenus elu jääb, kas reaalsalt klientid selle ka kasutama jäävad või mitte ja siis vihkavad minema ja unustavad sellistat ära, et selletõttu neil on ka mingid sada unikaalselt teenust. Võite ka leida mingi teenuse näiteks Amazon Data Pipelines, mis implementeerite aastalt 2010 ja ole mitte kordagi uendatud. Et lihtsalt on ära unustatud ja mingid uendusi sissele veetud. Ja nii, et on tekkiin teedite Amazoni sellise Everything As A Service, ehitate oma sellise tehase, soovite tehase panna kaamerat, et ära tuvastada mingisugust metalliobjektides defekte Amazonis eksisteerib teenusele jaoks. Miks ta eksisteerib selle? Ei tea ka, lihtsalt eksisteerib. Keegi on seda küsinud, neid, kes neid on ära implementeerind, et te panete oma kaamera ja siis panete tööle mingi aeg ta lihtsalt proovib ära õppida, mis on et objektid, mis te liinipel jooksevad ja siis ta õppib ära tuvastama erinevosi sialt. Ja siis proovib teile siis näidata, et misugustes nendes liinipel olevatel tootetel siis on mingid defektid ja mitte. Sellest nädalas praktikumis siis me hakkame asure pilve teenuseid kasutame asure staatilist webi lehted. Me midagi väga uudad selle tee. Me teeme sellise täiesti labase HTML webi lehe seal, aga tulevikus me kasutame seda edas, et teeme siin oma rakendaseaks front-tendi, aga mitte veel tänases praksis vist. Ja siis ühes praktikumi teises osas me seame oma Flask appi raamatute halduse appi asure virtuaalmasinjasi üles, niimoodi et me teeme ta internetist kätte saaduvaks, et teie rakendus saab see siis pilves jooksma üles ja saab seda port 80-pel kasutada, et saate ka endale sellise hostnamei oma appile ja saate kasutada. Aga praktikumi lõpuks pange see pilveserver kinni, et teete lihtsalt ekraani vaatad ja koodi ja annate, et me ei taham muidu seda rahakulutada, et ta vist läheb maksma kuskil 20 eurot kuus vist, et selle virtuaalmasini jooksutamiseks parem on ta jooksma mitte jätt, et me kasutame pilvega edaspidistest praktikumides ja virtuaalmasinjate asemel paneme oma appi hiljam konteineris asures üles. Ja, ja, te võite noha endaleoks kasutada, aga ärge nagu krediiterga, aga kasutakäib. Aga see ongi tänaseks kõik, kas on küsimusi? Ja asures te lihtsalt logige sisse oma ülikoolikontoga või minge asures students lähele, siis klikkig, et create an account ja siis põhimõtteliselt oma ülikoolikontoga proogi sisse logida, aga see ongi tänaseks kõik.

---------Loeng 8 Konteinerid.txt--------

 Tere tulemast siis kaheksandasse loengus webi teenustehäüsüsteemide arendusaines ja täna räägime siis virtualiseerimisest, mis on mõnesmõttes pilvetehnoloogia alus ja täiesti vajalik pilvetehnoloogia toimimiseoks. Ja räägime konteineritest, sest tihti ei ole mõistlik panna üles iga erineva rakenduseaks virtuaalmasin, et isoleerida rakendusest üksteisestest. Virtualiseerimine võtab omakorda resursse ja selleks, et hästi palju rakendusi samas füüsilises serveris jooksutada, siis tegelikult on parem kasutada kergema kaalulisemaid lahendusi kui virtuaalmasinad. Ja täna räägime siis natuke virtualiseerimisest. Räägime konteineritest ja räägime, mis on konteinerit ja virtualiseerimise erinevused. Räägime, kuidas konteinerid on implementeeritud, et vältida sellist riistvaralist või tarkvaralist virtualiseerimist. Siis on tegelikult kasutusest pikem tehnoloog, et isoleerida protsasse, kui virtualiseerime note. Räägime nimeruumidest ja C-krupidest ja falisisteemidest, mis on siis konteinerit alused. Ja räägime natuke konteinerite standardidest. Peamaselt tockerist, mis on muutunud selliseks mitte ametlikuks standardiks, aga de facto standardiks. Ja ainuke, mis tockeri selline olemus, mis on muutunud täiesti standardiks, on tockerfailid. Et kasutatakka üks kõik, mis teisid konteineriseerimise tarkvaral, siis tegelikult ikkagi kasutam tockerfailid konteineril tehitada. Ja räägime kas natuke konteineriseerimise elistest ja probleemidest luoingul lopus. Virtualiseerime on sellise arvuti, virtualise serveri loomine, mis suudab jooksutada oma suvalist operatsioonisisteemi. Niimoodi, et te saate minna pilve ja panna üles virtuaalmasina, kus on näiteks Centos või Rocky Linux või siis Windows Server või siis Ubuntu 24. Aga ei ole vahet, mis masinas ta reaalselt jookseb, et teie saate valida suvalist operatsioonisisteemi ja saate põhimõttelselt sellise virtuaalise serveri, kus saate sisselogida oma rakendust installeerida või siis näiteks Jupiter notebooki sinna installeerida ja kasutada ära seda mingite masinope rakenduste jooksutamiseks, et lood oma Python notebookid seal Jupiteris näiteks. Ja te ei oota seda kasuta näiteks operatsioonisisteemides, kus te saates üles VirtualBoxi oma arvutis, ja virtuaalboxi sees tekite virtuaalmasinad ja installeerisete need virtuaalmasinad täpselt, nagu te installeeriksite ütleme operatsioonisisteemi suvalise arvuti peal. Aga tihti, kui tähes pilvest tegelikult pigem toimub nagu te ka elmisest praksis nägid, et te valib te nime kirjast endale sopiva operatsioonisisteemi ja teile valmistateks ette sellide virtuaalne masinad. Te saate tegelikult nii Amazonis, kui Azures ka ise ette valmistada virtuaalmasinad image'aid, et te ei peha alati valima just nende seast, mis on nagu seal olemased. Tihti pakutakse teile ka võimalasse ise ette valmistada. Aga põhimest, et mis seal taustaks on, on lihtne koop ja filesisteemist. Kui tähes protsest toimub, et te installeerite täpselt nagu VirtualBoxi installeerit operatsioonisisteemi kuskile kettale, ja kui te teete selles kettas koop ja saate seda koop, et kasustada uute virtuaalmasinate loomiseks, väga palju töötab ilmadi virtuaalmasinate ketasta koopjate liigutamise või koopeerimise või pack-upimise teel. Aga selleks, et me saaksime määrata, et kui suur on see virtuaalmasin, selleks, et me saaksime juoksutada paljusid virtuaalmasinad sama serveri peal, meil tuleb piirata, et ku palju filesisteemi, ku palju CPU tuumasid, tuleb pole isegi rangevalt mitte terve CPU tuum, vaid mingi protsent sellest CPU tuumast. Kui me räägime, et me saame 50% CPU tuumast, mida see tegelikult tähendab, see tavas tehenab seda, et CPU tuum on kasutatav sisteemis ja see virtuaalmasin saab endale 50% sellest protsessori ajast, mis on alokeeritud ühele et CPU tuumale. 50% ajast meie virtuaalmasin kasutab ära siis justi CPU tuuma, et alokeerida vähem, kui terve et CPU tuuma. Virtuaalmasinatele seadistateks ka RAM, teaks eraldi virtuaalne võrgukaart, mis põhimised konfigureerib, et mis ympärsuunamised võrgutasemel kasutatakse, et sinna virtuaalmasina andsunat, et saab igal võrgukaarditasemel defineerida oma tulemyri reeglid ja rootida andmed, et kui andmed tulevad, siis teatud virtuaalmasin IP-adressile, et siis suunatakse need sellesse võrgukaart, kus on see IP-adresse ja IP-võrg konfigureeritud. Üldjuhul me vaatame seda, et me saame ühe riistvora seadme, kühe serveri, resursid jagada paljudi virtuaalsate serverite vahel. Kui me vastupidist tavast ei tehta, et me ei kombineeri mitud füüsilist serverid üheks suureks virtuaalmasinaks, et seda tavasti kutsute virtuaaliseerimiseks, et pigem käib jutse siis kas klastrite loomisest või sellistest, ütleme, superarvutitest, aga tavasti ei loeta seda virtuaaliseerimiseks. Kuigi me võime luua virtuaalsed file-süsteeme, kus üks file-süsteeme on üle hästi paljude ketaste ja need ketad võivad asuda võrgus, nii et on võimalik luua virtuaalsed võrguketaid, mis on petapaid suur, näiteks. Võrguketa file-süsteeme kasutada selleks, et luua virtuaalsed file-süsteeme, et see on suurselt tavalnega tavasti ei looda, näiteks virtuaalsed masinaid, milles rohkem tuumasid kui ühel riistvoraalisel serveril. Ja virtuaalmasinad võimalde, et pakkuda siis rakenduste aaks turvalist kohandada nii isoleeritud keskonda. Ja see on just sellest pilve vaatevinklist, et just me pilvest tahame pakkuda, et kui me oleme pilveteenuspakkuja, et meil on palju kliente ja me paneme kahe klendi rakenduse samasse füüsilis serverisse, siis me tegelikult tahame karanteerida, et üks klient ei saaks mõjutuda, teise klienti ei saaks sisse häkida või siis, kui hakkab mingisuguse probleeme tekimad, neil ühe rakendus võetakse üle häkerete poold, et see kuidagi ei saaks levida teiste rakenduste peale, ei saaks teisi rakendusi mõjuta, et siis on tegelikult väga tähtis, et oleks võimalik sellist pakkuda turvalist kohendatavad ja isoleeritud keskonda. Ja meil on ka hea, et me saaksime lihtsalt ühes riistvoraalisel serveris jooksutada erinevaid operatsioonisüsteeme ükstise kõrval. Minna kui ma mainisin, et virtualiseerimise tehnoloogid on pilvetehnolooga aluseks ja väga lihtne visualiseerimine on see, et meil on mingisugune riistvora. Tänapäeval ei panda eraldi operatsioonisüsteemi selle riistvora peale, vaid jooksutatakse otsa hyperviisor või virtualiseerimise tarkkvara otsa riistvora peal, kus see hyperviisor või virtualiseerimise tarkkvara ise hoolitseb teile matalat aseme operatsioonisüsteemi funksionaalsustest, et näites, kuidas riistvora seadmik kasutada, paas seda Linux kernelid pakkuda ja muud sellised asjad hoolitseb hyperviisor ise, et meil ei ole eraldi Linux operatsioonisüsteemi siin maja. Mõnikõrd on Linux operatsioonisüsteemi kernel sinna hyperviisor osa, nii et hyperviisor mõnes mõttes võibki mängida ka esimised aseme operatsioonisüsteemi ja peale seda siis pannaks virtuaalmasinad jooksma selles masinas, kus iga virtuaalmasinada on oma operatsioonisüsteem ja siis iga operatsioonisüsteem me jooksadame kas ühe või rohkem rakendusi vastavalt sellel, et kuidas meie kasutajad, kes sinna virtuaalmasinad löid, otsustasid, et kas siin jooksutada näiteks kuberneetes, mille see on palju rakendusi või jooksutada siin üks püütan rakendusi ja teha väike virtuaalmasinad, see on põhimiseid pigem siis kasutajate ja otsustada, et kui palju rakendusi ühe virtuaalmasinad ees jooksad. Mis ka kasutajisa valib, et kui suurse operatsioonisüsteem, kui suurse virtuaalmasin on. Ja üks sellised puudusi virtuaaliseerimise puhul ongi, et kui me nüüd tahame 16 virtuaalmasinad siin jooksutada, siis meil on vaja 16 kooped operatsioonisüsteemist, nii et meil on vaja 16 näiteks Linux kernelid, 16 kooped kõikides failides, 16, mis iganes operatsioonisüsteemi teenused peavad jooksma, siis meil on vaja 16 kooped sellest jooksutada. Ja see on nagu resursside natukene raiskamine, mida proovibki siis konteneeriseerimine hiljem parandada, kui me sinna juhulame. Ja üldiselt virtuaaliseerimine võimalatab siis jooksatud virtuaalmasinad, tekitavad sellise virtuaalseid versioone resurssides, nagu kettad, võrgud, failisüsteemid, keskkonad ja nii edasi. Ja ühed sellised kõige laialtasemad kasutatavad lahendused on Xen ja KVM ja siis VMware. VMware on selline kallim ja proprietorilahendus, kus maks taks litsentsid eest ja tihti võib minna, võib juhtud, et VMware litsents maksab rohkem kui Ristvara ise. Eriti viimase laial, kui VMware on tõstnud litsentsi tasu, mida nad küsivad kasutatelt. Ja Xen ja KVM on pigemselt vabavaralised virtuaaliseerimist tarkkonad ja virtuaalboxi nagu päriselt kasutatakse pigemt avakasutat raames seda nagu serverit, et see ei kasutata väga. Kas hurakar virtuaalmasin, sa mõted virtuaalboxu? Et virtuaalbox pigemt avakasutatelt kasutavad, et ta ei ole nii efektiivne, et pigem kasutatakse Xen nii KVM serverites ja oma arutis oleks ka parem kasutatada otsa näiteks Vcelli või Hyper-V, et jooksatad virtuaalmasinad, et need on palju efektiivsemat. Ma räägin ka sellest, mis virtuaaliseerimise tüübid on, aga virtuaalbox põhimõttel teab tarkvaralist virtuaaliseerimist ja ta ei ole väga efektiivne, kui Xen ja KVM ja teised on võimalis, et väga Ristvara põhist virtuaaliseerimist teha tegema, et ära kasutada neid funksionaalsuse, mis on Ristvara sisse eraihiidatud. Ma räägin ka sellest natuke hiljem. Seda jaastad tegelikult väga kunagi teagi, et näiteks Amazon, mida Amazon kasutab. Ma tean, et meil Hub et see kasutab peamiselt vist Xen nii või KVM-i või isegi mõlemad, kuna nad on vapavaralist, aga Amazon või Azure võivad toesti implementeerida oma, et teha seda efektiivsemaks. Kuigi nad ka võivad lihtsalt vapavaralist edasi arjendada, et nad ei pea täiesti oma nullist välja mõtlema. Aga need on väga laialdaset kasutuseks saanud serverite maailmas, kuna nad on ka efektiivsemad. Selles ainest ma ei räägi seda ajaluku, virtuaaliseerimise ajaluku, et pilvetehnoloogia ainest ma rääksin seda rohkem. Et seal on ka samm-sammulised uuendused, mis ajaka ja pilvetehnoloogia arendusega kaasas käisid, et kui teid uitab, saate natu kuurida nii virtuaaliseerimise ajaluku. Aga motivatsioon on siis see, et meil võibad olla serverid, et kui me sinna installeerime ühe rakenduse, siis terveserveri jõudluse võib-olla või resursid raiskem ära, et parem on panna ühte serverse mitu virtuaalmasinat ja virtuaalmasinate suuruseid kohandada vastavalt vajadusele, et me saame riistvarab efektiisemalt ära kasutada, tükkeldada suure serveri väiksemateks tükkideks. Lihtsustab keskkondade ettevalmistamist, kohandamist rakenduste jaoks, et iga rakendus saab oma keskkonna, oma operatsioonisisteemi, oma komplekti teke, tarkko aramisel jookseb, et siis ei pea nagu hoolitsema sellest, et kuidas me siis hoolitsema, et keskkond toetab rakendust aad, peed, seeed ja teed, või et me saame iga rakenduse aks oma keskkonna teha. Keskkondi on ka lihtsam teiselta ja taas kasutata, kuna me saame virtuaalmasinast ketas lihtsalt teha koopia, selle koopi teise serverse liigutada või me saame ettevalmistada näiteks mingisuguse Postgres SQL ja aks vaeliku virtuaalmasinakeskkonna installeerida Postgres versiooni ja enne, kui me hakkame seda jooksutama teha selle koopia ja tulevikas iga kord, kui me järgmise 3 kuu jooksutama, on Postgres jooksutama, me võtame selle koopia nataka modifitseerime ja jooksutame selle, et me peab nullist asi ülesse jaotma, et me saame suhtselt lihtsalt koopa, et lihtsalt peab virtuaalmasinaketastest. Ja virtuaalmasinaketast koopa tegeminam piisav. Ei ole vaja mälust koopet teha, ei ole vaja nagu tihtisegi konfigurasioonist koopet teha, et meile tihti tõesti piisab ainult ketta koopa ja kõik. Teatad olukordad, et see ei prugid töötada ideaalselt näiteks Windowsi puhul, aga Linuxis piisab lihtsalt ketas koopa tegemiseks, et virtuaalmasin takkapida või seda mitte korda jooksutada. Ja lihtsaltub ka haldust, et kui meil on kõik rakenduse keskkond virtuaaliseeritud, siis me ei ole otsa seotud enam riistvaraga, et rakendus ei, enam ei sõltu riistvaratyübist, et näiteks, kas meil on teatud tüüpi ketta riistvara või teatud tüüpi võrgukaardid, et kõik on nagu nende lähenemine virtuaaliseeritud, et siis meil on lihtsam serveritest riistvara välja vahetada, kui mitte katki läheb ja virtuaalmasin ei prugi sellest väga midagi arugi saad, et seal riistvara taga taustal muutus. Et see võib jälle probleem ajatelne olla GPUda puhul ja Windowsi puhul, et GPU-t tihti tahavad väga GPU-spetsifilisi teek, et kui me vahetame välja Nvidia GPU serveris AMD GPU vastudist teie tarkvaränamlist, et ei tööta. Meil ka tudenkit, kui jooksutasid Nvidia masinope asju sinn haapetsees ja siis hakkasid Suome superarvutid kasutamas, nad pidid oma containerit, docker-containerit ümberheitama, kuna AMD tahtis teht, kui sa teek, ja mingid versioonid töötsid AMD peale, mingid versioonid töötsid Nvidia peale, siis tuli päris palju teek ja välja vahetada, et see tööle saada. Teatud olukordades, nagu 100% ei ole niimoodi. Teoreetselt küll, aga lihtsalt ei eksisteeri selliseid driverid GPU-teaks, mis oleks täiesti riistvara agnostilised. Neid lihtsalt ei eksisteer. Kõik GPU-driverid, mida te kasutate kuskil oma arvutis või kuberneeteses või kuskil on, need on väga GPU-spetsifiliselt, kuna GPU-te on nii kallid ja te tahtet nagu tohutult efektiivsalt seda jõudlust ära kasutada. Lihtsalt keegi ei ole ehitanud selliseid driverid, mis oleks täiesti riistvara agnostilised. Driver peab teadma, mis riistvirade kasutubetaab, et seda efektiivselt kasutada. Seda on lahendatud ketaste puhul, et alguselt ka ketavirtualiseerimises tehti ketastest. Iga ketajaks eraldi driverid, nüüd eksisteerib riistvara ketaste ja SSD-teaks. Tegelik ei ole sellist üldist virtuaalselt driverid, mida sa kasutada. Ei päris teadma, mis riistvara ketast on, et võib sellist välja vahetada, aga GPU-te puhul seda lihtsalt ei eksisteeri. Ei ole sellist üldist virtuaalselt driverid, mida saaks kasutada. Meil ka hapet sest inimene pidi ümper ehitama Nvidia kuberneetes driverid, et seda saaks kasutada dynaamilselt ja kuberneetes operaatoreid pidi ümper ehitama, et toetada mingit konkreetselt version. Yks sellised suuripõhjus, et miks teie ka võiksete kasutada virtuaaliseerimist isegi, kui te ei ole plaanis nagu pilve pakkuda, või mida sellist. Turvalliselsest rakendusisab isoleerida ükstööselt, et kahes erinas virtuaalmasinas jooksid rakendus, et neil on palju raskem mõjutada. Eritikude panate virtuaalmasinalle paik ka rangel, et kuidagi palju resurss on, nad võidad kasutada. On palju range misoleerimine, sest põhimõtteliselt, kui rakendusid jooksid samas virtuaalmasinas, kui ühel rakenduses onnestab kuidagi saada root õigus, et nad saavad samas operatsioonisisteemis teha peagi kõike. Aga kui on kaks rakendusid jooksib kaas operatsioonisisteemis, isegi ühel on root õigus, ta ei saa midagi teise operatsioonisisteemi ligipääsu selle tõttu, et ta kui tegab õigusest saada, või õigusest saada mingi kernele bugisid kasutada, et kuna kõik need operatsioonisisteemi anmestruktuurid on erinevad, siis lihtsalt ei õinestu neid ükst eest mõjutada nii hästi. Palju keruisemal häkida teise virtuaalmasinasisse. Et on parem turvalisest, et ta ei ole turvaline, et kuna midagi ole 100% turvalina. Seda teile võib-olla ka räägid operatsioonisisteemid ainas, et kui me viitame host serverile või host masinale või võrstatale masinale, siis on see peamine server, mis jooksutab virtuaalmasinad. Võib-olla siin on koom operatsioonisisteem. Kui me räägime kest virtuaalmasinad, siis on need külaliseid, mis jooksevad selles suuremas masinaset. Meil on siin kolm kest operatsioonisisteeme või külalist ja üks selline hostia. Ja siis lisaks on meil hypervisor, kes hoolitseb selle virtualiseerimise ja virtuaalmasinata loomisest. Teatud olukordades ta hoolitseb ka tõlkimisest. Aga see natuke olemeb, et kui tarkvaralne see virtuaaliseerimine on. Mida ma mõtlen tõlkimises all on siin, et meil on rakendus. Me sellele operatsioonisisteemil on teatud mäluala, näiteks kolm gigabaiti mäluruumi, mida võib kasutada mäluna. Kui nüüd rakendus ütleb, et ma soovim mingid mäluaadressi kasutada, et on meid salvestada, siis see mäluaadressid kehtivad selle virtuaalmasinasees. Ja neid tihti tuleb tõlkida välise Ristvara mäluaadressideni. Ja siis tavaselt toimuvad siin tõlkimised, et kui siin rakendus kirjutab mäluala, et miljon, ide, miljon midagi, siis siin võib sa olla kaheksa miljonid seide jalati iga CBO operatsiooni puhul, mis tehaaks, see tuleb tõlkida. Mäluaadresse tuleb tõlkida mingid muid aadresse olguse, olguse siis kas processide aadressid, mäluaadressid, et kõik tuleb reaalaes mõnesmats tõlkida. Varasemalt tehti seda Tarkvaras, VirtualBox ka teb seda Tarkvaras, aga täna palju eksisteerivad ka Ristvarad asemele eraldi kiibid, mis tegelevad näiteks virtuaalmasinate aadresside tõlkimisega. CPU, protsessor enaajal peaks sellelegi isetegelema ja saaks kiiremini virtuaaliseerida. Selleiselt speciaalselt virtuaaliseerimiseks mõeldud kiibid ka eksisteerivad täna päeval emaplaatide ja protsessorite juures, mis kirrendavad virtuaalmasinate jooksutamistese. Ja monitorib ka virtuaalmasinade, kas nad jooksevad ja panem nad uuesti jooksma, kui nad tead jooksma, et ma jääma näiteks. Ja Hypervisor ongisesse virtuaaliseerimise Tarkvara, mis võimaldeb sama aegselt kävitada jooksutade virtuaalmasinad. Ta on nagu selline Tarkvara, mis on siis puhimised väga palju õigused, et kui teil virtuaalbox jookseb teie masinas, siis tal on õigused näiteks ümber konfigureerida teie masina virtuaalsseid võrgukaardtet. Et näid võrgukaardid luoks väljaspol virtuaalmasinad, et ei tekitada virtuaalvõrgukaard teie virtuaalmasina sees, vaid luoks väljaspol nii, et virtuaaliseeritad alati peab olema rohkem õiguseid, et teie masinas asju ümber konfigureerida, näiteks kas või selleks, et ruutida serverisse sisse tulevaid pakete teatud virtuaalmasina võrgukaardile ja siis virtuaalmasin saaks võrgupaketid kätte. Ja oleneb virtuaaliseeriat ja hypervisorete tüüpist võib neil olla palju rohkem õigused, kui teie Windowsi operatsioonisisteemilad. Kui teil on ülikooli süle arvuti, mitu virtuaalmasinad teil jookseb praeguselas. Kas kellegil jookseb nüüd? Tänapäeval tegelikult võibki vaadata nagu uusi arvuteid niimoodi, et teil jookseb pähamad üks virtuaalmasi, mis on teie Windows. Põhimõttel, kui te jooksutad Linuxi operatsioonisisteemi virtuaalmasina, siis ta jookse enam teil Windowsi sees, ta jookse selle Windowsi kõrval. Windows Subsystem for Linux või Hyper-V saavad panna virtuaalmasinad jooksma teie Windowsi kõrval. Nii et nad ei enam eksisteeri seda, et teil on Windows, siis ta on VirtualBox ja siin on VirtualBox virtuaaliseerib teie Windowsi nüüd sees uut virtuaalmasinad, vaid näid jooksevad pigem nagu kõrval. Ja võib isegi vaadata, et tegelikult see Windows ise jookseb ka nagu tuhimõttel virtuaalmasinana Riftvara platformil, kus Riftvara platform teie üle arvuti. Ja selled ötate saate sama laajal jooksutada neid ükstese kõrval ja palju efektiisem, kui VirtualBoxi kaudu virtuaalmasinata jooksutamine. Ja hypervisorit jaoks ongi siis kaks tüüpi. Tüüp üks on see, mida ma ka visuaaliseerin enne, et kus ma jooksutame nagu hypervisorid otsi Riftvara peal, et ma isegi installeeri operatsioonisüsteemi, ma installeerime otsi hypervisori siis Riftvara peal ja ta mõnesmõttes asendabki operatsioonisüsteemi täiest ära, võtab endale kõik need operatsioonisüsteemi kohustused ja funksionaalsused. Ja tüüp kaks on siis pigem VirtualBoxi tüüp, kus me installeerime näiteks Windowsi, Windowsi sees installeerime hypervisori ja siis hypervisor virtualiseerib ja jooksutab virtuaalmasinaid, siis olidseb ise selle virtualiseerimiseest. Ja üldjuhul on tüüp üks on rohkem efektiivne kui tüüp kaks ja peamine üks peamine põhiselt ka, et meil ei ole vaja eraldi operatsioonisüsteemi, et meil on selline minimaalne operatsioonisüsteemi, mida hypervisor ise nagu implementeerib. Tüüp üks jooksebki siis otsa. Riistvara peal suhteleb ise otsa Riistvara pool pakutud keeltega ja appidega ja tuntud ka, kui selline põline või neiti virtuaalmasin virtualiseerimistarkkvara, mis ja näiteda näiteks ksen osaliselt KVM, kui KVM on mõneselt mõlemad tüüpi VMware, ESX ja Microsoft Hyper-V. KVM on ka siis põhimõtteliselt otsa ja Riistvara jookseb virtualiseerimistarkkvara. Teine tüüp on siis see, mis vajab operatsioonisüsteemi tukevirtualiseerida ja siin on samuti KVM, aga KVM on mõlemas, kuna KVM on selles mõttes natuke huvitav, et ta võtab üle kül Linux operatsioonisüsteemi, aga ta kasutab ise Linux-it. Ta põhimõtteliselt muudab Linux-i kernele ümber virtualiseerijaks või hyperviisoriks. Ta lihtsalt aktiveerib teadud modulid lisaks ja ta ei nõua eraldi nullist ehitatud hyperviisorit, vaid pigem augmentib selle Linux-i kernele hyperviisoriks. Ta on selles mõttes natuke mugavam, sest saab kõiki Linux-i võimalise featureid ära kasutada, et Linux-i arvutid hallata ja siis võimalta taga virtualiseerimist juurda. Aga teist tüüpi virtualiseerijad vajavad operatsioonisüsteemid tuge. Nad jooksevad kõrgemad õigustes kui tavaprogrammid, aga nad on põhimõtteliselt selle operatsioonisüsteemi sisemised tavaprogrammid, mille on lihtsalt rohkem õiguseid. Ja teamine eelis on, et nad neil on lihtsam emuleerida teisi arhitektuur, et üld juhul nad saavad näiteks 64-pitises süsteemis ilusti virtualiseerida 32-pittisüsteeme või virtualiseerida arm-süsteeme või te saate näiteks Linux-i masinas virtualiseerida näiteks arm-operasioonisüsteeme või arv. Rasperi operatsioonisüsteemid saate rasperilaadseid väikseid virtuaalmasinad jooksutada, aga see on ka sellete ota, et nad pigem emuleerivad seda virtuaalmasinad. Ja tihti seda nimetadaks ka hostitud virtualiseerijaks, et me jooksutame seda virtualiseerijad siis operatsioonisüsteemi sees, et ta ei võta serverid või Ristvara ülevaid, ta on lihtsalt üks rakendus selle serveri sees. Ja see vahe on võib-palseliselt selin, et meil on type 1, mis on siis virtuaalboxi sarane ja type 2, mis on siis Hyper-V või Xen-i sarane, kus meil on type 1. Me võtame Ristvara sinna peale, installeerime näiteks Linux-i, sinna installeerime. Nüüd mulleks lähtaka valesti vist jäädse, kus mul jäi. Type 2 on siis virtuaalboxi sarane ja type 1 on siis Xen-i ja Hyper-V sarane, et kus type 2, me peame mingisoks operatsioonisüsteemi installeerima Ristvara peale enne, kui me Hyper-V sori installeerime. Ja me tavasad jooksutame osarakendusi siis väljas pooseta hypervisorit. Meil on hypervisor põhimselt samalt asemel, kus mõne teised rakendused, mis jooksevad, aga type 1-püle on, me paneme Ristvara peale Otsa Hypervisori ja kõik muud rakendused jooksevad mingisugus virtuaalmasinas ees. Et te võite vaadad, et kui teil on siin Hyper-V teie arvutis, siis jookseb Windows ka põhimselt virtuaalmasinana ja teie rakendused jooksevad Windowsi virtuaalmasinas. Ja kui te vese selli kaud installeerite u-buntu, siis teie u-buntu jookseb kõrval teie Windowsile ja u-buntus isemist rakendused on siis teises virtuaalmasinas. Aga põhimselt Ristvara poolt vaadates ei ole see Windows nagu see peamine operatsioonisisteem, vaid se hypervisor on see peamine operatsioonisisteem, kellel on siis kõige rohkem õiguseid nagu selles masinas. Ja see on efektiivsem, kuna meil ei ole vaja eraldi operatsioonisisteemi kihti ja meil ei ole nagu mõnesmõttes lubatud siis jooksutada rakendusi hypervisori kõrval, et hypervisor on nagu selline kõige rohkem õigusi oma system selles serveris. Ja meil on võimalik teha mitmed tüüpi virtualliseerimisi, et me saame teha täielik virtualliseerimist või sellist emuleerimist, kus me näiteks kõik virtualliseerimeid me ei kasuta ära Ristvara võimalusi virtuaalmasinat jooksutamisel ja need on kõige vanemat tüüpi virtualliseerijad. Need on ka virtuallbox on ka põhimõttel täielik virtualliseerija, et ta virtualliseerib põhimõttel kõike. Põhimõttel selles külalis operatsioonisisteemi jooksab selle virtualliseermisees, et tema tavas teie näegi, et virtuallmasin arvab, et ta on lihtsalt tavaline operatsioonisisteem ja jookseb nagu kuskil serveris, aga tema täiesti peidetakse ära, et on virtuallmasin. Tiihti tuleb ka CPU käske tölkida. Ja see on ka üks põhjus, miks sa pead teha emuleerimist erinevata arhitektuuridu vahel, et me põhimõttel tölkime kõik CPU käsud ühest arhitektuurist teise. Ja meil ei ole vaja Ristvara tuge üldse. Põhimõttel me saame virtualliseeride peaa üks kõik, mida me tahame, aga see on palju palju epaeffektiivsem, sest meil ükski rakens ei suhtle otse Ristvara seatmetega ja kõike tuleb nagu tölkida. Tuleb virtualliseerida ja selletuttu on üks aeglase moid. See on ka virtuallbox on seda tüüpi ja selletuttu ka virtuallbox on tihti aeglane eriti grafikakaartide kasutamise juures ja graafilist asjad võib tärks palju jõudlust vääda. Meil on võimalik teha ka para virtualliseerimist, kus me osa asju lubame minna ümber tölkimise ümber otse virtualliseerimised. Me saame isegi modifitseerida virtuallmasina sees jooksata operatsioonisisteemi, nii et me paneme teatud tarkkora virtuallmasina sisse jooksma, mis teab, et asjada on virtualliseeritud ja mis suhtleb otse virtualliseeri, aga näiteks see tihti kasutaks ka virtuallboxis, need kestad isjanid, kuhusab sisse panna tarkkora, et oleks võimalik näiteks USB seadmeid ülevõtta, et oleks võimalik teatud Ristvara otsa ära kasutada, nii et mõnesmõttes virtuallmasina ja virtuallbox on ka selline täielik virtualliseerija kui ka para virtualliseerimise näist tüüpi, et me modifitseerime seda virtuallmasina operatsioonisisteemi, paneme sinna teatud funksionaalsuse või tarkkora juurde, mis põhimõttes, et lubab meil mööda pääsada sellest täielikust virtualliseerimist ja teatud Ristvara otsa kasutada, et näiteks GPU-te jaoks pidi seda kasutama, et kui me tahame USB seadmeid ülevõtta ja et midagi keerulis, et teha, mida on raske otsa virtualliseerida, siis sinna implementeerime mingit lisadarkkora, mis proovib otsa Ristvara ka suhelda, mis on palju efektiisem kui täielik virtualliseerime. Aga tänapäevad pidem, pigem prooviteks teha Ristvara toetatud virtualliseerimist, et kui te keted, kui teil on kolm virtuallmasinad ja kõik tahavad kasutada, kõik tahavad kettale midagi kirutada, siis keegi peab otsustama, et mis järekorras operatsioonid kettastale kirutadakse, et kui meil on kolm virtuallmasinad, kes proovid täiel kiirusel kõik kettale kirutada, siis kusagil pead mingi protsess olam, kes planeerib, et kes saab ketta aega, aga selle asemel me saksime implementeerida virtuaalmasinad tev vahel järjekorrad Ristvara tasemel. Tänapäev ongi ketastel imod, et ketaste driverid või ketastel on sisse eitatud sellised järjekorrad, et nad saab automaalsalt tekitada eraldi ketta driveri või ketta Ristvara tasemel eraldi järjekorrad erinev, et virtuaalmasinad jaoks. Operatsioonisisteem põhimõtteselt ei pea ise hakkama planeerima, et millisel virtuaalmasina on lubatud kirutada, vaid kõik sisse tulalt päringud edastatakse ketta driverile, ja ketta driver sissemisel ise paneb erinatelt virtuaalmasinatelt tulnud operatsioonid erinatels järjekordadse ja planeerib ise, kui virtuaalmasinate vahel jagada ketta kirutamist. Et see outsorgetakse põhimõtteselt selline ketta planeerimine siis hyperviisorist või operatsioonisisteemist ketta driveril tasemel. Ja teene asimida ma näitasin on näiteks see mäluaadrasse tõlkimine, ka tänapäele on selline translation lookaside bufferid, mis on sellil, et chipid siis kas emaplaadil või prozessori juures, mille ainuke üle sanna ongi need mäluaadrasse tõlkida ja nüüd ei pea seda enam täieliku virtuaaliseerimise stiilist CPU tegemat, CPU ei pea real ajas virtuaalmasinada aadrasse tõlkima ümber päris füüsilisteks. Mäluaadrasse teks vaid seljaks on eraldi kiibid siis ja see paraliseerib seda, et samal ajal, kui CPU teab mingit operatsioone, instruksiooneid teav läbi, siis samal ajal saab teised chipid tegeleda siis nende mäluaadrasse tõlkimisega. Ja need on sellised ristora toetad virtuaaliseerimised, mida tihti tuleb ka teil näiteks bioses sissele üritada näiteks kas AMD-V AMD jaoks või Intel jaoks VTX, et teatud virtuaaliseerimist teile ei ole võimalik, näiteks teid saa Hyper-Vid kasutada enne, kui te selle bioses sissele üritatad, et see on lubatud teil, nii et need on midagi, mis tuleb tihti aktiveerida ja kuus kaheks sa kümme aasta tagasi pidi isega vaatama, et kui ma ostan protsessoriga, seal on VTX tehnoloogio olemas või mitte, et tänapäeval on kõikides protsessoritesse olemas, aga mingi kaheks ja kümme aasta tagasi oli et ainult osades protsessoritesse tugi olemas. Ja see on ka üks põhjus, miks pilvetehnoloogio virtuaaliseeriminid on rohkem, rohkem efektiiseks muutunud, et järjest rohkem Ristvaru on hakkanud toetama virtuaalmasinaid, et enam ei peaks peamisa arvutid, CPU, kõiki transleerimisi tegema järjekordasest haltama planeerima, et järjest rohkem on toodud Ristvaru tasemelle, et Ristvaru ise toetab virtuaaliseerimist. Ja see on ka üks põhjus, miks pilvetehnoloogid on efektiiseks muutnud ja see vajadus ongi tekinud sellest, et järjest rohkem on tavalne, et jooksutakse palju virtuaalmasinaid serveritest ja selledatuga serverite Ristvaru ja tavar Ristvaru siis on pidanud seda rohkem toetama. Ja näid järjekordad on tihti isoleeritud, nii et ka isegi Ristvaru tasemel karanteeritakse, et hoitakse need operatsioonid ükstisest eraldi ja saab isegi mõnesmõttes kaitsta Ristvaru tasemel, et üks virtuaalmasina ei saa teise virtuaalmasinaketta alale ligi või midagi sellist, et saab kaitsta erineades operatsioonisisteemides olevaid protsass üksteise eest, mitte ainult virtuaaliseeria või operatsioonisisteemi tasemel vaid isegi Ristvaru driverit ja Ristvaru kontrollerit tasemel. Aga üks puuduse virtuaaliseerimise puhul on ikkagi see, et kui meil on seda tüüpi virtuaaliseerimne, kus meil vaja operatsioonisisteeme, ja siis veel igale virtuaalmasina operatsioonisisteeme, siis igal juhul on meil vaja palju koopeid operatsioonisisteemidest. 16 rakenduse ja juoksutamiseks 16 eraldatud keskkonnas oleks meil vaja 16 operatsioonisisteemi juoksutada sama aegselt. Kõik need Linuxi kerneri, kõik need lisa Linuxi tenused peavad juoksma jääma ja võtavad resursse, võtavad mälu, kasutavad CPU'd ja see ei ole nii efektiivne, kui juoksutada 16 protsessis samarvuti peal ilma virtuaaliseerimesida. Aga kõvasti parem kui enne, et tänu Ristora toetatud virtuaaliseerimisele on see palju palju efektiivsem kui enne, aga ikkagi see ei ole ideaalne, et ikkagi tuleb natuke eeldatad virtuaaliseerimine, kasutab lisa resursse ja on võib teha aeglasamaks teatavad protsessid. On ka uued tüüpi ohud, et näiteks, kui meil onnestub juoksutada mingit pahalast või, ütleme rootkit niimoodi, et ta juoksagi meil ühegi operatsioonisisteemis ees, vaid juoksad virtuaalmasinana ja proovib ennast kärrapeita, et teised operatsioonisisteemid ei näed eda, kun nad listivad näiteks, mis on virtuaalmasinad VSL-is juoksavad. Siis võib juhtuda, et üheski operatsioonisisteemis sees juoksav rootkitid otsi ja ei leidasad üles. Võibki tekida olukord, kus kui on võimalik kärrapeita, et rootkit juoksab teise virtuaalmasinasees, siis seda ei prugi ollagi nii lihtne üles leida ja teatud tüüpi rootkitid võib selle totu olla raskemine leitavad. Aga üks põhjus, üks lahendus, mida me saame teha, et parandada efektiivsust sellised senaarimis, kus me sooveme kuute teist rakendust juoksudada samas serveris, ongi siis, et me virtuaaliseerimise asemel kasutame konteinerid. Kas keegi oskab seletada või öelda näiteks, mist teie arvates on virtuaaliseerimise ja konteineriseerimise vahe? T.K.A. kui ma jahan tead, aga kui ma virtuaaliseerimine, siis ma põe ikal eraldikoov. Aga fundamentalisemalt, mis on konteineriseerimise ja virtuaaliseerimise erinast. Kas konteineriseerimine on virtuaaliseerimine? Mis te arvate? Atsi, mida seda arvates, mida sa teha järgmikult tege? Jah, see on põhimust teige. Minul on natukse linnan ekstremisev arvamus, et ta ei ole virtuaaliseerimine. Näiteks mulle ei meeld, kui kusagil Wikipedia-sele kusagil kirjaldataks, et konteneiseerimine on õhukese virtuaaliseerimine. Ta on pigem nagu isoleerimine ja ta ei ole enam nii väga virtuaaliseerimist. Kuigi sellest on virtuaaliseerimist eriti võrguketaste tasemel, et tegelikult kasutatakse täpselt samasuguseid virtuaalseid võrguketaid Linux'is, kui virtuaalmasinete puhul. Osaliselt on täiesti vajelda, aga... ...saks võrguketaid ei juba tseksida, liga tseksida, saab suur ka võrguketa. Ta ei ole absoluutne mälururuma. ...selleks, et ise võib teeme teise üle, et oks otsuonist ei juba partab seda isele. Ia, aga kui sul näiteks konteneerisees jookse protsess, mille on ruud õigus, et väljaspol konteneeres, tema saab teha kõike. Tema saab teha teiste konteneere, mis ikäärast ta tahab. Võib aga virtuaalmasinete jookse protsess isa. Virtuaalmasinete väljaspool teisi protsess hallata, ei see kui tal on ruud õigus. Virtualiseerimise on täiesti ära isoleeritud, aga... ...ja, et protsess on vähem virtuaaliseeritud, kui konteneerise jookse protsess selles mõttes võib toesti nõustuda. Aga vaatame natuke rohkem enne, kui me näida samu asju uuesti võib-olla lõpupool arutame. Iga rakenduse jaoks ei ole mõt, et saada on üle oma virtuaalmasinete ja operatsioonisesteemid. Eriti, kui me on hästi väikse mikrotenuseid või nanofunktsioonid, kus meil on väike püütene funksioon, mida me tahame teatud ajal käivitada. Kron tööna näiteks. Siis miks me peaksime tekita mingi hiigel suure virtuaalmasina? Võisigi väikse virtuaalmasina, kus me paneme ühe kron töö jooksma öösel, kell kaks teistie, kas see virtuaalmasin peab siis 24 tundi jooksma selleks, et üks kord öösel jookseb. See on natuke ebamõistlik põhimõtsalt, aga täiesti tavaline muster, mida pidi tegema virtuaalmiseerimise ajal enne konteinerid. Konteinerid aitavad lihtsamini eraldada rakendused üks teisest, aga natuke nõrgema isoleerimisega, et tihti on raskem kontrollida, et ühes konteineri jookseb protsess ei saa teisi mõõtuda. Vissame pidi selle, et see on põõri. Jah, et palju raskem on panna virtuaalmasinates jooksvat protsesid. Ereemates virtuaalmasinates protsesi jooksema oma suhtlem, et see on palju raskem. Serveris, kui me kasutame konteinerid, siis serves on mingi minimaalne Linux operatsioonist teem võib-pol isegi ainult kernel ja kõik muu saab käivitada mingis vormis konteineride sees. Ja et mõnesmõttes harnaane siis virtuaalmiseerimisele, et me jooksatame kõiki konteineride sees, me ei pea, aga me saame. Ja see lihtsustab meil näiteks ka monoliisjates rakenduses liikuda hajusete mikro teenuste poole, sest me saame igale rakendusele või igale protsesse luua oma konteineri keskonna, kus on täiesti eraldi tegid, eraldi keskond saras virtuaalmasinatele, et me saame panna sinna ühele sisse püütanide, sille jaava kolmandele ruubi asjad ja täiesti hoida net fileid ükstiselt eraldi. Nii et server vajab kisest minimaalselt Linux operatsioonisiteemi ja muu asjad jooksat konteinerid, et mul on see lausevist millegus kahekorselt seal kirjutatud. Konteinerid on palju kerge kaalulisemad kui virtuaalmasinad. Ei ole tegelikult üldse raski jooksatada sadat konteinerid ühes Linux serveri, siis egini tuhandat oleneb sellest, kui palju on ülekattuvust keskondade vahel. Kui meil on 10 unikaalsed konteineri imidžid, siis võib-palju see ei ole väga võimalik, aga kui nad kasutad kõiki sama konteineri imidžid, siis see on pihti võimalik. Meil ei ole eraldi vaja hyperviisarid. Meil on vaja mingisugust konteinerid haldusrakendust, mis oskap konteinerid luua ja kustutada ja hallata, aga see otsi ei jooksuta konteinerid, see otsi ei virtuaaliseere midagi. Koguse isoleerimine ja virtuaaliseerimine on ehitatud operatsioonisüsteemi kerneli funksioonide põhiselt. Meil näid, et Stoker ise ei virtuaaliseeri mitte midagi. Ta on lihtsalt põhimised API, mille kaudume ütleme, et loome konteinerid ja Stoker võib-palju kutsub välja konteiner-dia-api, ja konteiner-dia-api kutsub välja mingi Linuxi süsteemi käsud, et konteinerid luua. Konteineri sisased protsesid on eraldatud üksteisest kasutades Linux nime-room, C-gruppe ja muid sellised Linux kerneli sisse eitatud võimalusi. Tavaliselt me saame, me ei pea, aga me saame konteineretele eraldada oma komplekti resurssidest, et kui teie kasutate Tokerit ja panete midagi jooksma, siis tegelikult defaulti nad osab ligi pääsu kõigile teie mälualale, kõigile teie CPU-dele, et kui te ei limiteeri, et palju mäluala võib kasutada või palju CPU-tumasi, et ta võib kasutada, siis defaultina ta võib kasutada kõike, nii et ihti on hea ära limiteerida, et ko palju ta võib kasutada. Konteinerit ülesseed on hästi lihtne, et kui konteiner image on valmis, siis selle jooksutamine võib võtta sekundeid aega, oleneb sellest, kas teie konteineri seest tuleb mingisugusi tegevusi teha, mingid filesystemi ümber kopeerida, mingisugusid kaustasid ette valmistada, et kõik see võib või ta aega, aga kui on lihtsalt processi jooksutamine ühe käsujooksutamine, et siis kui konteineri ei ole vaja ümber ehitada, ei ole konteineri pilti vaja pildida, ei ole vaja konteinerid allotamad, interetist siis konteineri käivitamine võib võtta ainult sekundid aega. Ja jõudlus on ligi lähedane serveri tavajõudlusele, suht vähevahet on sellest, kas te jooksutatate processi konteinerist väljaspol või konteineris seespol. Et see jõudlus võiks olla enam vähem sama, aga see olad jo oleneb, kas te panete mingi piirangud peale, et näiteks, kui piiratad kuid palju tuumad aega konteinerisjookse processi võib kasutada, siis ta on kindlasti aegelsem, aga see on steie piirangud ootbu aegelsem. Ja erinevad konteinerite raamistikud eksisteerivad, te tead toki tokerit palju, et toker oli üks esimesi populaarseid konteineriseerimise tarkvarasid, aga ta on ära standardiseeritud ja täna päeval toker enam ei ole nii väga konteineriseerimise tehnoloogia, ta on pige liides, mille kautu on mugav konteinerid luua, ta tihti nüüd sissemiseks kasutab näiteks täiesti teist tarkvarakonteinerid liid. Ja tokeri asemel kasutada otsa konteiner teed, ei pea enam tokerid kasutama, kui teil seda vajadust ei ole, tihti konteiner teed kasutadaks. Uperneeteses selle tõtta, et toker tegelikult enam ei ole täiesti, ta asuta tarkvara, et tokerid võib kasutada näiteks siis, kui te soovite teda õppetöösk kasutada või soovite oma hobi projektiaks kasutada, aga kui teie asutus kasuta profesionaalse tokerid, siis nüüd on licensid ja asutus peab mingist hetkes maksmakama sellest, et tokerid kasutatakse. Toker konteinerid implementeerimine on nagu pigem palju madalat aseme tegevus, kui lihtsalt tokeri jooksutamined. Näiteks LHC on Linux Containers LXC, mis on kernelid asemele virtualiseerimise metod, mis kasutab Linux kernels ja sisse ehitatud funksionaalsusi, et isoleerida konteineris jooksevad prosessid üksteisest ja kasutatakse Linuxi Nime Room ja C Group selleks, et seda teha ja teie võite Linux Nime Room ja C Group kasutada ilma konteineritada. Te võite tegelikult olevale prosessile või alustatavasse prosessi võimesed konfigureerida samat featureid, mis on konteineritas ilma, et te otsa konteinerid kasutada. Et Linux Nime Roomid ja C Groupid on kasutuses ka väljaspol konteinerid täpselt sama asja teaks. Mis on siis Nime Roomid? See on nagu prosesside, tabeli, filesystemide, gruppeerimine üksteisest eraldatud Nime Roomid, jah, et ühes Nime Roomis jooksevad prosessi ei näe teises Nime Roomis oleva prosessi resursse ja nad ei saaks nagu üksteist mõjutada ja üksteise mälu ola trasseerida, üksteise file kasutada, üksteist äratappa, et võimesed isoleerid prosessid üksteisest selleks operatsioonisisteemi anmestruktuurida tasemel. Järgine slaid vaatam, kuidas see töötab. Ja C Groupid on juba loodud Nime Roomile, siis kas CPU, mälu ola, ketta roomi ja teiste resursside piranguda panemine, et me saame seda looma näiteks looma sellel prosessile Nime Roomi ja siis jõuksame, et selles Nime Roomis, kus see prozess jookseb, on lubatud kasutada üks tuum ja 2 GB mälu. Ja siis üks kõik, mis prosessid selles Nime Roomi sees jooksevad, nende kogu maksimum resursside maht on vastavalt C Groupile, et saanab meile siis võimaluse täpselt virtuaalmasinate puhul öelda, et näiteks mingisugune Postgres Sunme baas, mis meie service jookseb, et tema ei saa rohkem kui 3 CPU tuuma ja rohkem kui 8 GB mälu kasutada, et te saate väga hästi prosessida või konteenete tasemel siis eraldada neile teatud arvresursse. Et kui nad mingil põhjus lakad proovid liiga palju kasutada, siis seda limiteeritaks ja neile rohkem mälu ja CPOa ega ei kasutada, et nad ei saa teisi rakendusi serveris mõjutuda. Ja konteinerid tegelikult ongi mõnesmõttes nagu selline liides nende ja plus lisafunktsionaalsuste peal, et oleks mugav prosesse panna jooksma sellistes eraldi nimeruumides ja näile resursse alokeerida. Lisaks nimeruumidele ja C-krupidele meil on ka konteenerite bildid, tocker imageid, kus me paneme kõik vajaliku tarkvara, mis on vaja vajalik selle prosessi jooksutamiseks ühte käivitatavasse musta kasti põhimõttel, et seal sees on siis tarkvara kood, kõik tegid, mis on vajalikud, kõik konfiguratsioonid, mis on vajalikud ja isegi se kirjutame selle käivituskäsu, et kudas see prosess käivitataks käsure käsuga, me paneme kõik selle konteeneri bildi sisse ja pärast seda meil on võimalik konteeneri bildi peale teha start. Ja kui me teeme konteeneri bildi peale start, siis tegid teda uus konteener selle konteeneri bildi põhjal, et see on täielik paket, et jooksutada mingid konteenerid. Lisaks nimeruumidele ja C-krupidele meil on vaja kihilisi failisest teeme, see on selled oot, et meil tihtime, maundime konteenerite sisse erinevad kaustasid fail, et konteenerite piltide sisse on mitmed kihid ja kui meil tekivad 6-8-10-15 kihdi, see on meil vaja kuiidagi loogiliselt see kihv teha kasutatavaks ühes Linux failisesteemi naa procesile, et procesi näeks kuhutades kihv, nad näeksid ühte loogilist Linux failisesteemi või uniks failisesteemi ja põhjimõtsed see on sellene kihiliselt failisesteemide union või mergemine üheks failisesteemiks. Lisaks turvaliselt seaks on meil vaja ka C-linuxid ja SECOMPi, kus C-linux piirab millised konteeneri failisest namespeisist väljaspoosed failid, portid, sisteemi teenused on kasutatavad proceside poolt, mis jooksevad nime ruumi sees, see tähendab seda, et me saame näiteks lubada procesil pandida porti 80 või kasutada kaustasid väljaspol virtuaal masinad, et procesidele oleks õigused välja kutsuda mingisuguseid teenuseid operatsioonisisteemi käske ja nii edasi väljaspol konteenerid ja SECOMP siis piirab täpselt just operatsioonisisteemi käske ja C-linux piirab pigem nagu sellised teenuseid ja resursse, võib-olla teenused on natuke valesana, pigem resursse nagu failid, portid ja nii edasi. Et mis süskool operatsioone siis konteeneres on lubatud välja kutsuda, et kas ta saab näiteks mingit failel uua väljaspol konteenerid. Konteenere pilt siis sisaldab rakenduse koodi, rakenduse käivitameks vaheliku keskonda, näiteks Python 3.7, vaheliku süsteemi, näiteks vket või kurli ja töökeskonda teke mingit Python tegid, konfiguratsiooni väärtusad, näiteks mis portid ta peaks kasutama, mis kasutanime ta kasutab, kas ta jookseb Ubuntu kasutajana, kas ta jookseb Grafana kasutajana, kuiigi Grafana kasutanimi tegelikult midagi ei tähenda väga, et ta lihtsalt ID-värtus, et see on juba. Ja mis on see käsg, mida jookseudutakse? Ja konteenere pilt saab siis kergesti teha koopjaid ja konteenere pilt on aina loetav, et konteenere sees jookseb protsess ei saa konteenere piltis midagi muutua, ta saab küll muudatuse teha, ka need muudatused tekivad kihina selle pildi pealet, pildi sees või selle pildi koopja sees, mida ühtegi fail ei muudeta, et kõik muudatused tekivad nagu uue kihina, et uuskiht ütleb näiteks fail kusud seda tera, uuskiht ütleb kusud seda jära, uuskiht ütleb kusud seda jära, uuskiht ütleb kusud seda jära, uuskiht ütleb kusud seda jära, uuskiht ütleb, et failis on nüüd uus sisu, uuskiht ütleb, et uus fail on lisaks või uus kaust on lisaks, et kõik tekivad nagu uute kihitina ja hiljem nagu mörgitakse se üheks loogiliseks failisüsteemist kokku. Mis on siis nimeruumid? Nimeruume võib seletada siis hästi listast niimoodi, et kui ma saadan näiteks mingisuguse firma kaevama kraavi ja ma ötlen tal, et kaevaku kraav riha 16 juures, siis kuhu läheb see firma? Kas ta läheb Tallinnasse või tartus riha 16 aadressil või läheb Pärnusse? Pärnus on ka riha 16 riha tänav. Ma arvan Tallinnasse võib pole ei eksisteeri riha tänav, ei ole pärnu tänav, aga põhimuselt, et kas riha tänav Tartus või riha tänav Tallinnas, et kudas firma teab, kus kaeva makata? Nimeruumid ongi täpselt samamõtted. Meil on Tartu nimeruum ja meil on Tallinnan nimeruum ja need aadressid sellest nimeruumis on täiesti erinevad asjad. Üks protses proovib konteineris. Ütleme, kui on protses 16 konteineris A, see ei ole samamist protses 16 konteineris B ja see ei ole samamist protses 16 operatsioonisüsteemi C. Kui meil on protses, mis jookseb konteineris ja tema proovib ära killida protsesi üks, siis see on alati protses üks konteinerisees ja ta ei saagi kunagi saata ühtegi käsku protsesile üks, teises konteineris või protses üks väljas pool, sest tema ei ole seda aadressid kuhu saata. Ja me saamegi jakada filesystemi, protsesid ja igasest muud nimed või aadressid operatsioonisüsteemid asemel eraldi nimeruumidesse ja niimoodi isoleerida protsesid kärnalil tasemel, et ühes nimeruumis olevat protsesid pääsad juurde ainult selles nimeruumides olevatele nimetele või aadressitele. Nimi nimelsi võib konkreese mõelda siis aadressid, et neideks file aadress, protsesi aadress, mäluaadress mis ikanes. Ja meil on erinevat nimeruumid, et kõige tavalse on protseside nimeruum, aga ka filesystemide nimeruum, võrgu nimeruum, et näiteks localhost mida tähendab. Localhost ühes konteineris, selle samamist localhost teises konteineris. Või näiteks mingisegi IP-aadress ühes konteineris ei prugu üldse olla samamist teine IP-aadress teises konteineris. Meil on ka tomeenite nimeruum näiteks, mida tähendab grafana.ut.ee. Ühes konteineris võib see tähendada üht asja, teises konteineris võib tähendada teist asja. Kasutate nimeruum. Meil on kõigis konteinerite sees olla kasutavu puntu. Aga mida tähendab puntu ühes nimeruumis ei ole sama, mida tähendab puntu kasuta teises nimeruumis. Lisaks on ka protseside vahelse suhtluse aadressid, et kuidas ma siis saadan protsesile kaks sõnumeid või protses kaks, protsesel kolm, et ka kogu see suhtluse aadresside nimeruumide vahelse. Selles võib olla natuke raska aru saada, kui ta jääb sellise abstraktiaks. Vaatame näiteid, et protseside nimeruumid on sellised, et meil on host masinas mingisugune protseside puu. Et Linuxist saate juoksutada käsku PS3, et näha protseside puud. Et protses 1 on siis loonud protsesi 2 ja protsesi 3, protses 3 on loonud protsesi 5 ja protsesi 6 ja protses 6 on loonud nimeruumi ja loonud uue protsesi selle nimeruumi sees. Ja nüüd kõik protsesid, mida protses 6 selle nimeruumises tegi ja juoksud selle nimeruumi sees ja kõik protsesid, mida protses 6-port loodub protsesis loob, ka jäävad selle nimeruumi sisse. Ja nüüd, kui see protses 6.1 siin nimeruumis vaatab oma aadresid, tema näeb ennast kui protsesühte. Ja siis on meil protses 1, protses 2 ja protses 3. Ja kui protses 3 proovib tapparaa protses 1, siis tapetaks ära see protses ja ei saa kunagi proovida tapparaa nagu seda protsesi, mis on reaalselt protses 1. Aga üks hiigel suur vahe virtualiseerimisega on see, et kui te ei olete siin, juoksad netiks protses 3 või suvalne uus kasuta selles süsteemis ja teil on root õigused ja te teete PS3 root kasutane, te näete kogusada pood. See osa siin ei ole mingisugune virtualiseeritud eraldi arvutid, on lihtsalt protses, selles arvutist on lihtsalt protses kuuaal olev protses ja root kasutane väljaspoolt te saada seda protsesid ära tappa, te saate seda hallata, te saate üks kõik, mida teha, mida root kasutasid teha, et nagu loogilised võib nagu füüsiliselt vaadates on ta lihtsalt protses suures masinas ja sellet ötav on ka jõudlus põhimõtteliselt enam äm samas, kui te ei limiteerida maa nagu ressursse. Ja natuke selline detailse m näite on siis siin, et meil on siin üleval siis välis arvutis ooks protsesid. Protses kolm on alustand konteiner üks ja protses kuus on alustand konteiner kaks, konteiner kahele luuaks namespace kaks, konteiner üheks luuaks namespace üks ja siin namespace üheses on neliprotsesi, protses kolm alustas protsesi seitse, protses seitse nimeruumi seest näeb välja nagu protses üks, protses seitse alustas protsesi kaheks ja protses üheks ja protses üheks alustas protses kümne, aga nimeruumi seest vaadates on meil protses üks, protses kaks, protses kolm ja protses neli. Et kui üks kõik, mis protses siin nüüd käivitab Linuxi käsu, et mis on siin masinas jooksad protsesid, et näiteks PS jooksatab, siis tema näeb seda tabelid. Ja siit seest jookse protses näebki protsesi tabeline ainult seda väikest tabelid. Aga kui te nüüd jooksutate root kasutana väljast seda PS käsku, siis teie näete siin kogutabelid. See üks väga ei tööta. Et teie näete seda kogu seda suurt tabelid, mis asub siis siin ja root kasutasab suvalist protsesin ära tappa ja root kasutav võib-olla ei näegi seda, et see on protses kolm tõmaneb, et protses üheks saab. Et root kasutav väljas poltsab tapp ära protses 14 või 13-15, aga kui siin namespace-is kahes jooksav protses 2 prooib jooksutada käsku, et kill protses 6, siis siin tabel seda eksisteeri. Ükski käsk, et tapp ära protses 6 siin ei töötas, siis ta saab vastu seda protsesi eksisteeri. Et kui sa ei saa jooksutada ühtegi Linux kerneli käsku või sisteemi käsku, et adresseerida mingit protsessi, mille ideed sinu tabelis ei ole, siis seda seda ei saa. Ja kõik käsud, mida sa jooksutad protses 3 peal, pransleeriteks ümber protsesi käsuks, mis töötavad protses 13 peal, niimoodi, et isegi kui sa proovid midagi halva teha, siis automaatne pransleerimine toimub ja sul ei õnestugi adresseerida midagi teha. Ja samamoodi töötab ka filesisteemide selline loogilne file-nime Room, et mõne on välises masinas root kaust, siis on slash var kaust, siis on slash var leap kaust, siis on slash var leap container kaust. Ja siin kaustal all tekivad alam kaustad konteenere teaks, näites kontee-nere 1, kontee-nere 2, kontee-nere 3 ja kui me vaatame nüüd ühe kontee-nere sisse, see ei ole samam, mida te väljas poolt näete filesisteemin, aga pikem see, mida te näete, nagu kontee-nere seest, et kui te kontee-nere seest vaatate, et te näete, et siin on root kaust. Et kontee-nere seest vaatate, see on teere root kaust, aga see root kaust ei ole see root kaust, see root kaust on tegelikult ümber transleeritud slash var slash leap slash container slash my container. Et kui te nüüd ütlet, et RM minus F ja R, et kustatakse kõik kaustad root kaustas ära, siis kustatakse kõik kaustad selles my container kaustas ära. Et põhimõttel, et ei saa adresseerida väljas pool asuvait kontee-nere, sest ei saa kasutada dot dot slashi, sest see pronseleeriteks ümber, nagu relatiiseks teeks selle filesisteemi sees. Põhimõttel, et siis linkiteks ümber, et kontee-nere seeas aru root kaust asub väljas pool siin, aga sees poolt vaatates ükski protsess, neid väljas pool asuvait kaust ei näe ja selledut, et nad ei saa ka hallata väljas pool asuvait kaustu. Kui te tahate, et see proses näeks väljas pool asutada kaust, see saaksid tegelikult mountida slash home siia mingisuguseks slash home kaustaks. Ja tavas seda me tokkerist teeme, et kui meil on vajalik, et tokkeri sees jaoks sa prozes saaks kasutada väliseid kaustasid, me peame nagu eraldi mountimise teha sisse, aga sista nagu siin selles filesisteemis alam mingis pool asuv kaust ja sista on adresseeritav, sest sa saad nagu allapool adresseerita, aga sa ülespool adresseerita ei saa. Ta on lihtsalt nagu ümpertölkimine põhimõtteliselt, et ja, et see ongi siin nimeroomide tasemel, et Linux kernel-i filesisteemin nimeroomide tasemel sa lihtsalt ütad, et selle protsessil on selline filesisteemin nimeroom ja et see algab siis root kaustast. Ja väljas pool masinas on ta siis mingisubun alam kaust, aga selle protsessi jaoks on ta siis kogu filesisteem, mida tema näeb. Ja tavas, et need samad kaustad eksisteerid, sest ka siin sees, et meil on siis omakorda slash proxine ja slash proxine ja slash pingeen ja slash pingeen ja nii-et asi. Sest Linux protsessi selleks, et ta töötaks, ta peab omama filesisteemi, nii et ta on sellesmõtteliselt ümpertölkimine, põhimõtteliselt lihtne ümpertölkimine, aga ta on nii tugev ümpertölkimine, et protsessi saa aru, et ta on mingisugus teises filesisteemi alam kaust, et tema näeb seda kui terve filesisteemina. Aga väljas poolt siis root kasutada saab minna, mina olen seda teinud, et näiteks kui siin filesisteemis tekitas liigasur logifile, kui ta seda logifile kustutada, siis mina olen seda mõningu kurt teinud, et ma lähen root kasutada ja siit slash varleap containers ja mingisuguse filesisui ümber kirutanud näiteks tühjas rõngiga, et saa tühjaks teha, et logifile tühjaks teha, et logifile on mingi 16 gigabaiti suur, siis ma ei tahakse, et see on kustas. Sest ma ei päris konteeerid ümber ehitada või konteeerid kinni panna, ma lähen lihtsalt konteeerid sisse, ma ei piha, et konteeerid sisse minna, ma saan väljas poolt seda teha, väljas poolt filesisteemist saa minna ja filesisui ümber kirutanud tühjas rõngiga. Aga tihti see isegi jooks nagu konteeerisees, jooks nagu konteeerikõrval, et selle konteeeriprocessi standard output sihti suunataks ühte jasonfile või lisad logfile ja see logfile või pärsti suureks osutuda tockeripuhul, et tockeripuhul salvestatakse kõik processide standard output üste logifile ja see võib hiige suureks muutuda üle aja. Et kui kasutad mingid ngenicsid, mis logib iga sisse tuleb pärin, kui logifile, siis see võib lihtsalt minna kuudes kiva suureks ja teil kogu selle virtuaalmasinaketta täis kirjutada põhimõttesalt. Tihti on seda juhtunud. Selle tõttu on soovitatav näiteks välises süsteemis maundida see kaust eraldi kettale, et seda kausta ei saaks täis kirjutada, sest kui see kaust täis kirjutamise tulemusena läheb kogu file süsteemi kogu server koku ei oosta. Aga kui te selle maundite reaalselt teise ketta voljumi peale, mille suuruseks näiteks märjate 20 gigabaiti või 30 gigabaiti ja väljas pool on siis veel 20 gigabaiti tokeri konteeenerid ei saa kunagi teil kogu ketasta täis kirjutada, kuna te limiteerid, et see onki eraldi ketta peal. See toimub konteeenerist väljas pool. See on pigem nagu se konteeeneriseerimise tarkkavära defineerid, et kui suurde logifailid on lubatud oida, et see logifail ei prugiga konteeeneris sees olla, ta võib konteeeneris väljas olla, toker hoiagi neid väljas pool põhimusult. Jah, aga see on ka keerulisem ja mõnesmõttes sellise eraldi voljumi tegeminu on suhtsalt rang, et see ei õnestugi, et see ei saa nagu ülepaisuda, et sul onki eraldi 20 gigabaitine ketta ala, siis ketta peal, mis on selle kaustajaks maeldud ja selt nagu üle ei saagi minna. Jah, sa võid ka see tarkkuvarad aseme, et sa võid proovida tokkerele mingi neist peasi tegitada ja sellet aseme selle kirjeldada, et ma isegi ei tea, kas see on võimalik. Jah, et see võib olla natuke keerulisem, sest operatsioonisistemi vaadates, et siin on palju protses, et igas konteeeneris on eraldi protsesid ja kui sa tõesti nendele kõigile nagu panad mingil limidid, siis see võib olla võimalik. Lissalt see probleem on selles, et kes kirutab seda logifailis, et see ei prugi üldse olla, see ei prugi üldse olla see protses, mis on see, et see ei sooksab, vaid siin võib olla väljaspol mingisugune rootõigustes protses, mis kirutab sinna ja siis on natuke keerulisem seda limiteerid, aga kindlasti on marvandse võimalik küll. Siin on idee. Mina pigem teen lihtsalt ühe eraldi poljumi sinna selle. Ja see kruppid on siis viis, kuidas me saame nimeruumile panna mingit limete, et näiteks me saame limiteerida CPU-aega. CPU-aega tavasid limiteeriteks nagu komakohtadega, et me saame mingile nimeruumile panna paja peale, et ta võib kasutada 0,2 CPU-aega. See tähendab, et ta saab 20% CPU ühes tuumast ja see tavas tähendab ka seda, et seda siis võeteks arvas protseside planeerimisel, et siis Linux kernel ei lupa sellele protsesile alokeerida rohkem, kui 20% ühe tuuma ajast. Me saame ka märat, et tuuma finiti, et mis tuumad on lubatud kasutada, et näiteks pirat, et ANME base saab kasutada tuuma 7 ja 8, et teisi tuuma siit ei ole lubatud kasutada. Meil on mahtu, aga me saame ka võrguliikluse kiirust, mahtu ja prioriteeti panna paika nimeruumile, et see protses, mis seal nimeruumis jookseb, et ta ei saa arva kasutada rohkem näiteks kui 10 Mbiti võrguvähendust. Ketta ruumi ja see ka seadmatel, et näiteks märatud, kas konteeneleis oleva protses võib GPU-t kasutada või mitte, või teatud seadme, nagu printerit, kas printerit on lubatud kasutada või mitte. Ja virtualiseerimise konteenerise vahe võib-olla siis selline, et kui meil on oma rakenduste jooksutamine siis otsa serveri peal, siis on meil vaja serverite operatsioonisüsteemi, siis paname lihtsalt rakendused siia. Teoreetselt me saame siia väga lihtsasti ka nimeruumeid C-gruppe isekasutada Linux-sid asemel ja me ei pea midagi väga erilist tegema, et meil peab siin konteenerid kasutama võtta, kui meil on täitsa okei manuaalsalt iseneid nimeruumisid luua. Virtualiseerimise puhul üks tüüb siis kasutab Ristvara eralte operatsioonisüsteemi, siis hyperviisorit ja seeraldi virtuaalmasinad, seeraldi virtuaalmasinad, siis eraldi operatsioonisüsteemid ja iga operatsioonisüsteemis eraldi koopja nagu teekidest ja failidest ja siis võib-olla mitu rakendust igas virtuaalmasinas. Aga siis on meil vaja koopja nendest pinnidest, teekidest ja operatsioonisüsteemidest. Konteenerite puul meil on tavastanud Ristvara mingisugun operatsioonisüsteem, see võib hästi lihtne Linux kernel olla, siis konteener ranta, mis tegelikult ei ole eraldi kihina, mina palaks seda viseliselt kõrvale võib-olla, et te näidat, et see siin ei toimu nagu Transleerimis nende vahel. Ja siis meil on kolm konteenerit ja siis rakendust sellest konteeneris ja iga konteeneris ees mingi koopja nendest failidest, mida on vaja. Aga nagu üks tudenks siin ütles, et me ei pea tegelikult konteenerite puhul tegema koopjaid failidest, me võime seda täiesti ära kasutada, et kui meil on virtualiseerimise puhul hypervisor, operatsioonisüsteemi jaoks, nagu Linux kernel komplekt nendest upuntu, nagu interfeisiprogrammides, mis on upuntust avaselt kaasas ja meil on neni virtuaalmasinad, kus kolm jooksatud upuntud, siis meil on upuntust vaja kolme koopjat. Ja kui meil on kaks upuntud jooksatud netkoodist vaja kahti koopjat. Me peame alati virtualiseerimise puhul koopjaid tegema. Aga konteenerite puhul meil tavast mingi hypervisor on, kus me saame virtuaalmasinad jooksatuda, siis me jooksatame tavast mingi virtuaalmasinad Linux kerneliga. Meil on selline Linux kernel, mida me nüüd saame kõiki nend konteenerite vahel ära kasutada. Meil ei ole vajanam nelja koopjat Linux kernelist, nelja virtuaalmasinajaaoks, vaid meil on üks Linux kernel, mis kus see siis toimub nimeruumide põhjal isoleerimine, aga kõik konteenerit kasutad sama Linux kernelid. Ja kui meil on vajalik siis Ubuntu keskond, et oleks Ubuntu programmit kasas, siis meil tegelikult ei ole vaja siin kolme koopjat, võib-as see visuallisioon on natukene... Põhjumist, et me saame täpselt saama moodi teha, et me saame teha kolm konteenerit, kus on seees Ubuntu need vajalikud käsud ja programmid, aga meil ei ole vaja nendest koopjat teha, et me tegelikult saame neid kasutada ilma koopjat. Siin võib olla tegelikult ainult üks Ubuntu Docker image, mida kolm konteenerit ära kasutavad ja nendest ei ole vaja kolme eraldi koopjat. Ma räägin sellest natuke hiljem Dockeri slideid juures. Docker ongi sellest üks populaarsemaid konteeneriseerimise tarkvarasid. Nüüd on järjest vähem populaarseks muutunud, kuna ta muutus osaliselt tasuliseks ja enam ei saa täiesti kasutada näiteks firmade poolt. Aga samas se kommunite version on siiamaani tasut, lihtsalt on licensid, reeglid on rangemaks järjest muutunud. Aga avaldati 2013 aastas. Esialge oli platformesa service pilve tehnoloogia projektiis, nagu .cloud, piskül suri ära, aga see tehnoloogi, mida nad ehitasid selleks, et isoleerida platformide eraldamist üksteisest platformesa service pilves, siis see jäi elu ja sellest kasvus välja Docker. Alates 2016 on ta siis komertsionaalne lahendus nii, et teatud olukordades peab asutud sellest mox makuma. Peamised on samad komponentid. Üks peamise erinele on see Dockerfile, mis defineerib ära, et mis on käsut, mida kasutatakse, et ehitada Docker image ja see on muutunud standardiks kogu konteeneriseerimise maailmast, et kõik konteeneriseerimise tehnoloogid kasutavad Dockerfile, kui kindlot taras seda enam Dockerid ei kasuta. Ja Dockercontainer on siis see, miss on ühe Docker imagei instants, mis jookseb, kus on kõik vajalikud nagu tarkvaraja protsesid, mis peavad selles konteeras jooksma. Docker image on siis konteenerfilist ehitatud sellise konteeneri nagu ketta maail, kus on kõik vajalikud failid, konfiguratsiooni failid ja sellene käsk, mida käivitatakse. Ja tavasalt serveris jookseb ka Docker daemon, mis siis haldaab kõiki neid konteenerid, mis serveris jooksevad, aga ta ei ole virtualliseerija, ta pigem nagu haldusprogramm, mis alustab ja käivitab konteenerid, kui restartte protsesid ja sellasees liigutab faili ja nii edasi, et ta pakub sellist appit põhimuselt. Ja tihtiame ikka Docker registry, kus me hoiame need Docker imageid ja selleks, et me, kui me soovime Docker imageid kasutada teises serveris, et siis ei peaks faili liigutama, aga me saame kasutada registreid nagu Docker haabi, kuhume need Dockerbildid üleslaadime ja alla laadime. Dockerbildis on siis kõik vajaliks olemas, et seda containerid jooksutada kasutab sellist union failisisteemi, et eraldi kihid, failikihid joinid nagu üheks loogiliseks failisisteemiks. Ta väldib igasugust koopjate tegemist, et kasutab sellist asja nagu Copy&Write, et kui meil on kaks protsesi, mis kasutavad sama faili, siis nad kasutad koopjad ja nii peab, kui ühte faili tehaks see muudatus, siis see muudatus teaks see kihina ja välditeks selle koopje tegemist. Ja kui tõesti on vaja koopjad teha, siis see protses, kes hakkab midagi muutma, see teab koopja, aga ülema protsesid võib kasutada samat originaaselt koopjad. Ja ehitadaks alati kichtitena need Dockerbildid, et aluseks võib olla näiteks Ubuntu Paaas Docker Image. Kas ta oskata välja, mis on siin kontekstis Ubuntu? Mis on Ubuntu Docker Imagei sees? Kas keegi oskata välja pakkuda? Ko Esta being jår sa teohmas kooped kohepionid? mis mida kasutaja või program vajab, et selle operatsioonisisteemis joostad. See võib olla lihtsalt shell nagus ütlesed, see võib olla v-ket käske, et sa tahad internetis mingit file alla tõmata. See võib olla lihtsalt file de-haldus, näiteks LS-kommandet listida file. See võib olla kätkommandet file vaadata, et mis iganes. Et alati meeldam, et Linux siis on mingisugust käsud olemast, mida kasutatakse ja see tuleb kihti väljaspol Linux operatsioonisisteemi või Linux kernelid. Et tuub puntuge tuleb kaasas oma komplekt nendest, debian nagu mingi tsaarnane komplekt, aga ROCKI Linux iga näiteks teine komplekt sellest. Ja siis kõik muud on eraldi kihti, tähna näiteks jaavajaks OpenJTK, siis oma rakenduse aks me liigutame siinne YAR-faili, siis YAR-faili lisaks paneme mingit konfiguratsioonifailid, näiteks logimise XML-faili ja viimases kihis tavalselt toimub selline kirjutamine, et rakendus enda poolt, et meil on alati selline viimane kiht, mis on write-kiht. Kõik kihit enne viimast kihti on read-only-kihid, et me ei saa põhimõttel muuta YAR-faili, kui me tahame YAR-faili ülekirjutada, siis tekiks uus kiht, kus võeldaks, et see file muudetakse ära. Ja mää etan selle vahele, kuna aeg on natuke vähe, aga kui te soovite, saate natuke lugele selle kopion writei kohta ja natuke googledada selle kohta, et mis on kopion write, et kui mulle aeg üleps, ma tulen see ju võrd siia tagasi. Et Union-failisüsteeme ongi selline viis, kudas mitu kihti joinida üheks loogisest file-süsteemiks, sest meil ei piisa ainult mountimisest, me ei saa lihtsalt ühte file-süsteemi kõik vaelikult asjad sisse mountida, sest meil toimuvad ka file-ida muutmise, operatsioonid teistes kihtides ja meil on võib-olla vajadus ühte kausta liigutada erinevad muudatused nagu niimoodi, et file-ja lihtsalt kirjutatakse üle või samase kausta panaks ja mitmed file-id erinevades kihtides, et lihtsalt mountimisega see tihti ei ole võimalik. Ja eesmärk on siis, et kontenees jookse protsest näeks file-süsteemi kui ühte sidusad Unixi file-süsteemi ja ei oleks vahet, et mitu kihti, meil on, et meil võib siin olla 60 kihti mingil põhjusel, aga me taam ikkagi, et nende kihtide tulemuse ana siis näeks välja ainult ühte file-süsteem, mis iganes järgmised kiit kirjutada ülepõhimist, et mis juhtub elmistes kihtides, aga see ei toimu muutmised, eel see toimub nagu sellise juunioni-del, et ja iga kiht, siin kihtide järekord on ka hästi tähtis, et iga järgmine kiht võib ülekirtada, mis see onne kiht, nagu määras file-süsteemis, et kas file eksisteerib või mitte ja mis file-id eksisteerid, mis kaustat eksisteerjuda. Ja see ketta kiht võivad siis olla sellise, et meil on siis masin, kus on siis mingisugne virtuaaliseeria, meil võib olla siis Linux, mis jooksetab dockerit, Linux-konteinereid ja Windows, mis jooksetab Windows-konteinereid, et kaks erineld virtuaalmasinad ja Linux-konteinere sees, meil on näiteks mingisugune Java-kiht, meil on mingisugune ngenicsi kiht ja kui meil on kaks konteinereid, mis mõlemalt avad Java-kihtis, nad jagavad seda, kui mõlemalt konteinereid avad ka Apache Tomcat ja Maven-kihti, siis ka võivad seda jagada, eesegu meil on tarkk vara sama, et sama rakendust jooksetab, meil saavad võib edasi seda kihti jagada ja kui meil ongi nagu kaks koopad samast näid HAPi rakendusest, siis nende sees on, nagu viimane kiht on erinev ja kaks erinev protsessis, siis siia viimaseise kihti kirutavad oma erinev anmed, mida nad siis jooksimise ajal muudavad, näiteks mingi logifailid või mingi JSON-nid kirutavad kettale. Ja mingi teinekiht, mis ei kasutas, teinekonteinere, mis ei kasutajahavad, siis tema on oma kihit ja üks peamine eliselt ongi, et meil ei ole vaja neid kooped nendest kihtidest ja Windows-is on põibist saa muud, et kaks rakendust, mis jagavad kihted, siis neid kihti ei pea koopeerivad. Ja Union, mis siis toimub, et kui meil siin protsess jookseb, siis meil on vaja, et need kihit näeksid välja kui ühe fallisisteemine, et ei tekiks nagu probleemi sellega, et kui üks kihti ütleb, et falli eksisteerib, teine kihti ütleb, et ei eksisteeri, kolmas kihti ütleb, et eksisteerib, siis mis see viimane tulemusisorn, et kasutatakse kihti tästi lihtsalt see, et Union mergemist, et lihtsalt otsustada, et mis see viimane seis on. Ja kõik need muudatused, mis siia kirjutatakse, neid võib kõik need alomised kihi seisud ülekirjutada, et suhalsed fallid või suhalsed kaustad öelda, et kas on kustutatud või loodud uus fall või ülekirjutatud midagi. Ja tihtun ka vahet, millist base imageid kasutada tokkereid ja konteinerite puul, ja miks olete võib-al märgand, et L-PAN on hästi populaarseks muutunud tokkereid ja puul on. See on nagu see hästi õhukene Linux kerneli peal olev käskude kiht, mis ei nõua nagu väga palju mahtu, et sa oled hästi väikse konteineri ja file luua. Noo.js L-PAN konteiner oli paar aastat tagas ajal 23 MB, samal ajal kui mingisel Noo.js Debian kiht on 202 MB suur. Nii et näid on nagu rohkem ettevalmistatud selliseks õhuke seks tockerfailideks, et saaks tocker imageid suhtselt väikseks. Ja kui te soovite, et teie konteiner oaks rohkem hallatav, et seal oaks igaselt käsut nagu v-ket, kurl juba olemas, et ei pea nii ise installeerima, siis saate mingit Debiani või Ubuntu-base imageid kasutada, aga kui soovite hästi õhukest, hästi väikseid file, siis pigem L-PAN põhiseid mingit püütane või JavaScript-base imageid kasutada. Et tokkere kasutama ei see elisid ongi siis, et saate efektiivsema jõudluse, et enam ei ole vaja meil nii palju koopeait fileidest, operatsioonisüsteemidest, et võib-olla saama ühe operatsioonisüsteemi kakkama. Tavallest me ikkagi kasutame virtuaalmasinaid, lihtsalt selleks, et oleks parem hallata kogu virtuaalmasineid seherakustutada uusluua või siis selle skoopja teha, et tihtime ikkagi virtuaalmasinete kasutama, aga me loome pigem nagu ühe suure virtuaalmasina serveri kohta, kui me piamised konteinerid kasutame. Me saame rohkem keskkondasid mahutada üste serverist, sest me ei pea kõikides fileidest skoopjat tegema. Suhtseid lihtne on docker image'aid teiselta teise serverse. Te saate ka docker image'i või docker konteineri võtta ja docker konteineril teha komiti. Ja te, praeguses docker konteinerist teha image ja nüüd saad ta image file'i ära liigutada teise serverisse või registrisse saata. Seda ei soovitada teha, sest sinna jäävad kõik väikselt muudatused, mida protsess on teinud sisse. Võib tekida hiigel suur kicht sinna, aga põhimiselt on võimalik teha juoksost konteinerist nagu commit. Ja sellest tekib image ja nüüd saad selle image ära muud liigutada teise serverisse. Väga lihtne on tekitada üks konteiner image'a nüüd seda 60 korda kasutada, et 60 konteinerid lua. Natuke lihtsam kui virtuaalmasinate puul, aga põhimiselt virtuaalmasinate puul tead saate täpselt sama asja teha. Ja on ka kiirem teenuselt ülesseada, kuna kui see image on olemas ja teie esimene skript, mis seal konteineri seisookseb väga midagi teeb, peale ühe käsujooksutamist, siis saab väga kiiresti konteinerid ülesseada. Aga teatad olukordades võib konteineri image alla tõmbab, aga päris palju aega võtta, et eriti kui internet ei ole väga kiire. Insoleeritavus on ka hea, aga see on õrgem kui virtuaalmasinate puhul, et kui operaator ei ole serverit hästi konfinud, kui ei huolitseta sellest, et kas konteineri seis on kõik hästi tehtud, siis võib juhtuda, et konteiner nil õnestub muukida välja konteinerist ja väljas polmasinat asju teha. Eriti kui maunditakse valjesid asjaad, näiteks, laisalt maunditakse kogu väline root disk sinna konteiner sisse, ja protsessi jookseb root kasutaja õigustena konteineri seis, siis no, konteineri võib üks kõik mida teha. Tokkeri puhul seda on ka raskem kaitsida, kui perneetisse puhul saab lihtsamini kaitsida, et kui perneetise puhul saab üeldad, teatud kui perneetise nimeruumis jooksevad konteinerid, neile ei ole õigust jooksutada root kasutana, neile ei ole õigust väljas pala mitte midagi maundida, et kui perneetise saab nagu reegleid selle peale panna ja üeldad, teatud annebaasi nimeruumis jooksev konteiner lihtsalt ei tohigi mitte midagi teha, et kui perneetise on see sisse ehitatud, et saab sellised poliitikaid määrata. Ühes loon, kus ma veel räägin kui perneetisest, aga selles ainest me kui perneetist ei kasuta, kui perneetist kohtam veel üks erald ja aine sügisel, mis on küll magistrile mõetud, aga pakatudengid vist saavad seda võtta ja pilvede analogist kasutame ka kui perneetist natuke praktiku mides. Kuigi vähem ühes praktiis ainult. Kokku võtak siis, nii virtuaalmasinad, kui konteinerid võimaldavad sellist infrastruktuurikoodina, saate täpselt ära defineerida skriptidena, et mis peab olema serveris, mida te üles seate, kas virtuaalmasinanna või konteinerina, aga konteinerideses on pigem sisse heitatud, virtuaalmasinate puhul on rohkem tavalne, et operaatord läheb ja käsur ja käsupelt seab asjad üles ja siis peab ise hooritsema sellest, et skript eksisteeriks, mis on tehtud selleks, et virtuaalmasin üles jada, aga konteineride puhul see tockerfail ise ongi skript tohimõtselt. Nii et teile nagu paas kasutus ongi see, et skriptige, mis peab konteinerisees olema. Ja täitsa, no ütleme, lubatud on teha niimoodi, et te võtate paas konteinerimidji, panete selle jooksma, lähete sisse, jooksotate käsur ja käske konteineris, et installeeri see, konfigureeri see ja siis teete, panete konteinerisees, ma teete selle komiti ja teile on image valmis. Et te võitisegi tockerfaili asemel käsur reaalta asju teha ja selle komitida uueks image-iks, aga see ei ole nagu best practice, et see on, saab teha, aga see ei ole hea viis, et parem on ikkagi tockerfaili kõik asjad kirja panna tockerfaili käskudena, et see on palju nagu standartsem ja saate tockerfaili dokumentatsioonina kasutada, kitis hoida ja teised arendajad näevad, mida te tekite palju lihtsameni, et ta ei pea minema ja tockerimidji kihte uurima, et mis käsut seal on olemas, et saab lihtsalt tockerfaili luugeta ja palju luge loetavam. Konteinerid pakuvad sellist ühtelast keskonda arenduses tootmisene, et väga lihtne, nagu oma arvutis testimiseal jooksutada, väpsalt sama konteinerid, mida jooksutad testkeskonnas, mida jooksutad produksion keskonnas, nii et saate samu konteinerid täst väpsalt kasutada, et ei pea keskondi erialdi hoidma, et ei ole vajadust, et jooksutama oma arvutis mingit SQL lite, siis testkennkonnas, MySQL ja siis productionis PostSQL ja siis teeme kõiki natuke teist moodi. Meil on väga lihtne Postgres konteinerid jooksutada oma süle arvutis, ja me ei pea väga muretsama sellest, et paljud ära suurse võtla, me ei võimeda lihtsalt hiljem seisemu panne ja kõik. Suurselt lihtne on eemadada oma arvutist vanad konteinerid, mida enam vaja ei ole, mida ainult arenduse ja testimiseal oli vaja. Palju lihtsem, kui otsutad, okei, mis mul on installeerimata või mis mul on aninstalleerimata, et otsida üles, mis ma olen kokemata unustan, me oleme installeerid, et ma istult vaatan konteinerid list ja kas veemalt annad kõik, et need on lihtne uuesti lua. Me saame rakendusi isoleerida ilmal oes lisakoopetet, aga siin on suure tagad. Meil on lihtsam serverite peal jooksutada hästi palju asju ja panna serveri peal näitis sada erinead konteinerid jooksma, see alati ole natuke, ku palju resursse iga konteiner vajab, ja palju kooped palju erinead keskondi on. Ja hästi lihtsam skaleerida tokkereis jooksavad asju, sest tokkereis endas on sisse eidatud tokkerservice, kui teed võtate serveri, muudate tavalse serveri tokkersform serveriks, te saate tekitada tokkerteenuseid ja panna tööle näiteks kolm kooped oma raamatud ja haldusapist ja automaatsal jagatakse teil, sisse tuleb päringud nende kolme koopi vahel ära, et tokkersformi on see sisse eidatud selline skaleerimine ja kolmuse jagamine. Ja suhtel lihtsam ka nGenics iga seda teha, et panate üles kolm tokkereid, kolm kooped samast tokkereimidist, kõik panate jooksma natuke erine porti pealis kasutada nGenicsid, et sisse tuleb liikus portile kaheksa jagada ja siis portide kaheksadot üks, kaheksadot kaks ja kaheksadot kolm vahel ära, et suhtel lihtsam skaleerida, et tekitada konteinerid juurdeist, panate mingi reverse proxy, nagu nGenicsi selle ette, et jagada liiklus nende vahel ära, et võtab mingi 50 minutit, no võib-al rohkem kui te esimiskorda seda teete, aga suhtel lihtsam skaleerida niimoodi, et panate mitu appid samase serverse või mitmesse serverse tööle. Miks üldse skaleerida konteinerid samas serveris on võib-al see, et näiteks, siis te ei pea prosesside sees tegema, mitme lõimelisi lahendusi või näiteks prosess on natuke piirata, et mitu ühendus on nad saavad samal lahti hoida, et ta ei prugi alati aidata, kui te kasutad mitut serverit, aga mõnikord on selles päris päris päris palju kasu. Aga samas ikkagi jääb vajadus kasutada virtualiseerimist, et karanteerida isoleeritus, nii et kui teil on mingi start-up, teil on kolm erinead klenti ja te soovite, et nad ei saaks ükstees mõjutada, siis mõnikord on ikka panna kolm erinead virtuaalmasinad ja nende rakkendused juosta nende virtuaalmasinad sees, et nad natuke karanteerida virtuaaliseerimist ja selletud ihti ka näiteks Amazonis ei ooksutada konteinerid alati samades virtuaalmasinades, et lihtsalt vältida seda, et midagi juhtub ja virtuaaliseerimist ikkagi pakub paremat isoleerimist, aga kui kasutada kuberneetes, sinna on siis sähitatud lisa sellise politikad ja viise, kuidas karanteerida isoleeritavust, ka saab tegelikult küll seada üles suure kuberneetes klastri ja siis näiteks erineate klientidele tekitada kuberneetesed asemel erinead nimeruumid ja nendele panna erinead politikad, turvapolitikad pealet, et nimeruumide vahel ei ole mitte midagi lubatud teha ja nimeruumide sees ei ole lubatud näiteks ruud kasutena jooksutada ja muides, aga siis peab olema ettevaatlik, sest kui teile on mõni lais karante ja siis lais karante näeb, et oh, ma ei saa seda konteerid jooksutada, kuna ta ei ole lubatud ruud õigustes jooksutada selles nimeruumis, a, ma muudan tema konfiguratsioon, et ta on nüüd lubatud. Et see on täitsa lubatud, et arendaja või operaator saab ise tsundida teha siel tööle, niimoodi, et ta panem lisapoliitika sellele konteerile ja selleks, et nagu mingisugusest politikast mööda saadan viise, et selline lais karante saab tegelikult sellest mööda ja siis te arvad, et teil on hea poliitika peal, mis seda ei luba, aga kui eegi ikkagi seist mööda häp, siis saab lisalt. Selles näedala praktikumist te siis võtad oma esimesi appi, raamatud appi, mitte selle open appi spetsifitseeritud versiooni, vaid selle esimesi versiooni ja loodte selle konteenerid ja konteeneriseerite selle ära ja siis me vaatame, mängime läbi ka paar sellist scenaarjumid, kuidas need konteenerid ehitada ja seata selle üles ja tulevikus ma hakkame need konteenerid kasutama ja me isegi agame selle ühe konteeneri mitmeks, mikrotenuseks ja mitmeks konteeneriks siis ühes tulevikupraktikumis, aga täna teeme selle esimesi korda läbi ja järgmises loon, kus ma plaanin siis rääkita anmebaasidest, nii hajuskui pilve anmebaasidest, et natukräägimelt skaleerimises ka, et mis on siis anmebaasida hajussisteemid omadused ja läheme natukene hajussisteemide juurde tagasi, aga just selliste suurte anmebaasida ja pilveteenuste kontekstis. Kas on küsimusi? Peske käsi üles, kes on kasutanud dockerid, konteenerid ja kõik. Et see ei pruugi väga keeruline olla, kui te olete kasutanud. Kes on ehitanud dokkeri faili põhjal docker konteenerid ise? Kes on dockerfaila kirutunud? Juba vähem, nii et jah. Võib-olla siis see teile esimesi korda. Aga okei, laboor on siis kahe tunni pärast ja järgmise näda räägime anmebaasidest.

---------Loeng 9 -Andmebaasid.txt--------

 Täna se loengu teemaks on siis hajus ja pilve-anmebaasid. Räägime natukene pilvetehnoloogiest edasi, aga tänane selline loengongi kombinatsioon anmebaasidest, pilvetehnoloogestest ja hajussusteemidest, sest me võtamegi fookuses just hajus-anmebaasid ja pilve-anmebaasid mitte nii väga tavaliselt esküel anmebaasid, aga põhimõttelikagi alustame sellest, et mis on üldse relatsioonilist anmebaasist ja mis on nende probleemid. Just skaleerimise vaate vinklist, et miks hästi skaleeritavate lanmebaaside puhule ei kasutada tihti tavaliselt esküel anmebaasid pilves. Ja lõpetame siis pilvetehnostega, mis ongi mõeldud anmebaaside jaoks ja praktikumidest hakkate siis kasutama oma raamatu, halduse, rakenduses anme toidmiseks, siis pilve-anmebaase. Esijal, kui me teeme sellest natuke lihtsamalt, aga eks te näete? Ja tänane praktikum tegelikult võidki oleks raskema praaktikum, aga eks seda vaatame, et teil tuleb oma se rest-appi natuke ümber teha, et põhjamasud peab kõikides meedodides, et sellase mele, et me hoiame neid raamatuid lokaalsed, siis nüüd panaks seda anmebaasi, ja me hoiame, kas seda jasonid põhimõttel anmebaasis nüüd, et kus hoidakse seda raamatuid nime kerja, kui ma jätin mõletan. Aga anmebaasi relationist mudelt, te ota kõik näinud, kas anmebaasid ainees, kas kuskil asutuses, kus te teete praktikat või töötate, põhimõttel anmet salvestavaks ta tabelina, kus tabelitas on kirjed ja tabelid tehaks see tavaliselt iga erinev oleme jaoks, et meil võib-olla näiteks olla kasutajatabel, siis on meil näiteks mingisugune kasutaja võtmetetabel, mingisugune kasutaja ostetud, ma tegime objektitabel, kui meil on mingi veebibood. Põhimõttel meil tekivad sellist erinevad tabelid, näiteks siin on customers, orders ja products, ja me tavaselt seome need oma vahel selliste välismõttelmedseostega, et see kasutaja, customer ID, customer staple on samamis, customer ID orders table ja siis product ID orders table on samamis product staple, et see loob siis otsased seosad endanemete vahel, mis on andes kolmest tabelis. Ja need on hästi ranged seosad, et näiteks ei prugigi olla võimalik teha uus order kirje, kui siia prooviteks kirjutada midagi customer ID ka, mida ei eksisteeri customers tabelis, et selledut tulemusel tuleb viga, et ei saa teha orderid tellimust kasutajale või klendile, keda ei eksisteeri veel klendi tabelis. Ja see panep peale teatud piirangud, me ei saa lihtsalt tohutul mahul anmeid sisastada näiteks orders tabelis, me peame enne hoolitsema, et customer stabelis on kõik kliendid loodud enne, kui order stabelis palju anmeid lisame. Meil peab olema synchroniseeritud ka anmete sisestaminud, kui me hakkame uue klendi anmeid sisestama order stabelis, siis see peab olema loodud customer stabelisse ja kõike seda tuleb arvessa võtta, kui me hakkame anme baase skaleerima. Ja ka anmete tüibid on määratud tihti väga rangelt, et kõik tulbad on siin näiteks Integer 64 või String 256 pikk või siis näiteks Float 64, et näiteks tüibid on määratud ja siis te saate vea, kui te proovete seda mingi teise anmeid sisestada. Et see anme baasi tarkvara, anme baasi engine ise siis kontrollid, et kuu see anmeid sisestataks, et näid rangelt oleks täpselt õige struktuuriga, kui anme baasis on määratud nende tüibiks. Ja tavalselt kasutatakse SQL päringud, et anmeid sisestada, anmeid pärita siis relationist anme baasidest. Ja siin on üks suvaline näide, mitte väga keerukast anme baasist, et kui te lähete töötama mingis siin firmasse, siis seal võib olla kõvasti rohkem tabeleid, eriti kui see on 10-20 aastat vanha firma, mis tegelebki SQL põhiste süsteemidega ja tänapäeval võivad, et SQL anme baasid ole palju keerukamad kui siin, aga mõnikord ma vaatan, kas siit seda võib-olla välja ei tule, et mõnikord tekivad ka seda süttyksed seosad, aga siin on pikemse orders, tundub olevat selline keskmine tabel, millega teised on seotud, et on nagu pikemseline puu mõnes mõttes, mis hakkab orders tealapoole. Et ma vaatin, et see on isendas. Jah, et see on selline... Huvitav tükkel siin. Ma olen ka seda mujal näinud, aga... Region is... Võib-olla lihtsalt seos nende vahel, et ja... Title, title of courtesy and region oma val seotud. Ma pole päris kindel, mis seal täpselt oma val seotud on. Ei pruugi olla, et see võib olla... Ma olen näinud sellist seeost, et sul on kasutad ja kasutajate tabelisab eer, kus on sõbrad, ja sõbrad on defineeritud nagu listina. Mis on hästi imelik, et relatsioonisandmebasis tavasad ei tee, aga ma olen seda näinud. Ja siis tegib endaga seeost, et saa seot ühe kasut oma sõprade, kes on samuti kasutajad, aga tavasad seda väga ei tohiks teha pikem. Peaks sellised seeos, et tegem äraalt ei tabelina. Ja sellist relatsioonistetabelite puhul on tegelikult keeruline otsustada, et kuidas neid skaleerida sellised andmebase. Et kui meil ühe serveri jõudlusest enam ei piisa, siis meil on tavasad kaks võimalust skaleerimiseks, et anda rohkem arvutusjõudlust, näiteks me viime oma office andmebasi pilve ja siis soovime pilves seda palju suuremast skaleeridad. Me saaksime teha vertikaased skaleerimist, millest ka ma aga natuke pilvetehnoloogia loengusist mainisin, et me lihtsalt suurendame ühe serveri võimsust, et paneme ta suuremast virtuaalmasinas tööle. Sella asem, et me anname teile neid 8 tuuma, anname 16 tuuma, sella asem, et aks 12 gigabaitimelu, anname näid 24 gigabaitimelu. Me saame alati andmebasi suurendada. Kas te ei oletu uurinud, mis on kõige suurend virtuaalmasina asures? Päris ja maksma läheb. Ütleme rohkem nagu sadatuhate eurad kus. Ma jääsi üksustel. Tegelikult on võimalik võtta hiigel suur virtuaalmasin. Me asures seal on speciaalsed virtuaalmasinad, mis on näiteks GPU-hevid või mis on CPU-hevid või mis on memory-hevid. Aga on võimalik ka annemabasi ehitada niimoodi, et võtta hiigel suur virtuaalmasin ja sinna ühendada kuni vist 64 kähendadele. Siin on viis kähendada. Ja ikka ketas võib olla mingi 4 terabyte. Või siin on 8 terabyte. Et see on pilve ketas. Sist virtuaalmasin ise võib maksida mingi 50 000 või 100 000 kus, aga ikka ketas läheb ka mingi 3000 000 kus maksma. Ja siis te võid arutada, et paljusel reaalsed maksma läheb ja tegelikult ei ole võimatul uur asures näiteks ühe petapaitilise ketta ruumi ka virtuaalmasini. Lissalt ei ole mingi 64 kettas, lihtsalt ei ole mingi 64 ja või rohkem ketast, mis on hästi mahukad. Aga see läheb tohtud kalliks. Selliste anmebasi veitamene, mis ühe virtuaalmasina peale on ülas eitatud, siis läheb väga, väga kalliks. Et tiedamine kasutatakse pigem, nagu horisontaalselt skalenimest, paneme rohkem servereid ja paneme anmebasi, siis mitte me serveri peal samakselt ööle. Ja me saame resursse juurdu panna sellekõpp, me lisame virtuaalmasinaid või lisame servereid. Ja see on odavam, et me ei pea võtma nii võimsaid virtuaalmasinaid, me lihtsalt võtame neid rohkem, nii et kolmkorda suurema anmebasiaks kasutama kolmkorda rohkem servereid näiteks. Ja see läheb kolmkorda rohkemaks. Aga siis me peame hakkama anmeid jagama erinevad serverite vahel ja tegib hajus anmebaas, tegibki süsteem, kus me peame nüüd ufolitsema hakkama, et kuidas anmed on, kas replitseeritud või... Kuidas anmed on jagatud nende serverite vahel. Ja relationaalis anmebasi saab samuti horisaantaalselt skaleerida, sellest ma lägin järgmestaslaadil nimetadaks Ingiske sardimiseks, aga no teist ka skaleeru väga hästi, et tekivad palju palju probleeme ja tihti tekivadki probleemid just nendest seostest anmebaasiid vahele. Kui me näiteks jõtame, et me jagame kõik tellimused kolme servere vahele ära, siis me peame otsustama, et millised tellimuse tähed ühte serverisse, millise tähed teise serverisse, millised kolmandase serverisse, siis me peame otsustama, kuidas seeotud anmed veste stabelitse hoitakse, sest kui me partitsioneeri näid hästi, siis võib juhtuda, et igakord, kui me teeme üks kõip mis select päringu, siis me peame kolme serveri pealt anmed kokku kokuma, et seda select päringule vastata. Ja meil olks palju kiirem, kui me ei peakse sellist kokku kokumist tegema, kui seda vaja ei ole, et teha lihtne select või join päring, et meil on tegelikult parem, et anmed tullada tähed tühest serverist, et siis seal on vaja näiteks võrgulinklust ja mälust, anmed küsimina on palju kiirem kui üle võrgu anmed küsimina. Ja selletur ta tegelikult tähtiselt partitsioneerimist tähti teha. Ja need kõik need relatsioonid tabelite vaheliselt seeoset teevadki siis tegelikult skaleerimise keerulisemaks. Kilustamine põhimise tehtab seda, et me võtame mingisuguse tabeli ja jagame tabeli mingisuguste tulpade järgi erinaeks partitsioonideks. Näiteks siin tabelis meil on customer ID 1-4 ja me paneme reegli paika, et customer 1 ja 2 läheb ühte partitsiooni, 3-4 läheb teise partitsiooni ja näiteks 5 ja 6 läheb kolmatase partitsiooni edasi. Ja siis me saame defineerida sellised reeglid, et mis anmed hoitaks esimeses partitsioonis, mis anmed hoitaks teises partitsioonis. Ja siis me jagame, et partitsioonid või eestikeles võib-olla kilud, anmedbasikilud siis erinevat serverite vahel ära. Ja siis päringute tegemisele, et kui on meil SQL-i, selleks päring, mis puuduta painud customer 1 või customer 2 anmeid, siis piisab sellest, et need anmed võetakse esimesest sardist. Ja kui need päring kõik kõik puudutakigi customer 3 või 4, siis võib-olla meil teises serversi olegi kõik ma vaadata. Ja samamoodi, et me võiksime vaadata, et kui meil näiteks employee ID on siin ja see tabel on siis seotud emploii teritoriis ja siis orderitega. Ka order tabeli saame partitsiooneerida siis emploi ID järgi, ka selle tabeli saame partitsiooneerida siis emploii tabeliga. Ja vastavalt meil võib-olla ei ole nii võimalik üleenused tabelid väga konkreestalt partitsiooneerid. See läheb palju keerulisemaks partitsiooneerimise tegemine, kui on tohutud palju oma vaja seotud tabeled. Kui meil aluks üks või kaks tabelid või, mida tihti tänapäeal tehakse, kõikite tabelidega kuidagi seostada üks konkreetne idee, et me igasle tabelisse paname emploi ID või customer ID, et me saaksime kõiki tabeleid partitsiooneerida. Seda ka mõni kord tehakse. Eriti tehakse mitte relatsioonlistus andme basidas, millest ma siis tänaka räägin. Ja kui meil tekikski see võimalus, et me kõik tabelid, customer ID, invoice item, kõik tabelid seeome, siis kõikite tabelisse paname customer IDid, see meil on palju lihtsam partitsiooneerid andmeid, sest me lihtsalt partitsiooneerimigi ühe idee värtuse kaudu või kaupa, mis kõikite tabelid tuseksisteerid. Seda mõnesmõttes nimetatakse näiteks ka STARS-skeemaks, et meil on andme basi keskel üks tabel, mis on customer ID, customer tabel, ja siis kõik teised tabelid on keskeliselt tabeliga seotud, et tegib selline täh või STARS-skeema. See võimalutab meil andmeid paremini nagu jakata partitsiooneerideks. Partitsioonideks me saame öelda, et me partitsiooneerime selleks customer ID väärtused ära näiteks 10 või 16 või 32 partitsiooni vahel ja hoiama neid näiteks siis 10 või 5 serinas serverid. Aga suvalisa andme baasi võtmine ja sellel ära partitsiooneerime et ihti ei ole väga lihtne või sikil võimalik, et seda tegelikult tuleb. Selle peale tegelikult tuleb mõelda, et kui hakkat andme baasi looma, andme baasi modelid loomat. Täiesti kasutusel võtta sellise suvalise mustrii asemel selline STARS-skeema, kus meil mingisugune ID, mingisugune muutuj on allalt igastabelis. Ja selleks, et oleks võimalik lihtsamine andmeid skaleerida, lihtsamine andmeid jagada erinat sõlmeda vahel hajussüsteemides, ongi siis SQL andme baasid asemel välja tuldude erinevate mitterelatsioonist andme baasid ja ka sellised hajussandme baasid või noSQL andme baasid. NoSQL on tegelikult väga halb nimi, sest te lähete vaatada, otsite noSQL andme baasi, leiate näiteks mingisugune kasandra kasutub SQL. Otsite mingi noSQL andme baasi, mis on... Mõnge on näiteks SQL kasut, aga mõned teised täitsaad toetavad SQL. Ja miks nad toetavad SQLi? On selletõttu, et SQL on hästi laialtaselt kasutuses, kui karem tead. Teavad, mis on SQL, kui me loovam mingisuguse oma päringu keele, oma andme baasi jaoks, siis me me kõiki kasvateid õpetame, kuidas sa tahak keelt kasutada. Nii et tihti, mitterelatsioonist, nii et isegi nõu SQL andme baasid, tihti otsustavad lihtsalt kasutame SQLi kasutus. Otsustavad lihtsalt kasutame SQLi ka. Et näiteks inflaks andme baas, kestibi andme baas, mis on ajaseri andme baasid, võid SQLi kasutu. Kui neil põhi päringu keel on teine, neil on näiteks inflaksil on kas Flux-geel näiteks, aga saad ka SQLi kasutada. Nii et tihti toetatakse ikka kest SQLi. Aga ei nõu SQLi tähelelikult tähendad pigem, mitterelatsioonist andme baasid ja visatakse seda näite relatsioonit tabelite vahel, et pohjumist et ei lubata sellised otserrelatsioon ja tabelite vahel. Ja kõiki andmeid vaadatakse, kui mitte seostatud andmetena. Ja nad on üles ehitatud, hästi tohutud lihtsal andme mudelile, kus meil on lihtsalt võtti ja väärtus. Meil ongi andme baas, kus meil tabelis on lihtsalt võtti ja mingisugune väärtus. Ja see on nagu see kõige madalat asemene, ütleme võib-pall-a valesti üelda, selline füüsilne andmesalvestuse struktuur, et andmeid oitakse tohimised võit ja väärtus. Ja miks on kasuliks? Sest võtme ärgim väga lihtne võimalik andmeid partitsioon eerida. Me lihtsalt tekida mingi hash-funktiooni, mis jagab võtmed erinevatesse partitsioonidesse. Näiteks hashime võtme ja siis kui hashi väärtus jagame siis näiteks kuue paketi vahel ära ja sellet tulemusana saab väga lihtsalt selle otsustada, et kudas me andmeid hoiame partitsioneeritult. Ja kui võtja näiteks ongi customer ID näiteks, siis me tegelikult väga lihtne on customerid jagatsi erinevata partitsioonide vahel ja erinevatesse serverite vahel ka üks süsteemis. Aga võtti väärtus on natuke raske aru saada, et kuidas seda kasutada. Tavalsalt need mitte relatsioonist andmebaasid panevad lisa skeemasid või lisastruktuurigas võtmesse või väärtusesse. Nii täna vaatame ka neid, mis need olemasolad andme mudelid siis on. Aga põhimiselt me kasutame mitte relatsioonist as andmebaasides, sest lihtsamait rankes struktuuritava, rankes keemata skeemales andmebaasi mudeleid. Ja nad on tavaliselt disainitud just kaleeritavust või suurt jõudlust meeles pidades. Kogu struktuur onki eitatud selleks, et oleks võimalik skaleerida andmebaas näiteks 100 või 300 serveri peale. Toetada rakendusi Facebook või Twitter, kus on kümmeid miljonid või sadu miljonid kasutajad, kes väga suur hult võipal igapäevaselt kasutab seda. Ja hajus andmebaaside puul meil on tegelikult vaja huolitseda, et kui me paneme andmebaasi 100 serveri peale üles, siis huolitseda, et andmebaas töötab isegi siis, kui üks põik, mis selleks hajusesteemis kokku jooksab, andmed tuleb synchroniseerida. Kui andmed on näiteks replitiseeritud kujul, et igast andmest on näiteks kolm kooped andmebaasis, et vältada seda, et andmed kadul lähevad, kui server kaob, siis ka peab andmed olema synchroniseeritud. Et kui ühes kooped ja andmed muutetakse, siis peab kõikides kooped ja andmed muutetud olema. Ja selleks, et jõudlust saada, meil on vaja sisse tula, et päringult siis jagada nende serveritevahel ära, et me ei saa tekitada ühte pudelikaale, et me saadam kõik päringult ühte serverisse ja üleent serverlist hoiaodanne. Et meil on vaja ka, et päringult jagatakse nende serveritevahel ära, et kiirendada andmete lugemist ja kirjutamist. Ja nad siis proovivad saavutada seda, et andmet on lugemine või ja kirjutamine on kiireld. Teatud hajus andmesystemid optimeerioid ainult lugemist ja kirjutamist ignoreeritakse, teeldatakse, et kirjutatakse harva, aga loetakse hästi hästi tihti. Et võib-al, et kirjutatakse sadakorda vähem, kui loetakse ja siis pigem skaleeritakse lugemist. Miks see muster on kasutus, on selle tõtud, et kirjutamist on palju raskem synkroniseerida, aga lugemist on lihtne synkroniseerida. Me kirjutame näiteks ühteserverisse, eest taustal toimub andmet ja replitseerime teiste serveritevahel, aga lugemist saavutakse kõikidesse serveritevahel. Näiteks tihti näid hajus, posk, rassandme, baasi teavad niimoodi, et üks server on pealik server, kuhul sunatakse kõik kirjutamispäringud, aga teised serverid siis serveri jõuad lugemispäringud. Enne, kui me lähme nende hajus-andme-baasi tüüpite juurde, räägime sellises teoreemist, agu Captheorem või Eric Breweri teoreem, kuna demo oliks selle autoreid. Selle teoreemi mõte ei ole andme-baaside kohtalt, on pigem üldised hajussisteemide kohta, et hajusarhutil või hajus-andme- baasil on võimatu sama aegselt karanteerida 100%-i teoreemide, et hajus-andme-baasi on tehtud, et hajus-andme-baasi on tehtud, et hajussisteemil, mis koosneb mitmest serverist, oleks võimelne sama aegselt pakkuda järjepidavust, kättesaadavust ja partitioneerimistaluvust või tõrkketaluvust. Selle teoreemi mõte on siis see, et me peame valima 2003-est. Aga mis asjad on üldise järjepidavust? Järjepidavus või ingliskeves konsistensi tähendab seda, et iga lugemisoperatsioon, mis saadad, klastris olevas serverisse, saab alati kõike uuema kirje või saab peateate. See tähendab seda, et kui keegi on just enne seda saatnud kirjutamisepäringu ja nüüd meie saadame lugemisepäringu, siis andmebaas peab karanteerima, et lugemispäring saab vastuse just selled uuendatud andme, mis just eelne päring ära uuendasid. Selle ei tovi, et me ei saa kõik uuendamisepäringu, et andmed kirjutad üle, siis järgmine päring, mis andme prog luge, täpeks saama kõige viimasad väärtused. Mida võib olla rastke saavutada, kui meil on 16 serverid, kirjutamispäring läheb esimesse ja sama aegs, et läheb lugemispäring 15. selle. Kätte saadavus või ingliskevesa veel afiliitit tähendab seda, et iga päring saab korrektse vastuse. Kui me saadame hästi palju lugemispäring, et me ei tohiks saada tagasi eroräid. Me peaksime iga sisse tuleb päring. Klientid tähts saama korrektse tulemuse. Loeb andmed, mis on andme väärtus. Kirjutab andmed ja ei tohiks tekida olukorda, kus mingil hetkel süsteemele kätte saadav. Akkab, et see erorid saadma ja ei tohiks tekida olukorda, et saadatakse erorid. Ja me ei saa kõik seda, et me ei saa kõik seda. Kõige keerulisem osa on see partition tolerants ingliskeles emision partitioneerimise taluvus. Mis tähendab seda, et kui... Ma mõtlen, kui seda selgitada. Võib-olla ma natuke joonistan korraks tafli peale. Aga zoomist meie hästi ei ole. Kui saame... Ma vaatun, võib-olla ma saan... ...seda. Kui meil on näiteks... ...kolm serverit... See on veel väga kirjubild sinna. Meil on mingi kliendid, mis saadavad päringud selle selle serverisse joonistamas ja klendi ka. Ma väga ei oska sõrmagi joonistaa. Kui meil on kõik kliendi, siis meil on kõik kliendi, et meil ei ole sõrmagi joonist. Ta mul oligi midu joon. Kliendidel tulevad päringud nendesse kolme serverisse. Törkketaluvust tähendab seda, et üks kõik, kui teid kolmene grupp partitioneeritakse mitumeks gruppiks, olgu see kas niimoodi, et meil on vasakul pool kaks serverit ja paremal pool üks server alles. Partitioneerium on tähendab seda, et võrgust grup A... ...ja grup B... ...ei saa enam oma vahel suhelda. Meil algusus oli anmebasik grup, mis koos näes kolmest serverist. Ja nüüd on grup A, mis koosab kahest serverist, ja grup B, mis koosab ühest serverist. Kui me jätkame päringutesaatmist nend kõikid nendesse kolmesse serverisse, et siis server peaks jätkama tööd ilma ühegi probleemita. Et server peaks olema kasutatav, või see kluster peaks olema kasutatav, kui praegu kasutate päringutesaatmine jätkub nendesse kolme serverisse, isegi kui serverid üks, kaks ja serverid kolme ei saa oma vahel suhelda. Ja see partitioneerium tähendab, et suvalne partitioneeriumne, et me võime näiteks 100 serverid jagata 50 ja 50, või kolm serverid jagata 89, et suvalise partitioneerimise tulemusena server peaks jätkama tööd. Ja see cap teorem, ma vaatame, kas ma siit välja minna, väga ei saa. Ma ei tea, kui tuli seda nõrkustutnuda. Aga see cap teorem siis tähendab seda, et ükski hajussisteeme ei saa sama aegselt karanteerida kõike kolme omadust 100%-lisalt. Peab valimaga siis järjepidavuse ja partitioneerimise või kätte saadavuse ja velability. Ja taval seda anmebasite puhul teaksab. Mõned anmebasid proovivad pakkuda ideaalselt jõudlust, et hästi skaleeritavad anmebasi, aga nad natukene annavad alla konsistentsiosas. Või siis mõned anmebasid... Mõned anmebasid siis proovivad pakkuda hästi sellist konsistentsiosas. Ja siis tähendab seda anmebasi, nagu transaksiooni teaksab, mingi bankasysteemid, mis tahavad karanteerida, et kui keegi on kasutaja krediidinumbri ära muutnud, siis kasutajale ei tohiks olla võimalust, nagu näiteks kaks kordased rahakulutadal. Kui rahanumber kontool ära muudetakse, siis igas järgmises ketväringus täheks olema kõige viiman väärts, et kunagi tohiks tagastada mingid vanakrediidiväärtust. Ja siis ongi anmebasid, kas proovivad karanteerida järjepidavust ja partitsioneerimist või siis kättesaadavast partitsioneerimist. Mõnesmõttes partitsioneerimne siin pigemma sõnastakski tõrketaalumus. Et üks kõik, mis juhtuks, et süsteemeleks ikkagi 100% kasutadad. Ja lahendused, mis keskenduvad, rohkem kättesaadavusele, mis tahavad olla ästi efektiised ja skaleerivad anmebasid, siis nemad kasutavad midagi, mida nimetadeks viivitusega järjepidavuseaks või eventual consistency, et anmed võivad jääda mingiks aegs mitte järjepidavaks, aga natuks ajaperast ja võib-pol nad karanteerivad, mis ajaperiod võib olla. Peab see, et järjepidavaks on järjepidavaks, et anmebasid partitsioneerivadki ennast kolm nurgal ühele tasemeled. Et need anmebasid, mis fokusseerivad konsistensile ja partition toleransile, neid on mongoDB, mis on Jason anmebas, hypertable, peaktable, retis, berkliDB. Anmebasid, mis proovivad pakkuda rohkem, on järjepidavaks, mis on järjepidavaks, ja tõrkketaluvust on Dynamo ja Cassandra. Dynamo on Amazoni pilve anmebas, cauchDB ja RIAG. Anmebasid, mis ei pakku tõrkketaluvust, need on piken nagu ühe serverised lahendused. MySQL, Postgres või Oracle. Kui me näedisime Postgresil, Postgres kukub maha, et ma ei saa järjepidavaks. Põhimõtteliselt üks server, kes on pealik, ja teistesse serverlite päringute saadmise tulemus, ei saa kui tegelikult karanteerida, et päring saab korreksed vastused. Kuigi võib-olla siin on natuke vale öelda, et pigem, ma ütleks, et see on võib-olla, et päring on päring, et päring on päring. Ja siis on päring, et päring on päring. Sa võib-olla kuskamasojad tegelikult põship Pilipantonala...... Aaa mõpinud kohotuseks jääniteth М referring wise on nüüd obedience sheet. Võib-olla siin on natuke vale öelda, et pigem, ma ütleks, see on ühen server・set lahendused, kui server maha läb, siis ei ole lahend Teen's kuskoskostamised kiireoresit. Sa assembling Saint. kui teiseks põhimõtteliselt seda tehaks igi niimoodi, aga seda tehaks on aktuke taustal. Mul vist selles loengus ei ole seda diagrammi, kuidas Postgres seda tehaks, aga põhimõtteliselt pannaks üles näiteks üks pealik ja kolm replitseeritud serverid. Kõik kirjutavist päringud läheb pealikuse ja taustal taajub protsess, mis pealikoole kirjutada tammed replitseerikad eestesse. Sulle ei ole suurt vahet, kas saadadaks kolm päringud kliendilt kolme serverisse või see toimub taustal. Parem on ikkagi, et sul oleks mingisugun taustaproces, kes karanteerid, et tammed on replitseeritud. Seda tegelikult Postgres hajusat tammepaasiid klastrite pool tehaks kea. Aga lihtsalt see protsess toovimad taustal, et me ei saada kõiki, vaid me saadame ühte ja seal automaatst replitseeritaks halati nii kiiresti, kui võimalik kõikidesse. Aga see tähendab, et see võtab aega, nii et sa ei saa ikkagi karanteerida 100%-list õiged järekord ei saegi. Et kirjutavist päring jõudis enne hanmepasi kui lugemist päring. Oli te lihtsalt kõik mul nõmida järekord? Jahaka, kas ta jõub kõikidese servietes sama järekoraga? Lihti tegijaltki probleemid mitte nagu ühe serveri vaatavinklist või just sellest. Aga see võib oma tekida, et on kui üks mõjest kalatatvaast näiteks, ma tegindin kõrra ka kirjutnese lugevise. Ja kuna see ei kõna teedimad järekordita, et kui mõe esimeses on juba käib, et ikka saan lugeveta vanaväärtust visel, kui me just kirjutusem. Jah, lihtsalt see, et kui see lugemine jõuab enne kohaliku kirjutamine, siis see on veel okei. Aga kui ta jõuab kahteserverisse erinas järekorras, siis pigemte peab probleemid. Ma ei tea, kas Moskan on hea näid, et väga tuua. Kui sul on üks järekord, siis sul on raske saata kahte näiteks kirjutamispäringud või kahte lugemispäringud. Nääid panaks see järekorda jõuavad samal aal ammebaase, siis see järekord ongi selline, nagu ta oli, nagu internetis kohale toimetasvõid. Aga kui ta jõuab kahteserverisse vales erinas järekorras, siis võib tekida see mitukorda rahakulutamise probleem. Et nagu üks server arvab, et rahavõib peab kulutada, teine server vastab, et rahai tohjel on kulutada, kui rahavõib peab kultatud, aga teine server vastab, et rahavõib peab kulutada. Ja sul võib selle tõttu olla, siis võimalik back-endist kaks korda küsida, et anna mulle raha või osta midagi. Et kui sa saad ammebaasist kahelt erinalt servelt erinal tulemuse, siis see ei ole probleem pige tegi. Et kui nad tulad ainult ühteservese kohale, siis see sama server ei vasta kaks korda erinalt. Aga ma peakse selle kohta võib pole näite tooma, et paremini selgitama. Viivitus aga järjapidavusek, eventual consistency, ta tähendab seda, et ma võib-olla näitan kiin visualtioon jänne, et kui meil on kaks anmebaasi või hajussüsteemi sõlme ja ühte toimub ühte saadatakse kirutamisepäring, siis tihtise synchroniseeriment toimub natuke hiljem. Et siin ei tea palju hetk on kasta millisekondides, mikrosekondides, mis iganes ühikudes, aga ütlem, et synchroniseeriminen jõuab nagu kolm ajoühikud hiljem toimub alles mingil põhjusel. Kas või see, et kirjutaman ise võtab aega, näiteks mingisugud indexet agututakse ümber mis iganes, siis samal ajal teisel ajan ühikud saadatakse lugemisrequest, mis proovib seda sama anmeobjekti lugega teisest serverist. Ja siis server jõuab juba vastata lugemise vastusega kiiremini, kui see synchroniseerimne kohale jõuab. Ja see tähendab, et see teise serverisse saadatud lugemine saab vastuseks vanad anmed, kuna synchroniseerimne veel ei jõuha ei ole jõudnud juhtuda. Aga seda nimetataksegi eventual consistency, alati toimub see natukas ajal, hilisemalt toimub siis see synchroniseerimene ja mingisugus aja ühikolguse siis kas sekundites, millisekundites. Pärast seda on anmed lõpuks järja pidavad, aga me ei saa karanteerida, et nad on koha järja pidavad, sest see alati võtab aega, kui me tegeleme võrguga, et kõik võrgupäringud võtab aega. Et siis need süsteemid vastavad, nad ei proovi ülekontrollida kas anmed on kõige uuemad, nad proovid hästi kiiresti vastata, et just pakkuda sest hästi kõrged jõudlust ja skaleeritavust. Ja eventual consistency onki, et me lubame mingisuguse lühikis aja ja võib-olla karanteerime, mis on selle maksimum pikkus, sellega ajaakna pikkus, et näiteks, et maksimum üks minut on inconsistent. Et siis need anmedbasiid, mis proovivadki, hajus anmedbasiid, mis proovivadki pakkuda hästi hea jõudlust hästi suurts skaleeritavast, siis nendel on viivitusega järjapidavas. Ja igas elme anmed muutuvad lõpuks järjapidavaks mingi aja järel. Ja siis see võimaldeb pakkuda väga madalatelt tentsust, sest me ei pea kontrollima üle midagi, et me saame kohe vastata lugemispäringul, et me ei pea kontrollima, kas anmed on vanad, me ei pea suhtlema teiste nõudidega selles klastris, et me saame kohe kliendipäringul vastata. Ja näiteks Twitteris meid ei huvita, võib-olla Twitter on vale näite, aga Facebookis meid ei huvita, et kui Facebooki posti kirutada, muudab oma postitust, et meie kohe millisekondite järele näeksime õiged vastust. Meid väga ei huvita, meid on okei, kui mingi minuti või 20 sekundi pärast alles näeme, et keegi muutis oma postitust. Võib-olla teatud olukordad, et see on alb, aga üldjuhul kõikid as-systeemides meid ei huvita väga, et kui anmed ei muutu koheselt. Teine omadus, mida mitte relatsioonilistes ja hajussüsteemides tavaselt on, võib-olla see slide on natuke vara, on agregeritusel orjenteeritus. Seda onneb seda, et prooviteks vältida vajadust anmeid joinida või grupeerida. Üks kõige kallimad operatsioone ka relatsioonistes anmebasides on just paljude tabellite, et joinida tegemine või anmed te grupeerimine, et raport ei tarvutada. Ja selle idee on, et siis näiteks me, ma hiljem räägin näiteks anmebasid tüüpidest, aga näiteks Chase-on anmebasides, et prooviteks hoida anmed, mida päritakse koos ühes Chase-on dokumentis või vähemalt samas partitsioonis, niimoodi, et nende anmed pärimisele ei oleks vaja anmed kokkuda kokku paljudelt serveriteld, et ei tekik seda vajadust, et serveritad oma vahel anmed küsima selleks, et vastata kasutatada päringuteled. Kui vähegi võimalik prooviteks anmed teenormaaliseerida, niimoodi nad ei oleks jagatud väga erinatasse partitsioonidesse. Näiteks üks võimalus on, et kui me teeme alati raporteid kuukauppa ja klendi kauppa, siis paneme ku ja klendi anmed alati samasse partitsiooni, samasse serverisse ja järgmise ku anmed võib olla mingi teises serveris, aga põhimised partitsioonime anmed siis samadesse failidesse või partitsioonidesse või samadesse vähemalt serveridesse, siis ku ja klendi kauppa, niimoodi, et sama ku ja sama klendi anmed ei ole kunagi erinatasse serverides. Ja see siis vähendab seda võimalust, et kui me iga kuudeme klendide raporteid, et raportide tegem saal me ei pea joinima anmed mitmest serverist kokku, et see nagu kiirendab tohutult tegelikult anmed pärimist, et kui me hoiamaanmed, juba kruppeeritud viisil. Mõnikord seda tehakse nagu otsa anmemudelid tasemel, ma kaan natuke toon selle kohta näiteid, aga mõnikord tehakse seda lihtsalt partitsiooneerimise tasemel ja mõnesmõttes sarditud SQL onmebasides samuti, teakse partitsiooneerimist just niimoodi, et vältida, et anmed on liiga laiali serveride vahel. Siin on siis näite sellises JSON anmebasist, kus põhimõtsed anmed, mida loogised hoiteks erinaates tabelites, näiteks SQL anmebasis meilaks credit card stable, order line stable, customer stable, order stable, siis on võimalik, et näiteks JSON anmebasis me hoiame sama klendi anmed kõik ühes dokumentis, et me paneme klendi meta anmed, klendi ID, klendi nime, samutib me tekitame näiteks JSON listi, me paneme kõik orderid ühte JSON alamlisti ja igakord modifitseerimisele kasutaja JSON dokumenti, kui kasutad, telib midagi uut ja isegi meil on võimalik näiteks credit card info panna samassa JSONisse, kui võimalik, et see kõige paremata ei ole, või vähemalt, kui ta krupteeritada, siis see võib-lega on okei. Et idea on, et me saaksime siis relatsioonis anmebasise erinaates tabelit, et info panna mitte relatsioonis anmebasis, mis on näiteks JSON anmebas, panna nadki samassa dokumenti või samassa kirjassa kokku, et vältid, et me peame tegema üle neljad abeli joini, me hoiame igi sama kasutajanmed koos, ja seda mõnikord teaksin mobiilirakendustes, et selle aseme, et ühe kasutaja kohta hoida palju JSON dokumenti, ja JSON anmebasis saab hoida ühte JSON dokumenti. See on kui mõnesmõttes võib-lega tüütu teile by-stab, et miks ma peaksin hakkama igakord JSON dokumenti muud, kui ma seda ridasid lisan või eemalden, aga see tegelikult hästi mugab, et ma saan appi kaudu küsida klendi JSONi, mulle kõik palju, kui ta andalt käes, ja ma ei pea eraldi päringu tegemad otsida erinatest kaustadest või dokumentidest, mis saan, et ma tahan, ja neid kogu kudagi võib-olla klendi brouseris kokku joinima, vaid mul ongi üks JSON, ja ma saan JSONid kirutada anmebasi, ma saan JSONid fetchida anmebasist ja ongi kõik, mis ma vajaan, et ma saan klendi idei järgi need JSONid fetchida, ühendada ja kõik. Ja partitioneerimisest ma juba rääkisin, aga põhimõtteliselt partitioneerimine ongi siis anmete jagamine, ütleme kas failideks või serverite vahel niimoodi, et need anmed, mida meil on tihti vaja koos hoida, on salvestatakse ühes serveris või isegi ühes failis, mõnikord on meil lihtsalt kasulik karanteerid, et anmed on samas failis, et siis piisab, et ketavad üks fail luge, et ainult. Ja see ongi põhimõtteliselt sama, mis killustamine SQL anmebasida puhul. Ja osad anmebasi enginid annavad kasutatele võimalus, et isedefineerida, kuidas sa partitioneerimine toimub, et saab näiteks defineerida, et kas partitioneerida, mis tulpade kaupa partitioneerida ja kuidas arvutada partitsiooni idei väärtus, et mis on partitsiooni identifikaaturi. Ja mitrerelatsioonist anmebasides tihti tuleb, kui kohe alguses anme modelid designimise käigus välja mõelda, et mis see partitsiooni struktuur peaks olema, et mis väljade põhjal me paneme paikat selle partitsioneerimise. See on niile nummade, et kui saab? Saab, aga see lihtsalt võib olla väga kulukas pratses ja see tähendab kogu anme tabeli ümber konverteerimist, mis saab toimuda samal ajal, kui see anmebasid on tööl, aga ta aeglustab kogu anmebasid, kui sa näiteks on 10 giga paiti anmeid ja sa taad seda ümber konverteerida, sest see võib sulle terve anmebasid kooma tõmata samal ajal, kui sa teed, et võib-olla ööselt teed, et see on okei. Aga teene asja on ka, et need eriti chase on anmebaside puhul, see võib mõjutada ka sinu koodi, et kui teadud olukordade saab teadud asju joinima klendii, brouseris, siis tõenast on saad, et sa kirjuta mingi JavaScript-kodi, mis sa tead, ja kui sa enam ei pea seda partitioon, võib kusulnud partitioon muutub, teoreetist võib su JavaScript-kodi vajam olla muuta. Ma pole päris sellest kind, aga see võib isegi koodi ka mõjutada. Ma pole päris kindel, kas sa oled korvata korraks? Ma enne juus öel, et pilve arutus, et sul onki teatab hulli nagu üks. Ia, et selles mõttes küll, sa aati näed seda klendi oma koodist, et ta nagu üks serveri ja sai näegi, mis seal taga toimub, et kas nad omavad suhtlevad mitte. Teadud päringud olisid aeglasamad, kuna serverid peavad päringule vastamiseks lugema, kas paljudest partitioonidest anmeid versus, et oleb ainult ühest partitioonist, mis on fiilid asemel võida, peab isegi teiste nõudide, kas anmeid küsima, et sinu päringule vastata. Ja sinna näed ains seda, et latentsus on teine või võtab kauema aega, et vastata sinu päringul. Sellisiljul kood oleks sama? Sellisiljul kood oleks sama, aga see natuke ole näeb, et teatud enginites nagu Firebase, Google'is, Google pilve või just Android, Firebase back-end jaaks. Seal võib sulle oleisid limiteeritud, mis sellise teha saad. Et sa näiteks ei saagi grupeerida anmeid, kui anmeid ei ole juba ette ära grupeeritud. Ja sa tead teha ainult mingisugus teatud limiteeritud operatsioon, et kui sa vaatad, et mida sa tahad pärida, seda võib-olla raske seletada, aga meil oli ühest projektisse problem, et tuden kasutas, Firebase ja eeldasime, et me saame raporteid hästi teha, aga lõpuda lõpuks anmei pasi on päringud, millega need raporteid teha ja mis tuli teha, et ta pidi alla tõmbama teatud hulga anmeid ja siis Javascriptis grupeerima neid ümber. See võib-olla on natuke teistukene probleem, mida sina sõnastasid, aga põhimõtsalt teatud olukordes sai kruugigi saada päringud teha, kuna anmei pasi enginite ei toheta seda. Aga tõesti, et kui see toimub ainult sissemisel, siis selisel juhul sa koodi muutma ei pea. Kui see toimub ainult taustal, anmete lugemin erineutest partitsioonid, erineutest serverid, siis tõesti see reaalselt sinukoodi ei toveks üldse mõetle. Siin on üks näid, et kui me näiteks on loogine struktuur, et me salvestame anmeibasi, tüübi nime, riigi ja mingisõlguse kuu ja aasta kombinatsioon, mis aastele, mis kuul see kirja toimus. Ja nüüd me taaksin raporteerida, siis kui mõetli mäljataan kuupäeva ja tüübi kaudu, et me taaksin iga tüübi kohta teha raportid. Ja me teeme mingisugune SQL päringud, kruppeeri anmed siis kuupäeva ja tüübi kaupa, aga anmed salvestatakse anmeibasi tavasalt mingite failid. Nii on teha, et anmed ei hige suured olla. Meil oitaks anmed erindas failides ja kui meil ei ole partitsioneerimist, siis tavasalt anmed suure tõenudse ka kirjutatakse kuupäeva järjest, kuna tõenudselt saabusid selle samal kuupäeval või vähemalt lähedal omale kuupäeval. Või vähemalt kuupäevade järjekorras, ütleme pandi anmed anmeibasi. Tavasalt anmed on enamväem sorteeritud kuupäevade järgi erinudesse partitsioonidesse, aga need tüübid ei ole kui nagu kruppeeritud. See tähendab seda, et kui me teeme päringu näiteks 2011 veebrorikohta, siis võib-olla meil õnnestub sultsed vähe partitsioone läbilukada, saada 2011 veebror annad kätte, aga kui me teeme 2011 veebror ja tüübi neljakohta mingi päringud, siis on suur tõenudses, et me peame kõik partitsioonid, kus on 2011 ja 2002 läbilukema, need võib palju partitsioon olla ja siis me peame nagu kõikides nendest näid tüübi annad välja koguma. See tähendab seda, et meil on vähev, siin aga näha, et see kaks tõtti on siin, siin, siin ja siin ei ole, et partitsioonid meil võib-olla puntumar peab, kui andmed tulad lugehti selle partitsioonid. Ja lisaks, kui kuupäev ei ole nagu see partitsiooni määraja, siis andme vasitea, misuguses failis on kuupäev. Et lisaks selle, et me määrame kuupäev on nendeks partitsiooniks, andme vasitelt meeldas selle mätpingu, selle partitsiooni muutu ja siis nende failide vahel. Et andme vasitelt teav, et siia ei pea maatsuma, kuna see fail ei ole seotud partitsiooniga, mille nimes või võtmes olnud justus kuupäev. Aga kui me kasutame nende kuupäev jaa tüüpi partitsiooneerimisel, siis andme vas hoiab andmed niimoodi, et ta proovib hoida võisigi karanteeriteks, et hoiteks andmed niimoodi, et samas failis on põhimõtteliselt need andme, et andmed, mis on sama tüüdii väärtuse ja sama kuupäev väärtusega. Võib-mist prooviteks või hoiteks endud samad andmed, mis on sama väärtusega koos. Ja sellisel juhul on meie päring pudetab vähem fail ja selle, kes andme basi engine saab kiiremini vastata meie päringkuttele. Läheme nüüd nende pilveplatformide juurde ja me räägime natuke kaar nende mitrerelatsioonist andmebasi tüüpidest, et pilved eelised on mõnesmates üldised, aga ka andmed, baside puhul, me saame lõpmatute resurssid ilusiooni, et teil on võimalik, siisiga amas on küsida täiesti hallatud andmebasi, kus teid ei piisagi teadma palju sellest serveri, aga on te maksata näiteks päringkut arvuest ja enam ei maksa serveriteest. Tihti teadud teelused me saame ilma ettemaksutada, kasutada, et väikse projekti, kuhul me võib-melle ei peaagi andmebaisest midagi maksma, kui nimeil kasutat ei ole. Olen, et andmebasi mudelist võib olla arvetus sellised mudelid erinevad, et mõnedes andmebased ja puhul me maksame serveriteest, teistest me maksame päringkut eest, et me saame teoreetised valida endale sopiva sellise hinna mudeli. Pilve teenused võimalde, et pakkuda rohkem skaleeritavad teenused, et amasõnist või asulest saab otsida andmebasi teenuse, mis skaleerib ised, meie peab selle pärast muretsemat, kuidas Postgres klastrisse serverid juhuda panne võimaldada. Ja mida minam õtlen, siis hajus andmebasi pilve teenust all on sellised hallatud salvestust teenuste pakkumised. Selle peal võib mõelda, kui salvestus kui teenus või storage as a service. Ja kui kiis sellist ametliku klasifikatsiooni väga eksisteeri, et see on ka natuke halb nimist taas. Ja nende eelis on see, et pilve teenuse pakkuja saab huolid seda kogu installeerimise, konfiguratsioonimise, ülesseadmise ja partitsioneerimise varukoopet eest. Et kui te võtate täiesti hallatud pilve teenuse, siis te ise ei pea halldama näiteks, et kui tihti teaks varukooped. Aga see natuke oleme ja me vaatame erinevaid tüüp, ja mida ainult neid, mis see tabakuad. Peamised tüübid, mis on, on sellised võtti- ja väärtusanmebaasid. Mõnikord nimetadeksene eka paket või ploobanmebaasid. Peamine põhjus selleks, et hoiteks anmet pigem sellist pinaarsete anmetena. Ei vaatata väga sisse, mis on anmetesiehemine struktuur. Nagu kui te SQL anmebaside puhulte näete, mis tulbaad sees, mis väärtsalt sees on, sellise ploobanmebaside puhul väga sisse ei vaatata. Hallatud SQL anmebaside me saame täpselt samad. Postgresi või MySQL või Oracle SQL anmebaside ka seda hallatakse pilve teenuse pakkujapolt. Või siis hallatud mitte relatsioonist anmebasid. Hallatud relatsioonist anmebaside jaoks on peamasest kaks tüippi. Üks on see lihtne, SQL serverid, et me ei saa klastrit nõudmisel, et lihtsalt Amazon paned meieoks ühe nõudilise Postgres anmebasi üles. Või siis paned üles klastri näiteks, et meil saavad olega täielikult hallatavad kilustatud SQL klastrid, et Amazon panedki meile üles näiteks Oracle SQL klastrid. Ja need erine teenused, mis eksisteerjad Amazon RDS, on selline, kus te isesate valida, et mis on see serveris olev anmebasi engine, et saab olla Postgres SQL või MySQL SQL server. Põhimselt see on lihtsalt teenus, mille abilte saada hästi kiiresti klastri üles seada. Ja siis on see, et ma ei saa klastrit, ja see on siis jaas Postgres SQL server ja Amazon saab teile üles, et ilma, et täksite ise haldama näid virtuaalmasinaid. Mitterelatsioonist anmebasid, neid on peamiselt sellist kolm tüpid. Kas võtiväärtus anmebasid, mis on hästi lihtsalt, võite ette kuhutada, et ma panen mingi anmebasi võtmeja väärtuse ja rohkem väga struktuuris ei olegi. Kui me peadetakse rohkem struktuuriga, võtme selle väärtuse sisse. Sellist anmebasid on AVS DynamoDB või Google Cloud Datastore. Teist tüüpi, mida me tänna vaatame, on dokumentipõiset anmebasid, kus panaks see mingi XML-file või JSON-file anmebasi, kus võtja JSON-faili nimi või JSON-faili ID. Meil väärtusas ära, et meil väärtas ongi üks JSON dokument. Näiteks AVS DocumentDB, IBM Cloud Ant, mis on KAUSTDB põhine, või see näiteks Google Cloud Firestore on selline JSON anmebasi. Lisaks on sellised suurda abeli anmebasid või veerkude perekondade või kolumnoorjantat anmebasid tüübid, kus üks peamiselt on veerkude perekondade tüüb, kus SQL-anmebasi on tavaliselt, relational anmebasi on tavaliselt ridade kaupas olestatakse, aga veerkude perekondate tasemel põhimatselt kombineeriteksse kõik teie tabelid SQL-anmebasis nagu üheks, tuureks tabeliks, mida nimedates kolumfämilii tabeliks. Ja selleks on peamiselt kas Sandra on üks kõige tuntumaid anmebasi, vabaavatud anmebasityppe, mis kasutab seda veerkude perekondade mudelid, aga ka Google Pequery. Amazonis on selline Amazon Managed kas Sandra teenus, mis seab teile üles alles ja kas Sandra Clustry. Ja nüüd vaatame need kolme tüüpi, et mis on siis need kolm peamist mitreraatsiooniste anmebaside tüüpi. Kõige lihtsam ongi võtiväärtus mudel, kus me lihtsalt paneme anmebasi anmeid, meil on võimalus saata kettspäring, et anna mulle mingit anmeid mingi konkreetse võtmega. Meil on põhimatselt selline postpäring, et pane anmebasi uus väärtus selle võtmega ja siis kusutamise päring, et kustuta anmebasis selle võtmega anmed ära. Ja teatud anmebasisid, see on rohkem võimalusi, aga põhimatselt võtiväärtus anmebaside mõte on olla tohutult skaleeri vanmebaas, aga hästi lihtsam anme mudelik, et panna ainult võtmega väärtusi ja lugeda võtmega väärtusi ja kõik põhimatselt. Ja väärtusesse väga sisse ei vaadata, vaadatakse, kui lihtsalt mingisugune väärtus, aga sa ei saa väärtuse sisu põheal väga pärida, et ainult võtmeta põheal seda anmeid pärida. Et näite, et on näiteks TainamoDB Amazonis, Riaq, Apache Ignite, ArangoDB, BerkeleyDB ja Couchspace, kui Couchspace on pigem selne Seishan anmebaas. Ja nad on hästi horisontsaasa skaleeritavad, sest me saame võtmed või kogu selle võtmet the namespacei agada tohutult paljute serverite vahel ära ja meil ei ole, kuna meil ei ole väga keerulisi päringu keeli, on ainult võtmet järgi võtmene, siis tegelikult saab hästi kiirendada anmetes lugemist ja anmebaasi kirutamist. Et anmebaasi lugemist ja kirutamist on tägelikult hästi skaleerida ja meil ei olegi nagu selle join päringu tohi mõtsult nii, et meil ei tekigi probleeme selle, kui anmed on erinudne serverite vahel jagatud. Ja see on üks kõige skeema vabamaid mudeleid üldse, et meid anme tüibid võib-olla väga ei huvitagi, tüib võib-olla üks kõik mida ja klienti ise hiljem selle anme väärtus, aga teeb, mis ta igasest tahab. Ja tüibilselt pakutakse sellest rest, liidastad, ketput, post ja elite päringud, et need anmeid muutasis anmebaasis. Ja anmete päringne võtme järgi ja kirutamine võib-olla väga-väga kiire olemb selles, ku palju serverid on, ku palju kettaid nende serverides on ja kui paljusaparaliseeritud on. Ja sellena hästi lihtsustatud visuoloatsioon ongisi meil on lihtsalt võtmed ja väärtasad anmebaasis. Aga teil tegelikult tegib kohan küsimus, kuidas ta siis ise disainiks ühtegi rakendust, mis selliks lihtsalt anmebaasi kasutaks. Et üks viis seda teha ongi peita loogika võtmes ära. Me võime ette kujutada, et meil on kasutajate tabel, kuidas ma kasutate infosalvestaks võtme väärtusena. Ma võiksin seda teha niimoodi, et ma võimast, et tekin tahan struktuurid oma rakenduse jaaks, kuidas ma väärtused anmebaasis valvestan, ma panen visa struktuurivõtmetesse. Et mul ongi näiges, emploii anmed, emploii tabelis esimene kirje ja selle esimese kirje, kõsteem tult, võldub mati. Ja see on kogu minu võtmi. Kui nüüd mina tahan pärita, anna mulle esimese töötaja nimi, siis ma otsingi emploii, siia panen töötaja ID, kool on nii siia panen, et ma tahan first name nagu tult pakette saada. Niimoodi saab tegelikult rätliteerida sellist relatsioonilist anme struktuurid võtgi väärtus anmebaasis. Ma tekitan ki omale struktuurid, et võtme esimene komponent, on siis nii-haldi, et näiteks näiteks olemi ID ja võtme kolmas komponent, on olemi tult või olemi mingisuguna muutuja. Ja kui ma tahan tegitada näiteks mingisugus mappinguid, saaks ka tegitada, et ma olen, ma teen seda pigem hiirega vist, et meil on payment kahe kasutavahel, kus meil on võtmeks panem, et meil on payment esimese kasutapayment, esimese kasutapayment ja siis selle makse suurus oli 10 000 ja samuti, et esimese kasutaja, esimese makse kuupäev on selline. See võib-olla on natuke halb, sest meil ikanaku väärtiseks küsimiseks võib-olla on vaja eraldi teha ketparing, aga võib-olla anmebaas tuetab mingisuguselt wildcard, et me saame küsida näiteks, Anna mulle, emploi, kool on üks, kool on staar, Anna mulle kõik võitmed, mis algavad prefiksiga, emploi, kool on üks, ja siis ma saaksin kõik sellega kasutaga anmed küsida korraga. Et see täiesti olevab, kas anmebaasi engin siis toetab sellised wildcard ja näiteks võitmed pärimisel. Ja see on üks selline lihtne näide, et kuidas saaks disaimida SQLi anmebaasi puhtalt võtiväärtus stiilis. Näiteks ka teene näide, siin üleval on Amazon S3, hoitakse file. Me võime üks oma eest pildi file hoida Amazon S3, aga kuidas me teeme nende pildi file-te vahel vahe, et me lihtsalt aname näile tee selle pildi file-ini. Ja Amazon S3'es pildi asukoht ongi unikaalne asukoht internetis, et meil on näiteks siis mingisugun HOTATEPES. S3, et ta on U.A.A. West 2 regionis või ava öelja piliidisoonis, Amazoni SE-s, ta asub mypaketis, mis on unikaalne, unikaalne nagu S3 container või kaust, see peab olema unikaalne kogu Amazoni selles regionid vähemad. Mypaketis saeks siis teerida kahel kasutel samas regionis, et see punan osan siin täiesti unikaalne väärtus. Aga siis sellest kaustavõi paketis Ees on tääristid suvalne file struktuur, et ma võin tekitele see kaustu ja ma võin siinna panna siis file.jpeg. See tähendab, et see on selle file identifikaator siis sellises võtti väärtus fileid annebasis ja selled täielik ID koosneb mittele talam komponidist. Esiteks, mis ava öelja piliidisoonist on, teiseks, mis unikaalne paketis on ja kolmandaks, mis on selle paketi T-failini, mis on selle file T selles paketis praegimaltselt. Ja kuna see on unikaalne identifikaator interetis, siis seda saab rakendustis kasutada selle file aadressina, kus selle file aadressi sees on tegelikult ka selle annebasi aadress, ehk s3.amazon.avs.com. Nii et kui ki, see võtti väärtus annebasi on hästi lihtsad, on palju keerulisemaid anne struktuur ja võimalik nendes nagu dublikkeerida. Ja s3 on mis siis üks nendes näideltest, mida ma juba korraks kirjeldasin, et jälgib täiest seda võtiväärtus anne struktuurikus võtmõde lihtsad fileid asukohad ja väärtus on selle filei sisu, ehk mis anne seles filei sees on, ehk file ise võimatsed. Võimatsed. Ja see võimalde, et see hästi palju anneid salvestada s3-le, ehk võimatsed teil piirangut ei ole, teil on lubatud küll sada paketid luua, sada on ikka asut paketid, aga vajatus seal saate õiguseid rohkem juurde küsida. Ja otsast anne te struktuurive skeemad see ei ole, et ta võite üks kõik mis file sinna üleslaadida, alguta textfile, videofile, pildifile ja nii edasi. Ja meie ise kasutama asures, siis võib-olla asure file storage akounti või asula blob storaged, Google Cloudis anda Google Cloud Storage, IBMis on Google Cloud Object Storage täpselt samasugunud kui S3. Kui te soovite vabavaralist, siis kasutage minnajood, et minnajoon tegelikult võimatsed Amazon S3 clone, et saate Amazon S3 teke ära kasutada selleks, et minnajoos saan meid kirutada või lugeda. Kui soovite anmed ära liigutada Amazon S3-st oma serverist, siis saad mini-io ülesseada selleks. Selles ma enam rääkisin, aga ma rääkin selles järgmises laidi peal. Amazon S3 on tegelikult ka tähtis, kuidas standmaid salvestate ja mis suurbust konfiguratsioonide kasutate, sest selle põhel takkata maksuma. Amazonis te maksate miinimum 30 päeva eest, nii et kui panate ühe fail üles, kolmeks tunniks, te maksate 30 päeva eest. See ei ole nii, et te maksate vähemseled. Kuna ta võtab ruumi, siis ongi selline miinimum tasu, on 30 päeva salvestuse tasu failid. Aga Amazonis on erinevad nagu salvestuse klasid, on S3 standard, intelligent hearing, standard infrequent ja siis S3 classier. Kui standard on standardne anmete salvestus, kus te taab reaal ajas näid anmeid kasutada, näeteeks te teete mingisuguse kaleriirakenduse ja kaleris panete otsa S3 linkid ja siis kui kasutad, läheb teie kaleri aades automaasut tõmateks ja pildid S3-st alla, et te reaal ajas soovite neid faili kasutada. Et siis saate S3 standardid kasutada. Standard infrequent tähedab seda, et te ei soovi neid reaal ajas kasutada, teeldad, et näid anmeid kasutad kord päevas, kord nädalas, näeteeks hoiate seal mingit anme, data sette, et teete anme tõetlust, teeldad piltitõetlust ja igasekk on neid kasutad. Et siis infrequent accessi ka tõttu saate vähem maksta nendest, kui reaal ajas kogu aeg ei ole neid anmeid vaja. Et pigem kasutad seda standard infrequentid siis, kui mingit teised pilved eenused kord päevas anmeid tõetlev on. Ja kolmas tüüp on S3 classier, mis on põhimest arhiiv. Et siin ei teanud, et saalvestada anmeid päevadeks, kuudeks, aastateks, et te ei saagi neid reaal ajas kasutada, et anmeid otsasalt ei ole kasutatavad suvalsel ajal. Ja võib võtta minuteid kui tunde, et enne ole anmeid teile ligi pääseda. Ja on eraldiga ver classier deep archive, et siia salvestatud failid minimum või nagu võib juhtuda, et ei saa kui 12 tundi anmeid teile ligi, kuude ütlet, et tahate need anmeid kätte saada. Ja siis te maksate minimus 180 päevas, et pool aasta eest. Aga miks need nii palju on? On selled ütlet, et Amazon tahab optimeerida, et kuidas need anmeid kasutatakse ja siin et salvestatakse erineval viisil. Ja teiega maksate väga erineval viisil, et kui te kasutate täiesti standaardsed anmetes salvestamist asure või Amazon S3-s, siis te maksate ühe terabyte anmetes salvestuseest 23,6 dollarit. Te maksate lisaks infopäringuteest, et kui te küsite miljon korda, mis failid on seal, mis on nende failide suurused, siis te maksate iga infopäringu eest, aga anmetallatõmbamine ei lähde teile mitte midagi maksma. Et te saate tasuta nagu anmetallatõmata. See on üks väga suur aga, eik tegelikult läheb anmeted alatõmbamine lisaks veel nad ka maksma, aga S3-ootsaselt ei küsid asut sealest, et te maksate põmst võrgu kasutamiseest. Teised poliitikat kõik on natuke odavamad salvestuse osad, näiteks S3-klassiärki parkhaivas teileb maksma üks dollar, kuus ühe terabyte salvestamiseest. Palju odami, 23 korda odami. Aga, see on suur aga, alatõmbamine maksak 20 dolar, teravadikolt. Ja te saate nagu kaua aega salvestada sinna ja lõpuks alatõmbamata, aga siis maksate nagu 20 dollar lõpuks. Ja ei tea, nad siis S3-klassiärki parkhaivi puhul Amazon saab kasutada salvestuseadmed, mis see peale olema ots võrgu ühendatud, saab kasutada neid lintkettaid, mille sa anmetest alastan odavam, aga need ei pea olema reaalast kasutatavad ja võtavad kui nii 12 tundi, et anmetel liigi pääsad või lõpuks. Ta võib-miseks kobeerivad anmet teistel seatmattel, et teile kättasad alg teha. Ja S3 infrequent accessi puhul, ma vaatan, kus sa asus. Mis siin? Ja siin te maksate kaks korda vähem, anmete salvestamises 6, aga siis alatõmbamiseest maksate 10 dollar, kui standardis oli alatõmbamiseet asuta, infrequent access on salvestavad odaam, aga alatõmbamiseest maksate. Põhimõtteliselt idean, et te saate anmeid salvestada pidemalt, aga alatõmbamiseid maksa, ja tegelikult standard on kõige odaam olukord, kus te kogu aeg on uuesti alatõmbate. Ükskald päevas tõmbate terapeid anmeid alas teha, ükskald päevas 10 dollarit terapeidikohta maksat, kui siit alatõmbate anmetsis. Põhimõtteliselt standardi puhude peaa anmete kasutamises maksama midagi. Mis siin pooleb kus toivad? See on siis, kui sa saadad info pärin, kui S3 listid kõik failid kaustas, küsid, mis on failid suurus, metaanmeid või metaanmeid küsid näiteks, mis tüübi failid on, et sul näiteks mingisuguna rakendus käib ja listib kasutale, mis pildid on kaleri kaustas näiteks. Et iga kord. Liselt seda, et rakenduse teist pämiks seda liiga palju, siis amas on kõib rahasel eest. Et see põhimõtteliselt treening kasutavad, et vali endale õige mudele, siis kasutat optimaalselt. Ja et teie teist kümmele. Ja, et pigem cashi, et siis sa ei maksa sellest. Mõnesmõtteliselt samas on liisa tulu, kui sa teed seda, nii et nendel midagi väga paha ei ole, et saad rahalist sellest. Aga, ja siis kindlasti on see, et kui kogu aga allatõmata, siis pigem kasutada ja SKM standardid ja maksda fixeeritud hinda kuus. Ja siis allatõmuses, ma peab maksma sest muiduvõib. Ja siis üks on, lisaks on, intelligent standard on see, et nii ise valid mudelid automaatselt vastavalt kasutas mustrile. Et siis sa ei päris ära otsustama, et kui teid ei pärit, siis jäljal muudetakse infrequentiks ja kui neid ei nagu suuesti tilti pärima, siis ta muuda võib automaatselt nataka siin standardi. Proovid karanteerid, et saate mõistliku hinnaku, kui ise ei soovina, ette otsustata, mis politikete kastutada soovite. Aga selle kohta peab kindlasti iseja rohkem lugema, et kui ta täpselt toetab ja muidu ei tea, kas ta kõige odomaks osutab. Miks see plasiira on, kui see plasiira nii parpaili, kui kui sa oled põttas? See on see vahe, et plasiiripuhul sa maksad poole aastaest minimum. Ja kui plasiiripuhul sa saad, plasiiripuhul nii parpailikult, sa maksad kui nii poole aastaest ja plasiiripuhul sa maksad kui nii kolme kuuest. Ja plasiiri almed hoiteks enam vähem sellist, et serverides, mis sa minutite või tundidega saadavad, aga Deep Ark Havis võtab vähemalt 12 tundi aega enne, mis oligi pääst. Võib sa ma kui nii kohastast? Jah, kui nii 12 tundi võib pole, ehk mitte minimalt. Ma arvan, et see on piigem kui nii 12 tundi. Ja Deep Ark Havis sa oodad näiks anmed, mida võib olla mingisugun riigiasutus nõuab, et sa alles oodad 10 aastad mingisugused kirjeid, aga sa ei kõnagi kõna kõik kasutada lihtsalt, kui hiljem riigiasutust ütlepead. Saada meile need anmed, sest sa küsid Amazonist, aga saad väga nagu odaavad. Võib pole need anmed, mida sa kõna kui planeerigi alla tõmatad. Igaks juhuks, aga mitte kõna kõna kõna kõna kasutada, sest sa näist odaavad. 1 dollar. Mul on väga võib, et kui tiis pigisaab, kui see siirti Deep Ark Havis, kui sa 23. tundi, siis sa odaavad kaks kord. Siin on siis 4 kord odaavad. No, et sa oled nii, mis on viinil vaja, et 9. päevad, siis see on 28. päevad. Siis on sulle odaavad seda võida ja sulle on ka kättesaljumt arvas odaavad. Jah, et kui sa plant stand, kui kuu aega oida, siis see ei ole mõted. No, kolm kuud oida, siis ei ole mõted Deep Ark Havis kasutada, aga hea oida, seal neid anmed, mida sa pead, nagu alles oidmaga ei tule kus kasutada. Kui pole mõid, kolm kuugul tiimurvasi või kõrvõi kõrvõi kõnala, kui isa standa. Jah, aga kui seal on koostus, et aasteid oida, siis... Jah, siis pead. Teine mudel, mis sisemisel samuti kasutab võtme väärtusmudelid ja mida te tõenastavate kõige rohkem kuulud mitralatsioonist anmebaasidepuul, on siis dokumenti anmebaasid. Ehk ei tea, nad me kasutame uuesti võti väärtusmudelid, aga väärtus on mingi struktuurist dokument, et me paneme anmebaasid asemel paik, et väärtus on alati XML dokument, aga tavast on ta pigem JSON dokument, ehk JSON anmebaasid siis. Rangemad skeemate struktuur ei ole, ta on JSON, aga me ei uvita väga nagu anmebaasi tasemel, et anmebaasi kontrolli, kas selle JSON sees on mingi teatud väärtused. Võib-al-a, ta nõuab, et seal oleks datetime ja ID JSON dokumenti sees, aga ülejäänud tulpad või väärtused või võtmed JSONi sees on nagu klendi või rakenduse määrata. Anmed päritakse, siis kas võtmekaupat, anna mulle teatud JSON dokument kindla IDga ja mõned anmebaasid tuhetavad ka päringu keeli, mis vaatavad JSONi dokumenti sisse. Näiteks MapRedus saarvasid päringud. Näitid on CouchDB, MongoDB, CouchSpace, Mongo, üks kõige populaarsemaid, kui osad vihkaad, mongod osatele meeldib Mongo. Aga üks kõige kasutatamaid on Mongo. Teavad te kõik JSON dokumenti näinud, aga siin on lihtsalt üks ilustreerimise näide, et milline see JSON dokument võib saamebasis olla. Põhimise, et me ei võib olla mitmed tasemelised JSON dokumentid, meil võivad lisaks sellele näitel olla ka mapid ja listid see, et meil ei pea olemada ühe tasemeline või kahe tasemeline. See on kahe tasemeline, JSON dokument võib ole ka viie tasemeline, kus on järjest rohkem alam JSON-aid sees. Aga kui ta vaatata selle peale, siis kui ta on ühe või kahe tasemelise, ta on tegelikult väga sarna põhimadsed SQL tabelile, et meil on tulbaad, business ID kategoris, city, open, leditud, longitud. Me saameb võimselt sarna tabelistruktuuriga JSON-is hoida, lihtsalt meil on võimalus kasutada alam JSON struktuuria liste ja mäpe ja muid selliseid. Meil on peamaselt vahekas on string väärtus, juttumärkiidega eraldatud või numeerilised väärtusad, aga opselt meil ei ole väga range tüüppe. Võib juhtuda, et ühes dokumentis on mingi väärtus string, teises dokumentis on sama väärtus integer ja anmebasikontrolli, et need oleks alati stringid välati integerid. Ja seal tulevad lihti vead sisse. Ja kolmas tüüp on veerkude perekondade mudelid, kus põhimõdselt me proovime saavutada sarna olukorda, nagu ma loen ka alguses näitasin, et igas tabelis on täpselt sama kasutada ID või mingiselt, kus võtme väärtus. Seda nimetadeks ka veerkude perekondade nimeks, aga seda võib mõelda kui tabelite gruppe. Veerkude perekond on enamam sama kui SQL tabelite gruppid. Anmed on salvestatud suurte tabelite struktuuridest täpselt nagu SQL-is ja veerud me gruppeerime nagu veerkude perekondadeks või mõnes mõttes tabeliteks, et meil on nagu tabelid ükstise kõrval võib selle peale mõelda. Veerkude perekond on loogilne veerkude grupp, mõnes mõttes sama aegimist tabel SQL-annebaasides. Meil tekivad sellised mitmed asemellised võitmed, aga ma sõle koht räägi natuk hiljem. Väga suur erinevus SQL-annebaasidesest on see, et meil on võimalik suvalisel ajal veergi juurde panna. Ei ole üldse eriline, et veerkude perekondade annebaasis on sadatuhad veergu. Mis on natuke imelik, SPL-annebaasisidile mõeldes, aga see on teatud kindel muster, miks seda nimadi teevad. Näite, et kõige tuntum on kas Sandra, aga big-tape-ol on hästi tuntud Google'i pilves. H-space-jakumul on ka vabavarralised annebaasisid. Kõige tuntum on kas Sandra. Kuigi kas Sandra ennast väga meerkude perekondade annebaasisks enami nimeta, ta proovib näita ennast on. Kui kasutatele lihtsalt SQL-annebaasina. Kuidas see töötab on umbes selline, et meil on põhimõtteliselt üleval on loogilne veerkude perekona mudel, kus meil on mingisugune olemon võitmaks, näiteks kas see võib oleks kasutaiide või asutuseide. Siin näiteks on kasutaiide ja kõik selle kasutajaga seotud annemed on ühes reas. Meil tekeb see hästi lai tabel, kus me paneme kõik sama olemiga seotud annemed ühele reale ja meil tekik ainult üks tabel. Aga see tabel on hästi lai ja meil tekivad kolm familid või veerkude perekonad, kus meil on tohutult saaran SQL-ile, et meil on kolm tabelid, nimete, kontaktite ja messages tabel. Põhimõtteliselt see ongi täpselt sama asi, et me paneme mis taabelid kõrvuti, me karanteerime, et igas tabelis on ID, mis on täpselt sama, näiteks kasutaiide ja kõik annemed igas alam tabelis on seotud selle sama kasutajaga. Meil tekibki selline karanteeritud ühe olemiga tabelid komponent, me lihtsalt nimetame iga tabeli kolm familiks, aga meil võib olla kahte tüüpi kolm familid või perekondi. Ühed on staatilised, mis on sellised tavaliselt staatsed annemed, et meil on kasutate anned, kus me hoiame kasutanime, eesnime ja perekonnime või kontaktid, kus me hoiame näiteks e-maili ja telefoninumbrid, aga meil lisaks on speciaalne tabel, mida nimetateks, dynamiliseks tabeliks, et näiteks messages. Ja selle idee on, et me saame siis ühe kasutapoolt kirjutatud sõnumid, panna kõik ühte tabelisse niimoodi, et nad asuvad ühen reaal. Meil tekibki selline võimalus, et neidest kasutajatellimused või kasutajapostitused või kasutaja mingisugused püsivald, pidevald tehtud tegevusad panna samas rita, ja kudas me seda teeme, et me tekitame näiteks messages tabeli ja see tulp messages tabeli sees on üks kirja, ehk üks, siin on täisest üks message, et messel tulp isa nagu message ID, ehk ei item one, item two ja nii edasi, ja selle tulpa väärtus on põhimestad sõnumise. Ja see idee on, et me saame siis kasutasab siia kirjutada, et 10 000 sõnumid, tegib 10 000 tulpa. See on SQL vaatas hästi imelik, miks me paneme tulpadesse, aga tegelikult füüsiliselt ei hoita neid tulpad, et füüsiliselt hoitaksa neid võtme ja väärtustana, nii ku nii, need ei ole vahet, et me nad niimoodi defineerime. Reaalselt hoitaksa anmed kõik nagu siin alumises tabelis on, et meil tekib selline anme struktuur, kus paremal pool valge tulpa on väärtus, ehk Chase Smith on võtijäväärtus anmebasisest põhimestad lihtsalt väärtus, ja kolm elmist tulpa on nagu kolmed asemine võti, et meil siis tekibki anmebasis võti a001 names, username ja väärtus on Chase Smith, või siis a001 messages, item 7 ja message 7 on väärtus. Meil tekib selline mitmed asemelline võti ja siis väärtus anmebasis. Põhimest, et anme struktuur, mida hoitaksa näites ketal failides, on pigem selline võtiväärtus anme mudel, aga loogiliselt on ta kasutatav kui tabel. Miks me seda loogiliselt tabelne kasutame, sest me tahame SQL kasutada, et me saame teha näiteks select from names, select names dot first name dot, ja select names dot first name, where id võrdub a001. Me saame SQL kasutada anmete päringute tegemisel, isegi anmete sisestamisel, et insertiga lisada anme-tannebaasi, aga füüsiliselt hoitaksa neid sellisel kujul, ja füüsiliselt tihti hoitaksa staatilised kolumnid, staatilised perekonnad ja tünnaamistist perekonnad täiesti eraldi partitsioonides. Ja tühe partitsioonid on neid, mis alati jäävad samaks ei muutu, eks staatilised, ja tünnaamistest partitsioonid hoitaksa sellistest failides, kus me kogu aeg paneme asju juurde. Iga kord, kui kasutajad uue sõnumi kirutab, me tekitame sinna uue sellise kirjet, poemist a001 messages, item n plus 1 võrdud message n plus 1, mis saad lisame appendime sinna file sõnumid juurde. Ja selled, et meil ei ole probleem, kui üheski tuulbaas on näiteks 10 000 värtustest. Tegelikult neid ei hoita tabelit enam ja ei teki sellist tühja, selled, nagu ei teki, et meil tühjad sellid või sellised tühjad blokit tabelis ei ole ütse probleemit, kuna neid füüsiliselt kusagile ei hoita. Et nad failis ongeliselt tühjad, et näid, et see ei eksisteri. Ja kas Sandra ongi üks näid, mis lubab kasutada SQL päringud, et sellises anmebase anmeid siestada ja pärida, reaalselt füüsiliselt hoitaksa need erinevalt, et ei hoita nagu savast SQL anmebaseid, et iga rida koos, vaid partitioneertaks siis nende perekondade kauppa erinevadest. Eri naates ja failidesse, aga see põmist anmebasei engin ise otsustakud, kuidas ta päriselt tahab anmeid salvestada ja partitioneerida. Ja nüüd me oleme jäägi lopetamas, et kõik see, millest ma rääksin, see ei tahe tähend, et teie ei peaks relatsioonist anmebasei kasutama, et kui teil on väike projekte, teil ei ole vaja sadud enam paite anmeid, siis teil ei ole vaja hiigel suuri skaleerioid anmebasei kasutada. Kui teile ei ole vajad, siis pigem kasutada tavalisi relatsioonist anmebasei, kuna ta on vanad proovitud ja testitud tehnoloogijad, et tõetad hästi. Ei teki seda probleem, et te võtate Firebase kasutusele ja siis kolm kuud hiljem saate aru, et teil ei ole ikkui võimalik agregeeritud statistise raporteid teha, sest anmebasei engin seda ei võimalda ja siis te peate kõik seda klienti arvutis JavaScriptis tegema hakkama. Et allad on paha mingid kogu kuu anmed jasonina ja siis hakkama JavaScriptis agregeerima. Nad on hästi optimeeritud jõudluse jaoks, kui neid mahuad üste serverisse, neid testkuhelis saab tegelikult oodata päris head jõudlust ja Postgres anmebasei saab ka näitele klastrin öeles jahdada. Ma arvan, ma jahes tuleviku looin, kus toon näite selle Postgres klastri kohta, kuna selle kohta tekis mitte küsimust. Range anmebaseide struktuur tähendab ka vähem vigasid. Ei ole võimalik nii palju vigasid anmebasei üldse teha, sest anmebase vastab teile insert päringule, et sellist anmebasei saa siesestada, kuna tüüt on vale. Ja vigasid anmebasei ei tekik, et tegijad viga vead rakendustes. Võimalik paremini vältid anmeda puudumist, sest saad öelda, et teatult ei ole lubatud nullina hoida, et ei või tühed olla ja saada karanteerid, et kui anmed on anmebasi pandud, siis nad ei ole katki. Vähemalt anmebasi valjade tüüpide ja anmeda puudumise vaatavinglist. Ja SQL anmebasidele võib olla ka väga hea jõudlus, kui anmed ma hood nälu, nii et te saate tegelikult võite saada palju parema jõudlus SQL anmebasei krasutamise puul, kui anmeda väikselt. Et teatud mitte relatsioonist anmebasid alati ojavad anmed kettal ja te ei prugigi saada väga hea jõudlus, kuni need anmed ei kasva västi suureks. Ja mitte relatsioonis anmebase pikem kasutada siis, kui anmede maht kasvab liiga suureks, kuna neid on lihtsam ja odaam skaleerida, kui anmedestruktuur ei ole et ära fikseeritud ja teil on plaan, et kogu aeg muuta, siis võib olla ka parem oida erinal mitte struktuur erimalt anmed anmebasis. Näiteks soovitegi roo anmeid oida, seison dokumentida ja näitek jahaneid konverteerida SQL tabelliteks ümber. Prototypine võib olla lihtsam ja kui ta niku nii appis kasutad, et seison dokumenta näiteks mingis mobili rakendustes, siis tiisti arendatele meeldib, kui võtad seison anmebase kasutusad, et ta lihtsalt panetegi seison anmebasi, fetchite seisoni anmebasist ja te hoiategi kõik vaelikud anmed ühes seison dokumentis. Et siis mõni kordongi lihtsam, et ei peagi SQL anmebasi ümber konverteerima päringud ja lihtsalt natuke tuleb mõelda selle peale, et kui palju te tahate tulevikus anmeid agregeerima hakata ja kui teie agregeerimise vajadus, et kujutad ette, ettele on palju agregeerimist vaja teha, siis vaadake dokumentatsioonia oolitsege sellest, et see anmebasi engine, seison anmebasi, mida ta valisite, eriti Firestore kuhul, et ta tooetab neid päringud, mida ta arvat, et tulevikus vaja olla. Et muidude lukkustat ennast seison anmebasi peale ja hiljem tekivad probleemid. Ja mitte relatsioonist anmebasi lihtsalt on ka rohkem avatud lähtekodiga, kui palju relatsioonist anmebasi on ka avatud lähtekodiga. Et pilves saabki lihtsameni valida endale sellise serveri, kui te vaja on ja siis vajaduse selle serveri suurust muuta. Iga nädal võite neid serveri suurust muuta, kuidel vaja läheks, et ei pea siis fikseerima oma füüsilist serverit. Nii esküell anmebasi, et kui mitte relatsioonist anmebasi tihti pakutakse teenusena pilves, et te saate vaba valida endale vajaliku, nagu teenuse ise ei pea virtuaalmasineid haltama ja kõik vajalik ülesseadma. Te saate ka tihti loota, et need hallatud anmebasi on hästi optimeeritud, et te ei pea itse ette teada, mis peaks Postgres konfiguratsiooni file'is ära olema muudatud. Et Postgres töötakse efektiivselt, kuna hallatud anmebasis seda tehaks ette eest ette ära, aga mõnikord, kui teel on vaja need asju ise optimeerida, siis jälle on probleem, et Amazoni teenuses teile ei võimalik olla tehtud asju konfigurata, mida te tahaksida. Aga siis te saate ka Amazonis SQL anmebasi ise virtuaalmasinas ülesseada. Lisaks täis hallatud anmebaside kuhul võib kas ka leerime teie peedetud olla, et te ei pea ise muretsama, et kas ma pea, see on üles piisalt suure virtuaalmasina või piisavalt suure krastri. Näiteks Amazon DynamoDB puhul on minimaalselt teie poosad haldust, te ei pea isegi annebasi versioonide uuenduste pärast muretsama, kuna te ei nägi need versioonia anmebasi halda ja isemudab need versioone. Ja tihtid ei pea isegi muretsama, et kas anmebas on piisavalt suur, et saate sinna lihtsalt rohkem anmeet salvestada ja Amazon skaleerib neid. Aga see täiesto olev, et kas te kasutate täis hallatud platforme või pool hallatud platforme. Pool hallatud platform on selline, kus ta Amazonid küside, et sealtki mulle üles SQL cluster kindlasuurusega ja siis võib-olla ei ole nii lihtna seda suurendada. Ja teid täis hallatud platformid võidad ka pakkuda ka sellist karanteeritud jõudlust ja te saate Amazonist teatud lubaadused, et kui neid ei täideta, et siis võib-olla saate mingi alla hindudusem midagi, et kui midagi juhtub, siis maksdakse osade, sest kuludas kinni. Näites Amazoni cluster maha läheb ja siis hiljem saate küsida nagu trahvi sellest, et miks Amazon ei töötanud, kui te olete nenega midagi kokkulepinud. Sellene nädala praktikumis siis onki pilve annepaase te kasutamine, et me muudame oma hdte appi raamatude halldusrakendus niimoodi, et ta nüüd hakkab asule annepaase kasutama. Kas on küsimesi? Aga lopetamis ära ja siis täna kahed uniberst on praktikum, et seekord võib praktikum natuke raskem olla, et soovitan rohkem kohal käie, kui varasemalt ei ole käinud. Et natuke rohkem on ise väljamalda, kui võrralte selline varasemalt praktikumi on. Nägemist!

---------Loeng 10 - Mikroteenused.txt--------

 Tulemast siis järgmese loingus. Tänna räägime peamised mikrotenusteest ja alustame konteerinetehalduste platformide teemada. Tulelikus lähmed tulemise tagasi natukene. Räägime tulelikustokubet neetesest, aga mittele tänases loingus. Tänas räägime siis, mis on üldse mikrotenused näidete põhjal ja räägime, mis on nende peamised omadused. Nadukene samume tagasi ka hajustus, teemeid omaduste juurde ja teine loingu osa räägeb konteeritehalduses. Mis probleemid meil tekivad, kui me seame üles masinaid kus jooksad tokker ja kui me proovime hakkata kasutama edeks tokker swarmid, selleks lua suuremat tokker cross trade või konteerite cross trade. Järgne nädal ma ei jätka veel kui ka neetesest, aga ma räägin järgune nädal siis veel väiksematest teenusteest, nanoteenusteest, functionase service või serverlessist, kudas näid kindiskeesti nimetatakse, aga siis pärast seda tuleme konteeridehaldust platformi jõudas tagasi ja räägime nad kui me näedame sest ka. Räägime siis, mis asjad on mikro teenuseks. Mikro teenuseks on põhimõtteliselt hajustus, teemeid ja arkitektuurimuster, kus me mingisuguse rakenduse jagame väiksemateks muoduliteks, aga need muodulid ei ole nagu tarkvarasees, vaidada võrgus eraldi väikset serverid või pratsessid, mis suhtelad ülese lokaase võrgu. Kui me luome sellise rakenduse ilma mikro teenuste ja mustriutad, me tavaselt luome nagu sellise yhne rakenduseks sees, me teeme erilad muoduliteks kasutete halduseks, ningilt postistuste halduseks, mis postistuste oondamine kreetiteks, vaid ka hea teestikesed sana ei tule pähä. Päekeks meil on mingisugune Node.js appi telus, mille sees on kolme ühtki hästi erilaadiga appi endpointe ja metodid, mis halduvad kasutajate ja postistuste. Aga mikro teenuste mustris me võime näiteks jagada siis sellise malolidise rakenduse kolme apps, et üks appi, mis tegeleks kasutajate, üks appi, mis tegeleks kreetitega, üks appi, mis tegeleks pastistustega, haldusega. Ja me seame nad üleskaites kolme erineva Docker-konteehnerina, sellase mõned tekitada üks, et sa appi serverid, et halda pünt. Ja miks seda tead, me tuleme seda juba tagasi, aga põhimõttem see, et kui meie rakendus siigel suureks kasab, et näiteks nii kui rakendus on Uber või Netflix või Twilio, et siis ei ole kerge luua hästi suuri monolid ja ekskaleerida, et siis tihti meil võib-olla kasutajapäringid jääb koko aeg, pastistusi kustilistapäringides koko aeg osa ningite muuturite päringid jääb harvemini ja meil on mõnikord lihtsam skaleerida ainult ühte seda rakendusosa, kui hakkata kogu rakendust palju koopleid tegema. Ja sellise juul meie süsteeme enam ei kuolsud nagu serverid, et mis kõik tead täpselt samas asja, et meil oleks ütleks monolid, mis 3D-t replikad, vaid meil on 3D-tyndi serverid, et me igas tões võib olema kiik saada räägmikäil, et me tegib selle haiusam süsteem, mis suhtlevavad oma vahel, et näedis kasutaja. Me näedeks ütleme postituste, appi-meetod võib-olla või põeandes kasutajate teenusega, et kontrollida, kas kasutale on nii-daugusete mitte või siis kasutajate info küsida või kasutajate infot muuta. Ja mikroteenustel on tistis selline autonoomsust, et ikka erad nii oleva mikroteenuse võib siis designida täiesti eradselit eradli seisud rakennisest, mis mõnesvõttes ei jää siin teada teistest mikroteenustest midagi, et kui tema ei ole vajalduks, näist postitus mikroteenuse ei ole vajalduks, et võib-olla teeme hõta pasta nii pärin, et teegiselega togaasest midagi, aga ei kuu kisegi teada midagi teistest mikroteenustest. Ja see rakennisest loogika, mis tegeled mikroteenustest oma vahel suhtusega, see võib-olla on teistest mikroteenustest, et meil võibki sellised mikroteenuded olla suhtset autonoomsest ja meil võib-olla kasutusavaatest, ja meil on erilisava arjensusmeestkonna tegelevat erinat mikroteenust inklementeelisega, näiteks see meest, kes tegeled postituse mikroteenuse ei tegelega väga palju teapunketudes teise mikroteenuseks töötavad ja saab ainult fokusseerida väitsamale osale suuremast rakennid. Ja iga mikroteenus on spetsialiseeritud, et ta ei teada nagu teadma teistest mikroteenustest, aga samasta tavaliselt valitaks sa sene loogiliselt niimoodi, et meil on nii, kui olev mitte koupo, või nii, kui teadub tegelusta koupo eralata mikroteenuseks, meil on tegeled ainult postitustega, ainult mind kasutavatega ja see teadab ka seda, et meil on väiksem komplekt mingisuguseid teke, mida vaja, et kui see mikroteenust tegeled Maija Skuelliga, siis ta ei, temale ei pea ole, mis ta on eritud, samast tocker konteenust mingis teginist tegeled oskasiga meil sellist. Saab ka nagu neid keskkonalt väiksemana hoida ja natuke puhtuma, et me ei pea tegedama keskkondamise oska tegele ta kõikid vajalike väljas asuvate teenuste suhtusega, vaid väga konkreetselt postituse, mikroteenuse näiteks, kasutavai Maija Skuellia, siis siin rohkem võib-olev või või argevile olema mingisuguse teegid püütalise ja mingisuguse teegid Maija Skuelliaoks ja kõik, et ta nagu puhtuma keskkona. Ta saab natuke spetsialiseerida. Ja tänusele spetsialiseerilisem on ka võimalik, et näiteks see mikroteenus imperiuseerideks püütalis, see näiteks Node.js ja see opis jaavas. Meil võimalik teha otsuseid vastavalt enda vaadustale või näiteks, et on töödad, kes oska, et jaavad väga hästi ja nemad tegelevad kasutajate mikroteenusega, kes nemad saad seda jaavast teha, aga teine meeskond, kes tegelad postitust hallusega nemad saad seda püütalistega vaja. Või kui näiteks on mingisugune hea põhlus, et miks teadud tüüki olemeid, miks teises programeeriks tead, et meil ei tead teha, et erlandis, et saavutada nii hästi jaav lõimete jõudus või paraliseerimine selle mikroteenususe. Selleks, et see oleks kasutata fomata, kui meil on ühe selle monoliidse teenuse asena, näed pallonis omapäevat pead suhtama, on meieks vähtpised meelitame näed sadarvittele vastavaks. Sest me ei taha, et tegiks see olukord, et me mõtlen ise mingisugune selle protokolli väljakudas postitusteteenusega, siis kaks aasta pille on inimesed lahkujed, kes ole protokolli väljamõttesid ja keegi enam ei osteta protokolli arendada ja edasi arendamena rost. Pige peab kasutama standartsaid, liidaseid protokolle appi appisid, et kui me otsustame kasutada appisid, see on parem kasutada näiteks open appi standartid, et igavasega väheksama appi spetsiokatsiooneksisteeriks, et uus arendamiseks sisse tulla, kui ma oma potpima, kuidas sa appid kasutada, saab mõõdate todta open appi spetsiokatsiooni ja on suusse lihtne aru saada, et kuidas sellega appiga suhelda sellase mõet kasutada mingi tästi keerulist ja ise väljamõeldud lähenemist, et seda appi kõmme päevad inklementeerid. Aga mõte on üldkagi see, et ei oleks vaja midagi täiesti uut väljamõelda, vaid kasutama näid veidi teenuste standartaid. Appid tuleb kui kireldada, nii teht open appi spetsiokatsiooneks hea läheks vahelpõdele kui kui ei pea. Ajalooliselt sellist lähenemist on kasutatud ka teist sugus nimetekad, et mittele mikroteenuste, vahel üldse teenuse, seda olub keisimil nimetel teenustele orjene teeritada kõik tuur, et erinev moodulid laheanduses on eitele teenustena ja üks teenus kusub teise teenuse meetodeid välja ja meil tegib see teenuste komponeerimise meetodeid selle suuremma rakkemise loomine. Enne kui seda nimetelti mikroteenuste, siis lihtsalt oli teenustele orjene teeritada kõik tuur ja tänapäeval ka seda kasutatakse sellises tarkvaratehenika valdkonnaselt. Mikroteenuste nimi on pige nagu sellises arendate valdkonnasel nimi, aga teoreetis, tauksta uuringus kui te teete, et sootsite nii tartikteid, midagi, et võite leida ka romkem SOA-kompetit service-oreendad arviteksioon. Vaatame siis näiteid, et see on selline ühe monoliidi jagamine tükkideks näite, aga vaatama, kes siis konkreetsavad näiteid võib-olla. Meil võib olla näiteks selline mikroteenuste põhjumine rakendused. Meil on mindisugune shipping service, meil on inventory service, account service, mis on suhtselt sarralad meil on nagu kolm jagadust. Aga meil on ka mindisugune frontend, et me tahavad kasutat, saaksid meie rakendust kasutada üldus läbi frontend, et palen näiteks nii olos kürtis jäete jahvast lipp või see frontendi. Aga teadud teised rakendused ei tahavad frontendi kasutada, tahavad appid otsa kasutada, et nemad siis peaksid välja kutsuma näiteks. Account service appimetodeid, inventory service appimetodeid või shipping service appimetodeid. Ja tegelikult see on suhtselt tüütud, kui nüüd meie peame oma mindisugune kolmandosopole rakenduste lakama selgitama, et meil on kolm erine appid, üks asjadud selle IPA peal, teine asjadud teise IPA peal kolmandosopole rakenduste peal, et ei ole nagu selline lihtne kasutada haeosusteemi komponente kui iga mindisugune kolmandosopole rakenduste näiteks kelegi pood poodud mobiili rakenduste peabhaid, niil on meie siseelu, et lihtne on nüüd teene. Selle tüutud tihti paneks selline appi lüüs või vära või appi cakevi vahele, kus tekib meie rakenduse, meie saad üks aadres, võib lihtsalt inhost näid ja seal on defineeritud näiteks endpointid, et meil on tele rakendus slash accounts, tele rakendus slash inventory, tele rakendus slash shipping ja saapikeit või tegedab siis õigese kohta suunamisega, et kui tuleks meie hostname slash accounts, siis suunateks meile aggouns konteinerisse, aggouns servisse, kus sisemist võib olla mitu konteiner. Ja lisaks on suhtselt tavaline, et teaks eraldi ammebasid, et olde eraldiga need amme, et ikkust tõlsest, et näegiks shipping teelud, nende oltud shipping ammebasid, inventory teelud see on inventory ammebasid ja shipping teelud tavalist peab kirjuta inventory ammebasid otsäe, vaid, et nii teha on vajal või kisida näiteks mingisuguse, hetke seisu mingite opektide, mida ostatakse etke seisu, et see on igelgis, et selle inventory teeluse käeks. inventory teelud on see, kes vastutad, et kuidas amme hoitakse ammebasis. Ja see väitib seda, et kui inventory teelud midagi ammebasid kirjutub veel oot, et mingi teene teelud, see mudab seda infot ja inventory teelud seda teab. Ja füüsiliselt need ei pea olema nagu eraldi, et servereid või konteinerid võib olla samas, ammebasi servereiks kolm erinev ammebasi, aga nüüd olega täiesti eraldi konteinerid täna, et meil on kolm ammebasi, kolm IHLSKL või kolm Postgresi, ehk see olelem nagu ammebasijõuduse vajadust, et võib-olla kasutus on nii suur, et meil on mõistlikum teha kolm ammebasi. Kuna neid iguni koosju kasutata, siis me saame ammebasid aseval natukas ka leerida, et kui meil tõesti on, tekib ammebasijõuduse problem, et meil on teed, et me saame ammebasi agada eraldi ammebaateks, mis vajaduseb misse keraldi, et ka leerida näid. Kuigi see teeruseks sellega, et meil on mingisid rabort teerimist vaja, siis võib-olla meil oleks see, et saame mingis ESKL mängid jooksutada, mis join-rool tabelleid saha seerinev ammebaateks mõni kordud sellega problemolla. See on sellega tüüpil nästi lihtsa ammebasi näide, mis on võib-olla puudu kaegu, et kuidas need appid omavaja suhtevad, et kas võib suhtevad OXE, kas võib suhtevad väga appi Gateway, aga põhjumõtsad shipping-tenus või väljakutsus inventori-tenus on eetud, et vaadata näiteks, mis see on ja mingisid mõned hinnad või kas objektid on laos, et üldse neid saaks ostaja need. Aga see on selline suhtselt lihtne näide. Natuke keerusem näide, et ütlevad, meil oleks vaja designida mingisid Uberi või pool-designena rakendus ja me soovime ehitada sellist sõidujagams appid, et mida meil vaja läks, et meil tõenad, et on mingisid appid, mida need sõitjad ja kliendid kasutavad autod tellida või sõitja või juht täeks, kes soovik taksaks tellida. Ja selleks, et appi ehitel tavas me peame mingisid ress liidese tegema, tõenad, et me taga meil ka brouseris saaks meie rakendusi näha, kui meil pihtime, soovime nagu eraldi rakendus unua brouseritele, mõnikud muurtsed tähtsalt sama rakendus, mis töötab nii brouseritest kui mobiilis, aga võib-liseks pihtidaks eraldi. Võib-olla meil on vaja mingisid sõidjad SMS-et alata, siis me peame ka tegema mingi võimalas näiteks väliste sõlumite kohale toimetamise appidega suhjad, et näiteks teeme trilio, appi ja adapteri, et kuidas trilio. Ja siis täst vakastavaga ammebase, siis tegneks saame ammebase adapterid, ja võib-olla meile veel mingisid teised teenad, mis vajavad nagu legipäsev. Kui me eetame siis monolidse rakenduses, me peame keetama ühe sellise monolidse rakenduse, mis oska suhelata kõikiga ja tekivadki sellised väliset küljev, et iga välise integraatsiooni haaks me peame siis haldama ühtene külge oma rakendusest. Ja see tekitabki näge monolidse rakendus ja sõsteemide keeruliselt. Ja mida rohkem on meil sellised välise komponent, midagi me päris suhtlama, seda rohkem meil sellised külki tekib ja meie monolidse rakendus peab saama hakkama kõigi suhtlusega. Ja me peame siis otsustama näiteks, et kuidas skaleerida, et kui mingil hetkel tohutul palju rest pärin, kui siis see tuleb, siis selle tõttu võib kõrgatada meil suhtus Maija Skool adapteri, kes me ei saa neid eraldi skaleerida. Meil ei ole lihtne öelda rakendusalat. Kaksent procent aast tegele Maija Skool päringutega ja kui siit tuleb liiga palju päringut, siis ära nende peale liiga palju aega kulutamiseks. Meil on raske, kui meil tekib tohutul palju kasutad, meil on raske loogiliselt eraldada, puhu peaks fookkuda panema ja mingisuguste väliste teenustega suhtus võib lihtsalt kannatada selle tõttu, et teised küll on lohtemakkiinsama. Ja samuti see, et kui me muudame näiteks juste mootelid rakenduses, siis see muutus võib mõõntida kõik teisi, kui meil on suuren rakendus, mis otsustsutna Maija Skooliga. Meil ei tegi seda olukord, et kui me siin midagi muudame, siis me saame seda hoida täiesti sellise autonoom sõnad. Iga muudatus, mida me teeme ühtemooduse võib teisi mootuli suhtseb palju mõjutada, see peab jälle ka rakendust testima, nimoodi sellitele monoliidsemeleks. Me ei saa juste komponeerid lihtsalt testita. Ja lihtsalt see monoliid kasvavad väga hästi, hästi keeruliseks ja tänapäeval on täitsa taval, et mingites kritilistest sõsteemides 30 aastat vanaa mingi koopoli monoliid kusagi jääb ja selle asendamine läheks nii pole maksma, et seda ei taheta kea asendada. Aga kui nad võib-al lihtsavad sõsteemid, siis mida võib-al teha, kes on see, hakkakse enam tükki välja löödima. Meil on see monoliid, meil onks vaastamotendiseerida, võtame dry management jääb välja eraldi mikrotenusena ja hakkame monoliidist tükki välja löödima. Aga kui me Sarnas Asia monoliidse rakenduse ehitaksime ütleme mikrotenuste põiseks, siis võib-al sa näksid, et meil on nii igalse mootul eraldi mikrotenus, mingi passenger, webi, driveri viides ja võib-al me oleme need isemeehitad, et nad ongi brousseri teoks isegi ehitam eraldi ja siis appide jaoks me ehitame appi metodid, et nad saavad appid appi metodite kaudu annatele liigi ja siis võib-al appidele on eraldi veel, ongi eraldi mobiili rakendused, mis otsasalt ei ole sealtud salle arkitektuuriga. Ja me saame komponentit panema, panema üks teisega rääkoma, siis taalt, et need peab pii appi või resti kaudu teketada siis eraldi sellised mootulid või mikrotenuseks ja kui meil on näiteks mingisutuseks, vaja võiks suhtust hiljuga, et või send pilik, et saavad kas sanumeid, me teemeegi juba eraldi sanumete saadlise ja mikrotenuseks, et kui siin jääb, et tuleb, mingi mul on väägus saavad kas sanumeid, siis poedakse sõjadus selle haldile peesende erodega ja nad ei peesende erodega sisensed, siis siin pealik peeli, kuidas midi jahe send pilikin autuk sanumeid saada ja toivomattalisev. Nüüd kui tuleb toodu palju appid väljude, et strip managementi, siis otsasel see ei mõjutada teiste mikrotenuste jõudus, eliti kui meil on näiteks sellest strip managementi jooks, ma saanud üks konteinerid ja kolm konteinerid, et kui me ei tee lõrmatuks ka leerimist konteinerid ja tasemel, et me suvalsel aal luba ma suvalden aarav konteinerid juutapanna, et me siis saame korampeerida, et eks peegi teistest mikrotenuste, sest on oma konteinerid üleval ja nendest suunad, et siis siis saad ülepäringud, isegi kui strip management mingit tohjusest saab ülekoormatud, et ta saab liiga palju appi päringud, siis see ei mõjuta teisi, kuna nad jooksevad võib-ale isegi teiste serverides, pilvetsuohja teiste serverides jooksta, et siis saab hoida jõudluse vajaduse või resursid niimoodi, et karanteeride võib-ile resursse, et teha vajalik operatsioona. Ma saab otsustada, et ska veerida seda ära, agi seda mikrotenuste raaltikukäis on teadud. Ja siis on ka see, et kui me muudame üks kõik, mis mootulid siin, siis see järjest vähem, nagu mõjutad teisi mikrotenuseid, et kui sa appi jääb täpselt samaks, aga sisended võib-ale loolike, kui sa saad ütlema tervi, siis välja seid mikrotenuseid mõjutad, et nemad, kui sul on täpselt samab umeeta teid, kui me muudame appi, nagu sisended võib-ale väljutad, siis võib-ale, et kui siia lisama uue sisendi, et nüüd, et lisama paymenti tegevaks ka mingisuse lisa parametr, et siis tuleb ka muhtada kõiki teisi mikrotenuseid, kes kutsuvad välja seda meetabid, aga ta on ikkagi natuke limiteeritud, et me saame neid eraldi testida ja iga mikrotenus saab olla tegelikult implementeeritud mingi eraldi meeskonapool, kui näiteks meeskonad saad valida, et me ei ole meid payment-ski, et vihti võib, et kuulda mingisugune tööpakku, mingisugune tööpakkumine on, et lähed te sellesse asutusse tööl payments-tiimi ja nemad tegelevad ka ainult payments mikrotenustega, võib juurdu, et see sama tiim seal meeskondis, kes tegeled näide payments mikrotenusega, nemad väga ei teagi nagu või või viidestest või teistest mikrotenustest, ja uuel töötal võib-ale on lihtsam, nagu sisse hüpbata ja hakkata tegelema ainult osa mikrotenustega nemadi, aga kogu koodi baasi tunma, et tead kõik, midas mikrotenustest kõik, aga sammult siin tegid ohu, kas te märkata siin mõnda probleemi, mida võib-ale ei ole nagu monoliikse rakenduse pulud? Mis on need joone? See on need joone. Mida? See on need joone. Aga meeldis, mis see misse joone on? See on suhtlus nagu mikrotenustel vahel. Kus toidub suhtlus siin? Jah, kus kes selle serveri tead suhtama ise endaga. Et suhtlus on põeks meelus. See on lihtsalt kutsud metodi väljas, jätu jätu meelus ja kõikide nenda metodi üks teise välja kutsumene üli kiire. Monoliikse rakenduseeliid on see, et sulle ei ole nii palju nagu lokaalsest võrgu suhtlus. Moment, kui sa lähed üle mikrotenustel, et kõik väljakuksest toimud üle lokaalsa võrg. Vähemalt jõtne me sama serveri vahel kaks konteinerid saadaad üks siin resparenguid. See on tohutud palju aegus tegelikult meelu. See on vajalik olukorras, kus sul on vaja skaleerida seda susteen. Ühes serverist enam ei piisad, või kasutatab päris nii tähad. Tead sa tead vähemalt hakkama meid serverid repitseerima ja kui on rohkem kõiks koopad, siis nad hakkad oma suhtlusteku. See oli seal ninguni. Olukorras, kus ma ütleme kolm või neri replikaad monolitist vaja johsutada, ei ole see väga erinev selles, kui sul on 15 mikroteevas, mis omavad suhtsavad. Sest suhtus võib toimuda ninguni üle võrgu ja see läheb palju ulemaks, kui mida rohkem replikaad ja sellest hakkama saada sinu miljoneklendida või 10 miljoneklendida. Aga samas see võib pea tähendada, et lihtsa rakjandise mikroteevasse tegemisen on mõniga toht. Kõik need pärinud tegemine, aidustav tegelikult seda aega, kuni kasutada saab pärinudle vastusa. Teine opt on see, et see on suhtselt keeruids. Aru saada, mis probleemid on süstheemis, kui see on mingid jõudluse probleemi, kui tegivad mingid eateatled. Selliste süstheemide debugimine ja silumine ja jõudluse testimine on palju keeruidsemaks. Siin võivad tekni veel palju erinevad probleemid, mida mõnale süstheemis väga palju ei tule. Võib-olla ei eksisteergi mõnda akitektiasutuses, kes mõistab kõik, mida või teene, et nii hästi, et ta oleb kõigest ideaalne ülevaade, kuna iga mikroteevasse see, et olla täiesti erinev loobid. Eri nagu meilis keeled, viisid, mustvid, et mikroteevasse mõistmine või ülevaade saamine võib olla palju keeruidem. On välja tullud, et teatud tüüki rakendused ei ole hea mikroteevasse teaks. Tavalliselt, siis kui väga suur maht anneid tuleb saata mikroteene prohael, on suhtseba ette pilne. Video streamingis lahendus Amazon Prime Video, nema oltsustasid mingi, et tagasi minna monolyptse te rakenduste poole. Nad kombineerisid päris mitme, et mikroteenuse tagasi monolyptse, ja nad raporteerisid, et said mingi 80% kasu sellest. Nendel pilve arved olid 80% väiksemad ja võtsid vähem resursse. Liiga agar, nagu mikroteenuste teale ülemine võib kogu sisteemi tegelikult natuke nebafektiiseks tegema teha ja võib olla palju keeruidem. Mikroteenuste omadused, üks asi on käa tiinsam, et meil on palju lihtsam arendada sisteelis koosad väikestas komponentidest. Me saame arendada ainult seda komponenti. Arendajad ei pea teadma kõik, kõidest muutest ja komponenti mõistmine ja arendas võib olla palju kiirem. Ja kui meie muudatust puudutab ainult 10% kogu suureks rakendudest, siis on seda palju lihtsam testida. Mida väiksemanse ala muudataks või selline indistias võibba surfasere, seda lihtsam on saa testida ja kiirem nii saab muudatust ära testida ja laivi panna. Meil on ka lihtsam võib-al teha sellest, näiteks driver veeb uist kaks koopjad ja testida neid eraldi ja jätana tööle paralelselt. Seda tihti kasutadaks selliseks testimiseks, et lasta kasutatak kasutanud nii varapersioonid uud versionid ja vaadad, kas uues versionid tegivad, kui ei tegi, siis pahetada kõik varapersioonid uue versionid ära ja isegi lasta kasutavad testida, kum persioonid on ennest rohkem meeldid, et saada kahtu uidneid, et sama aeksalt jooksutada niimoodi, et me saame testida, et mikrogenostik on see lihtsam. Teenu on skaleeritavus, et me saame individuaalsed kõiki mikrotenuset eraldi skaleerida, typiliselt me paremene oltu üles konteeleeritene, lihtne repliceerida konteeleerit arvu. See natuke oleme sellest, kas konteeleerid ja mikrotenus ehitada niimoodi, et nad ei ole üks tehtud üldsa sõltuvad, aga tihti, selline, kui mõnes mõttes sisse ehitad mikrogenosti põisesse lahenendises, et me iga mikrogenus ehitame nii autonoomseks, kui võimal. Kuna meil on väikse komponentiks, üksik komponenti on palju lihtsam sinest ülesseada testida uueldada, meil testkeskkonada väiksemad meil on lihtsam, et arelda saab oma süveargutis, või mingis trip managementi konteeleer üleks seada, kõik ka ei ole jooksutama, ilmatab teha mingil midmeid anmebaaselikolla jooksutama, tommolel trip managementi testiselt see olega anmebaaselikse vaja. No, tüpilist on tegelikult. Teno loogilne vabaadus me saame iga mikrotenuse jaoks valida oma tehnologia, programeerings, keeled, teedid, keskonad, et ei ole kui liimiteerikult, et projektiis kasutadakse ja püütanid, et siis ei tohi ühtegi teist teed kasutada. Kuna minkrotenuse nii ole ole üksteeselt väga sõltuvad, siis teoreetselt ole iga üks suvalises keeles kirjutud, mis küll ei proovi hea olla, sest kui kõik inimesed lahkuvad, kes erlangi oskavad ja siis pitad otsima töötajad, kes tuleb esim. erlangi oskat, siis või või raskeme, lihtsam on ikkagi hoidane keelet lähedasest ühtesele, et saaks asendada arenda, kui lihtsam on iga lahkumaid. Koodid võib olla rohkem kordud kasutatavud, kui neid tulakse väiksemate mootulitena ja aita pältida sest teedubid seeritud koodi, et olukorras, kus on üks mootul, üks mikrotenus, kui saavadud video ka rääkid ja teiste ei olegi juba, et muulatud video sõnumid otsedaata, see tegi, et seda kohtud, seda olukord, et meil on mindmäs erinevad, mõnolid immoolkulis meedatud video sõnumid saavad. Et see ongi täiesti objekto orjenteeritud lähenemine, et meil on need tarakvaramist tegeleksest video sõnumid, et ongi väga konkreetsev video või notikiteisjonteehuse sees ja seda ei saavgi muu ala eksisteerida. Teevretselt saav ka arendud alust selle teedada, aga väga loogiliselt meil on teada, kus sa asukort peab sollelema, et seda sõnumid saavad. Ja väitsem kiusatud, saavad kooperide koodi, mis sama asja teed, kuna meil on loogiliselt mikrotenus, et saavad selleks vastutuoli. Ja vastupidelus või tõrke talus on ka parem. Selled oltu, et meil üks mikrotenus maha läheb, võib-a näedil, kesja mikrotenus maha läheb, et siis ei tähend, et kogu system crashi, et mikrotenusajas tekib mingisel viga, mis jooksad kogu konteehneri või selle pratsesse, mis selle konteehneri jooksad, et siis ainult see mikrotenusele tohle prestarti teha. Kui lastevad üles vale koot, siis võib-a, ratifikation teenuse töötab mingit aega, ei testitud korralikult läbi, aga üleään rakjamele tööda, kui ratifikationid jõu kohale võib-a, see on väga halb meie klientidele, kui sõitjade saan mingisel tead, et käte või kasutaja ja tead, et nüüd auto on kohal, aga põevist üleend asjad jätkuvad töötamist isegi kui süks teedata maad. Samas võivad olla, meil mõned väga onnuduselt keskse teenuse, läheb strip management, mis võib olla kriitiline teenus, teiste teenuste korralikult töötamise jaoks, meie 100% ei saa kalanteerida, et ühe mikrotenuse crashimine ei tähenda seda, et kogu rakjumus on kasutatav, imma selle mikrotenuse. Aga vähemalt me saame restartida ainult ühe mikrotenuse või palandada üste mikrotenuse, et üleend saavad järgata jooksist ja võimalik, et midagi muud väga pärkile. Ja konteenerit ongi nagu üks teamise aluseid mikrotenuste mustri edukuses, et on lihtve üleselda komponent ja panna nad oma või suhtama. Tuleviks väginu ka natut ja võib-olelne teistest protokollides, mida kasutatakse mikrotenust maha. Tänasest tänarääginu tigad nendest võib-olelne haadatakse ja tegeapide ja natuke ka järjekordate näiteks. Mõnesvõites võikki olla alguses lihtsam luguva selle monolitte rakjumust prototipina. Eritukes meeskonna suurus on väike, et teete mingi startuapi. Alguses võib mikrotenuste lähenema isegi natuke naaglustada. Teie lähenemist, et te peate võib-olel liiga palju keskondisid üles. On teed otsustama, kuidas jagatuda nii edas. Monolite prototipi heitame alguses lihtsam. Samas on hea vähemalt planeerida, kuidas see tuleviks monolitist mikrotenuste üles ümberjagab. Monolite seeis on parem, et jäta konkreetselt eraldatud mootuliteks. Hiljem on lihtne mikrotenuste jagada, sest lihtsalt on vahelik, kui tohutult palju kasutajid hakkab tekema. Kui teil ei olegi nägemust, et hiljem tohutult palju kasutajid tekima, võiks hakkab, et võib-olel see ei ole vaja otsalt mikrotenuste rakjumust kandu. Aga risk on see, et hiljem monolitist mikrotenuste ülemeed võiks väga kalliks minna võiks. Ajamõttes vähemat kalliks minna võib-olemite rahamõttes, et teab väga palju ümper arendama selleks, et sa teha. Tasub itkaka alguses planeerida, et isegi kui me heitam monolitit, me heitam selle niimoodi, et vähemalt loogilselt on meil mootulit, milles on saam moodi selline eraldatus. Meil on konkreetne mootul, kelle on esegele paljub lenda välisid suhtusega ja meil ei ole sama kootist hiljus, onumine, et saada kogu kootist laia ligal kooli. Milline konteinereid teed ühemasinepe kogu tööplastakõst? Kui te teete samamoodi mikrokrestru rakenduse ja panete kõik konteinereid samas makinest tööle, siis saad või ikka eraldi virtuaalse serveri. Te peate nad panema kui tege oma suht. Kui te tead teise viisi, kuidas saad suhtema panna, et mulle on samas makinest seisad proksessi ja ma kasutam teist viisi proksesside valjad suhtuseks, kus te kasutad kogalselt võrg, kui te teete digipääsu, linuxi, mingi teile sõnumi saadnud selle proksesside valjad, pilde proksessi communication, tõrreidselt see oleks enam sama kui ilma võrguta. Aga suhtseid keerulnud, et sa seidele talastatak teete. Pige ikkagi panaks rääbi üles, saakutakse sõnumeid saadma järe korda, et see on kõik serele, madate teada pärinud, et see proksesside valde käib. Selle hetke kui tegimte, et samas serveris sellide proksessid, mis oma vahe suhtad üle lokaalse võrgvõrg, see ei ole väga erinev selles, kui on microteamasut, näinid kahe erinev serveri peal. Ikkagi selle lokaalne võrgvõrgvõrg suhtlis on palju aegaselt või alu mälu suhtlis. Või nõimelohannes suhtlis. Aga kui jäänki, et meil on teinastid otsüükstisega suhtele, et teid lihtsalt kiinutavad kiin samale mälu adressi. Ja siis... Ja siis on siis sellie suhtuure, et meil onki üks kiinutavaja, siis kaks lubejad näiteks. Ja seda saaks teha, seda tavaselt väga ei tehta nemaati, mõnes mõttes sulle ei olegi siis väga mõtev, võib-olla et mippa erinevse konteeerise panna, aga sa tõesti saaks seda teha, et... Siis sul tegivad natuke näin probleemid, et kuidas sa ei jaga õigus, et sama mälu ala lugega konteeerite vahel. Mõikud sa teaks, et näiteks lastakse näite konteeeritel kasutada mingisuguseid mällisid faileri, aga sa tegid mälu, et sa tegis mälu mätpitud failneid, et sellist asju kasutatakse. Et see läheb suhtselt keeruiseks ja tavaselt seda ei tehta, et sellise hõu pigem eitimid otsa monolidi, et miks ma nad siis eraldi konteeeriteidut panenev. Siis parem võib-olla panna kiinat eraldi üks rakendus, mis siinemist kasutab võib-olla lõimesid ja suhtlab otsa mäluus rakendustega ja ikkagi hoiandud samas konteeeriteid. Kuid tähekte, et sa oled kui mõikud see kaululikus, et juba on see mikro teinustleiga süsteemi valjumast, aga sul on vaja ajuudiselt mingisuguseid on saite prookseleste kaks kohvud kohvuseleis maimada. Siis sa oled, et sul on näiteks üks server kaasalet. Sellest mõtus, et sa loomulikom panna see sama mikro teinustel rakendustest keskkonna ühti serversse ja konteeerit on samas serveris, suhtelad kaasavõrku kaotu üksteisega ja põe teada väga hästi. Lissalt ei ole monoli, ta on ikkagi mikro teinust rakendus. Mingi probleemi sul sellest ei tegi, et kui sa tead, et on imatioksid käe. Ta oled oma läpaka, seda samamoodi panna mingi rakendus, mis koosna 13. konteeerist oma läpaks töövad. Kuid tööta tegad väga hästi. Kas tundja ei olnud kui plusseks sul ei pea kõrragioks, et see oli siinutimiseks, et see ei pea kõrragioks, mõtus on kõrra päevas. Ia, mõni kord on seda lihtnega lõimadega teha, lõim jooksad korraks, siis panasin ja kõik. Ja mõni kord on ei näle hea, et on eraldi konteeeris. Väga tihti teoks tõeda. Kui päris kupeenete seda, siis ma spawnin ühe konteeerid, mille see on minimaalne vaalikult failid, et jooksad ta mingi asikron jobina tööta vära, ees konteeere läbi. Sellest oleme räägine kui kupeenetes lõandub natuke. Kupeenete seda teoks tead päris tulti. ja kus ma en? ja siis on hiljavad seda monoliitsed rakendus keerulise meie arvendada, kuna meil jäävad kugevavad seosad erinele moduülte vahel aga samas mikrotenesta põisest rakendus on väga lihtne, nagu võtta üks komponent ja ta ümberteha näiteks kui ma tekin nüüd selline vajadus, et ütleme ningisugune Passenger mäes mända apvi ei ole liiga skaleeriga, et meil on maile liiga palju näitas, et replika et näis konteinerid, et teelete ümber pyytanist erlangi ja problemi jäsku erlangi saab seda kiusest toonudid kirjenta ja meil on suhtseb lihtne ühe komponenti ja implementatsioon täiesti ümberteha, sest ta suhtur teisteiga läbi standartsada apvideina, kui me muudame siselis koodi ja kasutam täpselt sama open app specialkasiooni, siis keel ei väljas palju teha, et mis keeleks on implementatioonitudne, et neid ei huvita, mis keeleks on, me saame lihtsameni välja vahetada ja... Samasi on juba monoliitsaga, et näiteks teist röktes, et seal saagal kuseltaks pyytani, aga seal importi teke, et mingid funksioonise kutsud, et see ei pea tead, mis seal seest toimab, seal funksioonikutsud, et seal ei pea oleks. Üks näite on see, et sa soovib 20000 masinopeteteeki, sa pead siin, siis nüüd on kõik on pyytoni, sa kakutad 20000 masinopeteteeki, see masinopeteteek talab pead versioni pyytonteegist. See pyytonteegi on mingi konflikteise püytonteegiga, mida teine muod on kandutada, kui kohe tegis on probleeme. Sa pead siis otsustama, et mis on see pyytonteeg, näiteks mingi openSSList, ja millest tegist töötab mõlema versioniga, ja kui sul on mingisuguse nõud, et see osa tarkvarast veel ei ole ära uuendatud, et ta ei ole kompetiiv, siis uue pyyt on mingisuguse teegi versioniga. Ja sa vaad selle teegi uuendada, et koheleki probleeme probleema eht, uuendad selle ära ja sa lähen siia uuendada, et seda ära sa lübab nende teegide tasemelid probleeme tegide. Tihki on meile ainult, see on kõr seda näha, et me oleme kasutanud näiteks pilveteonoloogias mingi siis komplekki püytonteegidest töötavad jälgminevastele meid tegid, läpsed sama nagu requiem as file. Kuna me ei pannud teegil, nii täpselt paikat, näiteks ühe teegi versioon oli pandud, et ta võib olla üks püttnis versioon, mis on suurem kui teises püytoni versioonis, teises püytoni teegi sellepandutatud on täpselt kui konkreetne versioon. Ja see üks püytoni teegi versioon, siis järgmine aasta on üht uem, ja see ühe teegi vana versioonegi töötab, tulad ka teist teegi uuendada ja siis tegivad itse sellepäeksed probleemid. Ja sa pead siis olema tead, et kas lõib selle teegi uuendada, kui siin on üks sama teegi, mis siin. Ja see võib juhtuda, et see on mingisõguses teegi meeldodi signatuur on nüüd teine, sedaks parametritaturi teises kui kasutama uues versioonis, kui vanas versioonis. Ja see võib juhtuda, et ma uuendan seda, kuna ma panen sinna uue maginapeteegi, aga see maginapeteeg pahab kõige uuemad versioonid püütan teegist ja siis ilagi muud läks, kus on muja monolidis väik. Sellist väikse probleemid, aga tegimeed. See on kül üks selline labane näite võib-olla ka lihtsalt meil ei ole nagu eraldatud testondi. Kui me paneme konteneridese, siis igavühel on erinev vähemalt konteneri, kes on. Siin teegi tuleb, seda ei muidu kõige siin olevad. Kohe on nagu selline, natuke lihtsam, et me pead aga mõtlema selle peal, et kas mingi teegi muudaltus ja teegi uuendamene võib midagi muud kõikki teha. Aga sul saab ju olla sama asja arvudis mitu eria teegi versiooni, seal ükskust ühte teegi ja tege teist. Jah. Aga niis ma või ma ei pilvona teegi. Aga sest ta ei oleks karismonoliid, siis ma ooksutaks neid eraldi protsessidena. Ma pean nad väemalt erinevad pyytoni protsessini ooksuma, kus mõnev on pyytonil erinev virtuaalne keskond. Et siis ei saa, et sama pyyton protsessi ei saa korra ka kahe erinev pyyton keskondi kaks oksuma. Siis nad peab peame kaahe protsessini ooksuma ja siis ma ütleks, et miks mitte nad panne kui kõik erinevtele ooksuma. Kui mõnevad mingu nii kahe erinev protsessi ooksuma, et ma teiknud kui kõik konteneritena. Ja siis tekib sul see probleem, et kuidas sa nad omaju suhtsema paned. Ja kas sa kasutad standardid või mõtled ningisegust väga krastama asja, et kuidas mälualased kasutada välja. Ja siis täna töötab, aga puole aastapärast võib-olla ningikui võib-olla sa ei enami tööta. Võib-olla sina tead, kuidas sa teist implementeerida, aga teised uue töötead ei teha, et kuidas sa mäluala võist optimeeritud suhtus teha. Tekijad kohage see probleem, et mida keerukemaks süsteen tekib seda raskema, nagu seda tuleb seda säranduda. Kui sa ei kasutada standardseid viise suhtsut viise. Aga kui sa tästki huvita, et optimeerimisest teeme nii kiireks, kui võimalik, siis lihti minnaks standardseid kommunikatsiooni viisides kaugamale. Ja siis see teab kogu rakenduse kieruisematse. See on ka üks võivus, et miks monoliidi ei ole lihtne konvertida ümber mikrotenostalahelistest. See on väga palju sellised, et läksid kasvama asja, mis sa ei tehkud, kuna oli lihtne teha monoliidis, aga kui sa neid ära jagad tükiteks, siis see võib olla päris asja. Monoliidis ka, ja sul kasutab palju funktsioon, iga selle funktsiooni saad spanoma ette mingis teinus. Jah, ja see ongi sul, et sa hakkad seda niimoodi tegema, aga olukordades, kus nad ei ole mõeldud, et nad täiesti eraldiseisvad asjad, siis see pruugi ei ole nii lihtne, ei pruugi ei ole nii võimalik. Loogik on lihtne, et kui me taame siit minna siia, siis me hakkame selliseid tükkesid peale lõikama ja loodame, et me saame nad teist eraldiseivad teha ja tead, et tüüpi akkendistest saad, aga hiljem võib-ki olla, et nad toesti kasutavad nii mindid mõluola oma või suhtemiseks või mingite parametriade muutmiseks, siis sa tead nüüd hakkama metodeid vähel muutma, et sa pead nüüd rohkem infot kaasa panema, et ei saa meeluskustel pärtust võtta, ei saa liselt globaalselt muuteid kasutada, isegu sa arvast globaalselt muuteid kasutavad, siis üks pool muudav neid, ja teene pole ei saa sellest teadami, et sa pead jälle mingit synchroniseerimist tegema või siis need parametrit kõik kaasa panema metodidega, et sul kohe tekivad hästi palju, siis palju sellest väikse probleeme, et kindlasti sul on õige mõtte, et täpselt seda teeme, et siin on mingi metod, liikutama selle metod, et selle on nii funktioni ja vaatame, et kas ta töötab ningmaldi, kui kohe töötas, ka midagi asju ümber tegema, aga see probleem on, et midagi, midagi ümber tegem, meidud toogud palju aapade tehtima, et kui on hästi designated monolith võib-al, aga mina täitsa on mitte ja töötab, aga see lihtsalt kunagi ei tea seda ette, eriti kui see on monolith, hästi vanamonolith on 10 aastat tagasi lood. No siis samal probleem tekib ju ka seal, meil on palju net mikrohysteeme, et kui ühes ei muudame seda vissel, siis või väljas loig on, ja see on atuk umutub, et siis mingi laitete tehti võikad olla. Et kui me muuda midagi sees ja meil muuda seda appi spetsifikatsioon, et meil näiteks ootan appi spetsifikatsioon ja tead jääb täpselt samaks, siis ei toivud see, et meil väljas oleb mitte neid muud. Võib juhtuda, et nüüd on see kolm kod aeglade, ja siin on mingisemene delay või sellene timeout, et ta ootab ainult või, kui ma 5 sekundid, aga nüüd mingi pudel, et sa töötab selle üks sekund, teatad olukordotus. Nüüd võib tegida problemi, ja mitte midagi väljas kohti muudlud, aga sees muudlused nüüd on aeglasenud, ja siis siin on ka võib või. Ikkagi on alati midagi, mis kaettumid minna. Tein asi, et kui me väljas toot, muudame, et siin on meedadi väljakutse ja siin on olema lisna argument kaasad, mis on vajalik argument, siis ja, et meil seda metodid või üks kõik mis teisi metodid või siin längilik, tarkkara jaavascripti siin muutmakama, sest nüüd tuleb mingisugud lisaparanad ja kaasa panna, siis me peab meid ka mõutma. Ja see läheb palju keerulisemaks, eriti, kui meil on mingisugud muudatused, mis on mingime mikrovenuse peale, ja me peab meid ka mõutma hakkama, et mono teatad olukordotusest muutmine võib olla lihtsam, kui sellist asjad hajusas sesteemist aru saamine, selle kogus koopi mõistmine võib olla palju keerulisem. Ja kui arhitektuuride läheb peaa valutama, et alendatel võib olema lihtsam, et ma muudan mingisugud, et see on metodid sisu ära, et viib pole mingisugud töötavad, muudakse töötavad, aga, et arhitektuuride, et õigete arhitektuuriooksid, et teha võib olla väga keerulina. Kõist vist väga keerulina, aga võib olla palju keerulisem. Ja testimine ja viga teast aru saamine, et kui kasuta sai veha, et sai mingi veha teate, kus sa tuli, kasuta pärin lähti siia, siin, miga ei olnud võib olema, siin, miga võib olema, siin, miga võib olema, siin, miga võib olema. Aga kui sa sinna arhitekna võib logina, kõik need logid läbi vaatad ja leiad üles, kus viga tekis, ja otsid, oskad üles leida, kus on viga, aga sa täksid rääkuma selle mikrotelise meestonna või selle mikrotelise meestonna või selle mikrotelise meestonna käel. Ja need asjad saad lipaakimine asi läheb ka palju keerulisemaks. Ja see probleem võib tekida ka siin vahelmilt osad, mingisest järjekorras või mingi võrku konfiguratsioonalil paigast ära ja selle põttes ta ei tõeb, et selleks tehaks se visakse monitorinle ka siis stressimist, et sul sisse tuleb kasuta pärin, sa tead seda pärin kui ID meelde, ja kui siit tead, et sa logisid, logit, sa palaks sa pärin kui ID, kui siin tekid, et sa logisid, logit, sa palaks sa kaasa pärin kui ID, ka siin pärin kui ID ka, siin ka logiteks ja siis jääd, et sa need, et pärin kui ID logiteks, et nüüd mingisest lipaakija või siruja saad minna, mingisest selle kestse selle logimis vahelmist näist asures ja küsida, et panu mulle kõik logimis on seadud pärin kui ID ka, millel on 702,50 kuu. Ei võib-olla selled, et sa tead arvan, aaa, see jõudnudki kuraks siia järjekord, iga peab olema siin või siin vahelmilt ja siin ei ole nüüd, et ta prooju seda välja kurt suuda, siin logia ei ole, järjekord see jõuendus kudagi ei onnestunud või pärinkode ei tund kohale või mingi võrku probleem võib-olla. Nii et ta võib selles mõttes keerutunud minna. Eriti kui siin on erinele progameerist kieli erinele logistandard, siin on erinele logistandard ja siin on meile erinele logistandard, siis tõesti võib-olla probleem, et kui sinahab, et minema ja tockerlogid läbi laatama, siis tockerlogid on 16 gigabaiti pikaad ja võib-olla päris pare käsidev. Kas kohati proogate ekskontrolli playing cross eal see mitte teemannistlikus jaotus, et kui ma olenki suhtlus, et kui ma olen meilusotas, siis mul peab alati, see mis esimeses on, jõub esimeses, aga kui mul ei võrku, siis ei proogini. Ei proogini, aga prooviteks sellel designid see nimot, et see järjekord väga tähtis ei ole, sest üldjuhul ja, et kes saab taksu esimesena kätte, ega kasutada seda ei pea, et keegi teine proovis samal ala, nagu taksid kätte saada ja tema sai kiiremise ländale. See ikkagi probleemi tekitab, aga see olema väga sest pakkan, et standarts on. Ma ei oosti aga praegu võib-olla hea näida, et see tuu, et kindlasti see, mida keerulisem, see loogike seal on, sest see on, et seda raskem, aga mul täna ei ole olev teile väga väga rääkida. Ma mõtlen sellepäev, et juba toonagi näiteks tuleb. Me jõubasest ägst, et kuidas sulle siis hakkame jakama näiteks, monolitsiv rakendust mikro teenusteeks. Me saame äri loogikajärgi otsustada, et need, mis tegevad tellimustega on, siis tellimuse mikro teenusteeks, et me tegevad, mis tegevad kasutate, kui on kasutatud mikro teenusteeks. Tihki prooviteks, et seda nimati teha. Implanerateerin iga sellise isaseistva loogilise teenuse, mis ningid olemistega olemitega tegeleb, siis eral kui mikro teenuse. Ja me saame need mikro teenuseks jakada oma asutus on meeskondatele vastik, salaka upad näiteks, iga meeskond saab isegi valita, et mis mikro teenusteega nad on rohkem parelsamad tegele, et kui mis mootuditega nad on rohkem parelsamad tegele, siis saavad teha näiteks valida. Teatud asukusti teads isegi, et töötad veel lastaks valida, mis ma järgisena teha tahal. Ja ideaaliselt võiksik ole iga teenustelemine suurselt lihtsa väike selle vastutusalaga, et ei teaks liiga palju teadma, et skoop oleks väiksem, et see ei pea liiga palju teadma. Aga see olev, et kui suurkele asutus on, kui väike asutus on, siis seda ei ole võimalik. Ja eka et ei tahaköet oleks 125 mikro teenuste. Lihtse selle peal olema jääma ikkagi lihtsalt selle mõistiku ja suursel, mis olev inimesi tarvud ka. Meil on ka tihi otsustatud, et mis suhtlust me kasutame mikro teenuste mahael. Taasest kasutades kasvotse suhtlust näiteks HTP, suhbi väga dihti kasutataks, aga näiteks HTP asemelud GRPC kasutada, mis on see ARPC tüutbi ja palju efektiiseen, kui HTP üle lokaalse võrgu. Ma tuleb suhtlul natuke räägjadest GRPCs. Ja tead, et järe korda on hea kasutada siis, kui me võib sisse tulla hästi palju sõnumeid, aga meil ei ole tähtis näite töödelt ära ülikiiresti. Meil võib-olla on kasulikum jääta sinna puhver järe korrana, eest meie mikro teenuste saab minna ja järe korrast sõlmusi võtta ja ne vära töödelda amme paesi panna. Sõnumid saad, et võib-olla meil ei olegi tähtiselt SMS-või e-mail-jooks koha kohale. Me võimegi sinna tead, et ta saad on jätte teketud järe korra. Ja see võib-olla eriti hea, kui me näiteks ööse saadame 10 000 SMS-korraga või 10 000 e-mail-korraga. Meil ei ole tähtiselt, me skaleerime nüüd kiiresti konteeerid arvu ühe pealt saja peale, et korraga tead 1000 sõnumid ja 10 000 sõnumid kohe ära saada. Võib-olla on täits okei, kui see toimid nagu aegaselt üle öö saadetakse nüüd sõnumid kohale. Meil ongi võib-olla hea panna sinna järe korra, ja siis panna mõned konteeeritöölems järeks võtavad ja saadavad sõnumeid. Näält sõnumid ja järekorad tihti töötavad päris hästi seste puflitena. Meil ei pia olema aktiiselt mikroteenust ja kujult töötajad, kes kogu töö kohe ära tead, vaid me saame tekitada neidne vahelisele järekorra ja lastane järekoraks tegemust võtta endale ära teha. See vähendab selle skaleerimise vajadust, vähendab sõdeb me peama korraks hästi tohutud paju resursse tööle panema. Meil on eriti fixeeritud arvservereid ja meil on maksimum konteeerid arv või maksimum resurssid arvmedatuseid kasutada, siis mõnigud on lihtsalt hea asjad panna ootel järekorda, mitte eeldada, kui keegi saadab hattete pe sõnumi, et kohe on prokses valmisida vastu, et ma ära töötama. Teina alternatiiv oleks, et meil on hattete pe server, kes siseemised hoiab järekorda, et hoiab kõik saabunud sõnumid endasees ja töötad nende paeksad läbi, aga selle oht on see, et kui see crashib, niis juhtab lokaalsse järekorraga, et see on nad kohtlik, kui lasta mikrodenustel endal siseemised hoida järekordem mälud. Väliselt järekordi jäedate järekorvast rääpikit kasutad, hoida asjad mäludus mikrodenustel vahel pufrina ja mikrodenustel saab võtta, kuna midagi töötab. Aga see samuti teeb kogu selle lähenemise jälle teerulisemaks, kui meil ei ole otses uhtlus, siis kaua on sõnumid järekorvast. Kas nii-kui sõnumid liiga kaua järekorvast? Me peaksime juulta panema mikrodenust, ütleme neid replika, et olukorras, et järekorvast on liiga palju objekte või liiga palju sõnumid või sõnumid arvi järekorvast järeks kasab, et me peame siis selle põhjem, aga see teeb siis järekorvast otsustat mõnigult keerulisemaks. See võib aidata, kui me paheme jäädata järekora mikrodenust ohele, aga see ei ole veel atvitektuurike keerulisemust tegega teha ja rohkem sellest hajussisteemide problemi esine tõsta, et kuidas me neid järekorvast raldame, mis me teeme, kui järekorvad järgst kasuvad. Ja mõnigult meil võib olla ka keerulisemaid operatsioonet, et me kasuta saada päringu, ja selle asemel, et see päring on päringu väljakutsumiseks, me kutsume välja ühe metodi, võib-olla me peame parele ees, et kutsuma välja nelimeetodi, nelas erinevas mikrodenuses, et kui tegi kokku kombineerimis kasutale saadma, et meil tekib selline olukord, kus me peame väljakutsuma järjest edasi saadma seda sanumest vaid mitu pärinud tegema ja pärinud tegema, et kokku kombineerimiseks vastuseks, et kuidas komponeerid, et mikrodenuseks väljakutseid teha. Ja meeliks küsimuseks, et kuidas kasutame ühte keskustatannebaasi, niimoodi, et igal mikrodenuseks on õigus näiteks lugeda kasutatanneid, või me teeme eraldi kasutat teneuse ja ainult me saadame rest pärin, kasutatelt teneuse, et kasutada infot kohuda. Ja kas me peame kõikile mikropenestala oma anmebaasi konteeleerid või on üpselne anmebaasi server ja kõigil teeme oma anmebaasi tabeleiga mitte. Tekiju ota päris palju sellise küsimuseks, kuidas me haltamis mikropenestamaalis koosti. Et kui me tegime vajatus, et sellise Appi Composer boost rielel, et meil on mingisuguna päring, mida me teeme ja meil oleks vajana, et joinida anmeid kasutate teneusest, orderite teneusest ja mingisugusest delivery teneusest. Meil on vajanest raportit, et ku raport ja kui me ei tee seda otsa annebaasi põhjal, et meil ei ole teeda warehouse, kus või kannada kokutud, meil on peama apiide kaudu tegema, et meil võib-olla peamegi seda päringida vastuanduks, saadme kolm päringid, kolm erinal mikropenusele ja koko kombineerime selle vastuusele, sõesti tegema näiteks mingisugusek joini, pääluvus, mis sealt maha vastu. Meil on kolm chasoneid, joinime kokku ja saadame ühe chasone vastuudame. Et sellise liul me saaksime teha eralte api-komposeri, kas api-gateway tasemel, et meil onki mingisuguna api-komposer mikro-tenus, mis meshiid kolme teenuse kutse üheks väljakutsuks välja. Kled, kes selle api-komposer meeldad üheks väljakutsuks, tead selle taga kolme teenuse väljakutse. Et see on siis natukene vastu pidin olukord, kus meil ei kasutada päringid nii-ajal, et ei jookse läbi erinalte mikro-tenuste, vaid kutsutakse välja ja koha vastatakse. Eralte anmebaaside tegemise hea külg on see, et me saame teenuse täiesti omavad sõttumatuks teha, et ühe teenuse anmebaasi updateimine näiteks ei mõjuta teisi teenuse tõtsi, et meil ongi täiesti eraldi anmebaasi konteenerid, ja kui me ühe MySQL juuhendame, siis sa ei mõjuta kui teisi mikro-tenuseks, sest need on enda MySQL konteenerid või Postgres konteenerid näimiseks. Ja muudatused, et me muudame sisemist tabeliskeemat ja näiteks kasutatabelis, kui on meil iga mikro-tenuse haks oma anmebaasiskeema seal tabelis ja ühel või teisel mikro-tenusele ei ole lubatud selle tabelile päringu teha, siis tabeli anmebaasiskeeman muutmine ei saa mõõde teisi mikro-tenuse, nii et jälle on selled mõttes hea. Ja mis saaksahab see võimalse, et mikro-tenuse saavad valida endale sopiva anmebaasi mudelid näiteks. Mani tahab JSON anmebaasi kasutada ei, ta tulegi kunagi vaja mingi taga keerimispäringuid või raporteiks generereeda. Ta lihtsalt kasutad JSON-ed hoia, võtab kasutada JSON-e, kirutab kasutada JSON-es uued läärkused, ta ei ole ka vaja mingiselt kasutata üle mingi päringuid teha, võib-olla siis that's okay, et ta on mingiselt hästi kiire JSON-dokuments, database kasutus oli ja teine mikro-tenuse paljad, et valida Postgresi 300-maja-sküeli valid. Teoreetiliselt võib sellest kasu olla, kas ta päriselt ka kasu on, et meil on lisa kontainereid, lisa resursid, mis näide annebaasideks vaja on, et sellest ei kruugi väga kasu olla. Jagatud annebaasi puul on lihtsam üppemete erite transaktsioone, mis puudutavad erine tanneid, et samal aal, kui me kasutame, me tahame samal aal muuta, ka kindlasti tellimuse teavad ja me ei taha, et need autos sünd läheks. Näiteks meil on mingiselt kasutada päljad ühes annebaasis ja sellest tellimuse infoteksias annebaasis ja kudas me kontrollime, et selle transaktime mõnikord saab seda teha niimoodi, et me kasutame hapikomposerit, kes on siis, kelle ülesana transaktiivselt korma anne vära muuta ja kui see ei õllestud kõigist tolmes, siis saab tõmata see transaktsioon, aga kui see on kõik ühes annebaasis, meil on lihtsam jooksata üks pärind, üks SQL-annebaasi pärind, mis ongi transaktiivne, et muudab kolm tüüpi annet korraga ära. See nõuab ka vähem suurtust mikrotenustumahel, et kui me jäägatud annebaas, et kui me muudame kasutad annet, siis me peab suhtsama kasutavad teenusega, ja tõrreedsed me saaksime kiilema suhtluse, kui me kasutame aga see annebaasi, ja me ei püa niipal erine oida annebaasi päringud tegema, nii et mõlemal valikul on oma sellised ediselt. Kas lihtsalt XT-a, aga kui aga problema on kõik, et kui on sellised ühke jüüb lihts? Nel on ikkagi eraldi igal asutus on oma annebaasi ja XT on sellised api, ma ütlesin, et api aga põhjelis see, et see on sellised nimetud, et see... ...tüüs. Nel on oma security liusid küll ja security serverid nende ees, aga see on see kiir tee nende vahel, et XT ongi sinne lihtsalt apid oma vaheline suhtluse standard mõttes, ja iga asutuse ees on see XT security server, kes suhtlust vahelatab ja kõikidel asutustel on oma annebaasid ja kui sinaka asutad näiteks mingisugust riigi registrid, siis seal registrids olevad anmed ei kooperi ühtegi teise annebaalde. Eesti riigi lähenene karanteerik ja anmed on ainult ühäskohas ja kui need muutatakse, neid muutatakse ühäskohas ja kui teene asutus taab need anmed, siis ta peab peab läbi XT päringi tegema ja security serverid, et siis logitakse, kes küsis need anmed ja iga anmed päringi saab logida ja ei teki synkroniseerimist probleeme, aga saab pead, kui tööst tegema päringid, et kui sulle on ningisugune teenus, mis vajab kolmest registrist anmed, siis ta peab need kolm päringid läbi tegema ja sega karanteerib, et sa saad see logida, et sul ei ole koha peal mingis mälus need anmed ja sa ei saa vältida nende anmed uuesti küsimist, ja politsi ei tee päringid, siis jääb alati jäljad, et politsi ei tegi need päringid selle hetkel. See igal teenus on oma anmebas haitad, kes sul tegelikult jälgidad, kes need anmed kasutab ja Eestis on kõist seadused, mis karanteerib, et anmed ei tuplikeerita, et inime ei pea kolm koord oma anmeid edastama tästasama anmed kolmel erinele asutusele või registrillel, et registr on vastutavad nende anmed ja küsimist teises registrist ja selle tehtu neil on vaja. Aga ta ei ole nii väga mikro teenuste muster, ta on pigem ikkagi süssteelida vaheline suhtus, mitte mikro teenuste põhjine suhtus. Sisemiselt mingisuguse asutuse registr võib olla mikro teenus, aga päljaspod vaadab, kes on taragu mingist on monoliitid ja mikro teenuste kombihaatsioon, nagi nad ikkagi suhtavad üle internet ja üle XT. Aga ta on mõnesmõttes rohkem kõrgemataasemalne service-oriented arkitektuur, et kõikidel on täpselt sama standardiga teenused, ADTP ja SIP, siia maani on SIP-päljapäe kasutusel. Ja siis appid panakse painka mõnesmõttes teaduse standardja XT jaoks, aga sisselemist registritele võib olla omaapi, aga XT suhtuseaks on omaapi ja mingite arbet see tüüpi meedrute väljakutsumine toetab saan läheb seubi. Mikro teenustele on võimalik, et tulema või või võimalik, et mingist on osa üle internet? Sul on kindlasti võimalik, et nad on üle interneti sul ka, aga siis tegik küsimest, kas ta siis enam on mikro teenustele. Samas kuiks sul tekid olukot, kus sul osa mikro teenustele on pilve ühes regioonis, siis on teises regioonis. Ja saan, et ta on kui nüüd sama mikro teenuste rakendusosa, aga see lihtsalt paned nad kõikid asja kohtudest, kus on klientid näitud. Klientide ei peaka sootsa ühendustatma Saksama keskusega, vaid saaksid võtta kõige lähendalat asemega. See läheb natuke keeruliseks ja ta on lihtsalt võib-olla definitsiooni küsimuseks, kas sa nimeltad seda mikro teenustele. Või sul on mikro teenuste rakendusele erinele tasu kohtades ja teadud tead federeeridud viisil oma maail suhtelavad. Aga tõesti kuperneetises on sul võimalik, et sa defineerid rakenduse ja sa üldad, et mul on kolm kuperneetese regiooni või klastrit. Ja paned selle rakenduse kaks kooped sinna, et sul on rakendus, mis tegib nende regioonide peale suurem rakendusena. Ja siis teadud komponentavad mõjal. Ma ei oska võib-olla hea näide tuua, kas see on üldse mõistlik. Sest sa tehti tahad, et sul oleks enamahend kõik mikro teenustele kõikides regioonid olemas. Sest sa ei taha, et sul suhtus oleks liiga aeglone ja isegi annebasides. Sest sa ei taha tegelikult, et sul oleks eksisteeris ainult ühe anne, kes päris annebaside. Mõnes pohjast tegaks peikem replikatsioon, et sul on samarakenduse replikatsioon peikides regioonides. Aga teadud olukordades võib-olla, et mõned mikro teenuste komponentid on erikaks tegelik. Aga paremaks võib-olla näide leida. Siin on koost ja näite teadate järekordade kaudu. Meil on mingisugune order service, kes kussees on mingisugune operatsioonid. See on mingisugune operatsioonid. Kui meil on vaja näiteks väljakutsuda mingisugune customer service appi meetood, ilma töödete järekordadega me saaksime, et ta süü proosalt väljakutsud. Me teame tegema asumtroncent, et me peame selle väriingu ja operatsioonid kirjutama järekorda. Kui meil on kohes, et tulemas vaja, teame ma ootne leema. Aga mida ma ootame? Päringu läheb siia, töödates usaga mõel. Me teame tulemas kätkesolda, mis tavasalt teaks on, kui siin teha päring, toedate järekordade kohel, tavasalt panaks päringu raasad kaks asja. Üks on päringu ID, see on minu päring 1,67 miljoon. Tavasalt panaks selliseks, et ma kuulan seda teadate järekorda ja saada selle päringu vastus siia teadate järekorda. Kui see meedot saadab selle päringu, siis ta hakkab kuulada seda teadate järekorda, kus peab vastust tulema, siia võib saada näks 10 vastus, 20 vastust. Ja kahu, et päringu ID, mida te kaasa pani, et siist seeerida, milline vastuste järjest ilmua, milline on vastus selle originaalsal päringule. Ja see töödleja customer service, kogi sõkone konteele, siis kuulab seda päringud, ja ta vaatab, et mis on selle päringu, mida ta redb live to järekord. Töötab sen ära, et sa võtab annemaasis kasutmea info ja sa praad seda kasutme info vastusena sellese järekorda, mida saad te kuulema käkkesaamiseks ja siis siin, mis treeniteks, et oodab, et kui nii saabub sinna järekorda, siis päringu vastud, mille sama ID, kus originaale päring. Aga jälle tekitab see kerukust juurde, et nüüd peab hakkama haltama, et mis juhtub, kui need järekord nüüd suureks kasuavad, kuidas skalereida seda teenuste, et mitte võiteks, et mitu röntgikad peab sellest teenudest olema. Tihki nüüd enam ei saa, nagu teenus, et CPU või länukasutise järgi otsustas, et kas ta on üle korva, aga mitte, et sihti see teenud, et isa otsustab, kui kui kiresti ta neid objektsidesalt järekoraks võtab ja pigene töhaksama otsustama järekordnade pikkuse turhjal, kas siin poolt peab olema rohkem töötse, kesid järekoraks midagi võtab, et siis võib, kui seal järekoraks pigaks, mis võib olema siin peab skalereidimaalt, ta ei saa hakama nende vastuste töötlemisega, et siin peab olema rohkem kontainereid, kes tegelevad sellest oordeks servicei töötmisega. Mis kasul me saame, kui me mikro teenuseid rakendame, on, et Tarkvara on lihtsameri hooltutada ja testitunud. Võimalda sage ta silmi muudatusi teha ja neid testida, et ülespanna uus version kohe, et saab teha sellist continuous integration ja continuous deploymenti, et saab kiresti ära testida ja kiresti uue version üleslaste ja vasta kasutada peab saa testida. Teenuseid on suhtse mõrgalt üksteise ka seotud, et on lihtsam, et meie arendad saavad arendada teenuseid ilma, et ma täiksid kogu sisteemi tunnuma ja see vähendab muudatusta mõju kogu sisteemile. Mida vähendab, muretsava sellest tõttu, et kui ma teen samakoodis, et kuidas sa muudatub muid asja, seda vähendulid testida, seda vähendulid teadmiseva jääva kiireni ja saab muudatustu teha. Kõik teenuseid on ise sestad juurutatavad, et me saamegi teakitada neile omad kit repositooriumid ja eraldi CI-CD pipelineid ja meeskonnad saad näite luenudada ühe teenusei versioon vahetatud näite kuberneetise välja, ei peagi teisi teenuseid pausile panema, et kuberneetise osateks väga hästi nagu rolling update, et teenusei koopad välja vahetata ilma, et ilmstegi eroged tegiks. Mida väiksem, sest teemoond seda tõenaduse on, et meil onnestud seda teha. Monolidse rakenduse uuendamise, et kui me peame kogu monolidse rakenduse pausi tegema ja siis ta ühes panema, on raske vältide olukorda, kus mõned kasutavad saada eroneid. Aga kui me välja vahetame teenusei nagu väikeste tüppide koopa, on seda lihtsam ka. Likult see on võimatu monolidselt puhul. Võimalik on areldada komponente meie süs teenist palju väiksemate meeskondade poolt, et võib-olla meil ongi tuleed asutuse praktikant ja lööldaks, et meid huvitab, kas peab. Peab, et notifikatiivne teenuse oleks palju efektiivisem, kui me püütanasame erlannu kattu. See võib-olla ei ole asutusseks väga tähtis, aga kui oliks huvitavad seda praktiku projekt. Uuel praktikantid on suhtse lihtne. Oltbid ära, et mis on notifikatiivne teenus, kui ta ainult teab seda, et mis püütvii päringud saadab, et sa ei ole muuskete peagi jäägi jõupima. Ja ta või sa proovid implementeerid, et võtab sa püütnud kohti kirutada erlannu sümbad ja testib sellel ära. Võib-olla raporteerib, et nüüd tegin sühteetnist test, et saad sinu 10 000 sanumid. Ja see oli 56% kiirembu püütnud. On lihtsam mingi väikse, et araneleks teha ja uutel töötanest ja praktikantid sühteemiga tuttuvuda, kui ne peavad võib-olla selgelt sõltima ainult ühe mikropeenuse tehtud olukordid. Aga mikro tehnuste puudused on ka see, et raskem on arvusalmata kogu süsteemi hajutatud arhitektuurist, et me ei tegele enam ühtse rakendusega. Meil on võib-olla ühe kit repositooriumis asemel 12 kit repositooriumis, minne ka tuu tuttuda. Ja tehnustevaalist interaktioonise testimine on ka palju keerulisem, kui rakenduse enda testimine. Me teame, et kõik ülespane on meid uvitav võrgukiilus ja kogu süsteem juurutada on ka palju keerulisem. Meil võib-olla ühe komponenti teie ülessealtmine lihtsam, aga kui meil komponenti paljas järjekorrast tööle, panaks selle, et tekida mingi imelikad olukorrad ja meil 16 konteele ülespaneme võib-olla natuke aeglesam, kui ühem monorid ülespaneme. Ja võib ka rohkem mälukasutust vaja olla, et kui me kasutame, et kõikil erinev, kui me saame neide mälu panna täpselt niimoodi, kui vaja, me teame ikkagi planeerima niimoodi, et kõikil oleks 500 mälu, et oma maksimum kasuksega pakka ma saaks. Kui me jagame ühe suure monorid ja väiksema tükkideks, me võime igale väiksema tükkile, et vaja olla panna lisamälu, niimoodi, et see kogumälu kasutas on veel suurem, kui monoridibugul. Ja teistid resursid saavad mood, et me peame igale järkma ikkagi mingisuguse isa resurside mahu ja selle tõpul kogum resurside mahu tükkideks jagamise tõttu olla suure. Nüüd teene teema, mis meil on, on tokkeri-anhitektuur ja on need teene, et haldus, et ma võib-olla seda lõpuna ei jua rääkida, kuna me vaatasime siin näitud ja arutasime natuke, aga mul ongi plaanis kui kui kui kubernetissa lõend, et ma vaatan palju, ma siin jauan ja siis ülejäänud jätan siin kubernetissa lõenduse sest. Et natuke meeldetuletust, et kui me seama üles tokkeri-serveri, et kui me seama üles tokkeri-serveri, siis me tavasalt on mindi hulk konteeleid, mis jooksad sellisele serveri peal. Meil on serveri peal tokkeri-demon, kes haldab neid konteeleid ja tavasalt iga konteeleid oksamiseks meil on rekistist vaja alatamada konteeleid pilt, kui me saad kaha sa teita, et me tegid ka mindistune pilti lokale rekister ja me teame haldamad tokkeri-pilt ja tokkeri-konteeleid. Siin lihtisest käsepid me ostame tokker pilt, tokker pulli ja tokker ram, mida teisevare te tahtipumides kasutam. Tokker tavasalt tänapäeval on pigem selline liides interfeis, nagu konteeleid halduseks, aga siseliselt enam ei islele teerik, kui tõlsene tokkerid jooksad, mida me käinudid. Hihti tokkeri kasutab nüüd sellist tarkkura nagu konteeleid liih, mis on siis tarkkura konteeleid loomiseks ja tokker ise pigem annab teile neid apikäsud, et kuidas konteeleid tuuga, kuidas konteeleid hinni panna, aga isegud sa peale konteeleid ei apikäri. Ja konteeleid on selline tehnologiasta soovima tokkerit ja kasutuda konteeleid halduseks, on tokkeri asjad teise tööristad, kui on tokker nüüd nagu tasuuline enterprise teenus, et teene luba, kui sa oma vajadust teha öpiga teha tasutakaasuta, aga mingis firmaas võib pole ei tubata tokkerid kasutuda teha pitsentilõtma. Ja siis tegelikult peale teeb saab ka lima tokkerid ette kasutuda, et on näiteks teie erinevad pinuks, käsur ja kandida, on eritse l, et käsur ja käsutus, mis on tokkeris arvan, et konteeleid liikauudu otsa asj jooksada ja siis on see pasku tarkkura. Et on amatud tarkkura tokkeri asutudist ta. Ja kasutatakse siis rand C, mis valjustab ette nimeruumid ja käivitevad konteeleid, et teavad konteeleid seest protsesid ja konteeleid seest soksad vähemalt üks protses tavaselt piltis. Konteeleid omadused meelded tuletus on, et neid on muutmatud selles mõttes, et kui me üks kõik mida konteeleid seest muudame, siis see konteeleid pilti ei muuda, et me saame samas konteeleid paas piltist ja uue konteeleid saada tagasi paas seis, et kõik on nagu, et kui meeldada ei muudatas tol originaalsed pilti. Konteeleid on mõeldud ühe kordseks kasutamiseks. Tokkeris võib-val seda väga ei märka, sest te teete, et tokkeri paata seisma, paata uuesti käima, paata uuesti seisma, paata käima, ja see olukord jätkab edasi. Aga kuberneetises seda teha ei saa. Et kuberneetises panas konteeleid seisma, see tähedab tegelikult kustutamist. Kuberneetises on mõeldud alati, et kustututakse lihtsalt ära kõik, mis on konteeleid seelt muudatuse tehtud, ja palaks uus konteeleid nullist tööle, ja see toimub iga kord, kui kuberneetises panad vahetat versionid akkuvarast, viigutab ühe konteeleid ühes serveres teise, viigutamist tegelikult ei toime, toime kustutamine. Kuberneetises on rohkem selline, et teate eelt, et teie annabase konteeleid võidaks seisul suvalisel hetkel kustutada. Kus teadab seda seda annabase konteeleid? Kostudad mitte. Peate annabase üles jääb ma niimoodi, et kõik vajalikult asjad konfiguratsioon anned oleks mingi voljumi sees, ja see ei kustutakse, kustutakse ainult konteeleid. Aga ka voljumide haldus on omakorda keeruline, sest kui te jooksutad konteeleid mitme serveri peal, siis millise serveri peal on see voljum? Kui see voljum on lokaalne file-i voljum, sest ta on ühe serveri peal, kui ta on liiga palju ühe serveri peal, siis te võib-olla kolmat ühe serveri üle, et seal tohku mõet selle balanseerilide peale. Aga ma räägins just kuberneetes loengud, et tegelikult see on tarp, mis haltab neid lokaalsed voljumid, niimoodi tõstab neid ümber, või kasutab visiagil võrgukettaid selleks, et näid voljumeid poidagi teise serveri peal, ja seda problem ei tegi. Aga teist, kui te jooksutate MySQL-i konteeleid, te liidite selle, siis keegalme kauda. Tokeris on normaalne, sest te ise jooksutate liidkasu, aks kuberneetes võib see liid toimida taustal. Teie kasutane ei tea, ketta ära kusul, et jääb pandi selle. Ma räägins just teises loengus. See on lihtsalt vajaalik, et kuberneetes saaks ennast optimeerida. Teie, kui kuberneetes administraator, peate seda teadma, ja peate konteeleid ülesadme niimoodi, et pide kadu meile. Võimeks maountime voljumid, või mauntime välise kausta ja hoidma konfiguratsioona seal. Te peate ise hoolitsema sellest, et kõik vajaalik, mis on persistempinea, ehk pidevana hoida, peate seda konfigurata niimoodi, et saab korra eht teha. Kuberneetes ei kasutata tokerpilte. Kuberneetes on tavaliselt ettevalmistatud kuberneetes templaidid, mis automaalsalt loovad õigeid voljumid ja asjad valmis. Kui teie peate poskress sellest kuberneetes, siis ei kasuta tavalis tokerimidžid, või kusutata poskress helm charti, või poskress operaatorid, kes ise oskap ja sinna sisse neidatud korrektne kasutus, mida tokerkonteeneritesse ja tokerpistitesse tavalist ei ole. Sellest mõttes on lihtsam kasutada kui tokerit. Tänal ei ole sest aega rääkida, aga meil tuleb kõik eraldil oend selle kohtal. Aga sellise juba ei ole pohutu, et tegigi mul on suurit, eks ma ala vakrani hidutama, panen siis sellele lõu alla lupu, aga siis protseist abetakse arasemale alu. Ja, et protseist peab olema loodud sellisena, et annab asi protseist ta vasta ange, et nad küiaad selle signaali kimmi, teevad kõik transaksioonid ära, või panavad need transaksioonid tagasi, kui nad teevad transaksioonid ära või roolivad ära, ja siis ise lahkuvad, nagu ise eksitivad. Et sul peab olema protseist loodudki niimoodi, et nad võivad neid võib kildita suhjais lajal, aga see kilimine ei ole kohene, vaid see on ikkagi signaali kinni püütmine ja protseist tead lopu, nii siis lahku välju. No see kilimise mõttem, et kohestab, et toonis signaali välju. Kui sa annaad maksimum signaali, et midagi ära tappas, siis on sinu probleem. Mõtlen ka, et see server jooksid kogu, oleks meed toot, et midagi signaali vallel, lihtsalt ongi üks, et neb välja asjad. Jah, selle vastu taval see taitab right-ahead locking, et näites, Kafkas kavutatakse seda, et enne, kui sa midagi töötla, magatsead kirjutu kepale. Et sulle tead päring, see kirjutu kepale. Ja poskas kavutab kasadad, on right-ahead locking, kui te oota kuulnud see asi nagu pool. Et see ongi see, et ma ei hakkab töötlama, ma kirutan, et ma hakkam töötlama kepale. Ja kui ta järgmise käibitukse, ta vaatab kepale, mis oli see operatsioon, vaatab, kas ta tegi see lõpuni, kui see ei ole lõpuni, sest ta võtab uuestas right-ahead locking, siis hakkab see kasse tegema. Tekikselnad journal või right-ahead locking, ja seda kasutatakse ka Linux-is ketastale. Ketad samuti teevad endale nagu logid, et väga tihti kasutatakse, kes logid selle jaoks. Et tuvastad ära, mis jäi liimati poolelid. Ja see peab olema sisse eitadud protsessi endosse, et selle asja on tarkkarasse. Annebaasi protsessid peavad olema viisavad targad, et nad saavad logist võtta, et mis eeline protsess oli, mis oli pooleli sellele algukrasjist. Ja see on tegelikult suhtselt keeruline, mis juhtub, siis kui midagi võtla, et kui toesti midagi korrupteerud, siis võib öelda, et Annebaasi ütlele öelda, et teete start-container, Annebaasi ütlele, ma ei saa alustada, midagi right-ahead lockis korrupteeranud, ma ei tea, midagi ta teha. Ja siis administraator peab minema uurima, et mis protsaksioon ei pooleli ja midagi käsit siin korda tegema. Et teadud olukord, et see võib tõesti kõik täitsa metsu neme, et siis peab ikkagi inimene minema uurima seda. Aga ja, või tugev selle right-ahead locki kohtad seda kistikasutad, et saajustas teeme, et seda aga üks vägist läbi. Alaati midagi käsid. Olukorras, kus ma võib-ole ühe järgmiseks olla näitanud, kui suured on Netflixi mikro teenudad, ja mida ei oska, ei ole võimalik, et isa ei visualiseerida, ku palju need on, et alati midagi käsid. Netflixi teised teevad ka chaos testimist, kus nad laivis lasevad asjad Annebaasi näitas katki ja testivad kogu sesteemi ja tellu. Ja see läks liiga kalliks testida, et ei ole võimalik laivist teha koopet. See laiv on nii kallis, et see on lihtsalt lihtsalt ei ole võimalik koopet teha. Teadsisest chaos testimist täiesti laivis ja ei saa... On okei, kui kasutad teile video mängimine või filmimängimine korras katki läheb. Aga nad teevad sellist chaos testimist, kui ka natukse aadega, et karanteerid, et kui Annebaasi katki läheb, et siis asja teavad tõel. Ja väga hästi on võimalik konteeride abil tagata paralelisest, et me saame panna konteerides kolm koopjad konteerid tõele, et kõik töötavad erinevatud portid üle, me suuname sisse tulad pärilud kolme porti vahele, teeme näets nii Raun Robin kolmusjaoturid jaotus nende vahele. Konteeride teavad olema steitas selles mõttes, et kõik, mida nad hoiad, mäluna peab olema ajutine. Nad ei tohitsi mälus hoida midagi, mis on pajalik järgmise päringuteöötanese. Mälus võiks hoida ainult neid asja, mis on pajalik ainult selle päringuteäitmise, et kui järgmise päringuteeidame, siis me ei tohitsi tegelikult sõutada öelmiste päringuteese ootud anmedest ja mänualadest, nagu see käsimine taks olema konteeleete väline asii. Me võime ajutiselt pildi saallistada ketale, et käilitada mingi masinope teeg määgid selle peal, mis nouab, et pilt oleks netfallisistemis, aga järgmise päringuteeoksada maja otsalt ei ole maja. Me peame tegelikult eesame, et iga laal võib konteeleete haltust tarkvara migreeride konteeleete surgeda, skaleerida, väljamahetada, skaleerida nähele ka allaskaleeridas. Ningil hähpeal me tahame kolme konteeleeraaseandri oksida kaks konteele, millise konteele me kinni paneme, ku kõu ma ootame ja allaskaleerime alati see probleem, et võib midagi vahe kiitsema alla. Konteeleete elist on see, et meil on rakendused saavad juosta täiesti enamaltatud keskkondades, nad ei ole oma alasseatud, nad võivad jagata mingisugust file, aga need fileid on read online, nii et neid kunagi muudeta otsaselt, kui mingid muudatuse teaks, siis on lisakihiina nende peal enne kiitama ajutuse. Konteeleet on aesti lihtne, nagu liigutada, kui taas need isegi liigutata, aga saad seidma ja sama hiniks, kui sa te muu jäl üles, aga vajaduse saab ka mitreerida tokkere konteeleerid, et jääks meilusnapsot ja panmed kettastasnapsotne liigutatakse, aga tavasid seda isegi tehti erikub uber netse. Me ei saa me teha palju tehedama, et keskkondasid, kui me saame konteeleerid panna omavahelneet samu layeri jagama, et me ei tea, nagu keskkondades koopa tegema nii, kui me teeme näiteks samast konteeleer imidžiest võib olla 16 replikat, siis me ei ole vaja annetes või nendest alkfailidest koopa, et saavad need failjesid ära kasutuga. Konteeleerid on nii saa leeritud mitte nii tugevat kui kõrta omavahelneetapuul, aga ikkagi suhtselt head ja konteeleerid loomine kopeerime käibitene on palju kiirem kui kõrta omavahelneetapuul ja samat elis nagu elis, et saad juba lihtsalt saa leeritamas. Kui te hakkate looma nagu keerukama, et siis teeme konteeleeritapis, siis te oost te peate hakkama kankutama container-toker-komposi. Tõske käsi üles, kes on toker-komposi kankutamist. See on suhtselt lihtne, et põlimad siis siin üks blok on toker-rank-kuma, toker-rank-käs, kus te kõik parametrit, paepenavuus, standardsad kirja, et veeplad siis üks container ja siis erinev parametrit, et kas te kuiidite selle kõikist kaustast, kas tal on mingiselt mingi testrakonteeleeritel, kas tal on mõnid salapuseid, mis on keskona muutüad, mis port on ekspositud ja mis käes kaandud, et saa container-is toksudada. Tavastab lihtnese käst kirutud, et saab containeri emitsi sisse, aga mõnikord on hea, see on kõik, et see on kõik, et see on kõik, ja siis palju see, et saab container emitsi sisse, aga mõnikord on hea, see kasutat viitisema containeri pitti ja siis panas sa randkäs ka kohane randkäsu sisse, sest ilmes on me need procesi siinelmise ja oksutamise parametrit muute, et me saame siin kifad muutele, et ikka kaas poole poole papeid, et paname paname pane põlemud ilma, et me peaks olla tokkata niimoodi. ja tavalselt paraks. Nende võidate olla sinne eraldi nagu kirjatena Topper Composes, aga nende võib olega failist loeva. Siin nende ala mõetud, et nende on eraldi nagu kirjat siin samas failist Topper Composes. Siin on ka nähe, et nende on Secret, Postgres User Secret, Postgres Password Secret on siis failides poetud. Nad on nagu kirjat samas failis, aga nende asukost võib olla eraldi nagu failis. Nad on failis võistis keskkona muutööta naala poetud. Siin on siis hea, kui te selle template'i pärate kitst haabi siis se eläisalmast kaasa. Juhul, kui eritikudent Secret on kuski kittigi nooril kaustas või väljastol kaustast poetud, et nad ei pea olema alam kaustas. Siin ongi, ma parem üles Postgres ja me panan üles mingisels webiteenuse, millega me webiteenuse meiseb pildi, ma alam kaustatud, et see on Topper faili. Ja kui meil on mingit parametrit, näiteks me Postgres jõuda, mis on kasutaja parool, siis me siin saame aga midata samadele muutöötele. Kas eraldi, ma panan et paik ka või drag on etiks failid on abartad, et kus on kasutaja nime faili ja kus on paroolis faili. Ja kui kui kui nad on praegu nad kuulita tehtud. Ja siin saab isegi kerukamaks minna, et saab ka hakata panna paik, et mitte koopa, et näiteks sellest webiste, et ma taan, et webist oleks kolm korteereer, aga sellise liulud on portide kättevaatid olema, et peab siin oleks portide pandi, mis see panemaga, et me ei pananud, et see on kolm porti, neid 8000 kui 8200, sest muidu samasse masinasse ei ole võimalik panna kolm korteereer, et sama porti kuulama. Et siis peab olema ka portide reinge. Ta võtab need automaatsed selle reinge-ist alates alguses, ei ta kontrolli, kas port on kasutuses, kui on kasutuses, siis skipib selle. Mõnikord mul on teginu probleem, et ma proovin Docker Compose restartide, millegi pärast ta ei õnestu sama porti võtta, kun ajal, nagu container peab korralikult andu stopi, siis ta võtab järgmisev. Et seal on natukene, sest sellega tuleb ettevaatik olla, et need portid ei tohi kasutuses olla, aga peab kõesti skipib meed, kui nad on nitu. Aga ta võtab alguses peale 201, sest misti istja ma teha, et ma panen siit kui kolm hoopelt, leidis 21, 21, 22, aga on pärast kohvima, aga midagi välja spore, kuidas ma liidu see siia sellesse portid suuna, et kui ma näitis NGINXi containeri panen püsti NGINXi, siis ka seal jäts konfigureerimise viipaadresid on, nii et see on alati selline, et järjest kerõmiseamad läheb, aga see on väga hea, kui sa pakendata nagu mikrotenuseid siin üht ja Tocor Compose koku ja pananud korra ka tööle. Ja Tocor Compose tegelikult oskad neid nagu üks haaval ülespanna ja kontrollida, et kas kõik jooksevad. Ja siis saad ka panna neid siia. Panna näiteks siia. Tepends on, Postgres, idee on siis, et enne panaks sa Postgres ülesi, mis panaks see container, mis Postgresi täu sõltu ülesi. Selleks kontrolli tege järeekordad, mis järeekord on, et ülespanaks sa. Aga tavasult on ikkagi parem siia käskuri rakenduse sisse eildada, et kui ta saa Postgresi kõhendust, sa proovad vist uuaselt. Et täitsa louhulik peale. Siin on tegelikult aske kontrollida, et Postgres on vahelik, mis pärjegi vastavõrtuma on, vaidase see, et Tocor Compenerm alustab. Kui planeetises sa pananud reegmitsia tisse, kuna Postgres on valmis, sa panna teise containeri tööl alust, siis, kui enne on valmis. Aga see võimaldab, siis containerid käima panna, komplekt container käima panna ühe käsuga ja näites kithaad või pannagi kogusi infrastruktuurid kirjeldes selleks ühe Tocor Compos valinad, mida me taham üleks panna. Lisaks on võimalik, et Tocor panna tööl ja siis klastri peale, et meil on näiteks kuus serverid, mis jooksutavad Tocor Containereid ja me joinime nad kõik üheks klastriks ja siis panna meie Tocor Containereid tööle, siis terve klastri peale juba. Me ei pea Tocorid jooksutama ühe serveri, nad me võime jooksutama ka siis Tocor Swormina, kus meil on nagu üks appi, peale ka autume töid jooksutama, aga need tööd võivad jooksutama üks peal misuguse serveri peal nendest kuues näiteks. Ja seda näiten aga ei see ole võimalik, et mida Tocor klastriks on võimalik konfigurerida nagu üheks Tocor keskkonees. Tocor koodumia Tocor Paneetist on võimalik juba? Ia, itselt Tocor Sworma see on lihtsam ja kui Paneetes on nagu hästi kergu. Võib-olla mul on üks samm puudu, aga mis on vajalik, et Tocor Swormeetada ühe Tocor, masina peale on vajal instalida Tocor, siis on vaja jooksutada üks kas Tocor Sworminit. Ja siis teise, see prindib pendeleva käsu ja kui te kopeerid selle käsu ja jooksutad selle sama käsu prindib viie serveriga, siis viis rikki põhjooningad siia klastrisse ja teil tegid paari minutiga kuue nootine klastrit. Tocor Swormi loomine on täst lihtsalt. See veel eeldab, et masinat saab kooma ühelus, neid on võimalik instaleritud ja need on see, ettevallistus võib natuke kerulisem all, aga see käskude jooksutad on meil on vajal kuute käsku jooksutad, kus masinat üheks klastrit siia kokku panna. Ja pärast seda ma saan siin klastris jooksutada Tocor Run käskud asemel Tocor Service Break käske. Ja selle idee on, et ma ei nüüd enam jooksuta ühtekonteele, et ma ei vaidma tene teemuse, mille sees on üks kuni n konteele. Ja tagas ma määrad, siin oleks näiteks kolm replikat, ma määrad enam, mis on 40 ja ma määrad enam, mis on konteele, ja kui ma teinud, et käsku on enam samalmas Tocor Run, selle vahe on see, et siin see port tekib sellisena, et see port kuulateks kõik nende serverite peal ja väljas pooltu, et sama port rasutatavad suvalse serveriga, ma saan nüüd saata näiteks main node-ile pärin kuu porti 28.0.21 peale, et siit suunatakse liiklus sõistilendis kolmest replikast. Siin on sisse eedad kolmuseatud. Ma ei teha suunama liiklust teatud node-ipeale, ma saan suunata liiklus 1-pitmis node-ipeale või vähemalt main node-ipeale, ja automaatsed jagatakse siia tuleb liiklus kolme või ükslikku paljude replikate vahele äranistele on. Sisse eedad kolmuseatud või emal ta väga hästi tokas loormi abi skaleerida sõsteeme, niimoodi, et me seame üks kuni rohkem konteneet üles. Kasutatakse hästi lihtsalt sellist pannkoobin algoritmet jagada liiklus nende replika konteneete vahele ära. Väljas poolt mul jääbki nimaad selline port 28.0, et kui ma siia saadaan siis pärin kuu, siis saadatakse edasi, kas node 1-28, node 2-28 ja nõud 3-28, siis jäänud kohvalt konteeleerid või porti 5000, aga väljas poolt ma saan siis lihtsalt liiklus siia saata, ja ma saan jooksalt ära muuta mitte konteeleerid siin taustalt tegelt jooksalt, praeg on kolm, aga ma saan lihtsalt käsujuoksult, et tokas service scale vb1-le vb5-le, et mul piisab ühes kasutat näed, et 50 konteeleerid peale scaleerida ja ühevõi konteeleerid peale scaleerida, tohkes on lihtsalt lihtsalt nii imad, et nitu konteeleerid ei appist see jooksalt nende servete peal. Siin tegelikult on limitatsioonid, et kui te seda natuke ümber ei tee, siis see maksimum siin on tegelikult serveri tarvat. See on selletõtta, et tegelikult prooviteks sa panna iga serveri peal, et sama porti peal asja jooksma, ja ma ei saa sama porti peal, sama serveri peal seda porti kaks korda kuulata, nii et see defaultimeha saab sama paegi, mille konteeleerid jooksalt ja kui teid serverid on, ei tee anna, et anna piste, et konteeleerid on rohkem ligi tähes, rohkem cq, rohkem mälu. Ja kui te tahate, et saaksite rohkem kui teereed jooksalt, siis tuleb see porti ka selle tead, et tead, et pealist mord. See on kõikis väikilisioon, et kui meil on teenevast kolm replikat, siis lihtsalt ei jooksalt kolme võrkeri peal selles klustris kutagel, ja me tavast ei otsustad, kus ta jooksalt. Tokkas mormi on suurselt lihtne kasutada, aga suure huulga kontenele teha hallus läht keeruliseks. Ja teene asjumis läheb keeruliseks on klustri ketta avade aldame. Kui me peame mountimaan mingisugusid välised kaustasid, kui meil on anna, siis me olnud seal, anna, siis me olnud ter, anna, siis me olnud ter, ja me kasutame mingid molyumid, siis see molyum on tavas lokaalne ja me teame määram ära, et see server, et sa pannt siin ei oksutada, kui ta on siia võib ma mingid annaid saljastanud, siis me ei saa seda väga lihtsalt muha jooksutuda, kui need anned on saljastatud siia. Et tihti meil natuke tegid probleem just annebaaside jooksutamisega tokkas mormis, sest ketta alade volyumite hallus on natuke eba. Ma äitaksin efektiivne, aga ta on sulksed keerulne, kudas hästi seda hallata, et mul server alati jooksub selles noudis, siis kus need anned on olemas ja ta ei kasuta teise noudi anneid ja need asju. Automaastiskaleeristid on isäinneveteerivad, kii peab need scale-up meedodeid käivitama, aga nagist püütun skõptis selle jooksutamile suhtse flichtne. Ta ei ole nii stabiidne, kui teised lahansid nagu kuberneetes ja võrkude haldamine on võimalik, et ta saate igaroa hakkandis selle luua oma võrku, aga saate ka tokkere kompouse ja sisse kirutada, et loome spark võrgu, spark rakendise jaab sen edasi, aga nende haldamine reeglite panemine nendele, et spark võrgust ei ole lubatud andrabase võrku, midagi saata on, et mõnikord võrkude vahelise rootimis reeglite asjada paikapanemine võib suhtseb keerulne olla tokkere normuus. Ma jätan need vahel ja räägid nende kuberneetes laingus. Need on standaardsed viisid, kuidas konteerin halldust kasutada ja ma üpun ühele slaigile, kus ta võrgen tokkersvormi ja kuberneetest, et selleks, et hallab ka suuremat keskkond, on mis võimalik kasutada ka stokkerit ja kuberneetest ja näiteks, nii mõlemast saab kasutada klastriete haldamisele suuri klastried luua, saab protentsiönida üle klastrisel teenusele nii et sama teenusele, nagu kolmdes võrkliket näiteks. Meil on võimalik teenused, automaatsal leida teenuse nimetohjal, et kui meil on eteks poskress teenus, siis meil peab poskress teenus nii, et kasutama saame nime kasutude, kus saadub poskress ja tühendavam poskressi. Seda ja kormust on võialtas üle maailm mõlemus. Mida meil saad okkessu on, et meil on hästi teha sallestus lumi orkesteerilist kuberneetest, sest see on sisse eitadud ja lisaks saab kuberneetest ülesseada lisad hakkara, mis oskeb paremini sallestus lume ja voliumid automaatsalt liigutada, automaatsalt skaleerida ja automaatsalt anda luua uusi voliumid, kui me paneme uue konteerid ühels. Kuberneetest on ka võimalik paremi, tarkvarne versioni tagasid oma, et kui me paneme üles oma appist, tocker, konteerid version 2 ja see ei tööta, et me saame kuberneetest ilusti roolid takkida elmisele versionile ja tockeris see ei ole sisse eitadud nii lihtsastgi või. Kuberneetest oskeb paremini ennastat, ta on parandatud, kui midagi krasj, siis tihti on isegi sisse eitadud, et kui ei õnestasida parandatada ja mene varasama ja versioni tagasi, tockeris vorm oskeb meiteks tockeri konteerid restartida, aga ta näiteks ei oska juoksotada teise servere peal, kui ta selle servere peal ei tööta, aga kuberneetest võib valida, et ei õnestu selle servere peal käivitata või proovida teise servere peal selle samas juoksotada. Saladuste ja konfiguratsiooni haltus on kaks kuberneetest palju parem. Me saame saladusi tekitada kuberneetest olemitena, et kirjutada kuberneetest appist, et meil on oskras saladus ja siis teised konteerid saame üelda, et kasvab seda saladust. Toker sormis on salati fajlide põhine, et ta peab olema kaasas selle tockerfailiina, mitte tockerfailiina aga tockerkäsuka või tockerkompousefaili. Kuberneetest on sisse eidatud automaatna skaleerimine, et saab üelda, kuna peaks lisama või eemaldana konteeleid vastavad monitorimis parametri, ja kuberneetest on ka monitorimine sisse eidatud, et keeltud asjude saate monitorida kuberneetse enda appi kaudu, nii et saab nagu otseselt konfigureerida, et saate kuuluti, et et tockerkompouse sisse kirjutada, et kuna lisata ja kuna eemaldada replikate meilne konteeleid. Songi enamem kõik, mulle on paa slidii veel, aga ma jätan need konteeleid orkestreeenimise slidisi alles, saab iselukeda, aga need OCI, open container interface slidid ma siis räägin, kui panets laingu algus. Tegelikult parem nii mahu, etki sinna lainud esame siia. Kokku võteg, siis mikroteenused lihtsustavad mõnesmõttes hajussusteemide loomist, et me saame luua nad unikaalsete selliste konteeleid enna ja suhtusest kasutadastandaartseid appisid, tööde järjekordasid ja neid skaleerida, eriti, kui ma kasutam Tokers Formi, me ei kasut ühe sõlmest Tokerid. Tokers Form võimalda luua tockerklasterid, et me saame siis skalereid ühelta serverid, paljude serveride peale, järgmeste kordade me vaatame Kubernetest. Kubernetest on palju võimsam ja põhimast, et peab kõik kära automatiseerida, mida muidu peab operaatore tegema käsit Toker klasterid kuhul. Paljus obi on Kubernetest just suuremat konteeleid ja klasterid teidamise. Samast tead mikrotenuseid sistemi arvitektuuri palju keerulisemaks, et neid on lihtsalt palju raskel hallat nagu monoliitsed rakendusi, et natuke tuleb see ka ettevaate kolla, ka et mitte luua nagu siikend suur arm väiksev tenuseid, kui järgmine loegi me just vaatame, et mis aastat on nanotenuseid, mis on palju väiksevaku mikrotenuseid. Teeme ka praktikumis selle läbi, aga te ka näed, et need on tegelikult täitsa-täiset asja kasutatakse teist tüütbi, nagu funksionaasuse jaoks või mikrotenuste puh. Tõesti mikrotenuseid võivad olla epafeksidik tiisiamat resursi kasutus osas ja võid te näedid lugega selle Amazon Prime Media kohta, mis kasu nemad saaid. Võidsid paarsammu tagasi monoliidipoole, et nad täiesti monoliidiseks ümber ei teenud, aga kombineerisid mitmed mikrotenuseid tagasi monoliidsel, nad täiks mikrotenusteiks või midjumtenusteiks. Just see lokaalse võrku kasutamine, et kui tegelikult tegelikult pildifailide, videofailidega siis ei ole hea, et tõsta ümber üle lokaalse võrku, et ta on väga väga aegaseks. Hea on vältida suurpe mahtuda arme te liigutamist, nii et just sellist maasineopte mikrotenuste puhul lihti on parem nagu kasutada viiteid näiteks 5-i sisteemitele või objekts storage-i teenustele selle asemel, et kui tegi anmed ja piltte päringutega kaasa saada. Ja lihti ka, et töödi järekoht, et see ei panda piltte, või paneks see viidea piltidele näiteks selle asemel. Järgmine loengusest räägime siis nanoteenuste, ja tulevikus räägime natuke täpsemat kuba neetesest. Näedime natuke rohke mikrotenuste armitektuuridest ja sellest tandartsatest ka kontenerd liigestest. Ja viimases loengus räägime siis täielikult pilvepõhistest rakendustest, mis ongi desainitud, kas konkreestalt kuba neetes jaoks või natuke üldisemalt pilveteenuste jaoks, et räägime näedest täielikult pilvepõhistest ja rakendustest ja standardritestest. Ja teeme ka selle iseleb, et me võtame siis oma kasutuslo. Järeline kord me lisame või nad nanoteenuse oma kasutusloosse. See nädal me ehitame oma appi kaheks konteinerist, eraldavad siis selle raamatud otsinguappi eraldi konteinerisse. Siis lisame vahe mikrotenuse või nanoteenuse sinna juurde ja tulevikus siis jääme üles selle täiesti pilvepõhistest rakendusena ja me lisame ühe komponenti veel juurde ja paleme ka frontendi sinna juurde. Tekib me seal hästi lihtne Hardware Melee avaskript frontend, mis kutsub välja appi päringud. Ta on nagu sinna hästi puhas ja avaskripti põhin, et ta ei kasuta näidis reaktiivne sellist. Pige mõrpeltab, et kuidas neid päringud, appi päringud ja avaskriptist otsa välja kutsub. Ja siis lopud ja lopuks meil tekibki selline kahest mikrotenuse, ühes nanoteenuse, ühes frontendist ja mõndades pilvepõhist koos on selline rakendusmine, me lopuks asuret üles paname. Palun kontrollikega oma asure konto jääki, et kõike seda ära ei ole kudutanud ja palge mõned asjad kilmi, kui see on juoksmas teil midagi, mida praktikumii juheb ei nõudud, et see on juoksma ätakside, et iga küs kontrollik üle, et ei ole kõik rahma ära kudutud. Nüüd võib probleem tekeva ilmas, et praktikum ei tegema. Aga tänaseks siis kõik. Ega teil, zoomis siin pisim siia ole. Kui ei ole, siis ma panen zoomi väikselt kinni. Tänan. Kui ei ole, siis ma panen zoomi siia ole. Jaa, ta üle 10 ei olnud. See oli just alla 10. See ei maksa ütse midagi jah. See on teie tasku tänna. See on siis storage. Storage on lihtsalt se kontentri, et netvrakis hoidas ja hotmaili ei aastakõpfaila. See ei maksa ütse midagi jah, et nad isegi ei võtda, ei kisi raha vist aastakõpfaila. Ei kisi raha vist allotumbamise eest. Teoreetist võib pole, kui ta paate mingil hiigel suuret piljifailid sinna ja kasutat rohkem kui mingil 10 terapäiti kuus, siis võib lakata sinna kihima. Aga see võits olla sama nagu keegi ka mainis valasamas loengus, et see võib enamneam samamist kitpagents alavai kithab pagents. Et kui see lihtsalt hoidakse hotmaili ja jahastakõpfailet. Ningid püütanud saan väljakutsuda ei saa, midagi tunaamiselt ei jooksutata serveri pole kõik käivistatse teie browseri ja kõik. Javaskõtti ja hotmaililiselt teie browser käivist ja kõist. Et see on lihtsalt hotmaili ja javaskõtti failida allotumbamise.

---------Loeng 11 - Mikroteenused  Kubernetes.txt--------

 Tere tulemast Luangus no 11. Vist, kui ma ei ette mäljata, et täna räägime peamised Kubernetesest, aga natuke naalguses lõpetame võtla kokku ka mikropeenosti teema, kuna ehmise luangus läks natuke kiireks lõpupoole ja mul on plaani saanud kui paaresse veel ülekata enne kui me Kubernetesi juurde lähme, et me tõi rääkuseme konteineriseerimist puudustest ja sellistest olukorrast, mida Kubernetes laadne platform võiks parandatadame ja kordama sell otsa üle uuotski. Ajalooliselt on kokus veekitehnoloogiat ja üldse rakendust arendus liikunud edasi, et kui alguses pike rakendati sellist waterpool stiilis arendust, kus pandi nõuded algust paika ja arendati siis rakendus valmis enam päeha mahtal tõuetele, ja siis kile vaadate üle, et kas on mingisubuseid asju vaja ümber arendada, siis 2000-leidel alustati sellist agiliselt lähenemist, kus räägiti läbi koko aega näit klientidega, et saaks tagas, et nii kiresti kui võimalik, ja et oleks võimalik rakenduse version iga natuke saadagant ümber arendada ja siis klientile testimava hakkad, et ei tekki teda nõnu sellist ühti versiooni rakendusest, ma ei tekki palju versiooni, mida siis näidatud klientidele ajas ja rakendat edaselt. Tänapäeval prooviteks sa rakendada DevOpsi, mis toimistatud on samamist agile, aga ta paled natuke rangel on paika, mis toimub iga versiooni arendus käigus ja prooviteks sa teha niimoodi, et need versioonipe vahed toimub hästi-hästi kiresti ja ei ole proovleemi, kui näiteks mõnes asutuses teha mitte versiooni päevas ja laitaks üles ja lastaks vaadata, kas klientidele tuleb negatiivsi tagasliseid või puhtad meetrika või logidebojal näeb, et midagi on uute versioonte ikas proovleemi maatinda. Waterfall aretab sellist monoleiselt serverid, vahendid üldiselt üles püüsiinistel serverid, et ma olen suht rakendiselt üldiselt serveridele ja Anne Keskus keskus firmad pigem ehitsid oma Anne Keskus ja tain oma püüsiinistel serveridele üles. Ma olen me varasemata suhagustus läheb, et mitme iilised, ent iilised arkitektuurid, aga need hakkab nii siis 2000-tal aastat aane üles, aga virtuaalserverid keskus on nii firma, kes pakkusti näiteks Eestis ja sa on võimalast oma, nii misest ma ei eest kuidu, PHP-versioalsvasserverid, et saad oma rakendise sinna üles teada ja siin hakkas olema see, et sa ei ole oksutas seda enam ennaseerverid, aga nii misubise teise teenust pakku ja serverid ja virtuaalserverid. Ja umbes 2008-2009-2010 juba enne 2010 hakkas pilnpopulaaseks saama ja teavad, et kasutat jalgusev võrkaalmasinaidid kontainerid, et tuli tegelikult natukane hiljem, aga selle läpkel hakkas RNN-naga mikro teenuste maailmed hakkati järgis rokkem rakendu siis nii enampeal kihilisena, või niimoodi iga hiht oli ka jäägatud eraldi nagu sellistekse loogika järgide eraldi teenusteks, et võite ette kuududa, et oli üks root, siis tegisid ripas, erid on pige nagu maatrix rakendusja aranud, et oleks aga mikro teenuste maatrixed. Ja tänapäeval peab kõik asjad saata külleks kontainerit, et see isegi kui peamine eesmärka virtuaalmasineta sõle seda, siis on tegelikult ikkagi hea virtuaalmasineta eeskohdata kontainerit, kas või isoleerimise või keskkondade eraldamise eesmärkina. Ja tegelikult see mikro teenuste arend on ka aidanud ka agiilsest arenduseks DevOps arenduse poole. Selle tõttu, et ühest vaatest on vajalik automatiseerida arenduseks rakenduse üles, seal, mis kui rakenduseks olnud 16 tükist või 25 tükist, et siis ei ole hea, kui käsitsi pannaks asju üles, et parem on automatiseerida ja kogu selle DevOps mõnesedlads mõtte ongi, et võimalikult palju iga kiilsse uue versiooni ülesseadmine automatiseerida niimoodi ära, et seda ei peaks inimene käsitsi konfigureerima, vaid iga kord, kui lasteks välja uus release, siis automaatselt või panaks üles ta siis targvara rakendi sisse. Et sügisel on kõik DevOps aine, see on varasemalt, teaks sul on teie õppakavas järgmise aasta, pakkat udenkit, ta ei ole pande õppakavas, aga teie õppakavas, ta tõenab, et see on, et sa on mõeldud, et pakkat udenkit võtavad seda võib-olla kolmandal aastalega võimõttel, teaks seda saama etteks sügisel DevOps aine põtla. Kui võtavad vast, siis teist ma kistis. Tänna ma kistis, aga aine, ette õppakavas sa panen, et teed olevad ainult alati niimoodi sisse astuni hetke. Kuna teile sisse astusite, kui ta oli sellel hetkel teile õppakavas, siis ta on teie õppakavas. Isegi kui keegi muudab seda järgmise aasta ära, et ta enam ei ole õppakavas, siis tavalselt ei muudab seda tagant järgi, vaid muudetakse uutele sisse astunutele. Sest muudetakse olukorrad, et sinna astusid sisse arvasid, et sul on mingisest specialiseerilis moodul, järg kui kaab seda. Seda üldiselt ei tehta. Ära vaata kõige viimast õppakavad versiooni, vaata seda õppakavad versiooni, kuna sina sisse astus. Ja seal ta peaks allaks alati. Kui te näete õis, siis te näete, et pakka õppakavasid ongi iga aasta kohta uus versioon. Iga aasta kohta on versioon, iga aasta nad natukene muutuvad. Ai on kõik võtta? Ai on küsitavus. Kui on täiesti mavistri aine, siis on prioriteet mavistri tudenkitele. Võib-olla te ei olegi lupatud ise registreerida. Ta võibki ole täiesti kindi pakka tudenkitele. Aga see DevOps aine ei tohiks olla kindi. Järgmine SMS seda õppatatakse hapelt see inimeste poolt. Ja neil on rohkem inimesi ka, et seda õppatada nii, et nad tõanast tead rütmest juurda. Pähemalt see on esimene plaad. Me oleme nii liikud mono rakenuses mitmekihiliselle ja servisorientad arkti-pektuurile, kus me jagame asja peab mikrovenusteemist. Nüüd hakkame panema üles konteeneritena. Aga meil on üks asja veel, mida meil ei ole vaatanud, seda vahvame järgmine lai. Kui me lähme mikrovenuste konteeneritest jooks, mis edasi meednäisemale tasemeljadise nanovenuste, võib pole kõige parem nimetada naovenusteks, sest nad on tegelikult isegi erineva mustriga. Kui me konteenerit jooksutame pidevalt, et jätame tagstall jooks, nagu webiserverid, siis serverless ja nanovenuste jooksutateks ainult siis, kui tegelikult on vaja käilitada jäänna ja jääma jooksult augstalla. Aga sellest me räägime, mis järgmise on vahvast. Ennakoodi ma tõin sellise väga lihtsa mikrovenuste näite. Tegelikult meie praktikum rakendus muutub selliseks aine lõpuks. Praegu, mis me oleme teinud, me oleme jaganud oma rahmatukohaltus alti kaheks mikrovenusteks. Selle nägaval me paneme juud erasli sellise komponenti, milleks hakkab olema frontend. Me ei nimetakse seda mikrovenusteks, aga põhimõtteliselt me paneme teha konteineristööle, aga tulelikult me paneme ta Asures üles Statik Web viiteno sõne, kui te elmisteste praktiku, mides olete lihtsalt html lehti ülespannud Asures Statik web saiti. See nädal me teeme oma appi haltuse frontendi, veel Asures üles ei pane, aga järgmiste praktiku, mides te panete sellega eraldi teenusõne. Me oleme juba hetkel kasutanud Asure 5Storages selleks, et koida rahmatukohalte. Ja kui te palete sellega frontendi, juurde tänases praktiku, mis me omses, siis tegib see üleminn asa ja järgmine näedame TVB juha speciaalse funktion juurde, mis töötab sellise taustal eventit tänalt käegitava funktionina, mis iga kord, kui Asure 5Storages laitaks ule suus rahmatukohalte, siis meie funktion automaast käibidiga uue rahmatukohalte ja kommenterid rahmatu tegisfaiididele seks. Me teeme siis järgmine nädal sellise juurde. Ja ainult lõpuks paneme sellega kahe nädalapärast üles, siis täiesti TVB-liis lahendusena, kui kasutajad saab kas frontendi otsa kasutuda või rahmatud appid otsa kasutuda. Aga idee on siis selline, et ta töötab täiesti sehase Asure 5Storages. Panuma, vaate käige üle, et oma Asure predit ei ole täieste erakasutan, nii meie läheb veel viimases loendusasulid vaja. See nädal me võib-olla natuke jääb teame sellase Asure 5Storages kasutamist, aga justing tõrjutavad masinapre konteeleerit meie veel üles ja pane. Ja viimases praksus ma natuke ka hoiata, et me paneme kaks appid tohkelikonteeleerit üles. Ja see läheb paks. Nii et see maksad krediiti ja me peame sellega natuke ettevaatek olema, et me proovime selle võimalikult kiiresti ärahinnata need viimased praktikumid, aga pärast seda, sest te panest seda asjad kinni, sest muidude, et jookseb krediit ühehtude ja selle suveks tööle jätate. Nii et me anname, kas see viimases praksis tagasi, et asjad kiiresti kinni panest ja tööle jätate suveks. See aasta ka justus paar korv, et ma jätu juba krediiti elmistes aine, et ei ole elmistes aine, et ei sõra kasutada võisteltita probleem. Mikro-teenosti ja kokku võteks räägiks korraks uuesti üle näid mikro-teenosti elised ja puudused. Üks parem, pige tugemama elis, et miks mikro-teenosti kasutatakse, on nende lihtsam hooltatavus, et me ei pea hooltama nagu tervet monoliitikorraga või monoliitimooduleid, et me saamegi neid vaadata väikse projekte ja nende väikeste projektide omanikud või arendaad. Nende on lihtsam hoidad terve projekti ülevaadad ja teada saast projektes kõik, kui projekteid on väikse. Kui on mingisugune asutuses olev monoliit, kus annebaasias on näiteks 72 tabeliit, ja siis 25 mood, et see on väga raske, et arendatel on omandavad täielliku ülevaad, et kogu terves suureks monoliitiprojektist, aga mikro-teenosti puhul on pähemalt näidest väikestest tükkitast, lihtsam täielliku ülevaadad omada ja siis on parem hooltada, parem testida ja parem kajuurutada, et me peame tekitama näiteks automaattika, mis oska ühe tocker-konteineri automaatsast ülesseada, et ei pead tegelema olukordadega, et kuidas panna üles kogu süsteem, et me saame teha nagu tükk havalt, kui me tükkid on 500 väikse. Nii et ongi, et kui teenused, mida me ülesseama on 500 väikse, see on lihtsam aru saada, lihtsam uutele töötehtel tutustada, lihtsam praktikantidele tutustada. Me ei pea nagu isegi arendust keskkondadesse hiigel suuri projekte sisse importima, et me ei vend tõmba pallamigi 3 gigabaiti paile kuskilt, või kik jama kõtti teegi tere katta, mis katavad kogu monoliidi, et ei saa parandada väikeste tükkide maha. Teenused ise üksikult vähemalt alustavad juoks, mis kiiremini, et tegelikult monoliid võib kiiremini üleskutida, kui mikroteenuste rakendus, mis koostab 60 liitopad ja viie teistimeest osast, aga nagu üksik mikroteenus kindlasti ei lähed kiiremne käima, eest sa on kiirem testida ja ei võita nii palju aega. Ja sigal te korral on ka parem isoleerimine, sest kui midagi juhtub, siis parem on vaadata logisid ja uurida nagu ühe väikse mikroteenuse konteeneri logisid, kui seal midagi juhtub, et kiiremile jääb pead üles, samas kui neid vead toimuvad mikroteenusta pahel, või kudagi on seotud mikroteenuste vaelse logika, timeoutid ja muudiga, et see sõib omakõrda nakkate kiiremise mõna. See võit ei ole etteleiselt vähendid oma teinoloogi võlga, sest näiteks, kui meil on üks mikroteenus alvasti arendatud, ja meil ei tööta hästi ja on püültanud, et see on liiga aeglene, see on suhtseb lihtne üks mikroteenus imperaarandada teise gene peale või teisid, et see on teist annebasi kasutama, kui see ei mõjutada teisi mikroteenuse, et me saaksime näiteks. MySQL asemel Postgres kasutus on võtta ühe mikroteenus raames ja see annebasi välja pahetamine ei kruudgi mõjutada ühtegi teist mikroteenustad. Siis on lihtsam, nagu tehnoloogia otsuseid teha või midagi ümber arendada ja midagi välja vahetada. Aga puuduseid on siis jälle se kogu projekti skoop või väga suureks kasvadad. Olu korras, kus meil monolidid on nii suureks, keegi seda ei mõista, sest teha on olnud, et keegi ei mõstab, et seda on mikroteenustad siiaotab kuud süsteemi ja võib juhtuda, et isegi lihtseva monolididi puhul me mõistame kõik, aga kui me jagame, et 15 tükkib, inimesed, kes kogu arhitektuurid mõistavad, et see võib omakorda raske mulle, kuna peab teatma, mis toimub võrgus, mis timeoutid peavad olema, et teenevsta vahele kui töötaks, kui kaua peaks näiteks konfigureerima kuberneeteses ningi lihtsalt, kuid palju aega andada teatud mikroteenustele, et nad üles puudivad enne, kui neid restartiteks ja igasest muud problemid hakkavad tehnuma. Kuberneeteses osast siis räägime täna. Onki, et teenustevaale on interaktioonide testi, mida on keerulisem, kui me ei testi lihtsalt koodi, vaid peame ka poolitsema, et andebaas on üleval ja kõik omavahelised mikroteenuste omavad suhtlevad ja me võime küll iga mikroteenuste üksikuna testida, aga mikroteenuste arhitektuuripuul me peame ka interaktioonideeste tegemad poolitsevad, piktuöhtevad koostus ka. Kogu süsteemi nullist ülest paneme näites uuele keskkonnas, peab omakorda olla keerulisem ja rohkem aega võtta. Ja see võib olla palju sellised sõltuvused, et andebaas ka põeva oma üleval enne, kui mingi komponent on üleval ja mingi komponent ei saa töötada enne, kui teised mikroteenustele üleval, et selt tegib omavaheliselt sõltuvus. Ja meil võib paja olla palju rohkem mänu, kui me teeme igale teenusele oma mitte jakaku keskkonnat, kui me saame seda väga hästi tegelikult ka kubaneetes konfigureerida, niimoodi, et me anname karanteeritud mäluala ja siis lubaame dal komponentidel oma karanteeritud mälualas ka rohkem mälu kasutuda, siis tegelikult me peame ikkagi oma igale teenusele alokeerima mingisuguse minimum mäluala ja monolidin ka võrel, et see võib saa tegelikult palju suurmeidu kui kõik komponenti kokku liitmed komponentide summa. Mäluala võib olla suurem kui monolidijad vaalik mänu. Eritikuna monolidine puhud meil võib olla võimalik parem ei agada indisust mälualased, et mitte mootulid tegelikult samu anmeid ojavad mänus. Ja see võib ka minna kallimaks. Eritikult me kumperäete, siis üle saame, et kubaneetes tegelikult tahab seda, et me seaksime üles ka serverid, mis haldavad kubaneeteest, et suvalise kubaneeteset lastreaks meil tavalselt jõu nagu ei piisa ühes masinas, ja selleks, et see töökaks tökke kindlalt on tegelikult vaja plastra, mis on kolm võib piis või rohkem servereid. Ma räägin tove palju sellest mahtukrohku. Ja kui me kasutame tokereid, siis tegelikult problemid, et konteinerit on nõrgevad isolatsioonid, kui virtuaalmasinate puhul, me saame seda natukene paremni parandada. Kui pärnetases, kui tokkeris, aga üldjuhul see tihti olele paremda. Et kui arenda konfigureerib valesti konteinerite seadad, siis konteinerit saavad nüüta isoleerimest. Et virtuaalmasinate puhul see võib ka juhtuda, et kui te panetid virtuaalmasinale, sisse maandite mingisugust välised kaustad, kas te ei ole te märkanud, kui te näiteks VSL-i kaud jooksutada mingit linuks virtuaalmasinat, lähete linuks virtuaalmasinat sisse ja või teil on kättesadad pig-velist poosad fallid, et teile maanditeks nagu välist poosad masina kaustad virtuaalmasine sisse. Et see on suhtseks selle default konfiguratsioon, mida tehaks, ja selleks, et teile oluks muga, et te saaksid näiteks jooksutada mingisugust käsku sellest virtuaalmasinasees ja kohem muutaneid file, mis on väljaskool, et mugavased ötku maanditeks tihki nagu välise serveri kaustad, nagu virtuaalmasinate sisse eriti nagu tavaruutiteks mitte võib olnud ilgast ja serveri keskkondudes. Aga sellise valikute tegevuse ötkus, siis ole eerem kaupõimist ära. Kui virtuaalmasinasees on lubatud näiteks, vaadata, mis on password file-is väljaskool sellest virtuaalmasinat on võimalik hakkata ära arvama parooli näiteks. See on nii sila näiteks. Võisi, et ei kasutada mingisuguste file, mille kaudus on pigi pääseb dockeris, et dockeris suusi konteneer jooksud panal minuks keskkondudes. Iga liul oluks virtuaalmasinat või konteneerid on ästi tähtiselt, et on tehaks konfigureeritud ebaefektiiselt ja dockeris on väga raske seda karanteerida, aga administreerimised asemel, et ükski tabakasutaja või arendaja näiteks kokematai seha üles konteneerid valeda õigustega, millel on õigused siis kõikki file velas pa tuge teheks. Aga kuberteete selle on see natuke panal, kun aga pereini ajal politike peale panna. Sellega, kui me vähendame nende komponentil suurlust nüüd on ülasseamad, siis me hakkame ülesseamad palju väikselt konteneerid ja mikroteemasid. See tähendab ka, et meil on täiesti tavan olukord, kui võib olla, et 50 konteneerid jooksevad serveris ja meil tuleks ülevaad, et saad, et mis nad teevad ja mis nad on, nii kaks kõik on vajalikult. Ja need, et tegelikult komponentide arvukasvuga on pihti raskem arvusadad, ega see ei ole mitkagi vajalikult jooks näiteks. Ja süssteemid peaks skaleerima ja lastselt meil tähendab see, et me lisame konteneerid, meil tegelikult oleks vajaga lisada serverid juuded, kui hetkel olevad as serverid, et see viisa selleks, et kõik konteneerid jooksitada. Ja tegelikult meil onki vaja nagu selliseid orchestreerimis lahendus, mis oskaks hakkama saada, siis paljude serverite ja võib-olla sadade konteneeritega, et siis tokkersforma kuberneetes, tänareid on teemaseks siis kuberneetes. Ma vaatan, et see on midegära ei onnustu. Kuberneetes ongi siis põhjumist, et alpenarkiis tokkersformile, kus tokkersformis on suudselt lihtne panna üste serverisse tocker, initialiseerida tokkersformi klaster ja jooksitada kahtekäsku selleks, et lisada servereid tokkersformi, niimoodi et tokkeri kaudusab siis konteneerid jooksitada paljude erinele serverite peal. Aga tegijad palju probleemi näed, et kudas halata võrke, kudas halata ketta ruumi, selliseid küsivait ketta ruume või ketta kaustasid ja sellises production keskkonast tegelikult tegid topperi kasutamiseid palju sellised väikseid probleeme. Ja kuberneetes ongi arendatud selleks, et paremini automatiseerida konteneerid rakenduste, konteneerid ülesseadmist ja konteneerid rakenduste arendusti ülesseadmist ja automatiseerimist. Ja väga suur fokus kuberneetes ongi automatiseerime, et see on nagu kõige tähtsamad omadusi, et kuberneetes on kõik võimalik ära automatiseerida, et teoreetiliselt, kui süsteemu on ülesseadud, et inimesed ei oleks enam vaja, kes seda jälgib. Ma olen ise näiteks siin Habertse keskkonnas ülesseadud IoT-annebaasi, mis jookseb kuue arvuti peal ja kasutab kuberneetes paljude komponeetid jooksutamiseks, kes on aastaid jooksud ilmal, et ma väks kuberneetes klastret jälgima või kontrolli, et nad iga natk saab ära kis puhendal karkkora peal. Kuberneetes kasvas välja, sest Google Porg projektis 2004 aastal ta anti välja alaliku projektliina 24. juunis. Talla on väga suur arvendeete keskond. Iga versioon tuleb välja iga kolme kuutakad, nii et arvendeet umbes teavad, et kui tihtima pead kuberneetes tuendama. Myötan ta muutunud natuke selliseks tasutajäritse, et seeritab tööristakse, näiteks firmadel, kes teinimad raha ja kasumid. Nendel ei ole otseselt lubatud tokkereid tasutakaasutada, aga teil oma hobi projektideaks või optingutakäigus on tokkere annad lubad suvalisel, üliopilasel või oma projektideaks seda kasutada. Siin on siis ehitatud, et infrastructure as code või infrastructure koodina tähendab seda, et oleks võimalik defineerida, mida tuleb teha konteinerides või konteinerid ülesehatmiseks koodina või templatefailjutena tavaselt Jamli või Jason mina ilma, et pead käske jooksutama. Kogu kuberneentes on selleks üleseitavud, et arendade jooksutada käske. Me jooksutada docker runni, selleks me ülespanna, vaid me kirjeltame näiteks dockerfailjis arvasalt asjad, mis peab siin üleol olema, ja me paneme need info.anme-baasi läbi atni ja üleksame, et me tahame, et sellist asjad eks justeeriks, aga me ise ei jooksut otseselt kuberneentes ja käske. Kasutateks selleks sakel mikroteenuste juurutamise automatiseerimiseks ja skaleerimiseks. Selle hetkel, kui me oleme dockerfailjid ülespanud, kuna peaks automaatselt konteinerid juurde panema või eemaldama. Ja kuidas seda eemaldamist teha niimoodi automaatselt, et ükski kasutajarroodet ei saaks. Kasutades versionid jääksid aktiivseks ja sammult, et kuidas näiteks uud versionid mikroteenuste üles, panna niimoodi, et kasutat ei märkaks midagi, et taustavalt versionid muutuvad ja üksikasutaja vea teadeti saaks. Kuberneentes ja kõige peamistolemid on poodid. Eesti kerest võib kõige kaul, ei ole kõige varem sõna, aga kõige otsasem tõlge, et mina jätkam inglisti ja see poodi termi kasutamist. Kuberneentes peamistolemid ei ole konteinerid. Kuberneentes ei seaa üles konteinerid, me seame üles kuberneentesse kauna, mille sees on üks või rohkem konteinerid. Meil on eraldi nimaruumid. Siin ide on, et konteinerid ka sees on samuti nimaruumid, aga kuberneentesse nimaruumid on pigemseleid eraldi kaunade grupid, mille saab peale panna politikaid. Meil on susteemigrup, anmebaasigrup, rakendusegrup. Me saame öelda, et rakendusegrupiil, rakenduse nimaruumil on lubatud anmebaasinimaruumi poodides päringud teha või pakete saada, aga üheleki teise nimaruumi ei ole lubatud. Me saame nimaruumid tasemelt tama regleid. Nimaruumid on mõtevan, et ühes nimaruumis poodide nimed on unikausad, aga sama nimi näiteks poskles võib olla teises nimaruums ka. Meil võib olla kaks nimaruumi, anmebaas üks ja anmebaas kaks ja mõlemus võib olla sees pood nimega poskles. Nime ruumid on siis ka nimede eraldad. Me tavaliselt ei panene poode, üksinda üles, et me ei tavaliselt, kui me näed, et run pood või deploya pood, me defineerime poode peale deploymenti, mis kirjandavad ära poodi sellised metaanme, midu koop, et sellest poodist peaks jooksutama ja muud informatsioon. Me defineerime replikaseti, mis ütleb, et deploymenti seest peab olema kolm poodi ja replikaset kontrollivs seda, et midu poodi hetkel jooksud. Ja kui me replikaseti muudame, et kolm asemel kirjutame annubaselt midu on viis, siis taustal toimuvad protsosid, mis muudavad poodid arv automaatsed ära. Meie ise ei käivita uusi poode, vaid me lihtsalt kirjutame, et midu poodi peab olema. Risaks on serviceid, kes teineerivad rootimise ja võrguregljude, kui me saame tekitada annubasi teenuse, nimetame selle Postgres teenuseks. Ja service, Postgres service, siis pireldab ära, et kui tuleb pärin Postgres service IP-adressile või hostemile, mille nimi ongi näiteks, postgres.cloud.ut.ge või sellist, siis et millistele poodistel liitus edasi suunatakse, et service on selline rootimis reglid, et kuidas suunata ümber liitust. Ja ingress on samulti selline võrgu olemis, mis defineerib ära, et kuidas välis võrgus tuleb liikus suunata milistele teenusteese. Et ingress siis defineerida näiteks hostneime, et kui on Pelle app, siis tuleb liiklus Pelle appi adressile, et siis millistele teenustele see ümber suunata. Et ingress teab siis sisevõrgu kätke saadaoks välis võrgus. Ja lisaks on sellised config mapide secretid. Secret on mingisubiselt saladuse, et näiteks saame asure, file storage, accounti, connection stringi, salmust kuberneetsse sisse saladuse. Ja siis rakennust ülesseab, mis on lööda saladuse nime, selleks, et meid eaks kasutama keskkona muutueid või mingisubist erilist viiselt kust võtta neid vääritused. Et me saame kuberneetsse ongi eraldina pole saladused, ja me saame vaelikult vääritused sisse kirjetud lihtsalt. Config map on sarane, aga ta ei ole mõeld, et saladust teab saada lihtsalt konfiguratsioonideaks. Et näiteks, kui meil on nginx konfiguratsiooni file, ja me tahame iga deploymentige seda natuke muuta, siis config mapi me saame kiihutada selle nginx konfiguratsiooni ja kasutasest mpk telt, et kudas vääritus ja muutad näiteks automaalsest lööda IP-agressid, siis mingisubuse poodi muudest meta annetest ja kirjutad see automaalsed nginx konfiguratsiooni kui selleks jaabaks. Mis on siis poodid? Poodid on põhjemusel kõige väiksemat käivitatavad üksused kuberneetsse, et ma kasutan korraks laserpointerit, et siin iga ring on üks pood, ja te näet, et selle poodi sees võib olla näiteks mitu kausta või voluumi ja mitu konteinerit, et ühe poodi sees võib olla näiteks üks konteiner või kolm konteinerid ja kaks maunditud voluumid. Ja põhimatsed igal poodil on unikaal IP-agress ja sama file system, et ühe ringi ühe poodisees olevat konteinerid kõik jagavad sama IP-agressi ja samu file, nii et nad saavad ükstese paljadele ligi. Et näiteks on näiteks, et meil on mingisemene rakendust, et me soojam ülest palja kaks procesi või kaks rakendust üks, mis tõmbab raamatuit, internetis, võib ütlemperikse tegidutamne file, kes me eraldin teema appi teeluse, mis neid pakuksis neid file kätte saada. Ja me saaksid pannada tööde nagu samas appis või samas procesis, aga me lõmmed aga kaks konteinerid, üks konteiner, mis võib tõmbab file ja teine konteiner, mis saada veri neid. Ja sellest, et nad saaksid meid filejad jagada, siis nad paremene nad ühe poodi sisse, nad jagavad sama IP-agressi ja sama samu mountitud file, nii et nad saavad. Ja need on ka sama poimust, et mälualaad nad saavad ühe omavajas suhelda, mis on maailmik olnud kõige. Nii et nad ei ole omaval isoleeritud, poimust, et ilma isoleerimata, toksultad samas nagu keskkombas. Ja skaneerimisel me siis ei muuda nagu siseliste konteiner, et arvub, et me teeme poode, et endast kogu poodist ja kogu sellest ringist, et kõik kaustad kõik konteiner, mis on endast oot skoopet ja kogu poodi kaupa. Ja idean on tegelikult seda, peaks enam päeva väitima, et parem on tegelikult ikkagi poolstas, kui on ikkagi loogiliselt eraldi mõe protsest, mis tegelikult millegad siit parem, nad ikkagi panna erinatuse poodidesse. Et ei ole nagu eesmärg, et kombineerida palju konteinerid sa vasta poodi, vaid kui otsest ranged valjadust ei ole, siis parem on ikkagi eraldi oida. Kui pärjätel, et namespecies eraldab protsestistikruppid või rühmad erinatse namespeciesse ja namespeciesse siselselt nimelt peavad olema unikaalselt, et me ei saa samase namespeciesi teha kaks poodi nimega postkas. Ja võimalda siis hakkendist keskkandi eraldadada. Aga defaultina nad ei ole isoleeritud. Et üks namespace saab teise namespeciesi ka ühenest võtta üle võrgu ja kui teie ei pana eraldi reglid peales, siis keskkondi ole eraldatud. Kui te tahad, et oleks automaatsus eraldatud, siis te peatud ülesseadma eraldi tarkkora kupernetisees, mis automaatsus konfigureerid uued namespecies niimoodi, et nendest panaks jääb paik ka näiteks võrgu poliitikad. Nii muda, et igas uueks namespecies on võrgu poliitikamisei lubav üheleki teiseks namespeciesi selle kõhendast võrtaistad. Aga võib pole käsit siin konfigureerima, et mingisest poodid saavad siiski sellest namespeciesi liidipäe suud, et kõik sellised asju saab automatiseeriga kupernetisees. Deployment, kui meid paneme poodi kupernetisees tööle ja keegi tapab poodi jära, siis poodi automaatsal ei panda uuesti tööle. Selleks, et pood oleks küsivalt jooksev, tulebki pood panna kas deploymenti sisse või stateful seti sisse või teemalsetisisse. Deployment toimimesed kirjaldabki, et see pood peab olema jooksev süsteemist. Ja ta määrad kerra sellise poodi soovitud oletu, et näiteks, et ta peab jooksma ja mitu replikat peab olema ja saab deploymentisees muuta versioone. Et näiteks, meil on deployment version 1 ja omme on deployment version 2, kus me muudame ära poodi ningisemise sissemise container image, siis automaatsalt hakkab toimuma selline taustasolev protses, mis vahetab välja kõik need jooksevad poodid deploymentisees. Deployment jääb samaks, aga deploymenti sissemiste poodide versioonid vahetades välja ja me tähaga räägime sellest, et kudas neb vahetaselt toimub. Ja on eraldi deployment kontroler peenus kuba näetases, mis jälgid kas kõik deploymentid on sellises vahelikus olekus vahe, et kui mõni pood on puudus, automaatsalt skeduleerib see suurde poodide loomist näiteks face to the node'ide peale, et kui on näha, et midagi on puudu. Poodi te arv on kolm, aga tegelikult replikeid seti järgi peaks olema viis, kui kasutel on seadistandud, et me tahame skaleerida poodide arvu viiega. Need olemid on tegelikult palju rohkem, et siia ma olime rääkinud poodist replike setist ja deploymentist, ma juba näitan see laseriga. Ja deploymenti asemel me võime ülesseada ka, kas stateful seti või demon seti. Deploymentis on näiteks kolm poodi, replike seti tõttu, siis ne poodid saadud sellised suvaliselt nimedest, random, genereridud nimedet näiteks. Peale deploymenti poodid võib-aad olla nimetatud näiteks peale, siis deploymenti nimi ja siis mingisuu random ID sellele kootide näiteks 237, 6, teeme nüüd elist. Kui me seame üles stateful seti deploymenti asemel, siis pannakse nimet staatiliselt nimedet esimene poodide, et peale 1, teene poodide peale 2, 10 poodide peale 10. Stateful seti on kasutatakse armebaasi tüübi rakkendustana, kus on vajalik, et äitsid nii täpselt kontrollideks, et kui me seame üles ühe nüüd ja armebaasi nüüd, siis tema on näiteks liiged ja tema on vastutavse selle clustervii oksutamiseest. Kõik järgnevad, näiteks, poskres 2, poskres 3, poskres 4, poskres 5, nema ei ole, siis liiterid nema on näiteks replika, nema veel liiterid nema on võitsu replika nodeid. Reed replica nodeid näiteks. Stateful set on sarane nagu deploymenti, nagu mõõdud, kige on staatiliseks staatiliste poodid ülesseadnud, et poodid nimed on tähtsad, et ei oleks random nimed. Demonset on ka võimult, sest te kui poodid sarane, et jääb üles poodid, aga siis me ei kontrolli enam nimekal nende poodid arvu, vaid me soovime seada poodi iga kuperneetises nüüdibel üles, iga serveri peal. Et näiteks, kui me soovime kuperneetises serveri peal hakata koguma logisid, me võime sinna panna näiteks logi scraperi, ja me tahame, et igas kuperneetises nüüdibel jooksas logi scraper, siis me paneme sinna üles konteineri, Demonset kontrollib, et pood panaks üles iga noodi peal, ja sinna maundime sellesa poodi logi kaustad väljespool, ja siis see pood hakkab tegelema nagu logifailide söömise ja kuskile kesksesse logi koidlase saatmusega näiteks. Demonsetiga saab siis panna näiteks, kas nüüd eksportarid või mingi taisad tööva iga kuperneetises nüüdibel. Lisaks on ka sellised grand job tüutki molemit, mis tegitevad vastavalt ajastusole töö, et iga öösel keel kolm tegiteks kuperneetises töö, ja kuperneetises tööobjekt kirjadab, et mis konteineri peaks ülessead, mõe mis poodi peaks ülesseadma, ja tööde esmerga on jooksutada töö, kuni see väljastab, et õnestus. Ega grand job paned näiteks, iga öösel jobi tööle, ja job paned poodi toole ja kontrollib, et see pood tagastab nagu saksessi põnima, et ei oleks errolo koodi. Ja siis pood jooksev ja kui pood väljub korreksata ei tagasti errolo koodi, siis job on nagu tehtud, et grand job siis kontrollib, kunagi paned selle job tööle ja job kontrollib, et käilitada töös, et jooksalt korreksad. Aga poodises võib oleks ka kahtu tüutki konteinerid. Et meil on tavaselt konteineri näiteks Postgres konteinerid, mille esmalt on jooksutada Annebaasi processi, aga meil on eraldiga inid konteinerid, mis tavaselt peavad jooksma enne, kui see peakonteiner jooksad. Ja need võib oleks valmistada ette, millid kaustad, millid failid kaustada ja failid õigused, mingiselt konfiguratsiooni failid ettevalmistada. Ja ideea on, et selleks, et käilitada peakonteinerid, peavad kõik defineeritud inid konteinerid enne ära jooksma ja kõik peavad Anneba takavast samultis saksessfull koodi. Et kui inid konteineri annab eroli takasi, et tal näiteks ei õnestud mingit faili õigusi muuta, siis ei käilitada nagu tavakonteinerid. Et näiteks deployment-sest defineerid me tahame jooksutada, ötselt et Stateful Set defineerid me tahame jooksutada kolgun. Annebaasid pood hakkab jooksma, aga enne jooksutada inid konteinerid. Ja kui inid konteinerid ei takastada saksessfullid, siis väriks konteinerid jooksma ei panda. Ja kui pood saabsid lähebks konfiguratsioon, et viis korda inid konteinerid jooksutamisel vead, siis Stateful Set rääst deleitet selle poodi ja panu uuesti poodi tööle näite Stateful Set peal. Ja siis käibid, et see uuesti inid konteinerid ei korda tuni nagu kõik takastavad, et saksessfulli. Ja jälle siis panaks see päris konteinerid jooksma. Ja et selle apina võimalik automatiseerida, mis viisil me konteinerid ülesseame, kas me seadistame nad grondsoobid enam. Ja ka see, mida me teeme selleks, et konteinerid protsessi ette valmistada enne, kui ta jooksma panaks. Nii et sellist asja võib me ikka automatiseerida. Kui Tokers on lihtsalt, et kas Tokers service või Toker Nodes, Toker Runs, siis kui pe need, sest me põimsed defineerime, et mis jüüddi konteinerid ja töid me tahame, ja siis kui pe need esi ise orkestreerib seda, et kuidas jooksutada ja kuidas kontrollida, kas asja jooksad projektsi. Ja teine tähtis olema on siis TENUS, et ütleb, et me olema oma mikrotenusest appist pannud deploymenti üles. See deploymentis on epikes, et mis jüüdda, et me ei appistav jooksma kolm koop, ja tavas me seadistame, kui pe need esimene asjame nene poodid, et me ei rakenda sana, et põid poodid saavad rakendas liikvallis ala sellised lippud või leipolid. Ja kui me nüüd tahame liikvlusi takka suunama nendele poodid, et kuias, mis aadresid tulevad liikvlusi, suunab nendele poodid, et me saame teha TENUS, meid on TENUS nimeks, nagu aapana A, ja TENUS, et kasutavad sellist neid leipolid te mäksimist, et TENUS, et sa kirjutad, et otsid üles kõik poodid, millel on selline leipul, ja me ei kasutada liikvlus edasi suunamuseks. Kui TENUS, et see tuleb, ja TENUS on oma impaadres ja kostmeid, et kui TENUS, et saadad et kõik mis liikvlus, siis TENUS, et otsidaks selle label matchingse poe, et mis seal hetkel jooksvad koodid, millel on see rip või see label, me suuname sinna ümber selle liikvluse, ja seal tohaimub näiteks Round Robin liikvluse suunamined ja LooT talentsemined kormu sealturet, mis neide korme containeruonele, millel on täpselt sama liip, mida see, või label, mida see TENUS otsidaks saadad, see liikvluse tünda. Ja kriavase taosta toimuks liikvlusest suunamad selletipele adresid ühele Render, kallrastiipele adreside, ja kogu võrgul liikvluse tasemel on täpselt, nagu Linux'is rootims reegid, et mis IP-le suunata, aga nagu loogiliselt tasemet kasutab, et sellist label mäksid. Ja miks see on hea, et ütleme, et näiteks me tahame seda pootide versiooni muutelt, neid on meil versioon kaks. Ja kui me tahame seda pooti edasenduta uue versioniga, siis me saame meil meil eemaadale liipu, kui seda liip pärame jälle siis siia enam liikvlusti tuleb. Ja me ootame, et me saame üle samal teise pooti uue versioniga, ja kui siia enam liipist ei ole, siis me kustultame selle pooti ja parem uuele pootile siis sama liip. Ja selle tulemus on hakkad, et see suunamad liikvlust uuele pootile, millel on sama liip edasendu. Me saame, et lippe kasutad selleks ajutuselt näiteks liikluseste eemaldada mingisugune poode, et tema enam sisse tula päringub ei saa. Ja samastime uue kontene, et me saame lippu sellele panna ja siis ta hakkab liipnust saama. Me saame selliseid label, et kasutab ja potstustub, aga kas see teenud siis saadab praegu liip sellele pootile või mitte. Ja me ei pea nagu madalalt asemel kustultama asju, vaid me saame lippe eemaldada ja lippe panna, et osustuda, kas hetkel liiklus sinna saada või mitte ja see aitab nagu sellised dünameiliselt asju ümpe konfigureerida. Ja isegi, kui meil on näiteks sellest deploymentist väljas pool mõnii poot, et ta on kaas sama liiklus. Sildi te või defineerida näiteks siis, kas rakkandus on nime, rakkanduse pootid eril version, et veel võib oleid oleid lippud a.1 ja a.2 näiteks või siis eradi lipp. App võidu paha ja siis versio on võidu piikst ma nuli. Me saame ka teenuses kasutada näiteks versiooni labelid selleks, et asjuks või kas mõni lippus saada. Või siis saame näiteks teha äraulti need labelid näiteks test või keskonna, test keskonna või arenduskeskonna või production keskonna jaoks. Teadult teenuses suunavad liiklusa test keskonda ja teadult teenuses suunavad production keskonda ja siis testimiseks production keskonna saadmiseks ja kasutam teist teenust, kui test keskondi vaatnud. Ja see on kõvasti, ma ei teinud siis kõvasti, aga see on rohkem nagu sellised teenuse objekte ka. Meie praegu rääkisime sellest, et kuidas me saame kasutada teenusele poodidele liiklus suunata ja poodine on oma IP-aavrist ja ospeimid, servisidele on oma ospeimid ja IP-aavrist. Kui me taham, et väiaskot, kui pärjad see kasvõit võrk puuliiklus saada teenusele, me saame kasutada ingressi ja ingressi saame definierele tomeeni nime. Kui meie klastriadres on Pelle Cluster, siis saame definierele ingressi, mis on app1.pellecluster ja see on ospeimid, siis ingressi ja ospeimid. Me saame defineerida, et kui väljas tulevad liiklus sellale inters IP-aavrissile ja poordile, et vastavad ringisugustele, näiteks Satomai nimele, mille sa näite app1, vastavad sellele suunata liiklus servisile, mille nii on app1 ja siis servisist suunata liiklus vastavad labelile, kus mille väärts on app1 ja niimoodi saame definierele ümda suunavast. Ingress on selline väline kontroller, tüsti kasutab, et näiteks nginx ingress kontrollerid, et siiahtaks üks nginx kontainer iljast, kui päris edes ja teaks selle üks port, millega auto tema välis liitust kuulab ja siis selle index kontrolleris otsustab, kas liitust edasi saada sissepoole või nitte, et on ka selline, kas ta just tulemüür on, aga põhimise, et võtab sellise tulemüürin rooli, et otsustab, mis liitust siis sissepoole saada. Ja netwerpootidele võib ka annab panna ka netwerpolis, mis defineerib siis, et kui poot soov kuhugi jäänust teha, mis suurkustesse namespaceidesse või mis suurkustesse pootidesse tal on lubatud liiklus saada. Ja servisid võib kohele erinele tüütbi, kas ta on cluster IP vai node port tüütbi cluster IP teha, aga cluster IP teha, et ta on selline IP address, et kui mõetest, et see kastris ja selgselt sinna, et see teinusus liiklus saada saada sellel IP address või teinuse nimele, liiklus, kui teinuse nime ise annab ostmeid. Aga node port on atküldi teist suure teinus, et selle aseme, et meil on unikaali IP sellel ja teinusele, et klostrii kui mõetest serveri IP address ja mingisugune lokaalne portnäid 8080 või 5000 või 22700, et tekib mingisena port, kuhu me saame üks tõik mis kui mõetest sen uutida liiklus saada, et me selle ea teadma teeluse IP addressi või me teame, et on suvaalise kui mõetest serveri IP address ja mingisugune fixeerid portnäid 8080. Erad, kui me oleme väliselt teinus, aga me ei teast viimel load balancer, mingi pilve DNS, et me siis ei otsustada, mis on selle teinusele adress klostrii sisemisel, vaid, et küsime teinusile mingi IP address, mis on Amazoni mingisugune välisest load balancerist. Kui liikus läheb väliselt load balanceri address, siis suunadaks ümberda kui pärneetese sisse. Selleks, et me saaksime neid pood skaleerida, on meil tegelikult aesti lihtne, et me defineerime deploymenti CS replica seti, kus defaultina võib-olla, et meil on üks pood, kes mingil hetkel muudatakse ümber selle deploymenti konfiguratsiooni failis, jamblis võib tõhimist alvepaisest appi kaudu, et nüüd replikate arv on 1.4 ja see on kõik, mida ta tegema, võib-olla lihtnata appi, et ära muutma, mis on replika seti, replika vähestas ja kõik. Taustal, kui pa näete, siis ja olidseb selled, kus johdata seda kolmne omuute konteinerit ja kui ta see meid keema panna ja mitu korraga keema panne nii edas, et toimesed me ise jooksuta otsaselt käsku, vaid me pigem ütlema appi kaudu, et teaks nüüd olema rohkem poode. Ja tegelikult on tähtis, et oleks rohkem võibks replika tavaliselt, sest kui üks konteiner kokku jooksad mingil põhesel, siis liiklust ei saa teistevaale ära jagada. Aga samas on teil lubatud teeskaleerida 0-li, et ei pea isegi deployment ära kustutama, et ta võite replika setist seada pooditarvu 0-lit, siis kustutu olid 3 pooditarva aga see deployment ei pallas. Ja kui keegi nüüd muudab selle replika arvu 0-list ühen, siis selle panaks esimene poot tööle, et kui kubernetisest seest saab misselt skaleerida 0-lit, et kes on tööd, et näiteks, et meil ei ole vaja jooksutada mingid ofis rakkensest, kui kedagi tuleb jame, et siis saame konteinerid võib poodnud misselt skaleerida 0-lit. Ja tänu sellisele automatiseeriliselle on tegelikult võimalik kubernetises hästi palju automatiseerida. Me vaatame ühtel näidet, et kuidas me saaksime näiteks kas uuendada nende konteineride versioni, ja ka testida, et kui me paneme nüüd, näiteks meil jooksest praegu, et replikade tõlseli poodi, siis see on ühtel poodi, siis nüüd me näiteks ta, et üleks seada, et see on kahe, ja kudas siis replikade muutmine töötab niimoodi pitte replikat, 4 replikat, siis välja vahetud suute versionitega. Ja me saame sisse eitada testimise, et kuidas testide, kes uus version töötab korrektioll. Selleks siis teerivad erinevad juurutustrateegiat, kus osa nendest on automaatselt implementeeritud kubernetises ees, aga osa pigem nõuavad ka natuke rohkem ülesseadmist ja automatiseerimist, et ei kruugi need viimased olla automaatselt rakendatavad, kuna tuleb kombineeridega erinevate uute teenuste loomusega. Ja ideo on, et siis, kui me tahame tegime tokkeri containeri ümber, või tahame nüüd uue teke poodi, siis et siin laime rekistes uue containeri versiooni, ja näiteks me kirutame siis poodi definitsiooni ja selles deploymentis, et nüüd on meie container imagei versioon teise labeliga, et me näites uuen, et on lihtsalt ühe containeri versioon. Ja mida kubernetis siis teed? Taustal kubernetist hakkab kustutama poode. Ja see on hästi tähkist, sest suvalisal ajal võib kubernetise otsustuda suvalist poodi kustut. Nende kunagi saab kindel olla, et kubernetise kustutat teie poode ära. Ja kubernetis ei ole sellist asi nagu containeri sisemise processi restarti, nagu tokkere starti, põhimesed kubernetis ei ole. Et ainuke viiskudas millegi restartida on pooteliid. Ja kubernetis ongi, et see pooteliid võib juhtunud suvalisal ajal, näiteks siis, kui containeri tarp vara uue endatakse, või siis, kui on ülesseatud niiugusugune automaattik, et kubernetis hakkab loolutal lähe sema neid serverid. Siin on liiga palju hästi jooksma, et ta tahab, et siin serverids oleks vähe poode, siis ta kustutab selle ära ja liidutab teid selle kundmuna. Veid sa suvalisal ettele võtta jäägi ühe Postgres klastri poodi ära kustuta. Ja sellest ei tohiks, kui kubernetis siis midagi nagu alvasti juhtuda. See poodi kust teema ei ta ole võirega poodi üle. On, et sa võid näiteks hakkata defineerima sellised asju, et sul on meid prioriteedid. Sa saad defineerida prioriteetene, et eks meie sursside, liniitide kautta, et seda me selles ainees ei katta. Ja te võite ka nagu põhimõtteliselt teha niimoodi, et process iseg kuulab signaali, et panakse, et seda ei teha nagu hard killi, vai teaks ikkagi saad, et see normaalne kill signaal, ja process võib saan isekinnipüüde asjad ära teha ja siis normaalselt väljuda. Aga põhimõtteliselt suvalne tarkkora, mida ehitataks, peab olema selline, et ta on suvalisele kustutatav. Ja meid konteinerid ja tarkkora tuleb niimoodi arendada, et ka anmebaasid on täiesti suvalisele etke kustutatav. Te saate igasugust muid asju teha, et on see toleransid ka, et näiteks, et ta tolereerid erinevaid signaale asju, et teda ei oleks nii lihtne kustutada, aga põhimõtteliselt kuberneetes on ikkagi desainitud niimoodi, et suvalisele etkel võib kuberneetise kontrollereid asju kustutada. Ja selled oto anmebaasid peavad kasutama sellist asju nagu right ahead log, et nad suvalise operatsioone enne täitmist kirutavad logisse, ja siis ales hakkavad täitma, kui keegi pilib neid, see on täitsa okei, kui sa kimmi panaks, ja see right ahead logi on kusakil persistent storage's, näiteks, file systeemi kirutatad, järgmine korv, kui sa sama pood käeviitub, siis ta vaatab logist ja vaatab, et mis sellist näit operatsioonid, mis ei ole veel täidetud ja teed need uuesti läbi nõudlist. Pige mõn, see ka muud kogu see dockerit ja konteeleerit ja kui peab näet, sa areng on ka tegelikult muutnud, et mida anmebaasid tarp pala peab tegema. Selle tõpelt näiteks igaslused rabit ja kafkasannased message brokerid ka kasutad right ahead logi, anmebaasid nagu poskas kasutad right ahead logi, selleks just, et väestida olukordad, midagi läheb kaduma kui keegi protsis järgmine peab pala. Kunagi tead, et jäsku serverist teha kui restart ja serverist panas kinni ja keegi ei saa ehelda, et anmebaasi protsis ei tohi suvalise ettei kindi panna. Nii tõrked aluse, kui ka kubernetse jahks tegelikult on vajalik, et suvalise ettei võib saada põhensid kindisignaaliprotsis. Ja vaatamegi neid juurutustrategiaid. Ästi lihtsalt re-create, mida te saad ise teha, aga mis ei ole default tegelikult. Ramps uueldamistrategia, mis on default kubernetses ja siis selliseid logilisvii uueldamistrategia nagu blue-green, canary, AB testimine ja shadow. Re-create on see, et te saad teise, teil on rohelnõnese vana versioon, versioon 1 ja ise te liidite teise deploymenti, paate kinni ja siis lasete uue deploymenti tööle, et teete käsid sinna ku versioonu uueldamistrategia. Seda kubernetses ei kasutata, aga te saaksid seda administraatore ja käsid teha, et ma ajateleiselt vana versiooni deploymenti kinni või skeelite nulli ja siis paate uue tööle ja jääb natka aega, kui teie rakadist tegelikult ei ole kasutatud, kui need uue poodid tööle jäävad. Seda tehtid jaoks näite stokkeris. Paletake mingi tokker teenuse kinni ja siis paate uue tokker teemist käima. Seda on kasulik teha, siis, kui resursid on hästi piiratud, kui on vähe aktiivset kasutajad, kui teieoks ei ole tähtis, et kõik kasutajad saaksud see rakendist kasutatud vahepeal ja üldises teist kulude vähendamiseks, et teil ei ole vajalik lisa resursse, et näiteks kahte versiooni sama äksut rohsutada. Või tuleb kui ta kui ta kohde, et kahti versiooni korraga ei kasutata, et siis Anne Paaside pool, et teil teab siin vahepealt olema näites Anne Paasi skeemade uendus, et te paate Anne Paasi kinni, konnetereid tege skeemad ümber ja siis paate uue versiooni tööle ja vahepeal ei tohi toimuda kirjutamist, mis kasutab vana sellist skeema. SQL Anne Paaside pool, see tavaliselt probleem ei ole, sest kui skeema on vale, siis kirjutamine ei õnestu, aga teatud mitte releatsioonist Anne Paaside pool, lubatakse Anne saata suvalise skeemaga ja automaatselt uuan saab sähkest tulpased ja Anne Paasi võib näpat sega soks minna kui indegi kasutatakse samal aal kaks periaal versiooni, mis erinele viisil Anne et Anne Paaside alestadud. Näiteks inflaksis või kestigis juhtub see, et on lubatud näiteks tabeli automaatne geneerimene ja kustutate vanatabelistruktuuri, järetood uue tabelistruktuuri, kui samal aal pärast seda kegi Anne sisestab, siis lueks see vanatabel tagas. Nii on kui tegad, et mõnikord on hea väestpidat kahtereendverisooni samakastud. Aga see ei ole sellega default uuendavistrateega kui päris näiteks. Default uuendavisestrateega on pigem selline, et te lioks näiteks 10 konteehnerid see vanas versioonis, ja kui te siin muudab ära näiteks deploymentiselt, mis on uue versiooni, mingi tokke vinnis, siis mida, kui päris näiteks tegemakab, ta hakkab ühe või rohkema konteehneri kropa lihtsalt välja vahekama poode, niimoodi, et näiteks, mõne on 10 pood jooksmas, esim alvu teed uuest versioonist uue koop, et mingin hetki jooksad näiteks 11 konteehnerid sama aaksad, ja siis, kui see uus pood töötab korreksad ja on valmis vastu võtma linklust, siis hakkateks sa manuul kusutama. Ja tehaaks nagu rolling cocktail, niimoodi, et näiteks iga 200 asemtab, et siis üks pood ära, siis jooksvalt, vanas versioon, kui enam vanas versiooni pood ei ole, siis see on kui luid ja kõik ära asemtab. See vajab pähamud iht ja lisab poodi, et ma tegelikult ei eemalt ülti liht poodi enne ka muua lisame, nii et see nakkutkene vajab lisada susse, ja kui neid pood on palju, neid on 100 replikat, siis tõenest me üheaval neid vahetaväljad, siis neid on defineerid, et vahetatakse neid 5 korraga välja. Niimoodi, mis on seal hea, on tegelikult poodide template, on võimalik sisse kirjutud automaatkontrollid, et kas pood on valmis liiklust vastu võtma, see on nii laivlines, kui readiness checkid, et me võime näiteks defineerid, et saada minu poodi sellel kordil ketpärindiumise ketpärindiumise kood on 201, siis pood on valmis liiklust vastu võtma, et saab automatiseerid kontrollid ja checkid, et kuna liiklust poodi saata ja kas pood tagastab korrektse kodi ja kui tagastab korrektse kodis järe, kas on uus versioon töötab. See on siis defaulti käitumine, et kui me ningis kusest deploymentis, mis on palju replikaid, nagu poodi definitsiooni muudame, siis ei juhtu see, et korraga või kindi panaks, vaid see koimalt aegmasal üle aja ja see tavasalt toimab ma ühe poodi kaupa, aga me võime definerida näiteks 5% kaupo või 10% kaupo või siis kumbo minimum kas 1 või 10% näiteks, et kui siis on 100 replikaid, siis hakkab see 10% välja vaatama. Rollback on võimeks, see on kaks asja, esiteks sul on võimalik paus teha, et sa võid siin näiteks öelda, teha paus, eest ta jääb selle ta sama ja siis sa võid näiteks huurida, okei, siis kui teadab hästi, siis järgata sellega või siis sa võid öelda rollback ja siis toivuks vastu mitte. See on etteks siin aga teist testustama. Et ta võimeks, et järgtaab meelde, mis oli eeline version sellest deploymentist Anna Baasi ja see ise jääb saad lihtsalt rollbacki teha. Eriti kui sa märkad, et logins hakkama terrorid ningi loginsistenei hakkama terrorid tegema, sa saad lihtsalt rollbacki teha. Ja rollback teadab siis vastukidisel viisilaks samamoodi, et ta on tööda paegu tead. Ja siis täiendam saav, siis need valat poodid esit järgavad liikluse vastamist päringite vastamist. See võibist teadab niimoodi, et kui me on nelil replikat ja me soovime see uuededa, siis kui perneetes loob ühe juude kusagil kontrollib, kas see uus uus rakendis on valmi võtma liiklust ja kas ta on elus, kas ta vastab korrektud ja kui on, siis eemad võtsevad maha. Ja siis üks aaval järjest hakkab et see on eemadava, kui kõik on välja maha. Ja põhjeliselt sisemist, mis juhtub, et vanadur poodid on üks IP-aadres, et 05.06 ja sinna on 1.5.016, et lihtsalt labelid muletab. Meil on selleg versiooni label ja me ootame, kuni see pood on valmis liiklus vastavõtma, siis paneme tälle label ja see mapele sit labelid ja põhjeliselt seda võib-pal natku ootame, kuni enam sinna liiklus ühtegi aktiiselt sessioni alle, siis panas tagim. Me võime ka teha prune-green testi, et põhjeliselt me paneme, me ei jookse panaversioon ja mis me teeme, me paneme tööle korra kõik uue versiooni poodid, et meil on näiteks 20 panaversiooni poodi ja me paname üles 20 uue versiooni poodi ja minges hetkel, minges sekundid siin switchime lihtsalt üle. Nüüd service enam ei, näiteks meil on siin vanal versioon, ei ole label 1.0, uuele versioon ei ole label 2.0 ja siin selle hetke me teelasel muudav lümbere, et teenus enam ei suuna label versioon 1.0 ja vaid label versioon 2.0. Ja nagu hetkega suunates kui uus liiklus kohe uuele üle ja meil ei ole tegi seda olukord, et samal ajal kasutab see kahkere nüüd versioni, aga meil on vajadus, et meil sama ajal sellel hetkel oleks kaks komplekki kõikides poodides juoksmaas, et me vajame ka juba kaks korda rohkem tege sussa ja mingi ajal. Ja me võime samult nii nüüd logides jängid, et kes uus versioon on takkama, või saame poodid switchi teha vanal peale tagasi, et me saame vanal poodid jooksma jätta ja me saame instant switchi uuele versioonide ja instant switchi vanal versioone tagasi teha. Et selle puudus elmsel onki, et see üle minne kuule versiooneid ajal, kui ta siin võib-al töötab 20-12 minutid või ta vaa aega, siis selles AB-blue-green strateges toimub kohesalt see üle minne, aga rollback toimub kohesalt. Muudiks rollback ei toime kohesalt, kui me need vanad poodid kinni paneme, aga meil võib olla mingi aaja hakkean, kui me ei oksutama neid kahti versiooni sama aeksalt ja saame. Ja selle eelis on siis siis, et me saame kohe, kui erroreid märkame tagasi jüpata, aga puudus on siia, et meil vaja nii ka aes kaks korda rohkem poode ei oksutada. Ja... Aga jah, see läheb siis kallimeks. Ah, mul on siin väga hästi nagu ülegi tõmpsnud, aga see ongi. Teine on siis kanarid. Idee on siis see, mida sa isega mainisid, et me teeme mingi hetkel pausi ja me kasutame sest rampstaateeget, et me hakkame siis uut versiooni lisama, aga me tahame, et mingi on jälgide, kas need uus versioon tõedab korreksata mitte. Me juba defineerime, et me aselda ma ainult 10% vanadest ära ja jälgime näiteks mingisugust 10-15 minutid, kas tekivad logidis erroreid. Ja kui logidis erroreid te tekis, siis me kasutame järsku uuendust, et üleminna uuele versioon. Siin on siis heitavad jännilikivist period, mis oleks piisavalt pikkeb. Ne teame, et me logidest läia me veada üles, kui sa uus versioon millegi pead pakka ma ei saa, või siis läiteks mingi klientid elistavad meile, et kuurge märk midagi ei tööta. Siin on selline paus pohjumist siis heitavad. Ja kasutatel ei prugigi märgad, et osa on edasi kasutavad malam versioon, osa on kasutavad uut versiooni, aga seda pigem ei tea, et me näiteks 5-10% kasutavadest kasutamist testi ja ta näad. Ma aata, mis logidis erroreid tekivad, kui nema kasutavad seda. Ma asun siis testin productionest. Jah, aga see on ajukkine. Ja küsivam testin production on siis AB-testimine, kus me põhimõtteselt teeme kaks erineelt frontendi või kaks erineelt back-endi. Me lasume osadel kasutatel kasutavad ühtemersiooni ja osaltatel kasutavad testversiooni ja siis me võrdleme näid kasutatel tagasusid, või kasutatel mugavust või mingisugud meetrikad, et näites, ku palju nad plikke teemad, ku palju nad ostavad, et jäsku versioonis A vastatakse rohkem tooted, ku versioonis B, et me sama aaksed jooksutame erineelt versiooni rakendest ja vaatame, et kumme veel jääb, et see on nagu proovid, et me proovime mitut erineelt versioonid back-endist ja frontendist. Tihedamine täeks seda frontend rakendustega, test mobiiliv rakendustega või poer rakendustega. Ja näiteks mitut erineelt algoritme kasutama, et kudas näidata kasutatel, et millised tooted näidata sorterimiselle esimesena ja needas. Me lasame erineelt kasutatel, kasutame erineelt versioonid suurimegi, kum paremne töötab ja kum näidast võidab, siis hiljem seia põlgub. Ja siis me saame lihtsalt kaava erineelt pootile kasutame erineelt leibaleid ja saame kasutama loogika, et teatud liiklus suunad sühteteenus, ja siis niimoodi otsustatab nendeks, kui kasutatel kui kliendi ID põhjal või otsustata kumva versioonid kasutatel. Aga nii on tähtis, et ei tekik seda olugu, et samat kasutatel suunata erineelse versioonid, et me tööme karateerimelt. Üks kasutakindast näeb ainult seda versioonid, keda ei visata erineelse versioonid, sest muidu nende logid ei näita seda, kum neid rohkem meeldib. Et me pigem aga me kasutame nende versioonid omaid arv. Kus siin see ei prugi olla vajalik, võib-olla meil on okei, kui kasutatel näevad erineelt versioon, aga siin on meil hästi tähtis, AB testimise hästi tähtis, et sama kasutame aalt samal version. Lisaks on ka sene Shadow testimise version, et see on live testimise tegemine niimoodi, et kasutat midagi midagi näe. Me tahame teha 100% live testi, et paname uue versioone üles, ja me tahame täpselt võrra, et kui hästi uus versioon võrdle panaversiooniga, ja meil on täiks okei, kui tulad erorid, aga me tahame, et kasutat kunagi eroride näevad. Mis me teeme, me seame üles kaks versiooni, paraleliselt, täpselt samal tajad poodid arvuga, ja meil suuname mõlemasse kasutajaliklusel. Kasutajal teavad päringud, need päringud läheb mõlemase. Aga ainult originaalses versioonis, et see on üks vastus, et tulevad tagasi kasutatela. Versioon kahest me ei suunad requestid, et vastusid tagasi originaalset kusutatel, või me põhimest kustatame need responsuid ära, aga logides vaatame, et kum versioon parem ei töötu. Ne põhimest, et splitime ja repliceerime sisse tulevad päringud, aga me kasutame seda teist komplekti poodidest ainult testimise aks ja põhimest võrdleme logides näiteks, kum nendest on jõudlik, kum kasutab pähem mälu, kum kasutab pähem seet, et jõudin edasi. Me kasutame nagu testimise. Et see läheb ka tohutud kalliks, sest me teame mingi aegi oksutama kaks korda rohkem resursse ja kaks korda rohkem liiklust ära töötlema. Et see läheb isegi rohkem kallimaks, sest liiklus ka tegelikult laseb selle jõudluse. Sisse tulevad päringud ja töötluse teame kahe kordsed siis tegema. Et mitte, et meil ei ole kaks kord rohkem mälu, aga kaks kord rohkem seet uudle. Ja kasutad siis avad endiselt vastuda ainult, kõige vanemast versionist ja me hiljamse switchime ka suuele või kusutama uued teist ära. Kui panneet, et klaster ise koostakse kahte tüüppi serverid, et tavaliselt kui te ise seate selle üles, siis te võib-alla seate üles ainult ühe tüüppi serveri või ainult ühe serveri. Aga kui te soovik nagu hea klasterid, sest tuleb luua sellist tööliste sõlmed, swirkerid ja juhtid teenustest sõlmed, mis ainult tegelevad nagu klasteri juhtimisega. Sest kui te miksite neid, et panete samal ajal tööle, näetis mingisugused annebaasid ja mingisugused kontrollerteenused saman uudid peal, siis lihti võivad probleemitekid ja meil Kubernetes-signals näetis tekisid. Tutengid tapsid oma klasteri maha sellega, et paneid üles tarkvar, mis kasutas liiga palju mälu ja liigavalt share-brewed, mis tapis pohjamesse, tapiserveri, poodid ära ja kastere on kasutatud. Klastri juhtimiseks kasutukse tõimised haldusteenuseid, mis iie oksavad konteenette sees. See on hästi tavalne mustper, et te seate üles Kubernetes-klastri ja mida iganest te soovite, see seate üles Kubernetes-sees. Soovite annebaasideenuste Kubernetes-sees, soovite persistent file storage, haldustarkvara, seate üles Kubernetes-sees. Soovite uud Kubernetes-võrkulahendust, see on vastupidine pilvene, kus tead pilves, see on oma rakentuse ja või toalmasendu. Konteenereid, mis kasutatada mingil välised pilved eenuseid, et näiteks files alvestada võrku ümber konfi või VPNi teha. Aga Kubernetes-seest te seate üles kogu kestuna ise Kubernetes-sees. Ja see natukena haitab nagu sellel lukustamise, vendor lukustamise vastu, et saate suurstseelt hästi, mis iganest te Kubernetes-sees üles seate, tõstada üles teise pilve oma serveretele või oma serveretele pilve, sest see keskummel täpselt sama. Ja kasutakse sama Kubernetes-versioonid piktoed kus aavadi ja te väga ei kasutagi väliseid teenuseid. Siele on tegelikult agad, et te saate pilved eenuseid samulti kasuta, aga te ei pea. Ja te saate asjad seada üles väikse serveres ka, et Kubernetes-seest on versionid, mis väga palju resursse väa, aga tihtan idee ikkagi, et te seate üles suurstseelt suunta serveredest ja kasutate mingil kolme node või rohke node. Ja Kubernetes-seest juhutasandu komponereid, mis samundi töötavad kontainereid ühe. Kubernetes-seest näed, Kubernetes Appi Server on kontainerid, Kubernetes Scheduler on kontainerid, sissehäminne hajusandu või kontainerid ja eline kontroller mene, et see on kaal töötavad kontainerid enam. Ja tööliste selline testavad töötavad ainult, näites kontainerid runtime, mis on siis kontainer D või Docker või midagi mood. Ja siis kublet, mis kasutab kontainer runtime-i, et jooksutada kontainereid ja tähenglikub perenets Appiga ja siis GameProximise nagu võrgu ümper suunamise ja võrgu Firewall tarkvara ümper konfigureerimise teenus. Ja tööliste selmedes nagu rostkal tegelikult palju olagi ülendaselt töötavad kontainerid enam. Et tööliselt siis töölistisse servered siis jooksutad kontainerid ja hoolitsodad, kuidas liiptus nende kontainerite nii ualt. Ja need kompanedid andju kõige keskkone Appi server, on kontainerid kõik käis läbi Appi serverete kaudu. Ja Appi server on ainult, kelle on lubatud annebase tehti kirutada. Ja annebase soitakse kõik, kui perenetsse liiseltad anneid, nii mis on hetke staatus, kui seda, mis on soovitest staatus. Et kui kasutaja kasutab Appi serveri, koha sa ütleb, et loob on uus deployment, siis Appi server ei jooksuta käst, kui ei jooksuta käst, kui ei jooksuta mingi uus kontainerid. Vaid ja kirutab lihtsalt annebase, et nüüd peaks eksisteerim uus deployment nende konvekurentsioonidega. Ja kui nüüd on vajas, et kontainerid või poodelid jooksutada, siis eksisteerim scheduler, kes kuulav Appi serverit ja teed pärilud. Ja tema saab teada, et nüüd onnud suur deployment jooksutada. Tema otsustab, kus hakkab ka poode jooksutama ja kirutab Appi, et nüüd peaks eksisteerima need poodid, näiteks nende nootid peab. Ja ka scheduler ei mõta ühenest otsa võrkeridega, et jooksuta midagi minu heaaks. Vaid scheduler lihtsalt ütleb Appi, et kirutab annebase ja nüüd poodid peaks eksisteerima ja mingisuguse võrkeri pealt öörtab kuublet, ja ka kuulav annebase saab teada, et nüüd selle serveri peab jooksuma kolm pood. Ja tema vaatab, et mis on näide poodid templateid, ja siis ise otsustab kasutavad näid stalkerit või kontainerid tee, selle serveri peab panat tööle, siis kontainerid mis sa paegamme. Kõik suhtlevad Appi kaudu, kui pärineetesega, kui pärineetes Appi hoiab annebases neid anneid, ja see on haius annebase, et iga nõud saab läbi Appi, nagu infotsit. Haius annebase, aga kõikeb Appi kaudu, nii et kui Appi kontaineri mahaläts, mitte ei teha sa. See ongi nagu selline huvita olukord, kus Appi kontainerid, et ta on veel mitu replikata, ja keegi näiteks valesti konfigureerid Appi serveri kontainerispetsifikatsioonis, midagi panat palje versioonis, siis kogu kuba näid, seal on otsustatud kasutata läbi Appi. Existeerib kui pärineetes admin käsut, milleks saab olo korda parandada, ja on võimalik, et näiteks mina serverisse, kus Appi kontainer juoks, ja tockeriselt kontainerid ei aab nii midagi imbe muuta, aga võib-lihtsalt on olo kord selline, et Appi kaad elu jääma, Appi kontainerid kaad elu jääma, selleks, et kogu kluster hästi töötab. Ma juba mõned asjad läksin ette, aga ongi Appi serveris, võtab vastus Appi käske, ja mõnesvõttes töötab kui frontend teenusena, et kõik suhtevad tema ka, kui midagi frontend joksulust ei pakku, et ei ole aastikelt rakkandus. Appi serverid alati seeteks üles mitu koopjad, ei ole hea, kui sellest on ainult üks koopja, aga kui teine on ainult üks nud, siis ei ole võimalik see, et see on mitu koopja joksnuda. Ja kui Appi on maas, siis peab Appi kontaineri uuesti ülesseadma, ja siis saab se kuba näid saab uuesti kasutatud. Ja kõik sisse tulad kuba näid saapi päringud jagad, kes on nende kontainerid vahel ära, et existerib jälle üks kuba näid tese teenus, mis on kuba näid saapi teenus, mis suunab kõik sisse tuuad liiklused nende kuba näid saapi kontainerid vahel ära. Kuba näid saapi ise on kuba näid tese sees jookse kontaineride teenuse. ETCD on siis hajus annebaas, et kui Linux on ETC kaust, mida agal onid siis minuks on kajutatud just konfiguratsiooni failide hoidmiseks, siis ETCD on see lihtne hajus Linux annebaas, kus iga kontrolernoti peale joksab koopja sellest ETCD annebaasist, ja kuba näid saapi kasutab seda, et hoida siis hajusad konfiguratsiooni. Ja kõik üks kõik konfiguratsiooni on, et kui teed on kõik konfiguratsiooni, ja üks kõik, mis teie kirutad appide, et näiteks midagi teha ümber muuta, uus poor peaks olema, siis kõik kõigevst kirutus annebaas, ja siis ilm teised procesid saad annebaasi kaut teada, et millegi muutus. Kui aga ainult appideenuse on lubatud annebaasist kirutuda ja lugeda, et küski teine, kui pealneete see kontroler ei tohi otsa annebaasit asi oda, kui lugeda. Kontroler Manager on üldine rakennus, mille sees on mitte muodulid. See on üks pinnaarne projekt, mis saab jooksutada niimoodi, et iga alamoot üleks nuuaks uus protses, aga ta on üks konteiner, mille sees on võimalik aktiveerides erinevad alamootulis, näiteks node controller, mis oluks, et kui pealneete see serveri jälgib, et kas kui pealneete see server on elus või mitte, kas ta on kasutata või mitte, kas tema saab ühendasti mitte ja kas uus server on isatud või teematatud, et ta jälgib kui pealneete see serveri. Job controller siis jälgib töid, et kron-tüüpi töid või praegu peab see jääb jooksma või siis töö opekte, et näiteks loob jobs, et jobsid looban näist poode ja siis jobsid kontrollivad. Põhjuskontrollikas tööd, mida on tehtud kuberneetise jobid, on korrekset välju noot või mitte või siis kordab need. Aga näiteks service accountid hookemkontrollerid saab kuberneetise kontrole loomiseks ka hookema. Ja neid on rohkem, aga idee on, et nad jooksevad ka konteinerit ena ja siis me saame luvu uue kontrollerid mängasid konteineri äld, et ta jookseb node controllerina ja siis temast teha uusi replikad ja aktiveerida neid teised modulid selle tööd. Ja sellist alarmcontrollerid siis tegelevad ningite tegevusta automatiseerimisega klastris. Näite skeduleid on eraldi kontrollitasame teenus, mis siis vaatab, et kas kasutaja on defineerinud, appi kaude defineerinud uue, et mingisugus deploymentid või cron jobid või mingisugused ütleme need statefulsettid või demo-settid ja tema otsustad, mis nootidid peal näid jooksustada, kui on deployment ja deploymentis on kolm replikaseltimidist poodist, millise kui peal näid selle serveride peal kolm poodid ei panna, et tema põhjuselt loeva anno basist, et mis on state ja siis vaatab, et kui uus replik peal looma, siis tema põhjuselt kiinutab anno basid, mis nootid peal see replik peal jooksuma ja tõudab arvase siis ja neide poodid pereid surssida vajadusi, kõidis kui palju melu või see põhjuselt annenpahas anno basi pood soovib, mis on nende hetkel serverides olav liistarva, mis on politika piirangud, mis on tarkkuna piirangud, näiteks, kas poodil on vajad tepud, et siis ka otsustab, et panna selle poodi peal, mille on TPU vannud. Ka näiteks hetkel olevad resursse, kas poodi peal on või kas nootid peal on piisavalt melu või TPU-t siin uut poodi panna. Näiteks, et võib olla mingisugune disk-type võrdud SST vajadus, et anno bas tahab kasutada noode, millel on SST kasutada, et ei oleks nagu aeglane ketas näiteks. Ja saab arvaslata annete lokaalsust, kui mingisugune pood tahab kasutada voljumi, mis siis teerib kaustana teatud serveri peal, siis see pood panas selle serveri peal tööle muidulteta jooksutada tekinti saakist. Ja on ka igas tähpäeva, et kas saab tähpääge et arvaslata. Iga sõlma peal jookseb QBlock ja QProxy. Ja QBlock on siis peamine sõlma akent, mis räägib appiga ja võtab kuulub, et mis selle noodipeal peab tegema, et kas on uus pood, mida peab käebitama selle noodipealt. Ja tema tõmme pallaneid poodspekki või kiretused, mis konteiner peab siis jooksutama appigaudu ja lihtsalt käibitab neid kasutades lokaalsed selle konteinerahaldusrakendus kas tokerit või konteineradeed. Ja ta pidevad jäägib, kas poodid jooksevad. Kui poodid pärslivad, siis taastab neid poodid, et ta vaatab sellist sovidad olukordad, mis peab selle noodipeal jooksma ja siis kontrollib, kas on korreks, et jooksevad selle noodipeal nii mitte. Et põhjumselt, et jooksevad kontrolliba appist, mis peab olema ja vaatab, et mis on reaalne olukord ja liigutab reaalselt olukorda sovidad olukora poole. QProxy siis tegeled võrgu liiklusega, et kui me jooksevad sellel masina peal kolm poodi ja tuleb sellesse noodi mingi porti peale liiklus, siis millises poodise liiklus ümber suunatab. Ta võib seda teha aktiivsalt, et ta iseguulab seda porti või ta võib siis näiteks ümber konfigureerida Linuxi, iPad, Apple, et panam saad reegi paik ka. Kui selle portigale tuleb seda tüütbi protopolik liiklus, siis suunase selle liipaadressile ja ta kas konfigureerib nad, siis ümbersoonamse reegled või edastab iseliklust. Et kui ei ole, nagu iPad Apple siit instaleerid, siis ta võib iselisela neid porti puulata ja liiklust otsa ümbersoonata. Aga halda võrgureegi mõnesmaks mängib tuleb juuri ka, et mis liiklus tüütse seda, siis suunata ja suunab ka konteeerid tunnud liiklusse teiste noodid reale. Ja konteeerdahaldust, targ korra on see näiteks Containerd, või siis Docker Engine, tavalselt Docker Engine ise kasutab Containerd, nii et väga ei ole mõnud, et Docker kasutada kuberneete, sest iga on konfigureerid otsa Containerd, aga kui tead, põhjusel on soov, et ikkagi Dockeri targ korra kasutada näiteks kuberneete, sest välisehalduse jaaks, siis mõni kord on mugavam võib-olla arendatel, kes Containerd ei ole kunaid kasutamud. Otsa Dockerid kasutada, aga ültiselt on soovituslik Containerd teed kasutada. Aga lupatud ka kasutada teisi konteeerdahaldust, targ korra on mis toetada seda open container initiative standardis konteeerd, mis seda CRI standardid siis liiglast implementeerilad. Vanasti oli niimoodi, et kuberneetes ise pidi oma kit-havu projektiis tegema adapterid, et kuidas kuberneetes kasutab Docker, kuidas kuberneetes kasutab teisi container-haldust targ korra, aga nüüd on see ära standardiseeritud ja nüüd kuberneetes nõua, et selleks, et meie saaksime teie Docker-haldust targ korra kasutada, peab see Docker-haldust targ korra, et see on tolki, et container-haldust targ korra siis implementeerimisele OCI liidese, et mis on need käsut, mida poimselt kogu ma näedas välja kutsab ja siis targ korra isepäeba implementeerimine kesut. Aga teatud platformi teaks see näites eradi liidese naa containeri haldust targ korra peal. Näiteb üks ammirantis container ranta, mis on pohimõttel Docker Enterprise, tead on tasuline Docker poimselt. Aga üks kõik, mis see on RII liidese implementeerid kuberneetes kasutatud, nii et kui tegitul on välja uue containeriseerimise haldust targ korra, aga siis nemad, kui ne ema implementeerid OCI liidese konteerineete halduseks, kuberneetes saaks ta kasutada. Ja kõik materjselt konteerid haldust targ korra on kasutatud kuberneetes poolt. Ja vaatates uues seda arkitektuurid, siis meil on mingisugused kontroller, teenuset, mis jooksad containerit enam, mis siis haldaud kogu kuberneeteest. Meil on pooblet, coolprox ja mingi containeri haldust targ korra, mis jooksab iga nootipealt. Noodide ülessead, mis on sulkses lihtne, lihti vajab selline inna pari käsku. Ja üste käsku selleks, et liituda pean kuberneetes serveriga või serverte komplektiga. On soovituslik, et nendest neid jooksevad eralde serveritees. Ja nendest on vähevad kaks või kolm serverit, mis haldavad kuberneetes kontrollerid. Aga üldiselt, et kui teil on palju rakenduse jooksutat, teil ei ole, aga suurtklast, et siis piisav ka ühes. Soovituslik on mitte neid samam serveri peale kokku panna. Selleks, et need konteneerid, mida jooksutatakse võrkerete peal, siis ei saaks mõjutuda neid konteneerid, mis on paja, et pilsa kuba näist halaka saaks. Kuberneetes on sisse ehitatud teenaste leidme. Kui teil on näiteks Annabasi service, mine nimi on Postgres-Tenus, siis suvalne konteneer saab kutsuda või saada liiklusse sellele hostneemine, et näiteks konteneer Annabasi-Tenusa nimele. Me saame need Tenuse nimesid kasutada kui hostneemidele. See on väga mugav. Sarna asia on ka Toker Compose-puhul või Toker servisiste puhul, aga sinna on sisse ehitatud ka kormusõi jaatus. Kui Tenus leidab, et on kolm poodi näende leipoliitagi, siis automaalsed jääb kormus näedel ära, me saame hästi lihtsalt replikate arvu muuta ja panna näid samad liput. See on piisalt selleks, et saada hajusel viisil liiklus kõik teile replikatele. Sisse ehitatud kas allestustruumi orkestreerime, et me saame defineerida, et loodaks uusi kaustasid ja neid maunditakse konteinerides või poodidesse, aga selleks tavaselt jääb üles saama eraldi tarkvara. Kui te ei see eraldi tarkvara üles soovida anmebas jaoks tekitada kusivad kaustasid, siis te peate seda üldiselt tegem käsitse. Te peate näiteks ise defineerima, et mis kaustavad Linuxi serverites on, siis anmebas jaoks ja te peate, kupe näitse üldse, nad kus nad kaustav asuvad ja peate käsitse, et kaustavad looma ja konfigureerima, aga sellaseks saab üles seda, kupe näiteks longhorn persistent storage tarkvara, mis ise hakkab looma neid kaustasid ja ise automaatselt konfigureerib või ümber konfigureerib need. See siia luomise kaus ei mahtunud, aga saate ise selle kõrte lugega, et longhorn on ka sellene, mis automaatselt repliceerib need voljumid, nii et kui ühens serveris keegi kogamat kaustalakustab või server ära kaub, näiteks ketas korrupeerub, siis longhorni seeest repliceerib kõik armeded alati on 2-3 koped anmedest ja anmed ei lähe kaduma. Uute versionid automatiseeritud väljas, keegi tagasavõtmine on väga muga, et saab lihtsalt versioni annebaasis appi kaude ära muuta ja kogu see ümber konverteerimine on automatiseeritud, et ta ise ei pea käski jõursutama selleks, et tarkvara või konteinerid neid, sest version uuedud, et hea on ikkagi monitorist vaatata, et kas ümber konverteerimine töötab edukalt või mitte, kas hakkab erral tekima, et tagasi võtta või rolvergi teha, aga põhimõtteliselt on automatiseeritud ja ei pea nii palju ise käski jõursutama. Kui praneetas oskap isega, resursside kasutust atlimeerid, paned poodid seal tööle, mis on rohkem resursse vaba, aga sisse ei ole te foodina ehidatud seda, et ta ümber balanceerib asju. Kui te olete ise juoksma pannud palju resursse, niimoodi, et kõik nõudid on kasutatud, maksimumi, näiteks, mäluvõid CPUs osas, ja siis ta ei hiljane emaldata, näiteks, kõik asjad, mis juoksad ühe nõudid, siis ei toimu asjada ümber balanceerimist. Võib juhtud, et üks nõud jääb natuke ülejakormatuks, kui te ise asju ümber niiguta, aga siis, kui täitsa vaja on käsits asjad ja siis viisab selleks, et oda asja näiteks ära kustutada, ja siis kubernetis panadad tööle teise nõudid peal, aga selleks, et se balanceerima automaalsed tööteks, peab lisatarkkvara kubernetis ees tööle panena. Ja kubernetis ees on hästi palju lisatarkkvara, mida saab üles heada, nii et tegelikult on võimalik hästi palju, nagu ise tead. Siin on sisse ehidatud automaatne skaleeritavus. Kubernetisest saab defineerita sellise asja, nagu horizontal board autoskeeler, mis kubernetisest sisse ehidatud monitorimist jälgib ja oskab näiteks CPU või mälu kasutusse põhjal otsustada, kui palju replikat juurda panemeemata. Et selleks ei pealiselt lisatarkkvara vaja olla. Kui tead soov midagi muud kasutada peal, et CPU või mälu, siis saada ise näiteks promiituse monitorimis üles heada ja custom meetik, et kasutada selleks, et ümber konfigureerida, kunaa replikete arvuma muudetakse. Aga põhimiselt võredust stalkeriga kubernetisest sisse ehidatud sisse automaatne skaleeritavus. See on ka ise tärnelemine system, et näiteks, kui tead mingil hetkel kasutavalt tarkvara liiga palju resursse, siis võib juhtuda, et väheprioriteetsed asjad panakse seisma või kustataks ära. Aga kui see suure resursse kasutus näiteks öösele madalamast, panaks see poodid tagasi. Kui kubernetisest mingagi väheprioriteetsel mõteevaldab, seda iljem paned tagasi, kui sa olukord paraned. Näiteks, kui te ise panate uue serveri juurde ja mingid asjade ei jookstud, selle tõttub vähe resursse oli, siis kubernetisest paljame uuesti töö. Kui resursse tuleb juurde või resursside kasutus vähenad, siis isetervenne ja system balanceerib ennast uuesti. See kasialu agas ei mahtada, aga kuidas te defineerite prioriteete? Kui te on ammebas, te saaltu üelda, et ammebas vajab minimaalselt 1 GB mõlu, aga te ole lupatud kasutada kuni 3 GB mõlu. See on tegelikult halv. Kui teid pane paik, et ammebasil on rangel 3 GB minimum ja maksimum, siis need asjad, mille on lupatuda, kui olla pörstub olehk rohkem mõlu kasutada, kui on limit, on väheprioriteetsed kui need, mille olev väga rangelimik. Kui peadneedse on parem üelda, et rangel paikapane ammebasil on 3 GB minimum ja maksimum 3 GB, et seda tüüpi teenu seda kõrgema prioriteetiga. Ja need, mitse on näiteks väikse limiitikajaga lupatud, näid 3-4 kod rohkem mõlu või 3 GB mõud kasutada, neid on väikseha prioriteetiga ja need, kui peadneedse eemadab enna. See on kuvitava asja, mis on sisse ehitadud ja peidatud. Mõnesmõttes on hea ammebasile lubata rohkem mõlu kasutada, aga tegelikult mõnesmõttes on see halb, kuna kui peadneedses eemadab neid enne kui teistneed, alati on hea pana fikseeritud mõlu kasutus. Ja teine asjumise halb panan mitte üldse ei pana paikamälu kasutus või sietukasutus konteenerile, kui peadneedse peaks alati panema limidid. Need üleleil on üldse midagi määrahtud, on ka madalama prioriteetiga. Ja on hea ka, et sisse eetadud saladust ja konfiguratsiooni haldus, et saab, nagu ku pereadse see eskirut, näites poskressi paroolid ja hiljem itselt mingis poskressi manifestis linkida nendel, et võtta siit saadusad. Ja need saadust on ka namespeiside speciifiliselt, et me saame anne paasi namespeisiluua saladuse ja nüüd see on poskress saladus. Ja siis kui selles namespeis, siis paneme üles poskressi poodi, siis ta ja Anna ütleb poskress poodi manifestiselt, et võtta saladus sealt. Siis on nagu lihtne hiljem, kas saladust näiks muuta ja poodile kustutada ja poodi uuestil uue selleks, et ta saladus uuesti saab vajaks. Et saab saladusi ka muuta hästi ja need halata. Kes kellevil on küsimusi? Posk või see, kubernets on selline tenoloogia, mida me selles ainees praaktikult läbi ei tee. On pilvetehnoloogias ja sisteemihaalduses kubernets kasutuses, on ka DevOps ainees kubernets kasutuses ja siis sugi seal on eraldi kubernets aine ja see on peanud, et ma pistuid pealitele. Ja väike uuesti kokku võtta selle kubernets ja dockeri võrdlus, et klastritehalduse ja repütsieeristud klastvi üleselt teenusid on kubernetses tokerusmormis suhtselt mõlemast toetatud. Teenust on alka leidmine näitele teenuse lineärgi, et ei pea iga-aalduse kasutada, mene on ka mõlemast toetatud. Tokeris on ülliselt puudlus, valvandus, puumiorgeteerimere, et peate käsid kaustasid looma või neid voliumid looma ja konfigureerime annepaasetele. Ja siis hoolitsema sellest, et neid voliumid ei lähe katuma, neid on repütsieeritud ja seda repütsieeritud voliumitehaaldus ka tokeris on pari raskema. Kubernetses on see osaliselt sisse eitatud ja sa hakkakubernetses üleselta neid plonghoode. Versioonid automaatu uendus ja versioonid tagasi tööramine ka tokeris ole hästi toetatud. Selline enese parandamine kubernetses tokesolmise on mõlemast mõlemast mõttes olemas, kubernetses on ka prioriteetid sees, et saate määrata näiteks, et kui resurs on liiga vähe, siis jättada üles alles need resursid, mille on ranga limidid paigas, et näiteks annepaasi teenusele läheks viimasena kinni ja enne emadates niimoodi appi replikete. Saadust ja konfiguratsioonihaldus on ka kubernetses parem ja automaat eskaleerimist tokers ei ole, et ka peab eraldi otsima, et mis tarkvara peab kasutuma selleks, et muuta replikete arvutoker teenuste stokkers formus. Ja väike kokkuvete ka, et mikro teenused võivad lihtsustada halusüsteemide loomist, kuna me saame intimitavalsed komponentte hallata, areldada, uuendada, skaleerida eraldatud ülejansüsteemist. Me ei pea siis nii palju arvesse võtma ülejans mõnolitse süsteemii sisu, et me saame skaleerida näiteks üksiköid mikro teenust vastavalt sellele, ku palju resursse tema vajab ja me ei pea väga arvesse võtma, et mis on teiste modulite resursivajadusel või hetke jõudusevajadus mõnolitses rakendis. Konteinerid on olnud üle pealnused mikro teenuste edukese võimaldevad, sest lihtsustavad rakendiste ja eraldatud keskondadel oomist ja lihtsalt ülesseadmist, et väga lihtne on neiteks demoksis või CSCDs automatiseerida konteineri pildivist ja konteineri ülesseadmist, siis kui näiteks me muudame koodi kitis ja panaks automaatsal tööle mingi kit pipelineis automaatsal pildivis, olev konteineri uuesti ja laeb üles rekistrisse ja näiteks muuda pärasele versiooni kuberneete seha apikaudu, et mis on selle imituiolisioonistne peoksma. Üks ühe asja, nagu ma oleks ettevaadlik, et kui te olete konteineri tästid palju kasutada, siis tihtite ja tõmbate rekistrist alla poskes kool on leitest. See on tegelikult natuke nõhtlik. Leitest on midagi sellist, mis on selles mõttes, et tõmmartakse kõige viimane versioon praegus ja näitele alla. Aga kui tegib näiteks Toker Hubi uus versioon, siis Toker ja kuberneete ei tõmba uuesti uut versiooni alla. Et jääb ikka sellise, mis oli viimati, kui ta esimest korda jooksutat, et tõmad pange üles, neiks poskras leitest, siis ikkagi annem või sinna kuberneete, siis jääb ikkagi selle version, mis sellel hetkel oli ja ei ole automatiseeritud, kui leitest muutub siis tõmba uuesti alla. Parem on juhtida täpsemalt, mis on see versioon, mida te üles jate, et jõudame poskras 3.7 ja siis järgmine nädal vaatate, kas on uus versiooni, siis muudat äraad nüüd peks on 3.8. Mis juhtub see, et kui te leitest kasutate, siis näiteks production keskkonnast kasutad leitest, testkonnast kasutad leitest ja kuna sellel ühen ädal on vahe, siis mõlemus on erina versioon. Ja teine asja on see, et te unustat äraad, ma panin leitest versiooni üles, et unustat äraad, et tegelikult ei ole leitest, nad ka sajapärast, et siis ta on mingi vanaversioon, aga siis ka ei teada, mis versioon ta oli, sest teempleidis on kirjas leitest. Et te isegi ei saa luge, et misse versioon seal oli, kuna seal on kirjas leitest, et te tead isegi poodi sisse vaatama, et mista oli. Ja mõnikord te isegi poodi sisse vaatatast tead, et te peate vaatama, et mis reaaliselt on see inidž, mis on alla tõmatud sellesse nõudi ja võib teadud olukord, et te tegid isegi see olukord, et te paete leitest poskress üles selle nõudi peal ja siis lisate järgmine uue nõudi kuba neetesesse ja tema tõmab ka poskress leitest jalla, ja see on versioonid eri nõud. Sest üks kuba neetesese nõud pandi üle sellene nädal, üks kuba neetesese nõud pandi see nädal, ja mõle nad tõmbad leitest jalla, aga nad tõmbasid eri nõud lojal leitest jalla. Togger Hubi sisse eidatud see leitestjääg on natuke nõud ohvit teadud olukordades. Ja on tihti tegind olukord, et te ei arvat, et praktikumis näiteks te uuendasid Togger Hubis oma versiooni ja te teete konteineris Togger Service näiteks teete restarti oma konteinelele ja vaatad, et miks tarkvarajal uuen. Aga te reaalselt ei ole Togger Hubist uuesti leitestjit allatõmanud. Leitest versioone allatõmanud. Ja seda Togger Pull poskress leitest käsku seda ei kehta automaassalt uuesti. Ja et tegib sellise synchroniseerimesi probleemid, et alati olge natuke ettevaatlik nende konteineri versioonidega rekistitest. Eest parem on ikkagi kasutada konkreessid versioone. Iga uuendas ajal suurendada versiooni numbrid, et siis tead, mis versioonid te reaalselt kasutate. Ja te saada karanteerid, et mitte erinele serverist tõmati sama versioon alla ja ei tegi seda võimalik olukord, et te tegab erinele versioone. Et mul endel ka vihtun selle ka probleemitekki, et ei tule pähese, et te leitest tagavalt peidus alla täiesti erinele versioon. Ja ma olen näinud, et tudenitelt isti on mõningord väga raskate teete akitelat olukord, kuna ei saa aru, et tegelikult ma kõik luuendasin image-it. Aga mul see image on juba allatõmatud, aga reaalselt see image versioon on erinev, kuna taustas küll failid muutust, aga mõlemad on sama versioon, miin imin leidest. Ja kui docker-sformid võimalda lua suurame docker-klastreid, aga see on raske teatada asja automatiseerida, et kui perneetes lihtsustab konteened ja mikul pärast haldust, aga kõige rohkem peab automatiseerist. Kui teist, docker-s me saame üles näiteks seada Postgres nodeid ja saame docker-sformid üles seada Postgres klastri, kui perneetes me saame saada üles Postgres body, Postgres stateful setid, aga meil on tegelikult võimalik, kas sellase meil näiteks allatõmata kui perneetesest packaged Postgresi Helm template, kus defineeriteks ära, kudas üles seada Postgresi 7-nodilis klastrit või x-nodilis klastrit. Ja siis kõik konfigureeriteks see meile automaatsed, et me isegi peab template isemuutma, et lihtsam on näiteks tõmmat alla Helm template, mis defineerib ära, kudas üles seada Postgres klastrit, mille on 3x nodeid ja teise ei peab selle peale väga palju nõtlema. Aga kui perneetes on veel üks automatiseeris, mis saame kõrgemale, et on sellist asja nagu operaatoreid. Kes on kuulud kui perneetes operaatoreid osta? Mis nad on? Ja millest on see, et see saab selle kui perneetes üles? Võimsalt tiisab kui perneetes üles saab liisest Helmist, et Helm template on tiisab selleks, et üles seada. Et operaatoreid tegemikrataaks on kalli põrgema. Ütlem, et meil on näiteks töötaja, kes on Postgresi speciaalist ja teab, kudas hästi Postgres klastrit halata, kudas konfigureerita automaatses ka leeris või back-up ja midagi. Operaatore mõtta automatiseerida tegevuse, mis toimub väravst ülesseada. Mitte ainult, kuidas ülesseada. Üldjuul piisab Helm template selleks, et asi ülesseada. Aga kui sa tahad automatiseerida hilisemad asjut, siis operaatoreid on starkvara, mis jätkab jooksnud, kui perneetes sees, et Postgres operaatore ei ole Postgres. Postgres operaatore on näiteks koos kirjutatud või pyütonis kirjutatud, mitte ülesseada ja jäibida selle laadud jooksad. Ja näiteks jäibida monitorimist ja otsustada, kas midagi ümber konfigureerida. Operaatoreid on lihtsalt sisseleibadud, mist toimub väravst seda, kui asja on üleval. Ja sinna on palju rohkem asja automatiseerida. Kas või see, kuna poode juurde panna, kuna poode eemal, kuna back upi teha, mida teha enne back upi, mida teha pärast back upi. Ja kõik sellist asjad saab sisse automatiseerida. Võimest, automatiseerimise program, mis jätkab jooks vist kui perneetes sees. Aga tõesti sellel juba oleme üleaja, nii et see läks väga aega jõule. Aga soovitavalt juul to lugega operaatoreid kohtal päris huvitavad, mis kõik seal võimalik on. Aga tõesti operaatoreid on väga mugav viiskuda seda, et see poskust ülesjääda. Mikrotelusest samas võivad teha systemi palju keerukamaks ja ka kallimaks. Kogu systemi võib olla keeruisen, nagu hõlmata ja hallata kui lihtsamad monolitsed systemi. Aga ta võimaladab just rohkem lihtsamine arendada ja skaleerida just teene. Mikrotelusest võivad ka olla ka ega tegi kisemat, sest komponentide vahel nüüd aga tõesti kasutama lokaalsavõrku. Olmuse siis kas GRTC või HATTP protokoll või mingisamiselt töödejärjekorrad. Kõik töötavad üle lokaalsavõrku. Kui sõrvumite saadmine üksteisega suhtlus, võib toimuda üle lokaalsavõrku. See on tähtis, kui mikroteluste komponentid oma vahel suhtlevad. Kui me lihtsalt oma rahmatate halvsa api ja kakama kaheks konteineriteks liiklus tuleb ainult kannutatelt, siis väga seda pahet ei ole. Kui meie apid omavale ei räägi, siis võib olla teda efektiivsest ei kaota külse, sest liiklus ka klientid ja meie systemi vahel nii ülemõrku toimuma. Aga kui me jautavad mingiselt komponentid erineeteks mikrotelusteks, mis oma vahel suhtlevad, siis suhtlus toitab näluasemel näiteks. Sela asem, et on üks suhtlusi funktioni väljakutsuvad, nüüd pead saadma sõrvumite üle võrguni, et kindlasti ta hakkab olema natka aegada. Nii juhetki juba endusti, et kusitame seda asude proov storet siin. Jah, et see on mõneseltes seljetud, et me soovime küsivalt ja mahukalt skaleeritavalt jäägad salastavammed. Olukörras, kus ta sinu arvutis kannutav asuret, on ta kindlasti tohutu taeglase, aga olukörras, kus me paneme ta nähe asuras üles hiljem, siis väga seda pahet võib olla. Ja tõesti lokaalne ja võrgufailisisteem on erinev. Nii asuvad kusagi mujal, et asuvad kuskil lokaalsas võrgus, võib olla kõrval serveredas või teises väkis. Et on tõesti aeglase, kui ta oleks täpselt samas ketas, kui see virtuaalmasi nõuks. Aga praegu ei ole veel pilve üles kannud, nii et praegu on tõesti päris aeglan olla, kui ta sinu arvutis jooksad ja asuras saad juba süsvelast. No pilvas ka ei puhub, siis olla samas, see on kui olub kui piirub. Üldiselt ikkagi huoliselteks see sellest, et oleks effektiivsem, et ei oleks väga aeglen nähtud. Ma ise ei ole uurinud väga benchmark, mis ta mõõdavad, et kui aeglase näid võrgu. Näiteks ma panen liemi üles ja kasutan lokaalselt file versus selleket, et on palem peab asura vahe storias, võib olla leijad mõna avtikli, mis seda näiteks võrdleb. Ma ise ei ole nii, et ise uurinud. Aga kindlasti võrg on aeglase võib lokaalne failisisteeme meel. Eriti Linux tilti hoiab faili nagu mäljusse mäpitult, kui neid loetakse ja kasutab mäljul käsina, et vältida otsaja failisisteemist tugemus. Nii et lokaalselt faili on lihtne mäljumatide ja peab olev piirem nii tugega. Aga see ongi tänaseks siis kõik. Praaktikumis siis see nädal jätkame sellel kahe mikrotenus arendus, aga teen meile natuke ümber ja panen meie fonttelid ette. Ja teen ühe appi metodi katsud suurda. Nägemist!

---------Loeng 12 - Nanoteenused.txt--------

 Tänase teema sisuks on siis nanoteinusid, kus me harasamatest loandukes olemme räägit mikroteinustest ja erinele 15, kuidas me saame rakendusid ülesseada näiteks, kas manolympina või mikroteinustena. Tena vaatame, mis asjad on veen päiksematu mikroteinused estikilesele teematelubi nanoteinusteks, inglis peales pick and serverless või functionesa service. Estikilesele suhub ka neid tegelikult funktionid, teenustena või pilvefunktioonide nimekid. Räägime siis, mis on üldse nanoteinused, mis on nende platformid pilves ja implementatsioonid, kui soovit sagas vast ja ei tule teerideses oma keskkondades vabatakkuja, aga et ei sovi ennast lukustada pilveplatformidesse. Ja võtame siis loonikookunem pealist ja puudustega, et nende koht on väga palju viimasele ajal viimaste laste räägitud ja või keada mulle, et nanoteinuste hästi mugavad, skaleerivad ja odaamad, aga lihtsalt tuleb välja, et siit päris vimoodi ei ole. Nendele tuleb natuke alati ettevaatikolla, kui lukustate ennast nanoteinuste kasutamise peale liiga palju asja teavaks, siis võib palju kaljimata tegelikult. Ennast loonikookunem me räägime mikroteinuste, et tõeliselt näikud, et saame indistaks hapid jagada, et on väitsa mikroteinuste, kus osa hapid teinustast vägjad oma vahel, aga me võime ka sisse jäga pärinud hapid oma lära, et saame võib panna hapid peeperiks, siis kuhudid sisse paas pärinud erinele hapid mikroteinustele, maha, et millised mikroteinusteid on vastutavad seda tüutbi olemide halldamisees, et kontood või kellimused või maksev. Muidugi see maail on palju keerulisem, et saalt taga võib olla kõvasti rohkean mikroteinusteid tegelikult, mingi konkurenta amme paas ja halldamisega, ja need mikroteinuste võib oma vahel suhelda ja tihti pead kustu. Ma natuke nält peidaan seda tuumi asja seda. Me rääksime elmikult mikroteinuste elistest ja puudustest, et üks selline suurem puudus on see, et kui me hakkame suurt manuallised rakendust jagama väiksema tegideks, me tegelikult pihti peame rohkem, et susse kasutamus selleks, et meid ülev on hoida. Meil võib juhtustada osa mikroteinuseid, mis meil on loodud. Nii kasutada nii liht, et peaks tegelikult mingi mikroteinus igavast sooks määte, et meil on maksateinused ja maksed on juhtub 200 korda päevas. Eriti, kui meil on kuu maksed, et maksed ei tehta rohkem kui par 10, par 100 või par 1000 korda päevas. Meil on siis vaja üleval olnud na mindiskust konteinerid, mis tegeleb ainult ootamiseks, mis sisse tulevad mingi maksed. Me maksam näiks pilvesse selle konteineri oostamises ise, kui ta on hästi väike, sest võib juhtuda, et meil on mõned sellised teenust, mikroteinuste arkitektuuris, mis tegelikult ei piaks kogu aeg tööle jääba. Aga pilve platformides me maksame tavast iga sellest, et mindis mulle teenust on üleval, kas konteineris on võib ta oma asjad, me ootab, kui teile pärjelid tuleb, kui ise võltab järekorrast sõnumeid ja töötad neid ja me peame ikkagi maksam selle konteineri ooksumus aega eest. Ta võib-olla ei ole nii maksimum hind, et ta mingi väitikonteineri, et see ootab taustalt, aga ikka 24 tündi päevad maksam me selle. Ja kas meil on vajanud kogagi ooksumad isegi, kui sisel tandmeid ei ole, või saaks mingi, et see ei saa panhe. Nüüd on olemas lahendused, kuidas saab ka konteinerist jõtsad nuilis skaleerida. Kui per neete, siis on võimalik kasutada lahendusi, mis on nii-küks konteinerid, skaleerid nad nuilid. Ja siis, kui sulleks kusse, näed, et saapi keihu põisseb pärin, mida peab siia suunama ja selle suunamise pärin, siis see tulemusena skaleerid seda nagu tagasi nuilid ühele enne, kui kõikest pärin peale suunatakse. Näed, et need on G-ta ja G-neidid, kui per neetes sellised skaleerimis rakkembiselt võimalik, kui sa� pole on tegeval力 ta lenni Wing Rel, nii꾸你是 mink cabe tegeval l 소l Looney Balls. Juhu tead seda, et olime tervaks, hunting laisadab leo-otto Burger King koh haarajui, että te busesin seda poolぎ notification. ja aheadte seda aastap qui address Tram!!!! Sa ei mingi kohe need, kui skate viis on. päringust ja teenuust sees kaardistatakse, et kui tuleb siis see teatud tüübi päring, mis sugun püütani funktsioon, mis sugun jaava funktsioon käivitada ja see püütani või aava funktsioon ei pea olema kogu küleval. Selle asemel meil võib olla see timelik, külisnav funktsioon, mida käivitatakse ja käivitavad ainult siis, kui tegelikult tuleb siis see mingisugune päring, mis nõuab, et seda funktsiooni käivid. Ja sellest kasvuski sääli ja selline function as a service või funktsioonid pilve funktsioonit teenusena, olid te kindlalt kuulnud näid Amazon Lambast, Amazon pilves, et see on või see on sama mursta, et me ei jooksulta või hoia taustal jooks, vahe mingisugust funktsioon, mida me tahan, et käivitatakse. Me olidime, et meil on mingi raamistik, et see ostad, et funktsioon on väljakutsud siis vaja. Ja me saame nagu mõnesmates neid samu resursse ära kasutada, et meil on veel mingi konteeenerid, mis jooksevad, aga nemad on võib-olla vastutavadse erinevata funktsioonid jooksutavusevada. Ja see ongi võibas enne senditus, et kuidas mikro teenustest kasvat välja sellised väiksemad konteeenerid, mis väiksemad teenused, mis ei koko aegi jookse, või need käivitada allaks siis, kui neid vaja lähe. Ja need ongi sellised nanoteenused. Ja selle tõttuk nimetadakse mõnigult neid ka serverlessiks, mis ei ole mõige parem niisest. Taustal teavad olema serveri, aga see idee on see, et meie rakendus või meie funktsioon ei jookse taustal kogu aeg mingis serveris, või teda käivitatse ainult siis, kui see vaja on. Sellest tulik üle väljas, funksioonise service või serverless natuke halb kirjalduse mõelda serveri vabad rakendused või teenused, sest reaalselt servered on vaja, aga nendele ei alokeerita pidevalt taustal olevat serverid ja me ei maksa aja eestmida või meie funktsioon, mida midagi ei teed. Serverless funktsioonid või nanofunktsioonid on oma vahel sõltumatud, et nad on täiesti eraldiskaleeritavad, halvatavad, hinastatavad ja iga funktsioon võib olla eriliseks keeles, nii et nad jälgivad sellest sammast mikroviimaste mustrit, et neid saab täiesti eralduja arendedat, me võime mõned kirjutada kookeeles, mõned kirjutada lukikkeeles, mõned kirjutada kõitonkeeles ja ta on mõnesed loogini jätk mikro teinostud väiksematis minemiseks, et kui me teeme näiteks raamatute halvus appid, siis meil sama pyytoni rakenduses ees on et skettpärind, postpärind, selitpärind võib olla mikro teinostu maailmas me saaksime näid teha kolme erina funktsioonina, et meil ongi iga endpoint metod jaoks eraldu funktsioon ja me rekistreeerime need funktsioonid pilves ja defineerime, et kuna need funktsioone pealt käilitama. Ja idee ongi, et meil neid mikro teinostud ei oksa taustal pideval, nad ei ole kustis virtuaalmasinees võib konteineris kogu aeg siselt ei kuulamas, vaid nad käilitakse alle, et siistu sissepullad mingisugune sümmus, mis paneg selle funktsioonitööle, mis paneg mingi raamistiga selle funktsiooni välja kutsuma. Ja selleks pärin nagu elis on see, et me enam ei pea maksma aidil ajal. Et kuultakööta ette taaksute ülespanna mingisuguse rakenduse, mis kuulab, kas Amazoni file-i sistemi panneks üles mingi file ja kui see file on suurenku 1 gigabyte, siis palun käiviteki minu.jom, mis konverteerib seda palju täistama. Aga need ühe gigabyteidseid file-i võib-olla tegi päris ükskord päeva. Et mida te siis teete, kes te panad üles virtuaalmasinees, selleks et kuulata järgstu päevas ükskord tuleb üks sündmus ja ma siis päevitan selleks, et miks ma peaks raistamada seda virtuaalmasina aeg ja selleks, et oodate, et võib-olla tuleb mingisugun üks ästisumur file-i, nagu konverteerimaastas. Võib ma peaksin selle funktsioonalasuse sisse eitama oma mingis ja teise veepit teenuse rakenduse, mis ningu nii kogu aeg jooksad. Seda saaks teha, aga siin menelega tagas, siis monolistise maailma, et me hakkame lisafunktioonaalsest panema loogukasse, mikro-teenustesse, mis ei ole mõeldud sellest hoolitsevist. Ja need pilvapaksoonid võimalda, võib-olla siis hästi harva juhtuvad asju automatiseerida niimoodi, et ma ei pea neid taustal jooksma jätma. Et see on nagu see, et kaaptas kõige parin või kõike sopivam kasutus viis nano-teenustele, midagi mis ei pea kogu aeg jooksma. Väga palju näete näiteid veebis, kus kirjatakse, et kuidas micro-teenuseid või nano-teenuste katutad asjate aegs, mis on tavasad appid, mis koko aeg jooksevad, mis kohad midagi töötlevad. Ja ausalt üldes, need ei ole kõige paremad kasutuslood, sest kui te nii kui nii pead midagi koko aeg jooksma ja te ei olegi sellest haidel aega, siis tõenast micro-teenustele või need nano-teenuseid servelest funktionid näed palju väljumast. See on sopiv, et see staatuse karaksjegust jaoks, mis me ei pea midagi mängu, et üldeselt nad lõiksid väga lõidist aega töötavad. Ei ole hea, mingi västi pikkid video töötusrakendid nende avid teha, aga võib olla ka okei, kui see toimub näiteks paakorda päevas ja töötavad mingi minuutid või pari minuutid või 10 minuutid, et siis on okei. Ja näid siseliselt skaaleeriteks automaatselt, võrraldes micro-teenuste või virtuaalmaselete puhul, et kasutused tavalselt isegi ei pea midagi konfigureerimata ja skaaleeritaks. Ne skaaleerim natuke sisse eitadud enda see pilve ja funktionidesse ja tavalselt, mida te saate teha, on panna maksimum limikid, et te ei taha, et teie funktioni skaaleeritaks hopkem kõmme koopjat, mis saada töötavad. Lihtsalt see, et see liiga kaileks ei lähed, et saada limiid panna. Ja võimalt ongi selline väike visuatsioonet, kui mulle monolidist rakendisest, mis meil on mootulik põe rakenduse, see on ikka teed, et me jagame nad väitsevateks mootulik, et sa ka nad ikkagi jälgivad ja sama moose struktuuris, mis oleks olnud, aga nüüd nad on eraldi kontenerist ja see kooksad eraldi prozessi, et me jalgame nad väitsemaks funktionidest, kui te teed, et teed on iga kõrkna funktion appis, või et saaksime individuaalselt funktion registreerida, kui teenustena nad on ise oma keskkonnas, oma eraldähtud sellestis. Mini-containers, nano-containers, kust platformid autnud, tocker või kuperneetees või isiga. Et me jagame siis oma suurda näed mobiiliselt mootuliks, palju väitsevateks sellesteks funktionist ühtiselt. Ja tegivad samas probleem, et mit Mikro teenusta puhul, et uidelik funktionid peavad oma suhtama, sa peavad suhtama üle lokaalse kõrgu ja see võib tähedada, et kui me siin oleks võib-olla suurselt väikar väljakutsa, siis kui ma teame väiksemalik funktionel väljakutsamise, et näid individuaalselt teenusest, mida väljakutsutakse, siis lokaalse kõrgus näiteks kontenerita vahele, on kõvasti rohkem. Aga see olenne, et kui me jagame, kui me on appi ja ütleb, et neid on kõik nagu appi endpoindid, iga üks on eritud eraldu Mikro teenudas, et siis on kiinu see siis appi funktioni, kui me nad eraldi lieks appi funktionid saavu jagam, et kui siin appi funktion on eraldi kontenerist, otseselt see ei kruugi nagu lisaniiklus tekitada, sest võib-olla liiklus läks iga viie appi funktioni ja siia rüdev piide endasi kontenerist, et kui neid liiklus toimub välis, teg lendud ja appi funktionide vaalad, siis võib-olla see on väga palju epaeg, et niisemüüa. Ja ta ongi selline ajas väitsemaks mine selline arkitektuur, et meil jääres väitse vähem tüpt, et kui enna liib nagu hulb kontenerid, siis tõenas, et kui me prooveksime kogu Mikro teenuste rakenduse teha, et selle on tegud selle, et meil tegaksin veel rohkem kontenerid, veel rohkem väitsemaid teenuseid, mis jooksad kusagil tilves ja nende arkitektuurialdemid läheb misjagi keerulisemaks, sest meil peame nüüd hooma, mis toimub, mitte annud Mikro teenuste pahelvaid, mis toimub ka kuskil sünnmustes, et kui sisse tuleb nagu sünnmuste stream, ja iga sünnmuse erino tüübi jaoks on eraldi funksioon, siis tegelikult sellist rakendust ja hoomamine, mis on näitud servilevse funksioonide peal on päris keeruliselt pinna, keerulisemaks kui kontenerid ka pooru või Mikro teenuste puh. Mida tähendab sünnmuste põine käitused? Üldjuul me defineerime mingisuguse triggeri või päästiku, et kui sisse tuleb uus fail Amazon S3, kui Annenbassi tabelliselt tegi buuskirje, kui Annenbassi tabelliselt kasutajakirjat muudatud, kui keegi muudab faili, kui sisse tuleb uus sõnum järjekorda, kui poimselt üks sünnmuste, mis muudab mingit Annaid pilves, Annenbassis töödab teadati järjekorras, et me saame neid kasutada seiste päästikutlana, et toimus uus sünnmus lisaks sellele, et võib-pall, et kui fail on suurem kui 10 MB, siis me saame piste defineerida sellised e-singimused, et käivitame siis funktsiooni ainult siis, kui mingisuguse parametra on suurem kui mingi väärtus, kui logikirjes on temperatuur suurem kui 70°C. Ja siis on mingisuguse tegevuse, et funktsiooni väljakutsumene, siis näid on, et kui meil on uus fail laadid üles s3, on siis pärastik, keelt ingimus on faili suurem kui 10 MB, ja tegevuse on siis mingi püütunni funktsiooni väljakutsa, et vähend te pildi fail väiksemaset kui 10 MB suurem, siis kirutusid pildi fail üle väiksema pildi suurusega, et me vähendame resoluatsiooni, et me ei pea nii suurem resoluatsiooniga pitte hoidma. Või siis tekitada väiksema resoluatsiooniga fail asemel, aga siis monna suurem fail akhiweeril ja küski oda oma selle storid siis vähe palles, aga me ei maksa selle sinna palju. Ja nanofunktsioonid siis defineerivad sellised, mis on pärastik, mis on e-singimused, mis on tegevused, ja tegevuseid meil pole teerina mingisubes koodiga, et püütun funksioon, JavaScript funksioon, K funksioon, Ruby funksioon innsid ajast. Ja Amazon Lambda ei saa muodu, et kui meil kamera teab foto, meil on aktiveeritud automaatne foto synchroniseerimine pilve storidgisse, ja meile saame defineerivad, et Lambda funksioon kävitab, siis kui meil problemi on saadusti liigasuri pilted, me ei taha liiga palju makstani, et me saame automaatselt teha nüüd pilti väiksemaks. Ja siis see töötab hästi, siis kui meil pilted tekiv suurselt harva, kui meil pilted tekiv piisavalt, näiteks meil kasutat arvan liiga suur, siis meil oleks võib-pall parem mingisugune virtuaalmasini vaj mingisugune konteiner panna kogal peoksma neid piltekuulama selle asemel, et Lambda funksioone kävitab. Miks see on? Nii ma tulema tatke tagasi hinastamise model juures, et see maks mene kui läste maksate konteineri, versus funksioonide väljakutsete, on hästi hästi erinev, ja seal kui sa välja tuleb, et kunada kõige mukaavam, võib kunada kõige odaama kasutaja või mitte. Ja sündmused võib-a-t kõik midagi pilves, mis tekitab mingisugud logikirje kuski pilve teenuses, et alati on mingisugud limitatsioonid, et mis Lambda toetab sündmustena, mis Azure Functions toetab sündmustena, mis Google Functions toetab sündmustena, ja eriti kui te ise tekitate oma vabavaralise nano-tenuste plakformeid, siis on ka tavas limiteeritused midade saates sündmustena kasutada, aga neid ma juba teid näited, et näed, et see on uus fail, kuski pilved teed, see on uus annapaks kirje, temperatuurivärkis on kõrgemugu 100 kradi kuski, mis sisse tuleb jätete erekorda sõnumisees, uus kirjisaapus sõnumisees, erekorda uusi imeelturi kohale, või uus hatete peab pärin saapus, et tegime, tegimegi appi rakenduse põhjumist ta funksioonide pohjal, et me saame defineerid, et iga, haad, et tegime pärin ka on sündmust. Nel tõngimised me juba siis tavalselt olla kas sellan sündmuse meta annade pojal, et see on faili suurus, või teadud olukordat, et teadud sündmuste pool ka faili sisse võid näed, et meil on JSON, me juba defineerid, et JSON ei seeest olema mingusugune võitme, et te, mingusugune, point temperature on suuremne 80 m. Ja see ajalme siis väitida, et me peaame funksiooni käivitama iga sisse tuleva sõnume peal, ja sega täendab, et me ei pea olema loogika kusakul meie konteineris, mis kuulab kõikis sündmuse ja otsustab, kas käivitavad mingis funksioonia või mitte, vaid me põhimõtteliselt paneme selle vastutuse pilve teemist pakkujal kontrolli kontrollid, mis on objekti sisu ja alles siis käivitab meie funktioni ja meie maksame tegelt ainult käivitamiseks, et me ei pea maksma nagu selle kontrollie eest, kas midagi käivitada on itte. Ja see on üks osa, mille tõttusele võib-olla oda on, kui konteineris kõikides ünmuste kuulamine ja funktionite käivitamine, kui me saame vältida meie koodi kasutamist siis, kui tegad seda vajal ei ole. Ja tegevus on siis reaalne funktioni, mingis keskkonas ja mingis progameerimis keelega näiteks püütaniseb. Et luomame siis mingisus püütanfunktsiooni, et praktikumis me loomem püütanfunktsiooni, mis võtab sest teksti faili ja projekteerib selle BDEFiks. Et see on midagi sellist, midagi me peame pilves registreerima ja peame seda koodi looma, aga see on midagi sellist, mis vähemalt loogiliselt ei pea taustal pidevad töötama. Seal on üld suur, aga pilvet jäänustab pakku ja võita jätta jooksma, et see on põibst teeme otsustada, kas ta jätab selle taustal jooksma vii mitte. Et see on implementatsiooni küsimus, kas ta jooksab vii mitte, aga peame meie aks tähtmes, et me ei maksa sellest, kui taustal jookseb, et me ei enam ei maksa konteineritunni jooksimiseest või mitu minuutid konteineri jookseb. Nanoteinuste platform käibitab selle funksiooni, mida meie selle funksioonateerime, et siis, kui tuleb sisse sündmus, mille parametrit on korrekt, vastavad meie e-tinkimusele. Ja kui seda sündmus ei teki, siis meie koodi jookse ja meie selle koodi jookse peab teha maksaa. Siin on näide IBM funksioonid, IBM-pillas, IBM-funktsioonid teinustest, kus me saame, et defineerite sellese API-rakenduse, et meil on näiteks üks funksioon, mis on lihtsalt see, et ta näiteb HTML-vormi. Me teeme sellest püüttan funksioonid ja defineerime, et tema peaks välja printuma sellise HTML-leegine ja defineerime, et kui sisse tuleb kettspäeem meie adressile, siis käividelik see funksioon, mis printit välja HTML-li ja HTML-li siis see on vorm ja see vorm viitab välja teisele funksioonid, et sa post-typikid pärinud samale adressi pohjumad. Me defineerime ühe funksiooni selleks, mis kui tõb kettspäeengid näidata vormi ja teisele funksioonid, kui vormil vajutud, et saab midt tukkud sellisel vormil, kus meil on kajutaline nii nii sõnu, et send message saab midt tukk, et siis käiviselt see teine selveliks funksioon. Ja see on selline tüüpine viis, kudas proovida modeleerida nagu hot-dev appid võibilehte võimestse funksioonide. Ja siis meil on see teine funksioon, mis kuulab nüüd, kas keel ei saa et mis on selle visasõnumiselle message vormi kaudu. Ja siis see funksioon on teine pültal funksioon, mis põhimõttel võtab selle sisendi vormist, kus on message ja user, defineerib JSON ja paned JSON-annebasi selle kirje. Ja siis meil on üks funksioon, mis hot-emaili printi pärile, teine funksioon, mis võtab hot-emailist sisestel annmed ja paned JSON dokumentin annebasi, kus on kasutatud. See on kohoda annebasi, ta on siis couch-td põlin annebasi. Kaudat on sellep ütlemene commercial nimi ja IBM pilvas, aga sisemised on tovist couch-td vabatakka, mis IBM pilvas johtsut. Ja idean on, et ees arenda aina saab te minna ja pilve brousseris põhimõttel sellist asja programeerida, programeerida kirjat mingu funksioonid ja defineerida, et kuna neid funksioone käividad, et mis on siis trigger mingi suge siin selles olukorras on ta posttäreend tüutti, atte päril teatud adressile, saalt defineerida, mis on erineid parametrit, mis on randan, et mis suge sest küütun keskkonasta jooksama peaks ja mis on rengpoint, et kogu peab saab saab ma selle hard drive pärin, kui siin on send point näha, kui kui sa tead, et näeks nõigatud selle function's app domain cloud app version 1 webis funksioonid nimi ja veste paraustil. Ta on see, et põhimõtteliselt kiire viiskule prototypide või kirustada funksioone, sest rousseris ilmaate peaks, et te funksiooni keskkonda isel olma, või meie praktikumis loome selle keskkona oma arvutis või inuks vertaalmasseks. Ja need endpointid näevab välja sellised, et see on siis meie funksiooni selle app, et näiteks cloud funksioonid app domain cloud app web, jakovits, app.ut.de, dev keskkond, siis pelleform on selle funksiooni nimi, ta nagu minu keskkona sisemine funksioon pelleform ja saab defineerida, et täst avalid funksioon, et ta ei nõua mingist autentimist või ka siis on äna autentitud funksioon, et see on selle funksioon, et auavab appi vegid. Mina tegid avalikuks, et nagu inimesed saaksid minu webi vormis, siis sõnumeid saada ilma, et minu rakendes täks põldi appi vegid halda maha. Funksiooni implementatsioon on palju. Kuulite kettesuha, leist suurevat pilvi, pilv, teresta pakku, et pange otsa funksioon, sõl Azure funksioons, Google funksioons. Amazonis on tähinna Amazon Lambda, mitte Amazon Functions, aga on ka avatud platformi, nagu Open Lambda, mis on põhimselt nagu community, kui implementatsioon Amazon Lambda on, et saaks Amazon Lambda appid kasutaga oma serverite puhule, mis saab Amazon Lambda klooni panna üles, siis oma serverite, siis oma Open Lambda on avatud. IBM kasutab Apache Open List, mis on sammulti vabatargvara, aga nemad kasutab IBM funksioonid implementatsioonina, aga saab teise oma serveride panne open listi põhle. Red Hat funksioons jõuk on ka vist open fahas üks sellest avatud arkvara, mida saab oma serveridele peale üles jääda. Nano teenuste näilde, et kui meil on loodud raamatud halduse tarkvara, siis meil on erinevad appi funksioonid, kudas kasutad saavad, et raamatud üht alla tõmbata, raamatud lua, me saaksime teoreetilisevst lua fahas funksioonid iga ühtel metod jaoks, kus me välja kutsutakse mindiskuse REST endpointi metodi peale. Tiktud näiteks raamatude nimekriapunktiooni, raamatude kustutamise funktooni, raamatude vaatumise funktooni, raamatude vatsimise funktooni, raamatude loomise funktooni. Aga see läheb natuke mõtetuks, sest olukorras, kus meil tegelikult on vajadus serverida palju klientte, võib meil juhtuda, et meil kogu aeg meid appi mängadad, et kutsutakse välja. Ja kui meil ei tegi seda olukord, et sa on ajut või harva juhtuvad sõmmused, et siis väga ei ole mõteta, kui appid primodid esainida, et olukorras, kus kasutad ei ole, siis sellest, et kasu olla saab suhtsalt odavald implementeeridesese appi. Aga sellene hetk, et ju sa saab kasutama asjad, siis sa tekivad probleenid, et sa ei või liiga kaelliks maksamani. Ja igale funktoonile me saaksime tekituda sellise päeval, et meil on Vest Pellaraamatu Traktsjäännüse, Azure Web-side net, appi-essise raamatud ja sellegu see on tüütbiline appi-aadres, aga me defineerime unikaalse aadres igale funktoonine, igat funktoonisab eraldi nagu pilve funktoonine, pilve funktoonime implementeeride omas nagu keskkonnas. Aga saab kõik ostada appi värav, aga ei need teha nad käette saadavaks nagu ühe aadres sina. Kõik mõnesed onki see Pellaraamalute Azure Web-side net ongi maju suurksse naapi värav. Paatame ka nüüd, kuidas näide makstakse, kui me hakkame need kasutama, et näide saamas on lambdas, saab kävitada koodi ilma nagu infrastruktuuriläis panemis, et saate defineerida, mis on see kõutane ja heaadas grip funktoon, et see on klasikane nano-teenuste platform. Aga me enam ei maksa see jooksumus ajast, kui konteinere puul me ei maksma kõik tuundide jooksev, kui minuutide jooksev isegi sekundest, siis funktoonide puul me maksame käilitus ajast. Põhjimadselt ainult selle ajast, mis funktoon kulutab, et jooks, et kui panaks sa mingi protsas tööle kuski kestanas tavast konteinerist, et siikse kauas selle funktoon reaalselt jooks, ja seda mõõdik, et see millisekundides, seal võib olla mindisvõi nii minimum vaeg, et minimum maksimisev pikkus on 10 millisekondi kohta. Aga te ei maksa ainult selle ajast, te maksate aja korda siis mänuala peerimiseks. Et on sellised meetrikad kasutuses monitoriusi nagu gigabyte sekundid, et viitu gigabytei mälu oli alokeeritud korda, mitu sekundida jooksev. Reaalselt on ta muidugi jooksev millisekundid tegema. Teadud pilvedes nagu Alibaba-aifi pilv ja siis Google pilvesti peate ka tegelikult CPU aajaajast maksma, et siis ta on CPU kordasekund ja plus gigabyte kordasekund, aga tavaliselt pilveliselt ainult gigabyte korda tekka. See on selled üttu, et kui tead on funktion, mis töötab mingisugud väiksemaid anmeid, siis ta tahab väiksemat keskkonda ja kui te kasutab ainult 200 megabyte mälu, te maksate vähem, kui te jookseb sama kaua aega, kui te kallutad, kasutab 2 gigabyte mälu. Ja ta on o-o. Naga lineaarselt see sõltub nii, et te maksate põhimõttel, et kolm korda rohkem kui te kasutab kolm korda rohkem mälu. Kihki saab ka tasutada päringud, et igas platformist avalast saab umbes 1 või rohkem miljon päringed kuus, et te saate teha nagu oma funktionid panna üles, igas kuus valg ka kasutada seda funktion teelust, kui ta ei tasutada kui te kasutad rohkem kui 1 miljon päringed kuus. Pärast seda on see taks, et on maksma umbes 20 cent iga miljoni päringu kohta, iga miljoni väljakutse kohta. Need hidaat eril, nad erineetat platformidel lisaks, et te maksate päringu kohtete, te maksate päringu nagu jooksebu sajakoht, et te saab te tasutada 400 000 gigabyte sekund. Ja et kui teie funktionid kokkuvaada kuus, vähem kui 400 000 gigabyte sekundid, siis te sellest ei maksa. Et see näide on, et kui funktioni alokeerid 0,5 gigabyte, 500 megabyte, te jookseb 100 millisekundid, mis järeikult teidada talita, et teil siis 5% ühes gigabyte sekund. Aga peale seda maksate siis 0,007 dollarid Amazonis iga 1 gigabyte sekundi kohta. Et see arvutus enam ei ole selle põhjale, et kui mitu minutid või mitu sekundid või mitu tundine, et funktionid jooksevad kokku, aga nüüd peab ta nagu hakkama. No ei tegega, et te läheb peate korjutama nagu see on mõelo alokeerimisega. Enam te ei tea, et mul on virtuaal maasini jookset tundi aeg ja maks on nii palju, aga nüüd teid võib-al see tundi aeg teie rakendist kasutatakse, aga see tasu sõudub täiesti sellest, kui kaua teie funktion jooksevad ja kui palju kasutad on. Et kui kasutad on 10x rohkem, maksate 10x rohkem. Kui funktion on 10x aeglasem, et maksate 10x rohkem. Et kui teie k-funktsioon, ütleb teie püütalfunktsioon, võtab 100 milisekvõid, et teha kõik tehtudusrakenduse ära sistem ja homme te designete ümber näites k-rakendusena, mis võtab 10x vähem aega, siis te teate ka homme 10x vähem maks. See ka motiveerid tegelikult inimesi, vägutavad natuke optimeerima, et palju aega võtab. Lambas näib umbes sama välja, nagu IBMis, et te saate funktsioonid kirjutada otsi browseris. Te ei tee neist browserist kirjutama, te saate oma development keskonnast kirjutse ja lise funktsiooni ülets laadida, aga protosipimise mõttes on päris mugav, et saate testida ja funktsioone proovida otsi keskonnast. Ja teil on erina tõerist, et juureks kudest saad testida. Testimisaal tada saate panama, mis on see sõmuse metaanmed ja näites pildi paani sisu. Mõnikad on natuke tüütust, ta niimoodi testida, kui teate browseris defineerima ka, mis on see pildi sisu, mis pandi kusple annuva. Eerina tõeristatunud see juureks. Ja te saate defineerida sellise appi gateway, mis võimadsalt võtab vastu, näiteks hardtetete pärimku. Ja see appi gateway automatiselt konverteerid sellise hardtetete pärimku info metaanmed ja kaasa pandud data podi objekti jationiks ja teie funktsioon Amazonis alati saab siselik jation. Või enam ei saa siseltik nagu hardtetete headerid, hardtetete podid, vaid ta saab siseltik sellise teatustruktuurist jationi, kus see hardtetete pärimkust kaasas olev infoon sellise jationi alam võitmõttes kirjaga. Ja see on sellise tüpigine, nagu Amazon jationi, lambda funktsioonid alati tegele jation siselik jation väljandiga, aga kui teie tahad, et sünnmus, hardtetete pärimku asemel, xml dokumenti või midagi muud, siis tabast on, kui kas AQHL, kes selle ümber konverteerib, või teatud tüpis sünnmuse, kui on näiteks Anne paasis kirja, muudeti siis kasi konverteerib, sest sünnmus konverteerib jationiks, ja Amazon lambda saab teha stevis jasoni, mis sisängiks. Ja Appi Gateway saab ka teha erilad asjad näiteks, saab automaalsed konverteerida ketrakööste jationiks, ja siis jason teie funktsiooni jationi vastust saab näiteks automaalsed xmliks ümber konverteerida, Appi Gateway on sellist furgital teelus, et sinna saab sisseheetada sellise formaatide transformimist, et teetev funtsioonimis oska mainis jationist sissevõtta väljas, väljastada, aga teile on vajalik, et kasutada ketpärimkutene, et tegelikult väljastab xml dokumenti, või siis isegi näiteks midagi teatud steemis, hdml lehtvõm või muud, et Appi Gateway tasemel on amasomis võimalik, siis konverteerida mingisoks te rakenduste või funktsioonide sisjendid ja väljandud teistest formaatisse vaja. Ja teil on selle, kui konfigureerita, et kuidas siin oleb sellile string, et response ümber kongeliteerist xmliks, et panna tale mingist tagid ümber ja liigutada, no, põimsalt õiges formaatis dokumentistruktur vandite. Mõnikord on huvitav võib-lumalesena. Neid nanoteenused on võimalik kasutada ka sellise loogika workflowtena. Kui te käetete soovite luua mingistlus rakenduse, mis käivistateks siis, kui tuleb sisse uus kasutapäringed, näites kasutasoovi posta mingistlus toode. Ja see ei pärast otsustama talle, kuid palju lainad on anda näiteks. Ma saaksin teha lainarakenduse, panna seda virtuaalmasinast tööle, pannada tööle nagu konteeleerina luuaste jäävaast või pyytonis ja teha appi, et ma saan pilvast välja kutsuta, et kui sisse on päring, et tegis oed laina, et mis on see mikro teenus, mis uurib, kui seda lainad tähtiselt käelta. Aga on võimalik teha mitte ainult üks funktion, aga on võimalik teha ta funktionide selline jada või selline state machine või mõtsedu. Kui sisse tuleb päring käelita see funktion, aga pärast seda funktioni vastavad funktioni väljontüütle, tekitame nagu sellised loogilised otsuse, et kui if else stiilis või jüklide stiilis, on võimalik programmeerida pilvest täiesti pilvetõhine selline loogika state machine, mis teed teadud tegevase läbi. Selleks on Amazonist disaaniitud app functions või Amazon step functions teenus, kus on võimalik otsuseid programmeerida väljas panagi koodi pilve teenustana. See on natuke nalakas, aga võimalikselt meil on võimalik tegida teha AVST functionide selline loogilise teenuse, mis kontrollivad, kui näiteks üldse on võimalik ostamida, ketk on projekte sanda ka, et see on kirja, et praegu on näite objektide, mis oledes osta, ole rohkem kui nüüd. Siis on teel, mis proovib, et on võite, et nasastal raha pillida läbi krediitkaardi ammeta, mis on kasutakohta sallestatud. Nii kaua, kui ei ole võimalik teha, panaks objekti või sedeljumus omatele ja kui lõpuks ole võimalik roha kätte saada, siis minnaks elastud protsist, mis saada välja toorti, mida kasutaja ostab kasutasoi kosta. Muidugi me tekiteksime mikrotenuseb nende jaoks, mis oma suhtlevad, aga amas olis meil on võimalik teha sellised asja väljasponnud mikrotenuseb osaliselt funktionekasutades, aga osaliselt isegi ilma meie koodi kasutamata. On võimalik defineerida sellised, korraks me ei näed, edasi, sellised workflowed, kus meil on mingisugune sõnmus, mis alustab workflowed ja workflow lopput, et panaks saa kõik asjad kõik kinniga. Ja meil siin see on võimalik kasutada lambda funksioone, aga on võimalik kasutada lambda funksioonist väljas pole kisteerivad juba olemas olevad loogilsi workflowed samme. Näiteks me saame kasutada kontrolle, kas sisse tulevas sõnumis kasutahini on midagi või kasutaja, mingisugune mehta anneda mireg muud. Et siin on üks näide, et me saame teha sisse tulevas sõnmuse peal käib kõigeva lambda funksiooni, mis kontrollid näiteks, kas kasutaja anned on korrekt, sest kas selle kasutajaks sisteerivanne panist. Meil on võimalik selle kontrolli jäljel otsustada, et kui see kontroll on korrekte, siis minna siia teese, kui see kontroll ei ole korrekte, siis minna siia. Me saame kehitada pilve tasemel sellised work flowsid, kus see esimene kontroll on lambda funksioon, teine kontroll on Amazon Step funksioonida loogika ja siis panna siia selline eksisteeni plot, mis paned dokumenti, mis valiteerik kaasa tulid jäistu dokumenti, taelame tibia annemasa, ja saada viimeilid ja siis välja väljub. Ja kui selle kontroll ei ole korrekt, me siis saadame sns sanumid puugi, et viimeilime ei õnestu näite saada ja siis väljume sellest kontrollist, et kuna kasutaja annepaad, siis viimeil ei ole, siis me ei õnestu viimeil saada, et me tekitame uue sünguse ja kui kasutale on viimeil ja tema info on korrekt, siis me paneme annepaadis selle info ja saadame viimeil kasutale. Ja mis on sinu uvitav, et ainult esimene lampefunksioon üleajateiselt on loogiliselt samud, mis toimuvad Amazoni sees ja see ei maksa meile mitte midagi. Selline kontroll, et me jooksutame seda kontrolli, sellest me ei maksa, me maksame näite sellest, et me tainamust hoiame rotke mandreid, me maksame selle lampefunksioone kävitamisees ja meie võib-olla maksame viimeilis saadmisees, aga me saame niimoodi automatiseerida tegevusi pilves, et kui sisse tuleb mingis ümlus, mida selle sünguse pohta teha, et ilma, et me pääksime pea aegad tarkvarra ehitama, et kõik need asjad on parasamaa presteerilad, tarkvarra blockid me saame siis väljakutsuda ja võib-olla teatud asjad on kasutamistidis inkrementeerima, pyytanud või ei alastud funktionina, aga me saame pilves toimuvad tegevusi, mis toimuvad mingis ümlusa peale, siis nämne AVStep funksioonidega automatiseerida. Mul on üks pakka tude, päris hitved aast tagasi, kes ehitas asutusele kogu krediit, checkimise, mörkflow, siis ASURE, STEP funksioonidena niimoodi, et kui kasutajal päreidulad sisse, siis lambda funksioonid küsivad info tereinaates Eesti liigi registritest ja mingisugusteste teiste bankade registritest ja osustavad selle põhjal, kas anda krediiti või mitte. 8 on kindi, nagu nal oli asutuse kogu bisnetslogika eksisteeriski nende AVStep funksioonidega tõlise workflow-na. 8 oli ka teene probleeme, et workflow läks nii suureks, et need ei saanudki korralikult AA4 formadis lõpudöös korralikult visuaaliseerida. Aga põhjalist on võimalik, misseks logikat hakkab tehtama STEP funksioonideta tasemel ja ainult teatud asju peab koteerima, konkreetselt kutsustest ja teatud logikamide ei saa lihtsalt tasemide. Aga päris palju, kuidas ningist teenuseks midagi võrta, kuidas ningist teenuseks midagi panna, kui ta siin meil ei saata, nendeleks meil ei pärisid koodi kirjutama võid saama eksisteerioid logikasutama. Siin on ka näite, et kui te klikkite mõne peal, et siin on mis store account distribution in dynamotivite, saate ka tehtineerida, mis olevat stations kuttu, mis andra palju paljase, mis on parameetlis, mis mõeldes endustations ja mis on see järgkunele, et kui tehtineerid, et kui järgkunele staatsuse tuu isselgitse workflow stepida lähedne edas, saab niimoodi karameerida, et me põhjast konfigureerime, et mis just. Siin on näite, et on võimalik ka visualiseerida varasemaid väljakutuseid, et kui meil on seama workflow juba üks kas väljakutus, et me saame visualiseerida, et mis ta teatud klendi sisendi pool tegi ja vaadata, et mis oli meil klendi almed, kui see workflow käivitus üks kord, et siin on säite, kus ta on käivitud, et visi marga riita pealast, et mis sa teid need almed igas sammustad minna ja deepakime saada näiteks logitele ja vaadata, et mis need sammud olid selle käivitud ühele. Võib-olla seda käivitud ühele tuhandel kordi päevas ja siis vajalik on vaadata, et kui te roolid suhtiselt, mikse nad juhtusid, kas midagi tegis või mitte. Ma võimalik keerulisemad asju, et defineerid, et näiteks meil on mingisugune konkreetel chase on ja meil on tähtis, et see chase on niikuks läbi erinevades labra-funktioonidest ja straatise lõpuks või sellel ajal, et sühtli lõpuks peaks kõik mindist vahepeaselt tegevaks, et olema truud, et ta oleks suksess, kui ei ole, siis järeikud midagi failis ja peama või põpe uuest läbi tegemaas. Et on võimalik, et staati meed jääbda niimoodi funktionid vahel, et funktsioonid ise on statelessid, aga me anname edasi nüüd chase-onid, kus chase-onid seetakse meed, mis oli teimselt samud ja näide tulemusev, et me saame sellist ratkust stateful operatsioone teha, et niimoodi funktsioonid käivitadakse, et jäedas järgistav funktionid, et on võimalik, et funktsioone siis sühtlist chainida jadana, et jääks käivitada jätkselt neli-operatsioone. Ja siin on veel üks näide, kus on rohkem lambda-funktioone, mida välja kutsutakse nende workflow see, et näideks customer-info küsimine, sinna küsimine, kui mõnevad lähevad õnnelikult läbi, sest ta läheb alles järgmisevse staatuseks, kus on ningisuguse maksmisevse tõetamine. Ja kui maks on, et töötame ja läks õnnelikult ägastud, siis läheb selleteljumuse töötuseks, kui maks on ei näed läbi, siis saavad, et sa võib pala kasutada SMS-et, maks ei näed läbi, et mine poohu uud. Ja siis siin on nelisammu, kus me olemme implementeerinud sellise funktsioonid, aga nagu näite funktsioonide vaheise viikumise logid, et näite siimeli saamise saab, mis saame väljas pala funktsioone defineerida, et saab sellised keerukamad loog, et peame defineerida. Aga see on siis näite Amazonis, kui me sooviksime näiteks vabavaralist nanoteenuste platform ülesseada, siis üks võimalus on open listi kasutamine, mis on IBMi poolt nagu algatud, aga ta on Apache, vabatarkvara open source teenus, et teie saad seda oma serveltepeal ülesseada. Kahe üks on paljidel platformitel ka avatud tarkvara limitatsioonid, et ei kruugi olla kõik funktsioonaalsuseid avatud tarkvara kaasas, et mõnikord on avatud tarkvara alka sellise premium licensid, et te teate teatud funktsioonaalsuseid isa maksma. Ja ma olen märgand, et open fahsin näiteks, mis on teine nanoteenuste platform sellised limitatsioonid on, et kaheks ei saa alati eeltada, et vabatarkvara on täiesti vaba või täiesti talvata. Aga open list pooltat peab kõikki programeeniks teeli ja see on ka täiesti tavalne, sest tegelikult saab tihti võimalutavalt teile ja tegelti tegevõii funktsioonid panna docker container sisse ja defineerida mingi käesu, mida käisid otsi docker container sisse, ja tegelikult docker container sisse saab te panna suvalis programeenis teele, keskkonna, runtimei. Et tegelikult selleputtu ei ole programeenis teele, et tänapäeval enam väga limiteerikud nii mikro-teenuste kui nanoteenuste platformette puhul. Ja see näeb välja umbes selline, et meil peavad vabat, avad su tarkvara puhul, kui me paneme teenuste üles oma serveritesse, me peame olema võimelesed kuulama süllmus, olgu need siis annebasi kirjate, et uued kirjatekiad annebasi olgusesid, sisse tulevad mbtt või rabitent kui sõnumite, kuulame, et mingisugused teenuste pead eksisteelime, kes need süllmusi tekitavad. Neid tehakse siis Apache OpenMisc'i sellist, kuidas sa eestikere sest üheldad, sellist fiigida, kus me paneme üles tarkvara näed, mis oska rabitent piud järjekorda puulata ja tekitada meile OpenMisc'i tüüpi süllmuseid, mis annavad edas teatud struktuuriga chaseani. Aga need saab siis töölepana näiseks rabitentiu kohta, postres kohta, mingi pilve teenuste kohta või e-mailide kohta, et iga tuetatud süllmuse kohta saab ülespana sellise väikse teenuste, mis kuulab seda tõetud ühti süllmuseid, ja kui sinna tekist, midagi siis saadavad openMisc'i edasi süllmuse. Funksioonipuul me defineerime trigenid, et kuna funksiooni käimitada, iga erineva funksioonikohta saame aga defineerida reeglid, et kui pildi suurus on näiteks suurem kümme megapaitiks, käivitad see, kui süllmuseid ütval see ja mingi sekkone temperatuurivärkus on suurem puus, siis käivitateks see teene funksioon või kolmante korva käiviteks konnast funksioon, ja need funksioon on võimalik nagu ükst esi äral defineerid, et käivitateks sellise chaseani, et funksioon A käivitab siis, kui funksioon B on tööl õpetandu, ja funksioon B käivitab siis, kui funksioon C on õpetandu, et see on nagu selleks C,B,H funksioonil käib. Funksioonid ise võivad seda kutsuda mingist kolmanta osapolekeerused, et anna kaasimteid panna või file-i, süsteemiku, midagi kirutuda või nüüd. Kuidas see siseliselt on umbasiklemeteeritud, meil eksisteeleks selline ngenics reverse proxy, mis kuulab sisse tulevad näiteks HBP-päringuid ja näiteks, mis põhimõtteliselt defineerib selled, kuidas funksioon väljakutsutakse. Kui me tekib siin nagu trikke, siis me implementeerime kui seda funksiooni, aga meil on vaja, et kuidas seda funksioon nagu füüsist väljakutsud. Mida me saaksin teha, et käsurida kasutavad funksiooni väljakutsuda, aga põhimõtteliselt ta open list teeb, et ta paned siin vajal HBP-r5, et funksioone, peras seda on otsustatud, et on süngus, mille tõhjaal teaks funksiooni väljakutsuma, siis saavad hapete peab pärinud. Ja see hapete peab pärinku kuulamiseks on selline ngenics kontroller, mis on siis vastutav kõikide sisse tulevad funksioonide väljakutsat eest. Selle eest on selline open list kontroller, mis otsustab, et kuidas vastata sisse tulevatele hapete peab pärinku teha, mis on siis funksiooni väljakutsa. Kõik väljakutsad lähevad kahk ka teadud järe korda, aga neid puferletakse siin. Ja funksioonid ise töötavad sellises tokke keskkondades, niimoodi, et funksioon näiteks meie Swifties implementeeritudse action või node.js is tefineeritud funksiooni väljakutse, see on siis tocker as node.js tocker images ja funksioon ise näiteks see jaoskirt paimise väljakutsiseks. Ja see platform siis otsustab, millim suge sellised funksioonu olinta nagu elus, et kui funksioonil ühtikö väljakutsa te ole, siis ta saav näid konteeerid kinni panna ja kui sisse tuleb uus päring siel tööleta järe korda, ta peab seda töötle makama, sisse ta panem selle konteeerid uusti tööle, et see huppalist on võimaline, et on teeneerid nagu seisuma panema käima, panema nulli staleerineid meie edas, et nõid funksioonikonteeerid ei peab hoidma, neid võib hoida elus näiteks alles ainult siis, kui reaset on väljakutsaid funksioonil peab. Aga tocker pakub siis hea keskkondad, kuidas teha custom keskkonna igalat funksioonil. Funksioonid käibitamise järe, nad ei taakaan, et nagi vasta otsa, teed, et järjekorram vastust, nad kirjutad vastus annepaasi, võimest, et Compresssation annepaasi, kõik funksiooni väljakutsad, siis edastakse lihtsalt annepaasi ja kontroller, kui on sukrone väljakutsed, et see leid oodab vastust aata, et see kuulab, vaatav annepaasi, kas vastus on kohale ja tagastab selle, või siis, kui tuleb hilisev ketpärin, ket ma soovin nüüd funksioonitulemusi vaadata, et siis ta vaatab, kes annepaasi nii kohale ja ne vastab selle. See on suhtselt peerulline arhitektuur, aga pilves on umbes aamuodelt reaset ikkagi tehaks mindisust konteinerid, aga see erinevus mikro- ja nanoteinosta vahel on see, et konteinerid ei pea kohagi jooksmas hoidma, et neid saab kinni, panab ühtegi sisse tulevad funksiooni väljakutsed või üksiküks ümmus, ei olemas is vajaks sile funksiooni väljakutsed. Ja siin on üks keerulisem näide, et kui meil näid, et see on mindisugune kasutaleidese back-end, et kui meil näid, et see on mindisugune kasutaleidese back-end, siis see jooksab kasutaja brousseris, ehk kasutaja käibitab siiava script funksioone, mis asuvad kasutajendakauseris ja me saame defineerida näiteks, et see on mindisina HTML vorm, et kui HTML vorm ei pideks vajutukse, siis saadetakse väljakutse funksiooni põns HTTB Flickr-ele, aga siin on näide, et kasutavad see webhook triggerit, et siis tui siin lupu vajutukse, kutsutatse funksiooni trigger-välja, mis sa poeva stress standpoint või sloper visti serveris ja kõik järgnevad funksionaalised või selle saakalise on, on mindisugune funksioonite seelimise stiivis, et kui jooksab see jahvalt funksiooniste järgis, kutsutatse välja non-jailest funksiooni ja siis kui on teise pangra tegus, kutsutatse välja teise pangra teise funksiooni ja kui on vaja mingisugust näiteks anmebaasi, anmebaasi suhjadest, et jooksatudse välja mingisuguse anmebaasi tähad funksioonist. Ja vahepeal kõib lõu kasutatakse ka sellist eraldi SunStream jooket, opole päris timpel, kuna see märg ei puudu. Aga see on eraldi funksioon ka, mis tegeled, nagu versiiltide või siis tsekide kireneerimusega, et see on midagi ostatud. Ja siis salvestatakse minna hajost, et hiljem saab hard to do, go to, üle webis vaadata neid tsekkeid, andasest kas tege, tsekki link tagasi, kui te sellel mingi valata. Siin on üks funksioon, siin on üks annafunksioon, siin on üks annafunksioon, siin on üks annafunksioon. Või ole, saab funksioon väegi juurde, siis see mõe paketa anmebaasi, või siis see on mingisugune mikropenus. Et see on just annavoid. Asure funksioonid on siis midagi, mida me praktikumis kasutame. Väga sarnas, et siis Amazon lambda, aga Asure annab kasutale rohkem nähtevust, et mis teaselt toimub backpendis, et kas teie funksioon on tõesti päris. Serverlessed seal jooksad ühtegi konteeleer taga või te tekite te te oleid reaalise backpendi, et meil on kogu aeg nii konteeleer jooksmas, mis vastavad selleliga maksalt erinava modeliga. Saab ka funksiooni pisevalt pidevalt jooksma jäta ilma, et funksiooni muutmat, et siis on võimalus optimeerida, et kas funksioon on teed. Serverlessed seal stilis jookseb, et te maksalt iga käibitamiseest, või siis te jätate konteeleer jooksma, et maksalt konteeleer jooksma saaja, et ta on 240 jooksev, ei helle, et maksalt. Asures on võimalik paremi, nagu hallast, et ta reaalt kogu aeg maksalt pisevalt jookseviseest, et siis aina käibitamiseid. Aga on võimalik erinevalt triggered kasutada. Meie kasutame Asura Tile Storage blow-off triggered, et uus paili üleslaiteks, et siis teie funksioon fakturid mis käibitud, aga võimalik näiteks kosmoskiibid kasutada, et kui CSL arme baasi uus dokument üleslaiteks, et see on põhjad muudetakse, reep kukkide, et või tiksalt LESparend saadatakse, või event-crete, või event-hard-lose sõrum saadatakse, et nagu sõnum järgurid uus sõnum tuleb näiteks sii jõutas ja jääbma sensoreid, et siis on võimalikks funksioone käibitud. Või väga livitatsiooni ei ole, kui pealmuse toetat, keelt on C-sharp, F-sharp, jalost püüpt, jalost püüpt, nagu PowerShell kaudu, midis käsurja käsub käibitud, mis omakorda mingi teise programmiga käibitud, võib-alist käsurja meedlade kaudus uvalist, meedlade kaudust käibitud. Ja, ja sinna on üks väike selline lihtne näite, et kui me tuleb sisse näiteks võib-alist mingisugune rest request, siis on võimalikse suunata edasi tööd teadete järjekorda ja panne at asore ja funksioonist teadete järjekorda kuulama ja siis saadma dokument, kui asumast lihtviis, et meil ei peagi selline server kogati juoksma panema sellise teadete järjekorda sinna vahele buffina ja funksioon siis töötab iga korp, kui sa on uusalt teedete järjekordas ja kui neid teateid toutub palju ei ole, siis meil ei peagi ole minikontainer, mis koha kuula appi teenuse, sisse tulad appi teenuse päringud, seda saad kasut, siis kui näiteks päevas, püstu tuhald korva saadateks sõnum ja meil ei ole vaja kogu aeg kuulata ja me ei taha maksta kogad juoksma teenuseid. Või siis asjad interneted, kui mingit sensorid saadavad asure IoT teenuses sõnumeid ja me tagame mingit funksionaalsest väljakutsuda ainult siis, kui näiteks temperatuurivärtsis on suure kui 80 ja me ei taha kogad juoksmas hoida mingit teelust, mis kuula kõiki sisse tulad sõnumeid, vaid me defineerime asuret asemalsele preconditioni, et kui JSON-eis ole temperatuurivärtsis on suuremalt 80, siis käivitateks sa see funksioon. Siin on te defineeritud Logic Appsid, kus Logic Apps on midegi samasteb funksioonidele Amazonis, et siin seeis on funksioon, mis otsustab, kas kuulataas, kutsuda välja Logic Appi ja Logic App on siis tehnologika, et mis on need teadud tegevõist, mis me teeme näiteks, kas saada SMS, kas saada testoopis sõna või push notification näiteks ja viis. Siin kutsukates välja sendeski ja sendeski tehaks südmuse, et mine kontrolli sensori, et sensori temperatuur on liiga kõrge, et keegi peaks jääseb minema ja mingisugune tööline saab oma sendeski tegevuse, et peaks sensori kontrolliima minema. Siin saab kõik teedlain pana näiteks, et peaks mingis tunni jooksud sinna minema. Ja siis selle elis on see, et me ei pea tegida midagi sellist reausti track endust, mis kogu aeg kuulab meid IoT sõnumeid, me ei vaid saame pilvet asemel defineerida see loogike, kuna meie funksiooni tägitab, see funksiooni see saame custom loogike diplometeerida, ja Logic Appi, kes on me välja kutsuda teadada teise teinuseid näiteks sendeski sõnume saab mene, kuna Logic Appi saanaga sellel, sendeski prok olemas ja meie peab ainult defineerida, mis oleks isendida. Meie funksioon ei pea ütleb, et teere on püütanud, et kuidas sendeski mingis väreid, et saab teadad uus sendeski töö tegitada, või et me saame välja kutsuda Logic Appi, et nagu tegimus eksisteerivad sellised workflow steelist loogid, et kuidas sendeski mingi tuud hirja teha, kuidas Skype uus sõnum seada, saab ta kuidas Slack uus sõnum panna nii edasi, et on selline Amazon Step Functions arane teenud, põhimust ongi põhimust sama teenud. Nano teenuste sellised teamise teelis, et on hästi lihtne on funksioonne skaleerida, sest ei pea ise nagu nendest valda oma, et platform ise otsustab, ku palju konteinerid tahts juoksma ja teie maksata ainult nende käivitamise. Prototypin on kastikine, kuna saate pilves koodi kirutada ja koha proovida seda ja ei pea isegi nagu koodi kuskil pilve üleslaadima või kitti panema, ja reeds, et saaks koha pilvessa teha kui hea ei ole, et ainult pilvesta oidadest erinealt koodi versioonid võib koduma mingi. Lihtne modifitsi on ümberdesigelda funktion, et saab ühe funksiooni kaup parenduda. Üks elis on see, et me ei enam ei maksa aja eest mida ei kasutata või öösele ühtegi sõnumid ei ole, sest me ei maksada. Me ei pea isegi olnud, kas me panema lihtto olema siin seisma, kas ma panema korteene seisma, et kui funksioon ei ole, siis me sellest ei maksa. Ja saab kombineerida kurga väiksemaid funktioned tekitasest loogilisi rakenduse pilves. Täiesti pilve poistete teenustaned on tõukselopti pilves, mitte konteenerit ja mitte servete saels. Ja sellest ühtunad on defineeritud aga serveles teenustana, kui reaaliselt füüsiliselt ta peab servetiohkma, ja ka ta tohus kõik käibitu, nii et reaaliselt pilvesemist pakku ja peab servetise teogita. Peamiselt puudused on see, et on raskem vältida platforms sõttumatust, kui teie designerida mingisuguse asutuse, business process ja Amazon step-funktioonidena, siis seda on väga raske, nagu ümber progameerid, et te peate põhimiselt mitte külb nullis seda tegema, aga kõik integraatsioonid, kus oleksisterivad neid kuskund vabavalastis platformtise prüukiol. Õnneks Amazon lamda jaoks eksisterib open lamda nii, et saad täpselt sama funktionid samade sisenid ja väljul tüutte triggeritega külama servetes ülesseada, aga tahaks, et Amazon step-funktioonidest asure logic appsid ja peale minna siis tõnskõite suurem osa ümber designimad. Võib-olla oleks parem defineerida sellised asjad, aga kuberneteses ka tuhedab k-native functions või keda funksioon, et saate, kui põnedse see sees sarvast asjadega. Rastgeva monitorida ja aru saada, mis toimub servelase puhul, sest monitorime tihti on kõvasti raskem ja ei ole enam selg, et miks funksiooni käibikund, sest väga palju on asju logide sees, kata teie ei näed. Väga palju probleeme võib tekita servelas raamistiku enda logide sees ja teile ei toki tõlsse nähtavad olla, et miks? Miks võitis alajaga enne, kui funksioon käibitus. Te ei tea, ku kaua oodati enne, kui mingisem konteeleer ülespaati, kus pandi teie funksioon käibitus ja väga palju asja võib lehtsalt veidatud jääda, kuna need toimuvad. Mitte enam mingist stopkered konteeleerist, kus teie saada asures minna ja eses aga sisse vaadub, mis konteeleeres juhtub, siis näedelise konteeleerid see teie liik ei kõik muid pääse. Eriti amasaris asures te võite liikki pääsada, kui te valite sellest tidi, kus konteeleerid juoks seal taustad. Rakeidus teheitamine on juba keerukas, kui teile on mingi sada serveles funksioonimist järjest käibituvad ja väga keerulis rakeidus teheitada. Ja küll käitis võikki olla probleemen, mis juhtub siis, kui ööselt või omikul tuleb esimene sõlum, ühti konteeleerid juokse, kime teinud pakku ja käab teile konteeleer looma, alles siis, sunnatakse teie funksiooni käibidus ennäidasi, kaua võtab aegad konteeleerid üles jada. Et see olukord, kus me midagi oia taustal juoksmas, tekitab olukord, kus esimised käibidusad võib väga kaua aega võtta. Võib juhtuda, et kui te näest ajab riitiline tööselt omikul esimene sündmuseks koha ära töödeltud, kui te nii selleks seetmed temperatuur on kõrgem kui krasjokraadeks, kohedast kelle ei saadma, siis võib võtta kovasti rohkem aega, kuni see anned saavad tegelikult töödeltud. Selle vastu ainab, et te maksate rohkem, vajate ühe konteeleeride töös saada asures. Näiteks valitendale kaili-liima teenusne, mis garanterib selle iga funksiooni aastale mähem tüks konteeleer alles. Aga lõpude lõpuks siis sama mood, kui teha mikro teenuse või virtuaalmasine ülepanna. Kulusid on väga väga rastine ennustada. Kui teie funksioon mingil põhjusel hakkab kaks korra aega saada tooksma, maksate kaks korra rohkem. Kui teie klientid saadavad 10x rohkem pärin kõik mingil põhjusel, maksate 10x rohkem. Näiteks stritteris juhtus, kui elonvõttis stritteri üle ja nad hakkasid mingil mikro teenus teemal, juhtus see, et kasutaja javascript rakendustes, mis oli juoks teie browserites, ei saadud enam ühele teenusele ligi ja javascript browserites hakkas lihtsalt refreshima iga ühe sepelt aga stritterist maha. Iga kasutaja hakkas olema nagu tennaal servispot, võimest aga igas browseris hakkab lihtsalt spammi ma stritterit. Kas ma saan teenusligi, kas ma saan teenusligi, kas ma saan teenusligi ja põhjumest kogu teeterlalt maha sellate tõttu, et mingil teenusele te maha ja kui endi javascript rakendustes oli, et kontroli uuesti ja mingil sellest bräkingbox ei olnud, mis kontrolli kindi panaks. Ja mikro teenused võib selle tõttu olla palju palju kaljima. On tehtud uurintud, et kuidel on tavaselt töötama appi, mis kaljuta näks 10% konteeeneri või virtuaalmasine jõudlusest kestmiselt ära, ja kuidel teete selle ümber nanoteenuste põhjiseks, et ta kogu ööpäev on töös ja 10% CP-uuskandustab ära, siis sama asja ümber tegemiseks nanoteenuste peale oleb olla väljamud kaks korda kaljuma. Põhjist ei olegi mõned teha midagi nanoteenustena, kui ningu niinad sa peate midagi oks mehattma, et sellise liul võiks ikka teha mikro teenuste või virtuaalmasine tõne, et võib-pallel lahkene inna, mis ei ole, et asu mingi põhjendad vära, et rakendust peaks olema vähevalt 50% ajast aidul, et oleks kasu sellest, et on designistet nanoteenustena. Ja isegi siis ei ole mingit karatiid, et on oda. Nanoteenuste designistelisest rakendustelisest võib olla palju kaljivad, kui nad kogu aeg pajaavad funtsiooni käivitane. Kui te ei saa suurt kasu sellest, et te panete ikka natukus ajan tagant containeri kinni, kui sellist mustrit ei ole, siis tõenest te on, et võib juhtuda, et teie mikro teenuste või virtuaalmasinena sama rakenduse designi minu oleks tegelt oda. Igen sellist asjad, mis juhtuvad näiteks päevas 10x, 100x, 1000x võib-e liseb 10 000x, mingite pilti töötlaste võib-e lau 1000x päevas, 10x päevas võib-e lauks parem seda pilti töötlusena, teha siis nanoteenustena funksioonina, aga kui ta peate pidevalt iga minut on sünnmusi kogu ööpava juoksul, siis ei ole mõted, seda ka nanoteenustena teha. Päris paljud näitad, mis defineerid, et teeme appi ja elitame appi, need nagu sellist nanoteenustena, et nendest väga suurta mõtetust ei ole. Piga sellist asjad, mis reaasad on ka, eventi toisid juhtuvad mõnikord tunnijooksul, mõnikord minutjooksul, ja te näete, et teid ei tahaks virtuaalmasinate konteine, et kogu ajad juoks mus hoidas, aga tegevus teha, et siis on näidest kasu. Aga sa võtakse järjekordast asjad töödlapäeera, et see on üle, et see on kindi? Jah, aga kes on see, kes paljab selle konteeere käima uuesti järjekorda? Kui sa saa defineerid, et Scron tööta täitsed ööseltil kaks, tööta üks kordi peale kindi, siis jah sellist asjad nii olla päris. Aga kui sa ei tea, kunas sa sünnmusi juhtub, et sulle tuleb näiteks tööde järjekorda tulebu uus sanum, ja siis sa tahaks, et keegi seda koha ära töödleks ja siis kindi läheks. Et sellised asju on raske, nagu ise automatiseerida ja sellist asjadeoks on misse mõetud. Ja kuberneetises saab defineerida ka, et mul on mikrotenus. Kuberneetises on lubatuda 0 listkaleeride, et tõl puola 0 röpikat. Ja kasutada sellist tarkvaraga, ma ei nüüd ei mäletu, kums oli, kes keda või peinäiti, mis defineerib, et kui tuleb rabiti järjekorda sõnum, kui nende sõnumid arvan suuremkui 5, siis scaleerib mikrotenus ühe peale ja see mikrotenus ises ühendub sinna järjekorda, hakkab seda sõnumid töötlama ja kui tead, et järjekorros on tead, et arv 0, siis keda või keneetimine on õigus, konteeleer uuesti 0 listkaleeride. Sellist asjad, mis on defineerida kuberneetises. Et keda ja keneetim on samuti põimastud selline maksionasaserviisusraamistikud kuberneetis. Ja põimastud selliste mustrit jaoks ongi mõnedud, et kui sa ise ei oska, nagu ette arvata, kunas se sinnmuk jõutub, et näiteks tuleb alarme, kii saadad mingiduse ästi suure prioriteetiga send eski mingisõnumid sõnumi ja sa taadad kohes ära töödandeks just selliste sinnmust jaoks, mida sa ei saanud ette, nagu ennustada, kuna neid jõutub. Ma olen üksingamõeld, et näiteks ükskord tungi särkab teenus üles, vaatab, kas on midagi, ja kui oles läheb magama, tegis sellist, et kromni ka pannada, kontrolli nii ka natus sadaga. Aga siis võib-olla meil, kui paljem ta liiga kisti tööle, läheb ka palju maks, ma vii kasutada palju resursse, nii et pigem, et see, kui sa tõesti tahad, et mingi sünnmuse peale midagi käibiduks, mis näide mustrit jaoks on mõõdedne nagu teenuseks rohkem nagu kui mikro teenuseks. Aga see ei ole sünnmuse vai siit teie oks, et mis seda sõitlust toaltab? Jah, aga siis sa koondata kokku nagu üheks teenuseks, et sul on nagu kogu sinu asutus ja klastri peale nagu üks teenus, mis erinade tüüpi sünnmuse kuulab, ja siis otsustokas mitte käidita mitte. Et paljadki ühe open viskii nagu servere üles, ja siis tema otsustab, mis funktione kuna käib. Jah, sul peab olema mingi teenus, mis näite sünnmuse kuulad, aga nagu pilves on ta siis üks keskne teenus või üks keskne teenus iga tüüpi sünnmuse jaoks, ja siis kui peal näite, siis sa on nagu üks, mingis see on teda või geen eeti konteiner, mis on vastutav, sellest, et tema kuulab kõikki sünnmusi, kelle tema sa konfigureerid, et mis sünnmuste peal asa, mida tahad käilitada, et siis longi nagu üks konteineri otsad, mis need aetsa teeb, ja tema on siis see vastutav proces siis otsustav, et kuna funktione käib, kui kuna mitte. Nanoteenuste mõnesed on see nagu loog, nii jätku mikrodelast väiksemat, et see on vajalik või mitte, kas on optimaalnev mitte, kas on oda mitte, on täiesti erenev isk, siis sa võimalda peal väiksema, et selled, et hästi väiksev funktioni tasemel teenuseid pilve teenuste nagu tekitada, ehitada, ja teenuste on nagu mõnesed väiksemat või mikrodelast. Ja sünnmuste põhine käivitamine, siis võib olla oda, kui pidevad vingisuse konteineri või virtuaalmasine tahad juoksmine, ja seda tulebki nagu otsustada, et kui kudagi hinnat, et kumb on oda lomb, kumb kasutab pähemressuussa näiteks teie kuberneetist vastrist, kui kumb läheb pilves vähem maksma. Teatud olukordas võib olla lihtsalt mugavam, et lambda funksioone defineeride pilves, selle asem, et ise ei oksutada püsi palju konteinerid või virtuaalmasineid, aga tõenast läheb see päris palju maksmasuidel on lambda funksioonid, mis palju mõelu kasutab peale aeg kasutab. Mikro ja rano teenuseid võib arvistada pidevad tarjadust, et me saame CSCB pipeline'ides näiteks panna ajutiselt konteineri tööle või käivitada lambda funksioonid. Me saaksime näiteks mingisubliselt tegevuseid lambda funksioonid defineerida, ja siis CSCB pipeline'id kutsuor välja nende lambda funksioone triggereid, olguks see läks nii krestpärin või siis opis mingisubliselt sõnumisead mõne järekorda, et me saaksime näiteks idea hoidma mugid konteinerid elus, mis kogu aeg asju teevataid. Me ei taanud käiviteks siis näites kus nerds ja questulii või uus kommentuni. Mida on praktikumist teeme siis see kord? Te olete varasemalt teinud, et front-tendid, te olete appid, jõgavad kaheks konteineriks, ja meil see vasak poolne põhjimuselt juba existeeli. Me oleme ka salmestanud file asujut lot storidzisse, ja see nano teinudselt teeme on see, mis hakkab poolnud asujut, et kui siia tegid uus file, siis ta tõmbab selle file'is valmis talal, et me saaksime argumentina, et aga me oleme teelik textfaili pdf'is ja laevad üles pdf'i takasiv asujut lot storidzisse. Tulevikus on meil võimalik siis raamatu teksti, failina tagastamise odenud tagastus ja taga pdf-failina. Me meele ei tee muudatuseid, meie vakkanus hakkaks toetama ketraamatu slash id, kus on pdf'ina tõmataks, aga võib-olla võib tulevikus liidama, kes selle takase sinna ja veebilehtega. Aga põhjemist, et iga kord võib meie raamatud taludus appi uus raamat tekitada, siis nüüd on meil pärime teksti-failid pdf'it valda maatsud. See ei ole põhjame 50. kohe täha, sest me saaksime tegelikult ka siin sellest metodis, et me laev üles nii textfaili kui ka pdf'i, aga ta liikumi hea 50. saata harjutada sellist nanokultioonid loomist asures ja me teeme see siis klatsikumis jännabalt. Ja tulevikus me teeme veel mõned muudatused ja paneme ta täiesti pilvepõeise rakendusele tõrne, aga pärast seda nanofuksioonil liigamisten, nagu loogik osam, kea ka kõik ära imponenteeritest. Võib-olla teeme par muudatust veel, mõned meetodid või muudatud meetodid saaks ka pdf'aile vaadata ja üks, see on huvitavad, küll on see, et praegu meie tehtudad meil mõlemad raamatud apid isesuttavad annapasina, tegevõib-olla see parem teha, et see raamatud otsivap ei suhti annaparid otsa, või tõlma praamatud allasest raamatud metodid asest meie teised apid teised hapist. Meil ei oleks kahte apid mikro tehas, mis annapasimus uhtavad, et võib-olla see loogik oleks antada parem. Aga võib-olla sest liimast kaksist endesa natku pümma. Ja jäärekone loon räägid siis täiesti pilvepulist rakjandust, apitektuuridest, kus jään enda omadust oest, võib-olla see toodal natukasele pilve teema kokku. Kas on küsimusi? Zoomis ma küsimuspräeme näe. Tänas sais natku varem tehtud. Küsimus ei ole raamatud teisenmisega. Mis põdius oleks raamatud teist? VDF eks põe mää saane teksti teha sisse? See on selleks, et VDF kujuntav võib-olla seda raatata kui paremini. Ta annab meile teata struktuuriga dokumenti, mis ei ole puhas teksti fail. Näiteks mingites VDF e-raamatutel lugeades või-olla ees parem teisimormaati või teksti faili promaati luge. Otseselt on hea kasutus. Ma võib-olla oskord vimtuua. See on kigel näite, milleks nano-fuksoone sinna kasutada. Kuidas sais sinnmuse poist teha. Mitte kogu meid toimub, vaid siisku uus fail toimub, saame ma oma, kuidas see faili, ASRO-Po-failid nüüd kasutada funktioni väljakutaks. Otsesel vajadust, miks kagustajust edistaks VDF-i reaselt ei ole, sest me tegelikult VDF-id generiime suhtelisest taatbilgel. Hea oleks, et tegelikult oleks päris editor, kes korralikult vaataks, kas hea kikkused on korrektiselt ja neid VDF-id eetsikagi korralikult, et see VDF oleks natuke kasulikum, kui paas tehti fail. Siin on ta piges, et see praktik, et me näitän, et kodas see on. Kui sulle enda tuleb pähem, midi ideed, kuidas nano-fuksoone sinna huvital kasutada, siis täku välja ja ma järgmine aastalist. Huvitul on, et kui me hattemellii eraldaks teksti, et me selle ketteb, kui saame paneme hattemellile üle, siis sealt eraldaki teksti. Mis selle hattemelliga tegib, et tegelikult tegist, et VDF ei pole olevame. Jah, et tuleb suhessi, et sa arna, et juba see VDF tuleb natuke na epamugam lugevalt tegstifail. Kuna näitest tegstifaili lugemisel, me saame näiteks läpimist kasutada ise. Aga arknasuurist muut, aga VDFisse väga ei tööta. Teatud VDF luge, aga võib rost, et see parem teha. Aga meil samas ei ole hattemellid failid kasulikult siin, et kui meil olnud... Me saame panne selleks kirja viga teparendus, et meil ongi raamatud, et siide üle. Võib-pall, ja, et see läheb lähemale võib-pall sellest. Võib-pall, saaksime Eesti keeltet öökkida raamatud. Et me saaksime näiteks, ja, teise keeltet öökkida raamatud kasutada mingi pöökkide. Ma mõtlen seda peale, et see järg näha töökk proovida, et meie ülikooli tõhke teinuskatudud aard, mis meil teile teha, Ouliteo. Et muidu muud appid läheb võib-pall natukalt kalliks, aga võib-pall nagu tude, mis saab, appid rajalida teha, et muidu Google tõlgeid või midagi muid kasutaja. Võib-pall jah, tehtimine või sellene igade parandus kui tagi, et parem. Jah, mõte. Suumist ma praegu küsimisei näe. Tänne on siis lõpetave natukalt läks kiiremne kui parasemalt, et ma naptsin võitsin sellist mikrotienastikordamist väeemalt läheb.

---------Loeng 13 - PIlvepiste teenuste mustrid.txt--------

 Tänet tulemast siis eel imasesse loingusse, et see kui rääkime pilvepõhiste rakendust arhitektuuridest, et kui ei me kord rääksime konkreetselt, nagu oleme rääkinud Kubernetesest, oleme rääkinud mikrolinuste põhiste arhitektuuridest, siis natuke näed kombineerime neid kokku ja rääkime täiesti pilvepõhiste rakenduste kontekstis, kus rakendused ongi designitud pilvees ülesseadmiseks. Ja järgmine kord ma siis rääkin sellised kokku, et võtama kogu aine kokku ja kattama kõik teemad ja rääkime natuke selistest kõikki nend kaetud teemade eelistest ja puudustest, ning teine osa järgmise näedaval loingust on eksamikonstituatsioon, kus te saate tulla kohale küsida küsimuse eksamikohta ja mina selgitan, kudas eksam ole makad. Nii et tulge kindlasti järgminevalt ka kohale. Aga rääkime siis pilvepõhiste rakendustest natuke üldiselt, vaatame selliseid keamiseid tegureid pilvepõhiste rakenduste designis. Osa on endest on teieoks tegelikult päris loookiliselt, sest nad on nii palju üle võetud juba täna päevaltes rakendustes, et nad enam ei tundu kidega väga uudselt olevad. Siis rääkime erinevatest pilvepõhiste rakendust mustritest ja ühes peamisest me rääkime selline teenuse mõrk, kus me eemaldame teatud loogika mikro teenuste rakenduste seest ära eraldi tasemale. Ja see on peamaselt kui selline kuberneetsesese speiifiline muster, mida väljas poolt vägem kasutatakse, aga rääkime ka erinevatest omaadustest ja elistest, mida see muster siis pakku. Ja kui teil tegid küsimise, siis küsige suulid viisilas zoomit chatis ka. See teema võib olla natuke kasjust keeruline, aga võib raskeest huomata, kui te ei ole ise nende teematega väga tutta varasamad. Mida siis pilvepõhine, et see tähendab, hingest, kelles on see Cloud Native ja võib-al see ongi natuke kirjaltavam kui eestikenne term pilvepõhine, see tähendab, et rakendused ongi designidud pilve jaoks või pilves ülesseaduseks. Nii ole designidud rakendust, mida oma serverite peal võib ülesseada võib. Vähemalt vajaab selle vahedavselt pilveplatsformi ja tihsti selleks vahedavselt Priva Killer platformiks tegelikult võib olla Kubernetes, mis tähendab seda, et teie saab ikkagi oma serverit, oma klastrite peal ülesseada. Otsuselt ei ole vaja, et oleks avalik pilvetenuspakkone kasure, vaid pigem, et see keskond, kus rakendus ülesseatakse kuhuda deployedakse, on siis pilvepõhine keskond. Kas siis ülesseidadud konteineritele Kubernetes-ale rakendused on pigem mikro-teenustapõhised. Isegi, kui ülesseadda Anne-basi, siis Anne-basi ise töötab pigem mikro-teenustapõhised. Tänab vaatame ka näitas poskres näitele, kuidas selline kõrg käideta või haia või öelapalli poskres välja näed, kui ta ülesseadab pilves või Kubernetes. Üldjuul on eeltused, et me kasutame DevOps ja sellist kiiret rakenduste ülesseadmist ja lanseerimist, et need rakendused on designidud niimoodi, et teha väikselt muudatuse kippis ja rakendus uus version panedse üles automaatselt siis kest testkeskonnas või kusilikin production keskonnas ja muidin seal tise kontrollide, et teha toivam iga merge peale või iga realisi peale, et ei pea iga merge peale automaatselt tööpeale. Ja me ei loo rakenduse liiguselikilve vaid pigene arendamigi rakenduse pilve jaaksul isegi pilves niimoodi näiteks, et meil ei peagi olema endal testkeskonda rakendus koha panaks kui perneete süs ülesest võib-al teises test namespeisis, kui nagu lõpkaduta digi ei täese, aga teie võib-al ei paja oma arendusteskonna oma arvutus. Ja täna algust peale siis rakendust jaaksul, mis on mõeldud pirmais juurult. Me kasutame Cloud Native Computing Foundation'i definitsiooni, et see on üks selliseid community sellised organiseksioone, mis proovib standardiseerida pilve konvisiit rakendusi. Ja nad standardiseerivad väga palju, mis on seotud kuberneetesega, et näiteks, mis peaks olema kuberneetesest toetatud kontainerete piltiformaadi. Selleks on valitud dockerfile pöhine pilve, või mitte pilve, või kontainerete piltide ehitamene, et ei peaks kasutama erinevaid viis, ja kuidas kontainereid ehitada, et pigem paljutik töötab standard. Või töötab viis nagu selleks standardiks, mis oli dockerfileid ja dockerpiltide ehitamene. Selleks organiseksiooni definitsioon pilve põhiste platformadi rakenduste haaks on, et pilve põhisus on Cloud Native Technologies that empower organisations to build and run scalable applications in modern, more dynamic environment, public private or hybrid clouds. Ta on nagu väga konkreetselt ei ütle, mis seal olema peaks, aga isakirjadise kohjal, mis seal samal lehen on, mida te võitte minna juurida, on, et selle lähenemist viise aluseks on just kontainerid, tehnuste võrgub, mis me ka tänna räägime, mikrotenusad tegale või 5-et APIs ja muu selline. Ja idee on, et tehnikat, kui neid rakendud on imoodi nagu on ette nästud, sa võimaldeid kiinni taha nagu vähe oma vahel ranged seotud. Ega komponent on pigem nagu eraldiseise teenus, kui teenus või targvõra, mis otsaselt on seotud või sõltub teisteist teenust, kestegangis pigem mikrotenuste põhised, kui siga rakendus on oma keskkonnast ja ei jookse kokku, kui teised mikrotenuse komponentid teised hajusust kõrni komponent kokku jooksevab. Nad on vastu pidavad, piht isegi iseparanevad, et kui mire juhtu, siis on rakenduse kuberneetes deployment template sisse eidadud, et kuna peaks rakendus restartima, millistele pidevatele, päringutel peab vastama, saaks teda kutsuda terveks teenuseks, et kui ta enam nendele teenuse kanegi pide vasta, siis järeikult ei ole enam terve ja minge ajapärast peaks tala restarti tegemult pood jäält täiest ära kutsutama. Nad on skaleerivad, juhitavad ja jälgitavad, meid on võimalik mende mitte ainult seda kasand on elus, aga ka nende olekud ja tervist on võimalik jälgida, ingliskelesensuobservabilitee, et me on võimaline saada täpselt ülevad, et kui hästid on töötab, mitte ainult seda kasda töötab ja mitte ei ole nii või kapinaarne, kasda töötab ja mitte ei ole tegemaid uutad hästi töötab. Ja me pead olema juhitavad, et meid on võimalik reaal ajas ümber konfigureeride ilma, et kasutavad midagi märkta, et rakendisem ümber konfigureeride, et kasutavad ei toigi saada ja teateid, et mingisugust teenuks teada käette saadevad. Ja kombineerides sellise tilvepolise architektuurid, Cloud Native lähenemise, automatiseerimise, DevOps metodologia või võimalikse sarendatel, hästi minimaalsem aevaga või väitsa väga tõluga läbi viia pidevaid ning ette aemakavama mõjuka muudatusi, et ei oleks seda olukord, et me võtame terve nädalat teema uue riliisi ja loodame, et see riliis läheb tööle. Võib pigem tähtse hästi väikseid, mitukorda päevas muudatusi ja nette hennustatav, et mis nende muudatuste mõju on. Pigem võimalatavad hästi väiliselt muudatus teha, mille mõju on. Mõju on hästi väike ja palju lihtsamene ette hennustata, kui see, et me teeme näitiga iga kuus uue riliisi või iga kuus väli-alaselt. Võib pigem seda teha, et iga arentaja mingisuguse feature muutmise või arentamise tulemus, et kohe teakse live keskompele mõudatused läbi. Kuidas sõelda, see muudatuse ja testimise vahel on võimalikult minimaalne, et vähendada selle ohtu, et samal ajal, kui see arentaja arendas mingisuguse featureid välja, siis teine arentaja arendas teist featureid ja nende vahel on konflikt. Kui need featureide testimise ajad on nii lühimiseks, kui vähemalik, siis on ka väitsema oht, et nende vahel konfliktid tegivad ja midagi väga kaltkuline. Pilve põistarhitektuuride peanmised omapused on, et me enam ei huvitu nii väga operatsioonisisteemidest. Kui me kasutame konteinerid kuba näete sa poode, siis meid väga ei huvita, mis operatsioonisisteemis kuba näete sa server jookseb. Kui me jooksutame asju pilves, siis me jooksutame konteinerid, nano teeluste funktsioonide ja meid väga ei huvitud, aga see töötab Ubuntu, Rocky Linux, Centos või mingis muus keskkonnast, teadest, et see on Windowsis või mida ARM platformi peal. Meid väga rakenduse, designistid oegis väga huvituda, mis operatsioonisisteem tagane. Nad on nagaseliselt operatsioonisisteemi agnostilised, et ta võiks töötab ükslikmist keskkonnast erikõnume konteinerid või kuberneetist kastuma. Me panelme rakenduse tööle õige mahog resursside, et me saame igale konteinerid remelata täpselt nii palju resursse, kui tal vaja on, ja limiteerida, et nad mikrotenuselt ei olegi luba, et näile ei olegi lubatud kasutada rohkem resursse, kui jahast vaja läheb. Me võib-olla ümber konfigureerime näid suhtselt tiltie kiiresti, et näiteks näile lisavad resursse anda, aga ei tekita seda olukorda, kus ühel konteineri mingi põhjusel on võimalik kasuta 250 kord rohkem mälu või ketta ruumi või cpu-ud, mis tõmbab kõik teised teene koomad. Pige igale konteineri ja kuberneete selle rankelt seabistame limiidid, et kui palju mälu või ketta alaja, cpu-ud on lubatud kasutada. Ja kui midagi ei tööta hästi, siis me vaatame logimisest, monitorimisest ja muudamele konfigurationid ümber, nullist alates me paneme väga rankelt paik ka, sest see kaitsad selle vastu, et kui mingit teenused rünnatakse või võeteks ülevõi, nende on väga innelikult mingisuguse bugid, siis ei onnesti kogu sisteemi koomad omata kui mõned mikro teenused üleva, mingapõi resurssega võib. Sen on sisse eidratud DevOps Continuous Delivery pig-er juhutus Eesti lieles. Kõik teenused, kui võimalik vähegi on, ise seisvad, et nad ei sõltu otsaja teistest mikro teenustest, see alati ei ole võimalik, mikro teenust, mis kasutad annebasi on andanpalliselt sõltuuses. Ja kui vähegi võimalik, siis kasutada automaatsis ka leeritamist, et ei looda selle peale, et mingit operaatorid konturis siis iga omid ja iga õhtul muudavad konfiguratsiooni niimoodi, et see onks rohkem replikaid mingitel teenustel. Alati seda ei ole võimalik saavutada eriti annebasi tepugul, aga mõnikult on vaja näiteks annebasi mingisuguseid saavutane, et kui ümber arutada, ku palju partitsioone vats olema vastalt selge, ku palju nõud on ja ei ole alati võimalik rea laehas annebasi, et ka leerit üles ja alakulad võrelikas mikro teenusti. Ja siis olme paasinu ja ka tagi õrst on tehti, et kui sen kirjat ja siis igal kirjal on näiteks ikka nii tees, ja kui teed ergi õrselt ära, siis näiteks kui ma olen vaasime näiteks. Kordi mene niimoodi töötab, aga ühtemad sa soovid kesed päeva nõud kolme nõud ja asjame viit nõudi kasutada ja sa soovid ühe nõudi juurde panne emat. Kui sa sa olemas ola sa ammetega teed, et sa peadks kõik ammet kõik ümber saflima kesed päeva, ku palju kasutada. Selled jõudus probleemid on, et taaks jõudu panna, aga siis sa peadks taga ammet ümber konverteerima ja olema armete mahusse. Kui sa ei saa niimoodi reaaläest teha, et ei saa niimoodi reaaläest teha, et midte ammetabasid aru teava konteineride lisane ematame, nagu millisekundite viimust, aga ammetabasid puhul võib olema sisse heitada, võib olema sisse heitada kotsasid, mis sa teadat. Aga me oleme vaatane kõite posköösi lähendamist täna, kus see ei ole probleem. Aga seal on teatud imikatsioonid, et pikem skaleeri maind lugemist kiirutud, midte niimoodi lugemist ei. Kas sa saast oma andne baasi? Et sul on kiirutud aluks 3. aande baasi, sa tahad skaleerid vii ande ale, et sa siis võtad kinneist 3. aande baasi ja te mõlevad standaist, et 2. noori. See võib olla, et jätsed olukorral sa keib, aga siis sa avutad rempikatsioonid aande lugemiseks, aga mitte kirutamist. Siis sa sa piikagi kirutada ennakorra, aga kirutamise efektiivsus sellest väga ei parane, kui sa ei jaka andmed reasas liidepartikioon. Ma pole 100 % ikintel oma vastusest, aga põhjimõtteliselt jah sa saaksid teha koop, aga see ei ole päris olemas oled ja andmed jagamine viie vahel. Ja ta on tegelikult ka seda, et sa saad paraleeselt ainult kolmest lugeda. Sul on kui valik, et lugeda kahest vee lateratiivselt kahele, aga põhjimist, et sa saa viest paraleliselt lugeda sellise liulikade. See on see põhjimus, et mis typ nii päringud sul on. Kui siin tuleb sisse päringud, mis on hästi paljuded kasutatad, siis tööste saad võib-al nende viie vahel, aga see on suhtsev keerulne halata, et sa osades hoiad teadud hultpartitsioone, siis teistest saad koop, et osadest partitsioonidest sa tegem taaksud, et sul on mindisuguna hultkanneid, sa jõgad andmed partitsioonideks ja siis nendest kõikides partitsioonidest on fikseeritud numper koop. Et siis on palju lihtsam halata, et onks siis Annebaasi plastristus on piisalud Anne vära repriseeritudu mitte, ja siis sul ei ole nii lihtne, et okei, teeme lihtsam koopaid juurdele jämaldame, et see kõik uutab alega. Et teadud Annebaasisüsteemid, siis on see sisse ehitatud, et sa paljad 2000 juurde ja taustal toimub mingi prosess, mis meid replikajad liigutab ja ümverlikutab, ei ütlema, puole tunni perast on see süsteem võimsam. Et sellised süsteemid on paremega kuskil esküell Annebaasisüsteemis, et sa annad see natuke teeroidelt kikki. Ma ei täna korraks vaatalista ühes näkida. Ja ja sinna sisse on pihti ehitatud kõik kiire taastumine, et kui midagi kokku jookseb, siis kui perneetises võiks sa võtta paar sekund suuest ülesseada, plus kui meil on skaleeritevuse ja replikajad teenuks peale, et meil on midu koopad sest teenuks teenuks teoks, mille vahel liiklus jagatakse, siis see pihti tähendab ja seda, et et kui üks replika kokku jookseb, siis ei toeks väga mõjutada teisi. Kui kõik kolm, ütlema, et meil on kolm replikad, meil on hästi peale kasutajad ja kõigi kolme kasutus on suhtselt suur, et ei olnud olnud, et kõigil on nüüd 8% resurssides kasutus. Üks näidest ärakukku, mis tegelikult võib olla suhtselt tuge signaale, et midagi tööta väga hästi, sest kaks replikad peavad nüüd hakkama saama sellega, mida enne kolm replikad ärakasutus 20% oma jõudusest, et näid enam kasutata pärin kõik teelindada, nii et kaks ei kruugi nii hästi hakkama saama kolm. Kui midagi kokku jookseb, siis kohe taastatakse olukord nii kiiresti, kui võimalik. Ja näiteks kubernetest on see sisse eitadud, et kiiresti tuvastada ära, kui midagi kokku jookseb tegse uuest üles jada. Näiteks on health check mid ja liveness check mid poodides sisse eitadud, et tuvastaks ära kas seda, et mida ainult see, et püütan progamb kokku jookseb, aga ta enam ei vasta pärin kõige korrekselt, et ta jookseb, ta töötab, ta kuulab porte, aga midil põhjusest näiteks, et ta oli annu lepas jõhendas enam ei ole. Ta küll võtab vastu pärin kui ta, kui ta ei vasta nendel korrekselt. Kubernetest on nagu mingisuguse mikropeenuse deploymentisse võimalik sisse eitada kontroll, et pärin sellel n-poodi peab vastama koodi ka 201, kui seda ei toimu 5 korda järjest mingisuguse väiksete lei ka sisteemokoodile restarti või seeki teeme näiteks ka mingi annapasipoodil restarti, et saab sisse eitada, et kuidas kontrollidega susteem töötab, et ära tuvastada kuna peab. Ja see ei ole nagu sisse eitada sellega genuisa kontynvoreksioon. Me vaatame ka teatud selliseid tüüppilisi tilvevõise arhitektuurikomponente, millest me veel ainasi ole rääkinud. Ja siis lähme, mul on just slide-i natukavale järe korrad, enne räägime 12. tegurist ja siis vaatame mõndasid tilve teenust arhitektuurikomponente, millest mainele oleme maininud. Peamiselt fokuseerime servicemõhjile teenuse põrkulemte mainitiga selles pilve põhiste rakendustes definitsioonis. Aga ma enne räägiks üle 12 sellist kõige olulisemat tegurid, mis on pilve põhiste rakenduste designimel olulised. Aga ta ei rakkenda ainult pilve põhiste rakenduste, aga sellist hildiselt, tarkkura kui teenuse pilve rakenduste puhul, et mis on sellised parimat tavad, mida peaks kasutama nende arendamisele ja designimisel. Võib kaks teis, ütlevad 12. juba poolet teieoks on tegelikult loogikult, et kui te olete arendusele vähegi tegelinud, siis kõik ei tule teile üllatusele või midagi väga uudselt. Et neid on juba rakendatud aastaid ja nad on siis heitatud kuberneetises desaili, need osaliselt on nad nüüd juba kuberneetises hetta ära inkumenteeritud, nii et arenda ei teene pise selle veel mõrtamaks, aga nad on nagu mõetud arvessa näende pilve põhiste platformide, et kui te soovite rohkem selle kohta lugeda, see on selle trailfactor.net, selle kohta aga kõna räägim natuke ülevaatlikud, et võib-olla väga sudavale ei lähed. Neli esimesed tekurid on koodi paas sõltuludet konfiguratsioonite tubiteenuseks. Koodi paas tähendab seda, et igal rakenduseks olema ainult üks koodi paas. Teid oliks tekid olukord, et meil on mingisõmene mikro telnus, ja siis arenda on oma koodi paas, siis teine arenda, kas liitub, organisaorist, et tema teab oma koodi paasiga oma versiooni sellest, ja siis mingil põhus on näiteks eraldu koodi paasad testkeskkonna kohta, production keskkonna kohta, ja tekid meil olukord, kus meil sama rakenduse kohta on mitu koodi paas. Et seda tulaks väitida, organisaorist peaks olema ainult üks konkreetne koodi paas rakenduse kohta, mis eksisteerid. Ja see peaks olema versioonitud hoitlas kitis kusagi, ja kui meil on vaja erinevaid versioone sellest, siis me saamegi teha erinevat branchid, erinevat rliisid, kui meil on vaja erinevata keskkondade jaoks nüüd väli lasta. Aga me ei tekida testkeskkonna ja production keskkonna kohta eraldi kit repositoori. Ja versioonikontrooli käitik, kuna sa palati juurutada, on sellees tarkvarjamisele koodi paasid asu pitves erinevasse peskkonda, et hoidan näites konfiguratsioonid imod, et meil tekib kokku pandud rliis, mis on mõnedud testkeskkonna jaoks, kus on oma konfiguratsioon testkeskkonna jaoks. Ja me saame selle sissemised tekitada erinevad sellised tervoops pipelineid erinevata keskkondade jaoks. Meil on isegi sama pipeline, mis kõigeval pusid keskkonna testkeskkonda, vaatab, et see tulemas on korrekne ja alle, siis pusid edasi production keskkonda näitud. Aga miks on oluline on selleks, et ei tekiks segadust, et kui arendad töötavad, et mis versiooniga, mis koodi paase, kui nad töötama peavad, ei tekiks selliseks konflikte, et me peame nüüd hakkama nituud koodi paasi merge-ima ilma, et meil oleks ma üks kit keskkon, mille see on sisse ei tega funktionaalistus, et meid muudatis merge-ida ja kokku panna. Teene tekur on rakenduste sõltuused, et iga mikrotenus iga koodi paast peaks konkreetselt eraldama pakendama põrkoma sõltuused hõlmates muudatis kogu sisteemi mõjutamatev. Meil peaks olema oma keskkond, olguse konteiner, olguse virtual environment, olguse mingisugune muu mikrotenuste teised keskkonat tockerist või kui põrneetest eraldi. Siis on vaja, et kõik sõltuksed, mis see rakendust kasutab, on pakendatud selgelt, et ta täiteks ei sõltuks mingitest sõltuvustest, mis keskkonas on, kunagi teine asi installeerid enne seda tarkkure. Kui te näiteks, kunagi arendast H2 maped use mooduleid, siis on tegelikult hästi vastik, et eksisteerid mingi suur repositoorium, kus iga moodul on alam kaustades. Ja alam kaustades olevad, tarpkora installeerimise on vaja teatada asju ülem kaustades, nagu ka installeerida, aga kui te kõik ülem kaustades installeerite, siis asjad laad kahti. Kui te tegivad sellised väga imelikud sõltuvused moodulite vahel suurdes, manollitsetes projektides, et kõige parem on see, et iga mikro teenust saab installeeride täiesti eraldi seisalt. Ei ole vaja, et importida mingisuguse teisi püütan teekke, linuks paketste kui saagid mõjalt repositooriumites kuna tavalselt mõned asjad installeerideks jäik. Pikema on tähtis, et kui mikro pealus on oma koordne paalis, siis kõik väärikud sõltuvused on saa kirjeldad, et isegi siistud, et teate, et tõenalselt sõltuvused on olemas teatud linuks keskkondades. Kujutakete, et teil on mingisugud püütan rakendus, see kasutatav puntu docker image-it selle püütan rakenduse ülesseadmiseks. Puntu docker imageid tulevad kaasa mingisugud teatud linuks käsud või püütani tegid. Te ei pane oma containeri requirements-file, te ei pane oma dockerfile neid kirja, kuna tavalselt oot puntu dockerbaasimand image kaasa. Aga siis, homme on teil vaja selle ülesseada natuke teises keskkonnaus, näiteks armipial, ja te kasutate natuke teist upuntu versiooni face image-it. Te võidakasutatud upuntu aseme altpaini, et te proovite kasutada näiteks mingist muud face image-it, see siis käsutad kõik. Ja siis te peate uurima, et mis näid asjad olid upunta face image-is, mis minu rakenduse jaoks oleks tegelikult paialikud, aga mida meie arendada, nagu kirja ei pannud, rekoanudusfile või dockerfile, et täks nagu veegedkest olema või kurlkest olema. Et kui sõltude liiga palju nagu nendest eelmiste keskkondate definitsioonidest, siis tegelikult teie selles repositoorimis ei ole kirjas, mis on need ranger nõudad teekidest ja minuks käskudest, mis on vajarik, et teie rakendus töötas korrektselt. Et kui te toetate liiga palju mingitele välistele asjadele, siis te kunagi ei tead näed, et su puntu järgist dockerf image-ist ei tehta mingit väikselt muudatusi, et mingiselt see ruumi koko hoidmise jaoks enam kurlukest ühele kaadud. Ja siis teie rakenduse jaoks on sa rangered väära. Et siis kõik väälikud sõltud, et teaks olema defineeridud selle sama projekti seis ja tähtis on ka, et need oleks olt suhtse täpsalik. Et ärge kunagi kirjutage niimoodi, et oleks nagu, et minu rakenduse jaoks kui on vajad, oleks eksisteeriks Python Package Flask. See töötab tänas, see töötab järgmine nädal, see võib pool aastaväest töötab järgmine aastaväest ära me tööd. Sest installeerid teise liidu uus Flask versioon, mis ära on selles keskkone se tööd. Et seda meil tihti praktikumit juhtub, et üks aastav aastav aastav töötab, järgmine aastav ei töötab, kuna valitud mingisud versioonid, et näiteks Flask peab olema suurem kui C versioon, ja siis mingisugune krypteerilis paket peab olema suurem kui C versioon, aga siis krypteerilis paketi jäi uuendata, aga Flaski uuendataks ja Flaska uusime külteerilis algoritme, hata te peab S-i pakkuda näiteks, ja siis enam ei töötab. Kuna peab natuke nagu tagasi rollima Flask paketi eelnevall, kuna seda ühteen paketi enam ei toa, seda veel ei ole uuendatud. Tokkerite keskkondade loomiselt peab olema suhtseb ranga, et pange teekide versioonid vähemalt vaheämikudega paikvad Flask 2,5-2,7-räteks või, ja siis kontrollid üle, et selles vaheämikudne asjad töötavad. Ja siis kui järgmine kord Flaski uus versioon välja tuleb, siis keegi mingi arenda peab üle, uuendat Flask versioonid, eesti pärast see töötab, uuendat kõik muudle versioonide vaheämikude ja siis kõik asjad töötavad. Sest teed seda ei märka, et kui näiteks mingisuseks kuperneetases lisataks uus nood, ja see nood tood tuma pallal Flaski kõige uuema versiooni, ja siis see rakendus saab kakki, kuna see enamod lihtsalt ei tööta. Ja te ei näe sitä kohe ka, et ta ei tööta, vaid peata lohides kuski välja, et see on, et miks ta enamod ei tööta, ja siis isale saad taru, et kuna uuendatud Flask versiooniga, mingi teisel paketid ei tuha, et ta vaatab, või nende vaheamikud rankamalt paigas. Ja siis Flaski versioon oli lubatud põrgemaks panna, aga teiste paketid versioon ei olnud lubatud panna, ja siis see näed põrgemaks. Aga kui onki kaks paketi, mis ei ole enam samuga, et mul onki näiteks haadete pesraatu ja siis onki see Flask. Ja et näiteks mul Flask nuuab sama teha versiooniga, et näiteks on Flask 2.1.6, siis nuuab see vastavalt haadete pes 2.3. Aga see töötab nii Flask 3-l, või ka Flask 2-l, aga see haadete pes versioon peab vastavalt sama numpre kalv. Aga kui see onki ülepanna? Te saate nagu selle hetke, kui sina testid sa panert vaheamikud nüüd paik ka, et nad on maksimum versioonimis nubatud. Ja siis järgmine kohd kus Flask versioon välja tuleb saavu kontrollid üle requalmets failiga, et kui sa Flaski versiooni uuendad, mis nad järgmised ka peavad olema, ja sa testid, et töötab jälle siis muudat requalmets faili, et sa ningi arenda teeb selle testi läbi, et kas see uus versioon töötab. Seda saaks ka automatiseerida, et proovida, kas uus requalmets faili töötab, või mida töötab, või töötasid scrollbackidese. Aga põhimest, et kegi, kes sul ülekontrollima ja kui seda kontrollimist ei toimu iga nad, kui saad ennad, siis tegijad proovia. Aga siis avad niimoodi, et suurlise teed toimib kliimid, mees keskkonnest requalmets ütleb, et kas sul on see paad või teine paad? Jah, et lihtsalt teaks, et eraldi requalmets failid erinevalt ja testomete jaaks. Ma olen näinud seda, et on requalmets punkt production, requalmets punkt testing environment, et kui seal on mingisugust erinevalt, siis mõnikord on isegi projekti, mis ma olen näinud, et eraldi requalmets faila. Kes kui iselest saaks vist ootgi seelt selle kõrgust? See on rakendusega saab palna siia siin paikane sissele, et edasi asjad, mis kontrollivad. Aga ma ei ole seda prosentikindel, kas nad saavad saada ainult taadikult teha ilma reaast prooks. Mõnesmõttes on ju lihtne. Ma ei stallin ainult flaski, ma ei defineeri ükslikit eest packageid, flaski installeerik kõik, mis tema ajaks on vajalikud ja kõik asjad töötavad. Ma ei installeerik isele, et paketit saate pesjad vajal. Mõnikord seal ei tööta tead kestondades. Eriti pilvast, kui pill valmistab ette teile püütan 3.2.3.11 runtimei ja teie ei taade sinna piltitöötas tekki juurde installide. Aga see ei tööta, kuna pilvateid on paketilis, seda panod mingisugust tead kõik krüpteerimis paketi, millega tegime konflikt selle vahel. Ja ei saa ka tisti seda lihtsalt uuendada, sest mõnaid mõna põhti, et mõnikord on asjad lihtsalt tekivad. Aga kui teel on täielik kontroll oma mikro teaduse kestonna poolt, et ise teete tokkarpalli ja tegid palju paljumiseks, siis on selles mõttes vihtsam. Võib-olla te saate sinna sisse ehitada nagu mingisugust kontrolli, näidid siia siia pipeline, mis kontrollid üle, et kas on mingisugust võimalike konflikt rekordnatspallis. Aga saab looda, et kui te flaskid, flask jääb versioon istaleerib kõik te maaks vahelikud asja, aga siis sõltub, et mis on neid teise paketid, mis teieks vahelikud on. Ja kas siis nende paketide vahel on mingisugust konflikt, ei ole mitte. Ja kui eksist erivad rakendusad, mis ostavad siin nagu automaatselt teha enne installeerimist või oksetamist, sellest võiks olla hea, aga tihti ja rastist aru saada, sest jaa, flask jaaks on võib-olla nii mingisugust paketi 1.3 versioon, teise jaaks on 1.14, ja siis loodad, et te installeerid 1.4 testis asi töötad, et nad saavad nagu see paketide haldur, mis tip isa oskap selle teha, et ta istajad kõik uue paketi, aga mõnikord sellest isav tegud konflikt. Ja üks paket, sellel 1.4.20 ei tööta teine, vaja püstöö 1.4.20, siis see on konflikt. See ei ole nii keerule problem, et pigem ärge ei jätge versiooninumbreid panemat, on see mõtes. Pangeleks konkreetne versiooninumbre vahemik või mingisugune major versioon, et 3.6 suurem ja 3.8 väikse, et mingisugud vahemik panne paik ka, mida tult ole, et isa ülekontrollid ei teada, et see töötad. Aga mõnikord ikkagi tegid jõud progéli. Ja oht on pigem siis, kui see lihtsalt ei panegi välja nii numbreid ja lood on, et tulevalt, kui see töötab, siis kui uus flaski major versioon väige tuleb, et see töötab. Aga tihti ta ei kõugilise töötada. Kolmas tegur on konfiguratsioonis. Selle mõtte on, et konfiguratsiooni teave eraldataks ja mitu teelustist ja muudataks konfiguratsiooni või töövista kaudu konfigureeritavaks väljas pool kood. Siin on päris mitut asjad. Yks on see, et saate mõned asjad hard toadiga, et saate mingis kus ande vasuurli panna koodi, seda kindlasti ei toeks mitte kunagi teha. Parem olaks see ande vasuurli luge, et kas .n failist või sistemi muutujast, et see saaks sitte erinevate deployment pipeline'ides ande vasuurli purli ära muuta ja saaks ilmakoodi muutmata, ilmakfailja muutmata, nagu erinevades keskkondis asi üleksseadad. Need asjad, mis on vajalikud konfigureerita vahe peale erinevate deployment'ide erinevade ülesseadmisi, need keavad olema konfigureeritavad kas konfiguratsiooni failina, mis ei ole kõige parem või siis näiteks keskkonamuutujana. Üldiselt on kõige parem teadida keskkonamuutujana, sest ma saan teha näiteks uue docker-runni ja docker-runni muuta keskkonamuutujana. Kui ma saan ka teha niimoodi, ma kirjutan üle mingisuguse konfiguratsiooni faili, näiteks ngenics.conf-faili vastavalt väärdustele, mida ma saan, kui ma soovin uut poodi ülesseada ja siis mul on seal konfig map kasas, mis ütleb, et nüüd muudase väärdus millekski muuks. Kui mängisugune liitlusejaotur, mis jaotab liitluse kolme serveri val ära, et kui ma talle tema uuesti üles jääma, võib-palve pean tema conf-failis mingi IP-adress ära muutma, siis tegelikult ei saa seda alati teha susteemni muutujate tasemel. Mõnikord peab konfiguratsiooni faili intergenereerima, aga kui peal need, see näiteks on selleks väga hea võimalusolant, et saab konfig mapi defineerida, mis lubab tünaaamins, et genereerida konfiguratsiooni faili teiseisuvastavalt mingitele muutujatele, mis tuleb deploymenti ka koosladeks, kas mingi teampeadressid või mingisuguse annavaihtse urmiidulid või portide tundrit näiteks. Sest kui meil on targpane olemas, mida me soovime, on panna testkeskonda, production keskonda, mixedaging keskondas alati mingisuguse mängisuguse mängi väärguseks jäävad muutuma, kas või IP-adress või portide või annavasi aadressid. Ja kui me saame konfiguratsioonimu muuta, tünaaamiliselt ilma, et me peaksime yhtegi konfiguratsiooni faili muutmata, me tihti saame saada teha ilmakta, et me saame tocker image-it ei pea ümberpidima, see on pige pare. Aga kui peal neete soovimaltab, siis tocker image-i sees, põhimest, et file ülekirjutada tünaaamiliselt ilma, et me peaksime tockerfile ündag muutmata, me saame lihtsalt võtta rekistrilt image, defineerid ta la konfig-mapi, panas image püsti, aga konfig-mapi tulemus on kirjutudeks üks isenne konfiguratsioonil faili üle ja põhimest, panas siin uuesti jõupis mountimine, mis file asandab ära uuaan filega, mis on künne aamilist kindel, et jõudsa. Päris mugav. Et see siis ei tähend, et kui meil minget isennefaili on vaja muuta, siis me enam ei pea tockerfile, või tocker image-it ümberpidima. Ja siis selle juurde tulem, et kui meil on mingisubes tuki teenud, siis andme paas. Kui sõnumete järekord, pilve file storage, teate seda praktikumist päris palju teenud, et me paneme meende adressi kaasa siis süssteemi keskkona muutuena, et näiteks, kus asub Azure File System teenud. Me ei hardcode seda, me paneme mingisussteemi keskkona muutuena, et miks sütved, kus asub. Ja tänapäele see ongi niimoodi, et me enam isegi kasuta IP-adresse, me kasutame unikaalselt resurssid, identifikaatoreid, URIsid või URL-le niimoodi, mis defineerid läpsed ära, kus asub. Me ei tead, et IP-adressi pilved ennast pakku annab meile hostemim mingisubse päevi ka, mille taga on meie andme paast. Ja kui me soovime, et keskkonast teist andme paasi kasutada, siis me pahetame selle tuki teenuse aadressi vitsalt ära. Et igal tuki teenusel, kogu sa andme paas sõnumete järekordis iganas, on unikaalne identifikaatore, mida saab siis veelne pahetada. IP-adressi tegab palju hallel, nad ei ole tegelikult unik kaasad. Juhu IP-adressi taga võib palju teenuseid ja IP-adressid või tegab muutuvad. Et need on problemaatilised, et kubernetises saab kasutada teenuste aadresse, et tekitada andne paasidele, siis ka kubernetises teenus, mis viitab õige telepootidele, kus viitus jõu võigile kohale. Ja me vajame ajadnud, et tuki teenuste muutmiseks nende URI-t väljamahetuda. See on need resursid, siis vakaadus lahti võimalta sõoksalt väljamahetuda igal, kord, kui me uuesti ningis muidse teenuse mitte teenukse üleksame. Et tee haksa tegelikult ei ole midagi väga uutusti, oled seda näin, ikal poolel. Meil peab väga keeruliselt konfigureena, kus andme paas asub. Näiteks, Arkis, mis on see GeoIF ande paas, mina soovisin konfigureerida mindist, kus andne paas olikena, ei ole võimalik. Ainult ka võimalist, kui tähad teha on, on minna ühta serverisse, oksutada putan scripti, putan scripti, genereerid ande paase connection file, siis aga ande paase connection file panasid teadalt kausta, ja siis läbi veelid teenus on võimalist andme paas kasutada. See on väga himelik mitme kotsessi ja sammud selleks, mida andne paasi konfigureerida. Ja minu aks on see, et loomulik, et ma saan minna veebi leed, näiteks välja vaetad, et ma sooveks andne paase kasutada, kuski panan andne paasi hurlii, kas või andne paasi IT-aadressega, ühtegu sellist asi olevõimalik, et jääb reaaselt genereerima mindist mida see on fiili, ja see läks andeks jätu piirtan palju, et juoks seda fiili serverist, kus on litsentsolemas, et jääb reaaselt genereerima siin on. Üks asja, mida oleks ka hea eraldada, et meil ei tegiks ailu ühti sellistki aarsad fiili, mida me üleseame vaid me jääksime eraldama, nagu sellega tarkvara eitamise, pilgimise, tarkvara enleisii ja tarkvara käivitamise artefakid. Mis on siis ehitamine, et me võtame edekse oma C++ programmiga ja teeme sellest paineri, väljalaskmina võtab selle paineri ja panaks sinna kaasa konfiguratsiooni muudkõp, et näiteks, mis on andne paasi hurli. Ehitamine on, et meil on ainult oma tarkvara nagu väljalased, kas võib püütan kaust või siis püütan zippile, või siis väljalaskeb sinna kaasa panaks kõik need deployment informatsioonid, mis on see andne paasi hurli, kuhu see rakendist peab siuhenduma, mis on konfiguratsioon, mida seekord, kus ta jookseb, püüks vaalik kaasas olema. Ja käivitamine on siis, et sellest servades, kus ta jookseb, kõik vaalik on koos, et mitte midagi oleks vaja pildida, mitte midagi oleks vaja lisaks panna, mitte midagi oleks vaja lisaks konfigureerida. Et siis üldkihul on ta täiesti valmisehitetud nagu selline dockerfile, kus on ka kõik vaalik konfiguratsioon olem, mis on siis näite kuberneete selle manifest, mis kirjaldab, et kuidas ta ülesseada. Miks see vaalik on, et kui midagi oleks vaja põetki ja meil on vaalik, et sest see seda parandaks, siis oleks hea, et kui sest see saks lihtsalt uuesti ranni uubstuda, ilma, et midagi paks uuesti pildi makkama, et midagi paks uuesti konfigureeri makkama, et oleks hästi kiire, et saaks selle mikroteenuse lihtsalt uuesti ülesseada nagu sekondiga vähendu sekondiga ja ei tekis seda olukord, et kui me käeme uuesti dockerfile, pildi makkama ja siis teadud põhjusel, kunad seal mingit C plus pluks, package distallerid, et sa võid pyütoni pakette, ei ole võimalik allotõmata vaik, kui kompileerimakka võid, mis sa võid väga kaua aega võid. Paremat lihtsalt, et kui lokaalsest rekistriest saaks docker inni sa allotõmata käivu panna, et võibas allotõmata võid ta panata ka aega, aga üldjuul on tähtis, et sesteemid, mida ülesseadaks saaks hästi piiresti ülesseadavad ja ei oleks mingis, mis te leid seal. Mis saad selle vahelise väljilas ka ja teelitamise tapid? Väljal asub sul näiteks kusagi kitis, et sul on koku package jõutud zipfile, mida sa saadad dockeri rekistrisse. Sule põhimõtteliselt väljalas, kes on kõik konfiguretsioon ja asjad olemas, ma mõtlekits, ma saan paremat näiteks väljamaailda, kus käivitamine on võib-olla juba alla laetud docker image ja supernetese konfig koos. Näites, podi, manifest ja allotõmatud dockeri. Ütleme eitame, meid kütun zipfile, väljal asumine, et me tekitame docker imagei ja käivitamine, et meil on docker image, nad allotõmatud ja sellega kaasas selle platformi, kus ta üles siatakse speciaaline konfiguretsioon, näiteks see podi manifest, et kui kublet tõmbab kubernetese annan kohasest alla selle podi manifesti, mida ta jooks on pananud. Et siin väljalas, kes ei prugi olla seda väga speciaalist informatsioon, mis on pajalik selles serveris, kus ta jooksab. Ketsmõttel on see tihvõlssealistus, aga see run ajal on see, et mul juba on konkreet seda, et sannabasiparoolid ja uuletud, ve? Ja, et näites, väljalas, kes on kõik konfiguretsioon, mis on pajalik kusagi üles teada, aga kui tõesti välja vahetavaks näiteks annabasi URL, siis on vaja näiteks sigaret ära muutama. Käivitamise aal võib-olla on sul pajalik teada täpselt mindisugustlisad lisainfot, mis on seotud selle docker nodeiga või selle Kubernetes nodeiga, et näiteks, mis on mingisuguse teenuse nimi. Väljalaske, et on võimalik siis võtta ja panada testkeskonda või production keskonda või mingisel kolmandaste keskonda, aga käivitamine on juba konfigureerikud siin testkeskonda näha. Et see on testkeskonda speciaalised asja, kui polemas ja orkistreeri on võimalik peale lihtsalt restarti tegema või kustuma ja teema panne, et orkistreeri enam aegu midagi tegema. Ja võite natuke lugele, see on täpselt informatsiooni, et ma peast kõik, et enam ei mäleta. Ma kohraks vaatan, kas mul on märkmed, et see oli midagi pegas. Tavasti märkmed väga jälgi. Ei ole väga lisaks midagi. Procesid. See mõtta on kada. Tänab olul dockeris väga hästi ära implementeerikud, et ei peal seeks ole väga mõttanud. Kõik mikrotenuseid taakse, et töötame eraldiseid ja protses siin on mitte eraldi lõimel, et ei protses ees. Et kõik see protses kokujaoks, et see ei toeks mõõdlada teisi teenuseid, mis seal jooksavad. Et kui me tekkitame mikrotenuseid ja jooksame näide eraldi konteele, kes on automaatselt meieks näge ära tehtud. Tokkeri konteele, container, tin container või üldiselt inud container pakuvad isoleeritud keskkonna kõigile teenuste jaoks. Et see on väga sisse eidata mikrotenuste ja containeri poisele lähemisena. Portnede sidumine on ka see, et iga mikrotenus paks jooksma iseseisvalt ja konkreetse nagu kaase porti peal mingis masinas. Et kui ei toeks väga tekida seda olukorda, et selleks, et üks mikrotenus ühendaks, teise mikrotenus, sest seda peab ühendama mingisuse vahe kihi, et näiteks läbi n-genics. Ja siis n-genics otsustab, puhu edasi suunata. Miks on probleem on see, et meil on tegelikult hea kasustuda porttid kontrollide, kes teenus on üleadud. Et kui meil on konkreetne mikrotenuskontrol, kuulad konkreetselt portine, kes 80117 või 80117, siis suvalne orchestreriamonitoorium võimene vaatama, kes kaeg on mingi potsest, et kes raporti kuul. Ja selle põe, et on iba võimalik otsustada, kas see process on ja kui see mikrotenus töötab korrektselt, põe on näiteks maha juoksund enam, et raport ei kuula, et me saame linuks tasemme kontrollide, kes teegi kuulad raporti ja mitte. Kui selle mingi vara vahel, näiteks porti 80117, mis suunab edasi selle mikrotenusad mingil teisile portile ja me seda teist port ei tea, siis me ei saa kontrollida, kas mikrotenus sooksad. Ja kui iga mikrotenus või iga potsest sooksab oma kuulad oma porti, siis see tegelikult on hea selleks, et ka nad olaks ka jääb täiesti eraldatud, et ei tekik seda olukord, et me saadame kuulvi liitust ja kõige kuulab seda pealt. Et linuks ei saa ka olla ainult üks potsest, mis seda porti kuulab ja natuke rohkemisele tsooni tagab. Ja lihtne ka näiteks panna, et seal meil on API, API kuulab porti 88 serveris ja tahama API repliceerida ilmakuperneetest, et ta mida tokeris teeks, et te näiteks, et panna tuua API replika töötama 2021 peal, 2022 peal, 2023 peal ja siis kasutete midagi, mis nende portide vahel liiklusära jagab, et parem on niimoodi teha, kui hakkata nagu mingisugust teisi viise proovima, et kuidas liiklusära jagab, et näiteks rakendus töötab ühe porti peale, et siinna porti peale siin selle porti peal jagab, et kõik replikat reedida vahel liiklusära, et see ei ole kõige parem vahel niisand, pigem on parem seda teha portide tasemane. Meil on väga lihta portoja ümbermätide, kas tokeris või kuppeneetest, et me lihtsalt ütle nad suunad siin porti peale liiklus, et see on kõik, mis vaja teha. Ei ole vaja mingid erilisi muid võimalusi väljamõed, et kuidas me liikluse ümbersuuname, et me saamegi kasutada portiselt ümbersuunamiseks. Ja kuna see on kasutusel võetud, siis liiklusahaldus kuppeneetest samastest vastadest suhti flitne, et meil ei tea, et isegi olema tarkku aram, mis tegelev liiklusse ümbersuunamisega, ta võib lihtsalt konfigureerida IP-tables VG ümber. Et Linuxist tuleb liiklus teadud adresid, et porti peal suunaduks lihtsalt õigise korti ja kõik, mis vajalikult tead, jooksta üks käsik, ja IP-tables siis üks regel juurde panna ja on saavutatud see, et Linuxi tasemel suunaduks õigisei populiiklus ümber, et me ei pea ehitama mingisugus tarkkuara sinna vahele. Ja see vältib seda, et meil peab olla mingisugune tarkkuara, mis edastab ühele tarkkuarele, kes laialjaga. Selle probleem tegib see, et see vahepeal tarkkuara tegib kudelikaaljaks. Meil on parem, et Linuxi võrguliideste tasemel kasutada tulemyri-räägled ümbersuunamise teha sellase, et me paneme peitam mingi tarkkuarad vahele. Parem on vältida sellist mingisugust hästi kavalai viis, ja kuidas me suuname liiklused edas, et parem on kasutud Linux portga. See on tege efektiivse viis, kuidas liiklus ümber suunad räägletele pitkalt ennustada. Kui peate, siis saab vältida IP-tables siit ja tulemyriti kasutamist, aga sellise juhul teab kuhbleta tarp praeise vahendama, et liiklus tuse ei kluubi olla nii-eval. Ja sama haepsus, et kui meil on vaja skaleeride sisteeme panna rohkem mikroteenuse replikait, kui meil on vaja parandada mikroteenuste jõudlust, et rohkem pärimpüt saaks ära töödeda, rohkem pilitöötus taas, kes ära töödeda, siis pigem skaleerida, või ma riisam taas, et paneme kopejuuda. Meil on alati võimalik ka vertikaalse skaleeride, et paneme rohkem resursse, paneme mikroteenuse suuramata selle serverite selle tööle, aga tihti seal on peidetud sellised skaleerimist kahandavad tegurid sisse eitad, et näiteks, kas meil peab olema mikrit ja mikroteenuste sissemid järjekorrad, mis jätavad meeld, et ku palju kraaeg on piditudus taaske, mida on saadatud sellede mikroteenusele, et kui meil on ainult üks ästi võimas mikroteenus, siis ta võib-olla peab kinge suurst sisemist järjekod oidma, aga kui meil on hästi palju neid, siis võib-olla neid individuoasad järjekod, aga neid palju väitsemad ja juhtub pähem halba asja, kui midaid koko jooksad. See on midaid poeves, et näiteks on ka limitid Linuksist kotsasid, et ku palju üks kotsas või palju pidene lahti hoida, kui tihti need on pidem kogu serveri tasan, aga mida niimekal ei ole kotsasid kasanud. Et lihtsamas skaleerida niimoodi, et me tegitame palju replikaid, kui et me proovime rakendus üleseda niimoodi, et ta saa hästi palju mälu, hästi palju CPU'id, ja ta hästi suureks virtuaalmasinast, et tihti on panna efektiinsa palju virtuaalmasinad tööle. Kas selle töötab, et kui midagi väike virtuaalmasin või väike, konteiner koko jooksad, see mõutab pähem, kui koko jooksad mingi siin üks väestest konteiner, et see on üks väestest virtuaalmasinad. Kas see on probleem, et sul piirat arra fali pide meidlahti? Kas see ei teki sulle tokkari ka üldiselt, et sulle tokkari on üks protsess? Et kui sa tegi konteinerid, neid seda, mis seal võihtahavad oma 10 fali rugega, siis saan mingi piiri läis, et ma näid sile tuhade fali pide korra. Ei ole, sest nad on ikkagi inuks ja vaatas, nad on kõik eralda protsessi. Kui ma olen sada konteinerid, siis on pärast sada protsessi. Kui ma olen üks protsess, kas ta konteineris ees väljas või vahet, kui ma olen sada protsessi, kas nad on iga üks erinealtes konteinerides või mitte ka ajal vahet. Kui on protsess konteineris ees, siis ta ei ole kui tegi tokkari protsess, ta on ikkagi täiesti eraldiseise vinnuksi protsessi. Ja see ei väga muuta, aga pigem, see on midagi sellist nende unustatud, et see ümber konfigureerida, et teab Linux serveri tasanel konfigureerina ümber, et mis on see maksimum serveri limit ja mis on individuaalselt protsessi limit, et neid saab lihtsalt ümber konfigureerida, aha teatud olupõrast pilves võib see olla nad kui nendik teerikõttude nendik nano funksioone, serverlask funksioone kasutada, et siis teile ei kruugi olla Linux konfiguratsiooni ligi pääs, et see ei ole asjutsu muuta, aga sellistel juhtutel väga ma ei näe, mikrobeno või nanobenosed või funksiooni teaksid liiga palju file lahkto hoidmat, pigem need on sellised logi haltussusteemid, mis logi file töötlevad, või siis mingiselt annebasi näiteks, in-genie, in-genie, influx või kestiviir, mis hoiavad hästi palju partitsioone ja nad võivad teha toodult palju väikse file, et nad võivad annebasi aga tästipalju väikestis file, et see on sealt pigem tekega tegega tegega progene. Aga võikli juhtud, et näiteks, te paeta kuberneetises serverlase mingiselt annebasi, see kasutab peepfile pidemed ära ja siis mikrobenosed enam ei jookse, kuna ei aina ole terrori, et neil ei õnnehtu file lahki teha, et file te leviid, on täits, file pidemed leviid. Aga tihtisid asad lihtsalt ära konfigureereid ja tähist lubada kaks miljonid file pidemed, 100 000 aga. Otseselt nagu, neid tiirangud on suhtseb väikse, aga natuke epaväelikud, et tegelt, minuks on pakka ma palju rohkemata pidemed, mis konfiguratsioonitasanud, et sa arra pidatud. Ma asad ikka end. Teinaasimis probleemi tekib, et nihti on logifileid, docker. Pidemete, panete protsessi tööle väljas poolt dockerid. Pidemete, see on nginx või plus. Ja tööb logit teist palju. Seeles te tegi mitte mingi probleemi, sest on standard output, ei lähe kirja klas loki ja kõik mul korras. Panete konteele, tokkere, samas ja tööle. Koljaväeva on pärast ketas täis ja sest teeme jooks. See pahe on selles, et dockeri konteeleis väljas poolt keegi ei salvesta standard output. Aga dockeri konteeleis ees, kui nad taad juoksete dockeri lookskesk, kus see docker teab salvestama kõik väljandid poolti pälja. Ja docker salvestab seda kuskile dockeri kausta, konteele kausta tegaks nagu logfile, ja see logfile võib olla viskelt igavõiti suur. Kui te printite välja igas, siis tuleb pärinku kohta midagi. Näiteks nxerix teeb seda tihti, et igas siis tuleb rest pärinku, ja halutate ka pärinku kohta teed logifile. Ja kui sisse tuleb 200 miljonist pärinkud, siis sa on 200 miljonid omi reda ja ketas või täis. Selle vastu vaitab see, et kui te näiteks panete dockeri kausta mingisel teise virtuaalmasina virtuaalse fiskipeale, nii et ta on näiteks limiteeritud 40 gigabaiti võib docker sinna kirjutuda. Ja kui seda hänsi kirjutudakse, siis ei juurdu midagi dockerist väljas pole, virtuaalmasine ei ise jookse kokku. Kuigi docker ei protseisist kõik kokku jõusta. See kui ei ole otsedada sama aegas, aga see on kui taga üks näidieselestus. Nii, et limiid, mis on linuksist asjame konfigureedit, võib probleem, mis on jukka. Ajutisid eeemuse koopajad täiks kasutab ühe kortsalt, et võimaludada sellist ästi kiireks käilitamist, et suuradudas kaneerimise võimalusi ja et oleks võimalik nagu praatsialiselt välja lülitada, et kui teie püüta protses püüab kinni shut down käsu, signali, kill signaali, see on väga hea, et see on väga hea, sest te saate näiteks connectionid kinni panna, te saate mingisubist arvutused lõpuni teha ja praatsialiselt väljuda, et aati on hea tava praatsialiselt väljuda mikro teenuksest, sest eriti kui pärnetele, see võib suvalise laav kui pärnetele, see ei konteinalise kinni panna. Näiteks skaleerimise jaoks näiteks kasutaja konfigureeris ümber midagi konfiguratsioone failis, kui pärnetele sitab delig port ja siis palaks uutport. Tokkeris hoidakse ja teha restart, et teeme protses, mis jooksab panteria sees restarti ja ta reaasult ei lähe, ta ei ole täiesti kinni, aga ikkagi see restart ka tähendab, et killisemitaali saadnud. Parem on, kui teenuste on võimalised nagu kratisiliselt sestkuma, et püüad isegi kiliseknaali, tead teatud tegeluksed ära, et kõik kõus koneksioid kinni panna või ningid fileid ja kirjutamist ära teha, fileid ja buffer ära flashida, et midagi mällu jääks jooksime saajal. Aga põhjemist üks asi, mille ei tohiks olati üllatud, on see, et kui pärnetele saad suvalise teenusega, see on alnud ka siin poodi ära kutsutada suvalise väg. Seda saab teatud viisil kaitsa, aga see ei ole väga lihtne. Kõige niitsa mongi, kui tarp koreisja piiab selle, et killisid naadi kinni ja väljukratisid suhtse pühitsaaja jooksul ja lisab ootab seda, et teegi võtada suvalise aalpoori kinnikonna. Areandustestings ja tootmist keskkonna võib sooida saarnasena. Võimalikult vähe teha peinoloomilise erinevad valikud nende keskkondid mahal ja täiteks oma alvut, mis ma saan üles mingi SQL-lady test keskkonnast, saadest ja end, ma ees kõlli ja panen production keskkonna postres, jah, sellist asja teiks vältida. Konteineride kasutusevõt aitat keskkondis arvases hoidas, veel ei ole vaja postres installeerides, ta käima soidama saame ajutsed panna postres konteinerib oma süleharpest tööle testimise ajal või areandust ajal, ja pärast mis teha kustutada või seisuma panna. Et suhtel lihtne on nüüd konteinerid ajal tätsalt sama tarkvara ülesseada oma läpakas, mis üksküld mis production keskkonnas. Alati on mingisõmuse, et lividid sellele, et kui töösti tarkvara vajab toutu palju mälu, no ei te peud siis võib-olla väga nii vägas, aga keha ei saa eritimid masinuva mudelide puhul, aga eeldusel me saame samu konteinerid oma alvut välja oxtada, siis ei ole väga raske näid keskkondis arvases hoida. Sest muidub ta palatin atukene erineval testima, erineval taarendama, et kui me peame, kui me testimiskeskkoneese tootmiskeskkoneese on erineva tarkvara, kes siis testib, et kui testid juba keskkoneese, ära testiselti tarkvara toetab ka tootmiskeskkoneese, kui ne võib-olla täpselt samad, siis mis mõtle selle testimiskeskkoneese mõnesvõttes on. Hea on hoidanud, et delta võimalikult väikse, et oleks võimalikult vähe erinevasi arendustest ja tootmiskeskkondida pahel. Aga siis poeks veel parem, kui üle toles sama keskkond. Et veel mängu saavaks võtta selle arendustestimise ja lihtsalt jääb jaheva kordja onki tootmiskeskkond. No mõnikud sa tahaksid ikkagi vältida, et sul testimisaal, ennest jõudustestimisaal ülekoormataks on nagi päris keskkond. See on tootmiskeskkond sama, aga sa ei kasuta, enam mul ongi sama keskkonna taga, mulle on koopiasest keskkond. See on selle mõtte, et väikse olema nii võimalikult lähedselt koop, et kui võimalikult. Ja tänapäeva see tocker ja kuperetsing ongi päris hea teha, et samat kontenet jooksutada. Teatud olukordes on probleeme, et tootmiskeskkond on linuks ja arendustest on mäkk arvuti M3 või M2 prozessoriga ja nüüd enam väga probleeme ei ole, aga kui uued läb Apple, Arma arvud välja tulid siis väga paljudel tudenkitel ja ka väljaspele ülikooli oli probleemid, et enam tocker konteneet ei jooksut näiteks, et kõik jooksid kokku. Päris seda võiti rohkem arvesse seda, hakkati tegitama seda, et kui te paate midagi üles tocker haabi, siis teaks BildMitmall-arhitektuurile nii arviida, kui aende 64-le ja siis varmist, kui Arm arhitektuurist tocker imits alla tõmataks, sest oma armbersioon ei proovita alla tõmat enam linuksversioon. Meil oli tudenkitest pigi pikk asju ümber ehitama, et võitsid kogu selle tockerfailide sõltuvased ja iga layer ehitse ümber ise käsid siin Armu peale, et saasi tööle palju, et tekis päris tali probleeme. Aga tänapäeval see on, see arhitektuur on vähendähtis, kuna nüüd on väga lihtne nagu tockerhaabi pannas asjad ehitada lihtme arhitektuurile. Et see on lihtsalt lihtsa tockerpiltkäsule ja tockerpushkäsule, et see registasse saab panna. Ja tead, et olukortus on võimeks ja vist automatiseeride ka, et automaatsal heitab kõigitev platformi ja ots. Mida see soovit? Logimina, ma sellest juba aastaka rääkisin, aga logimina on hästi tähtis sellet öötu, et kui meil on mikroteenuse, et võib olla 16 koopjat näbjast konteineridest iga üks logid. Ja kui teie nüüd peate üle, et sootsima, et kus tekis viga, aga teile saadab suporgi kaudu, et ma nägin sellist erole, et saadab sellist screenshoti ja te näete, mis ekraanis oli veegi nii, sest aga täpselt, mis mikrotenuse viga tekis, on tihti rast arvutada, kui te kasutad ästi holistiku tracemist, kus tracemene teile ütleb konkreets, et mis mikrotenuse viga tekis. Et ilma sellise tracemiselt on väga keerune tegelikult. Et siis on tähtis, et logid, mida iga mikrotenus loov, et neid töödendaks, aga suust, et keerul ikkagi inimesel minna, kui konteinerid logid läbi vaadata. Et on tähtis, et neid logianne tegelikult kogutaks ningite, see keskis, kes on logihalduses justeemidesse, näiteks, logi kuberneeteses, mis siis on võimane, kogu konteineridesse, ta oogu maasalt koguma logik kokku ja näid ratupene ümber töötama, niimoodi, et oleks päringultega otsitav ja näiteks, kas võib graafikult eroritest, et mis hetke näid erorit tekivad. Ja et oleks võimalik ühest kohast kõikki logisid näha, et saaksid näiteks ajaajärgi otsida, ei pea enam liikuma konteineride vahel ringi konteineridesse sisse, minema, et logisid vaadata või tocker loogs keske, et kasutama iga mikrotenuse peal. Eriti, kui mikrotenustest on palju replikaid, et kuuti pettetel on 50 replikaid, mis te käeks tuurimad, mis sugu se teenususeesse iga on. Aga see on logi, et logid mainud riga asjad, et siin näib nii kui iga päringult logiks, see logi või saab täigi. Jah, et tichti on parem infalt mitte logida, kui selle asjad otsad vahel rast ei ole, võib-olla ei taidat vestkestkonnades, või roteelist, või production-kestkonnades, sest ta muidub kirjutab kõik täis. Aga teatud oluvu kordades, eriti nagu sisse tuleb päringult puhul, võib sa olla oluline, et logida päringult, et aru saada näib, et see, et kui tekes viga, mis reasad olis ja sisse tuleb Jason-lid. Et kui sellist asja ei ole, siis mõnigult tekib see probleem, et mina isa ole näiteks sellist asja sisse lüüta paju. Kui ma tean, et logides näen vigasid, mis tulevad mingis teenusesse hapisse, ma talan teada, mis oli Jason, mis selle vea tekitase, ma pean sisse lüüta mesele. Aga kui ma kõik Jason-lid logides, siis oleks toesti justeeme ajaks lihtsalt maha, et kui ma proovin nagu salvestada kõik, siis olevad Jason-lid, et kui päevast tuleb millioneid ja millioneid on fekste, et saadatakse reasad, siis ei ole võimalik kõik asi logida. Info on veel vähem, kui näiteks reasad sisendite logimine, ka info puhul lihtsalt sa ei taha niipole anmed salapugu, sul ei ole paljast teada, et pigem jaheant erade ja kibaat või mording mesudid logida. Aga sa oled kui viga, et sa oled siis logida kõik selle vea päringu, kui sa oled tegineks kõik? Ja see ongi keerulne, sest sul on vea päring tulad näiteks. Kuna sa saad teada, et oli viga, et see viga on ühes mikro teenuses, sul oli see anmed, võib-al kui läbi teiste mikro teenuste, sul oli võib-al mindipäring, kui sa pääregistusse kristiitse ära teg, ja kudas sa teed seda nagu mitte ühe mikro teenuse see, et seda on kõikida mikro teenuste raamdi ja selleks kasutad kõik tracemistid. Sa saad põhimõttelselt proovid ikkagi logida kõike midagi sisedunud päringuid ja kohta, aga lisaks selle, et sa logid kõik infomessagid, sa paned nendesse logidesse ka kasutaja päringuid, et mida et mida kaatri, ID-aid juurde. Ja siis kui kasutaja ütleb sul, et sul tegis eror või sa ise näed logidest erorid, ja sa näed, et see eror on näiteks seotud mingisugude kasutapäringu 1,766, siis sa saad minna keskendse logihalduseks tööriistaja, üelda et anna mulle kõik logid, mis on seotad sellega kasutapäringuid. Ja see võimalutab sa teha täpselt seda, mida ta tahad, et otsida, et mis juhtus kõikides mikro teenastas, mis oli seeotud sellega kasutapäringuga, ja sellise liul sa näed täpselt, et näiteks kahuada mingis järjekarvas oli, kahuada ootas mingi registrivastust ole, mis oli registrivastus, eriti, kui sa isegi aata jatione tovima. Aga see tegelikult vajab tolutad palju rohkem, nagu kettaruume, et kõikime tohvi saadata, et tihti seda ei tehta, kuna sa läheb niiga kallikselt kõikki nagu päringu asju logida. Aga mõnesmaks on ka see hea, et kui sa iseseda erorite ja märka, aga kasutajutab sulle, et midagi töötab hästi selle päringuke, ja sa küsite ma käest, et mis on see päringu idee, ja siis sa anad selle päringu idee siia logidalt tööristale ja ütleb, et näite pole peki annaid, mis on logides selle päringu pohta. Sa aidab sul tippakida sellised olukönti ka, kui sul otsast erorist logides ei ole, aga kasutajupalt tuleb nagu mingisugust tagasidug, midagi töötada, et ta ei õnnesta näite, et ostamidagi ja sinu sisteemise erorid ei ole. Et kui sa erorid tähed, siis tõblast on lihtsane. Siis ei oleks kui ma olin lihtsalt niigi piiru taelnobid, et neidas ongelnobid 24 tundi ja siis kõik vanen logid kustata vära. Ülgivult see on, et siis ei teed, et sa logid halbast tööristad, et sa mingisuguse perioodi sall defineerid. Prometheus on see läheb, et siis kaks nädalat automaatselt, et Prometheus alvestab kaks nädalat annaid. Et seda sa taad prongi suureerida näid. Kust lõmpad, et sa näid salast, et sa ei saa. Ja lähme edasi viimane. Muidume jooksema ajast suhtselt vara juba läbi, aga ma saan ka need teemat lõpastada jäänekõnekord. Viimane on siis haltustprotsesid. Kui teile Annepaasi, ütlele, et teil on Annepaasi poskas konteehner ja Annepaasi midagi katki läheb, mida te teete? No, installi Annepaasi. Et ütleb Annepaasi teile töötab, kui sa aga kõige selgale sõneks et ole tokke konteehnerina, ja midagi Annepaasi läks kaip, mida te teete ära? No, palju suurst teelt. Jah, kui sa taaks läheb teada, mis kaip läks või sa taaks näiteks kind olukorda tarakata, näiteks Annepaasi struktuuris on midagi vältvi ja pärgit enam ei tööta, kuna keegi kursutas midagi esiteisest taberist ära. No, siis tost sellel töötavall oma teha. Aga kui sul töötab nagu backup on nii ka vanale, et sa taaks käe maha. No, sa enne muudatust ja midagi põleks kõnev? Aga kui sa jah. Või ütleb, et teile on näiteks kimpisugun seine, et sinflaks on midagi vältvi, et mis te teete taad? Tänna valju mina läheks konteeris sisse, et keskjaoksutamalt vaadata, et kasutab oskres kesku, et vaadata, mis Anna valdi see, või aga rabelide nii eda. Kesks kõitele, et on jääb kui jääb kõist vahe. Jah, aga see on väga speciaalne. Minu mõte oli see, et te saate rauhusina keskkonda sisse minga ja jah, et te keskjaoksutamalt. Ja miks ma saan oskres annebaas? Sisse minga on selled, et ota oskres konteele ka kaasasse käs, mis sa põlmust oskresi annebaasi ikk. Et ma olen käsuriga käs, kes sa on toka konteele see, millega ma olen võimalik oskres annebaasi sisse vaabida ilmat, millega ma jääks importelahtega näida. Ja see on viimase mõte ongel, mingesud haldus, koksasid, mis on teil vajalikult halduseks, olnud see annebaas, olnud see mingisuguna file stories või teie enda kuita programm. Et selleks, et te saaksid uurida, mis on toiminud live systeemis, jookslas running systeemis, on võimalik lihtsalt konteele sisse mingna linnud keskjaoksutada. Ja tihk, et on näite tarp väraga kaasas mingisugust haldustarpe väraga, nagu poskresi puhul poskresi klient. Ja klienti tarp väraga, et ei ole ainult instaleeritud poskresi serveri tarp väraga, vaid aga mõelik selle peale, et administratore tahaks minna, lokaasad sisse logida ja vaadad annebaas ringi. Ilma, et peaks midagi juurde instaleerida, millite inuks pakete juurde instaleerima, mingis portelahti tegema, et oleks võimaliga ästi kiiresti minimaalse vivitusega minna ja vaadata ringi akatandivaal administratore keski jordetama. Et siis selle best practice mõtani, et hoida need haldustprogrammi koos selle keskkonnaga, mida jooksutatakse produksionsistemis, et administratore te looks võimalikult kiiresti võimalikult mingis haldustoimingud. Kas või see, et te tahate ise annebaasi back upi teha, et saate exekiga tokke konteeerise sisse minna, jooksutatakse poskresi käsu selleks, et nagu poskresi annebaast teha mingis snapshoti, siis paljina salvest peaa konteeerist välja ote kopiga või otsa konteeeril välja salvest peaa. Aga see ei ole siis see halb praktika, et hakkab esel kohteinele seismudev muutuma? See on halb praktika siis, kui sa soovit tema seismuta, aga kui sa soovit ainult dibagginida või aru saada, et kis on valesti. Ja kui sul on väga kiiresti back up ära teha, kuna sa tead, et tunne ääbrus läheb elektromahalega ja sellist. Kui sul on midagi väga üllatustliku, et sul oleks võimalik seda kiiresti ära teha, aga tõesti kõikis sellist tegevusi, mida sa ette puutud, peaks olla palju parem automatiseerida. Oltomatiseerida oleks parem praktika, kui käsit sa administreerime. Aga selle best practice mõtlen, et hallut protssel seda vaelik, et vaelik tarkvara ko kaasa panna nende keskkondudega. Ja tänapäele sa on mõneslõttu sisse eidud tokkeris ja kui pea näete, sest see on võimalik väga lihtsalt sisse minna ja käske jookstuda. Ja nad ei ole nagu ära peidetud või, et sa vestimist. Näädiks see, et piikida konteneeritaga panast ka su shell, et sa saad shell käske konteneerisees, et ta on sisse ehitatud tavad. Teoreetist, et sa saad selle keelat ära konteneeritapuul, et sul ei oleks shell sellimade kaasav, et shell ei jooksta selle konteneerisees. Ma olen näinneid olukordi, kus ei saa shell jooksta kõrte konteneerise. Kui päris, et selle konteneerite puul, annepaiseid puul, sa võib ka ketta kingikonna, et ei ole lubatud. Ei ole ühtegi riid, ei ole ühtegi fail, kihki, et kõik kiidab riid ombi, et ei ole kui lubatud, nagu sa seal midagi muht. See saab isegi selle annepaise puul täiesti kinnipannud. Administraatorele ei ole lubatud minna ja seal paljama. Ja ka processiise annu, ja processiise ka ei ole, tema ka ei saa paljama juha poimuse. See on ainult riid ombi. Seda ta hakkab jaa. Ma nüüd atuke mõtlen, sest meil on aegas uhtsalt vähe, kuna ma arutasime. Ma korraks mõtlen, mida me järgmasena räägime. Ma võib-kohle jätaksele service mesh ja sidecar patterni järgmase loonvõs algusesse ja räägiks üle mõned sellised pilved eelused, mis tihti on vaelikud nende täiesti pilvepohiste rakkelust jaoks. Kus service meshe ja sidecar pattern ja muud service meshi asjad jääbaks järgmase loonvõsse aine kokkuvõttesse. See on kelle selline teema, mis võib-olo pakkas ongi natuke liiga vara mõnes mõttes, kuna me selles ajan sisekuberneetist ei ole kaks otsaegu pakkikumise. Teised teemat, millest me räägime, me vaatame natuke annepohese. Vaatame hästi kiiresti üle, ta näeme, et TNS ei pilves ja CDNi, aga CDNi nagu otsaegi väga ei vaata, kui tegab vaatame, kuidas Google seda teab. Esimese räägimegi sellest annepohesid mustrist, mis on natuke imelik muster, sellest arusada, miks ta kasulik on, on sihti tegelikult natuke keerulline ja häid, päris elulise näiteid ka, sihti väga ei ole, aga selle CQRS või Command and Query Responsibility Segregation idee on, et eraldada kirjutavispäringud või lukemispäringud. Seda saad teha mitmel tasemel, et me saame teha sellel tasemel, et me paneme eraldu serverid, mis serveerid ainult kirjutavispäringud, ja me paneme eraldu serverid, mis serveerid viivad ainult lukemispäringud, aga võib ka teha loohike tasemel, et näiteks me lupeleme rakkeendustel teha annepohese päringud ja kõik muud päringud peale select päringud teha ne keelam ära, et täidis apte või in set päringud ei luba teha SQL-iga. Et luba ma ainult nagu pärit anmed, et lukega anmed SQL-iga, aga keelam ära kirjutamise SQL-iga, kirjutamiseks implementeerime eraldi fixeeritud metodid ja eraldi tartvara, et anned oleks kui muud misse toimigudele oleks täiesti eraldavud, kui anned lugemise toimigudele. Me lugemise luba ma siis täiesti dünameelisid päringud, et mis igajast kudas kavutavad sooviat joinida või kruppida luba me, aga samal ajal me luba kirjutamist ja me kontrollime palju rangemalt kirjutamist, et mis järekarasse toimub, et näiteks, mis serverite kavudust toimub ja võib-olla implementeerim ka metodid, et kasutaja ei saa SQL-iga ükskõik, mis anmed või tabellid muutavad on teatud fixeeritud metodid, mis isesel ära internetereed. Teine viis kudasest veha, et me jagameki kirjutamise ja lugemist toimigud erinealtest sõmmedamaal ära ja me vaatame kuna see Postgresi puhul töötab, et panaks üles Postgresi klaspreet, et anmed muutateks ainult ühes serveris ja see parandatabus järjestidavust ei ole võimalik, samu on meid trollide kahes serveri, sama aegselt ülehidutada ja ei ole enam vaja kirjutamist sõimmeda vahel reaal ajasikroniteerimist teha, mida on vaja ainult nüüd teha on paustavar replitseerimist, et kõik anmed kirjutamiserverise panaks liikutatakse piisavalt kiiresti kõikidesse teistesse ja serveritesse lugemine toimuksest suhtelmised kiiresti paljab muudata. Meil on ka võimalik teist eralsed annebasiid, meil on kaks annebasi üks, mis tegelab kirjutamisega, tegelab lukemisega, teha väga lihti ei kasutata, aga võidakse kasutata olukorrastus ta, kus on vaja ästi võimsaat kirjutamist, et oleks tohletult palju anneid ole paraleliselt kirjutada, aga lugemiseaks pigem kasutavaks raporteerimisi, mingisummised dashboardi loomisi, siis kasutab ühtepäeva, et anmedbasi ästi iskaleerid, et anmedbasi anmed kirjutamiseks, ja krančitaks anmed, ja teaks sellised anmed kopeerilisi ja hiljajan genereritisse raporteid kirjutud anmed põhjelva ja anmed te tõetust toimub kusagil, taustav mindite, tiktate anmed tõetust, aga lihtstabil, ei toimu reaal ajas, ei toimud näites ükskord ööpävas, et on võimalik niimoodi jagada. Ma avatam, et see järgine on, et siin on üks näite, et meil on täpselt üksisama anmedbasi, et ta ei ole te koommaks näite, kui meil on kaks eralte anmedbasi või pigemse esimene näite, ja meil on eraldisebised mikrotenusev või tenusev, mis jooksatavad käskemis anmed muudavad ja teised, mis teavad, et käsut SQL päringutüült kätte saadavaks, mitte käsut võided anmed, et meil on eraldi teedusebneid, kui meid on teeduseb asjad, et millega oltasab saada anmenda muudmisekästu ja eraldis, millega oltasab saada SQL päringutüült tammelt pärida. Et kui te soovite lukeida selle kohtes, on Martin Pauleri koduläele, on selle kohte kirjutatud, ta on päris palju huvitavad arktikleid hajussisteemide koht. Mis tänavahel tikkem kasutab, et see on see teine lähene mine, et teha SQL klastri, kus saavaks hästi heaad lukemisjõudlust, siis saame enitada sellise Postgres klastri, kus meil on siin 4 nodeid, nad on kuberneettisest Google Cloudis ülesseadud, meil on 4 primary, ja siis 4.1 standby, 4.2 standby, ja meil on lisad 4-dir on samas serverist, ja samas koalast ka selle replication manager, kelle üle saame on, et kui siia primarist on kirjutud tammelt ja muudadud see midagi, et kõik teha muudadud saab ska synchroniseerida, siis teistavse standby serverisse. Likte ei tee, et me peabest katsutada seda, aga kui sees seera kokku jaoks, et me saame katsutada seda ja seda, aga kui meie jaoks ei ole tähtis, et anned oleks ideaalselt reaal ajas synchroniseeritud, siis me saame tegelikult teha niimoodi, me tekitame kaks teenuusid, kui kuberneettisest, üks teenuus, mis on kirjutamise teenuus, üks teenuus, mis on lukemise teenuus, kirjutamise teenuus suuna taalt kui siia poodi, aga lukemise teenuus, kui sinna saada päringudis, aga kaks selle, selle ja selle poodi pael sisse tulad päringud äna. Et senneks, et töötaks kasutavaks sellist asja nagu TG pool või Postgres pool, nagu sellist annete, kui sa oda ümbersuunad või päringutaja autorit, kes ise otsustab, kuidas ja milisest see teenuus see päringud edasi tulad. Aga ta on selline korvusi autoris arvanu komponent, mis otsustab, et kuhu, nagu Postgres sii päringud edasi saada milisest see noodidisse ja kliendid kasutavad selle TG pool servisid, et Anne paasid lasti kõhendust, kui nad ei teagi selleks, kes on ride ja midu read replikate mitte. Ja siis TG pool siis, et kui tuleb, nagu S-päring, kes proovad Anne ka ennud lugega, siis ta saadaaks selleks, kuba teed, et sa teenustas, mis suunab siia-sia või siia edasi, aga kui sa päringud kirjutamist, siis saadaks suuna selleks, kuba teed, et sa teenustas, mis suunab aina siia-sia. Eest on siis üks viistkudes skaleeride Postgres siin imod, et ei pea siselmisel TG shardima, ei pea väga keerulist replikateerimist tegema, aga võimalik hästi hea lugemis jõudus saavutada, kui ei ole vaja, nagu võib-olla reaalast karatiid, et kui siia midagi kirjutatud, siis kolmas server, et see ei vastaks stail või natukamaana tannetega. Ja kõik Anne-pallise Anne poikakse siis persistav monumis ja saadastatakse kas kettale võrgukettale niimoodi, et seda pood on tubatud ära kustutuda. Kui see pood kustub, siis ta enne päringu töötamist alati kirutab nagu Praetahedlogi, siis see tulevad päringed enne kui tähed töötamakad, niimoodi, et kui ta ära tatad, seda uuest üleserb, seda vaatab logist, et mis oli kooperatsioonid, mis hetkel oli käimas ja enned uuest läbi. Ja see on talas, et siis ehtedud kõikides pilve põhiste Anne-baaside, tarpvärase, et sellist Praetahedlogid, olguned siis näedis Kafka, Sõnumitehaltur või Anne-baasid, et tihti tehaks juba seda, et ma saan päringu, kui jõutan enne sile kettale, nii allest sisakansa töötama. Või ma proovin seda paraleliselt poimse teha, aga tähtisane, et alati logi olks olemas, et mis oli see operatsioon, midama hetkel täida, või mis operatsioon on täikis järjekorras. Kui totsas ära tatad, et seda oleks lõimendada uuesti logi vaatama, et mis oli täikis, mis veel ei ole tehtud. Mis võib-al on problem, siis kui, mida kooperatioonis väga hästi ei ole, et mis jõutub siis, kui siin hakkab, et see tegema snapshoote ja backhafte või veel hullene backhafte, et mis siis jõutub, kui keegi proovib selle procesi ära tappa või poodi ära tappa, et seda on tullu aske nagu kuperneeteses kaitsta ilma eraldi komponentina, aga selleks on kuperneetes olemas kuperneetes operatoris. Kui te oled meist huvides, siis võite lugeva näiteks kuperneetes Postgres operaatori kohta CloudNativePG näiteks, et CloudNative Postgres tema tuodab operaatorit. Operaator on selleks komponent väljas pool, teid mikrotenuseid, kes võtab üle kuperneeteselt Postgres plastrite halluse, niimoodi, kuperneetes ei kustuta otsa poodi ära või saada pärin, kui meie operaatoreid kustuta pood ära, ja siis meie operaator on vastutav sellest, et kuidas see kuna pood, ja kustud võtab teatud funktionaaliselt kuperneeteselt üle, et hallab ta selleks, et kastamressusse nagu Postgres plastrite, et kui tead selleks kubik, et saada lugeks seda kohta. Aga Postgres iga palju rastgen proovid ja implementeerid seda, et meil on reaalselt write replitseerimene või et meil on mitu write nodeid, et pigem tehaks see midagi sellist, et meil onki üks write node ja ülepeeg teised on read nodeid, ja see listustab tohutult tegelikult selle hajussustemi anmebasiehiitamist. Ja me taame võib-olla lihtsalt karanteerid, et siia on kõik pilutud, et see on võimalikult kiiresti, et anmed synchroniseerikse. Siin, et see replication manager onki see takvara, kes siis politseb sellest, et anmed oleks hästi kiiresti synchroniseeridud nendama. Aga põhjelisted nendest paelidest, mis siin on, on enam vähem kooki, et mida reaal aja soib, et see süngik, et nad ei sisalda erineva tanne, et väljarutas kõige uuema tanne. Ma võib-olla see root 53 väga palju ei räägi, selle ei tea, et see on pilve sisemine DNS, et see võimalatab reaal ajas kirjutada üle, kuidas anmed suunateks sa DNSi tasean, et kui teile on mingi mikro-teanuse nimi pilves, mitte näha kuperneetises, vaid teie klientid ühenduvad selle adrese, mitte appi-adrese, mikro-teanuse adrese üle, et kuhu virtual machine-outesse, mis regionidesse anmed suunateks, et kui teie tahaks seda suunata näiteks, Saksaamal oleks klientid Saksamaa, Soomeks oleks klientid Sooma-Anne keskusesse, kuidas te seda teete. Pilves ongi järalti nagu TNS-teenuse, kus te saate seda konfigureerida, kuna suunatakse ümber, siis sisse tulevad päringud, ja kuna DNSid tegelete sellega, et mis siitke vastab, mis osneile, siis sellise pilve-TNSi taseame saab seda suhtselt kunaamise teha, kuna pilveväliselt DNSid, mingis teeneeti-TNS, ülikool-TNS, Eestisasol teised TNSi serverid või Google TNSid, nad on susta aga, et neie real ajal see on väga jõunest, vahe asju ümber muuta, seal on suuret käsid vahel, serverid, ruutereid käsivad neid asju ja et mitte ülekoormata neid, et kus Google TNSi, et iga sisse tulevad päringud peal teha uuestisevik TNS-päring läbi, see tapaks globaalse Google TNS-heikse arangil, kuna on väga palju käsimistakasutus, siis kiiressi meie asju teha ei saa. Aga pilve TNS-teenuseks võimaldovad ülejät kirutada need reeglid, et kui tuleb mingile hostneemile päring, siis kuhu IP-aadresel saata ja see võimalda siis ümbersuunata sissevavad päring. See võimalda ka nagu lantentsust halata, et kui lantentsus mingis serveris mingis agioonis on liikav madal, siis sa hakkab TNSid asemel tegelikult ümbersuunata liiklust, et see teoreetselt on võimalik, et ima kui ka päringed teha suutimist rea läheb teha kui mingit serveri enam ja aasta. Sisu edastamise mõõrgustikud, kas te jääta, mis nad on? Vahe hässi, aga siis nagu mingit on mõtumata tonnet jaoks. Jah, et saa poodi nagu me Asure, seda on võimest, et Asure static filesi kasutasin, et ma panan üles mingi HTML-fileid ja JavaScript-fileid, aga seda tigki kasutadoks ka piltid ja videofileideks, et selle aseme, et teie Flask rakendus-serveri piltifile ja saate need piltifileid vallalised pilve, et S3 Asure file löidesse ja siis suunate ümber kasutaja mitte enda rakenduse peale piltialatamata vai pilve piltialatamata. Neid oma HTML-i panate pilgilingid S3-est, omas on S3-est või Asure filesystemist, et te panadete täitsa Asure linkid sinna ja siis neid pilt enam ei pea alatõmbama teie virtuaalmasinast, et teie ei pea enam piltid alatõmbamise, otsena serverima neid, teie targvara ei pea vahendama neid piltid, teie virtuaalmasine ei pea kaile vahendama, et teie virtuaalmasinana vähem tööd, et teid piltid tõmadakse pigemagu globaalse kihist alla. Ja mis on näende elis, on veel see, et globaalsed siin on edastamise võrgustikult, nad saavad, aga anmeid lasted kasutatelt tõmad alla kõige lähemal asuvast anmekeskuses, et neid isekasutad kaasada TNS kihsti, et optimeerida kuhu üheneda kasutaja, kui teed pärin kui mingi pilgi peal ja vastavad selle, et kus tuleb kasutada pärin, saad nagu ümpeal suurate kasutajad kõige lähemal asuvasse serverisse. Ja üks kõigi suuremaid võrg, kes seda kasutab, onki Google Edge Network või Google Air võrg, mis pealised teedat juub tubi jaoks piltide kasjimiseks, mitte piltide vaid videode kasjimiseks, sest YouTube video kasutus on nii suuret maailma internet, mis saate ei elaksada üle, kui kõik peab tulema otsa Google Amna keskuskustest. Ja Google samas ei taha jälle anda lokaasatele IP- ja internetiteenus pakkujatele luba, et need videodid kasjida. Nääli steli jaale ei ole enda luba otsustada, kuna kasjida YouTube videod, kuna alab jõmaga. Sest seal on teatud tähtsad otsustad, mida Google tähtsad tead tegema näiteks. Kui Euroopa Komisio nõuab, et mida video maha võites või tuleb mingisugune TN-100A strike, et tuleb video maha võtta, siis Google tahab, et tal oleks võimalustada koha maha võtta, võite, et see oleks käsitud kolm teist tundi kuskil telia serverides. Aga kasi, kas Google saab seda nõuda telias, et nemad nii käsiks seda? Kui sa oled telijat, siis sa tead tema vabaselt esitev või mitte? Nad saavad ja nad tead lepingud selle jaoks. Nad võib-olla ei saa keelata seda, aga kui sa oled telija, siia sa tahad käsida, et sinu internetüüendus Google'iga oleks. Ja telial oleks motivatsiooni rohkem käsida, et vähem internetüüendus oleks vaja üle globaalse interneti kasutada, mis nende jääb laht kaelliks maksama. Põhimest, et Google tead lepingu kõige nende. Ja põhimõtteliselt ma ei tea täpselt, kas nad on võimaliselt, kas ta kudagi reaaselt ka füüsilist või tehnilist keelama, aga põhimest, et selle asemel, et lubada neid käsida, nad põhimest keelavad selle ja siis tead nende ka lepingu, et kuidas see käsimine põhme. Aga käsimine toimub. Ja et käsimine toimub peli. Ja natuke ongi see, et tänas sellega paari slide ideet visualiseerid, kuidas see toimub. Et Google jaaks on tegelikult hästi tähtis vähendada seda liiklust, mis toimub Googlei anne keskute ja inimesed vahel mis need videost vaatad. Ja Google on ehitant siis globaalsse sellise eesnettvörgi, kus keskel on Googlei anne keskused ja Googlei internet. Kes, et siin järgmises kiis on Googlei internet ja välis interneti vaheliselt sellised väiksead anne keskused või stationid. Et see siin Googlei routereid ja anne keskused ja siis kollases alas on partnerid, et näibks Telia ja teised sellised suure partnerid. Ja idee on, et on seda põrku võimalik kasutada siis Content Delivery Networkina, kus võimalikult lähedale tuvaks nagu Anmatt Cashemine Anmatt Delivery. Ja vähele on seda, kui ammed omaat ammat, et võimalikult vahel reaaalat ammet tõmmaks üle interneti Googlei anne keskustes, kui vähegi staativiselt ammed on millega tegu. Googlei anne keskused olid paar aastat tagasi sellised, mida võib-olla juurde pannud, et Suomessa on üks, Euroopassa mitte, Amerikassa paidi juh, Siin on üks, siin on paa. Ja nüüd on kindlasti neid juurdega tundud, et ma unustasin sehastada seda pilt juuandada. Aga see on ikkagi suurselt kaugel inimestest, et on püldus esiteesti sellised tentskonad võib-olla nagu ära kaad. Aga mis Googlei anne? Googlei anne on internet ise eitatud, internet nende anne keskustel vahel ja Googlei anne isegi creeper kaad, mida lähevad üle või all, ofiani alt läbi. Ja Googlei anne on sellised oma anne keskuste vahelise interneti ja välise interneti vahel on sellised ümper lülitumise kohad, kus lülitad ümper. Ja on eradesest väiksemad anne keskused, kus ei ole nagu neid olema pilda anne keskused, need on sellist vahe anne keskused, kus saab samuti Googlei oksata oma tarkvara ja serveerida. Ja need on paegutatud sinna, kus on nagu kül vähem piha asust, kus aga ikkagi väga palju inimete elab ja katab suurem osa Euroopast ja Põhja-Amerikast ära. Aga muja on võib-olla nadk vähem. Aga ikkagi meil on inimestin näiteks suurtes linnades. Eestis ei ole sellist, on tõmest, see on St.Peterburg, see on selline, kus Soomees on sanda keskus. Aga kui Eestist videoid, Googlei videoid vaatakse, siis ikkagi oleks parem, kus see käsinne toimuks suhtselt lähedal inimestele ja konteltele, liverit toimuks ka suhtselt lähedal kasutadele. Et Google teebi siis lepingud siis teenust pakkujetega. Muha juba üks piltselt puhulub. Kontrollin kiiresti, kas see piltselt on muid tegelikult olemas. Aga kuidas ei näidatud juba mingi esimest tegelikult juhu? Samul jaa millegi pärast ära peidetu. Ma panan on haid sellel, et siis panan suursti linnad. On selline. Ja panan ka zoomista uuesti. Aga ma millegi pärast panin ka zoomist kord kinni. Maan siis selline. Jah, ja Google teeb siis lepingud sellist interjete teenust pakkujetega. See vahe on ikkagi suhtselt hiigel suur. Eelmise slide ja sellest slide vahel. Et see on siis Google Anne keskused. Need on neid Google Switchover stationid. Ja siis need on neid partnerid, peenutpakujad. Kes teebad siis lepingu Googlega. Kuidas see toimub on tegelikult? Põhjumist see näiteks Eestis, kui me sisse zoomime Tallinnas. On näiteks üks teereus pakku ütlema, et sa võiks olla telija. Ja telija teeb Googlega lepingu. Ja pakub väikest ruumi oma Anne keskuses eest. Google toob oma rakid ja servidid kohale. Tühendab telija võrpu. Ja telija suunab YouTube ja Google TNSi päringud läbi selle rakid. Need kuglid on oma mini Anne keskuses telija ruumides. Kus on telija? See on siis kõikid suuremades linnades. Ja isegi väiksemades linnades, kui nad on piisalud kaugele erinevatest Eestis, Anne keskustest. Et see kandab väga suure osa kasutajad ära. Ja peamasest seda kui kasutad see YouTube jaaks. Aga kui Google tahaks näiteks Content Delivery Networki pakku oma pilve jaaks. See on kõik need kohad, kui ta saaks käsida pilte, videosid ja need. Ja idei ongi siis, et Google kontrollib 100%-iliselt, et kuna kasutaks YouTube videosid, kuna on nende tarkoare jaoksad siis ja kõigi ISP-te peale maailmas on nende ka lepikult tehk. Ja täna sellele siis Googleil on võimalik pakkuda sellised siigel Anne mahtu vajalikateenud, nagu YouTube-us tooltub palju videoid vaataks. Ja kui kõik ajaksid üle hitereet ja Anne keskustest oma videosed alla 24 tundi ööd avas, siis see läheks, toobaks interneti põhmes koomast. Aga miks siis obi Googleile see juhud, mida see ongi, siis kui ma aavetaks pooleliselt indivüete saada, aga kui olib siin mängas käsimisele kolm? Siis lüüta saab otsa oksustada, et see käsimise kusutaks hara, et saab see koha välja lüüta näiteks teliaserverite stalinud. Ja mis on pilnud nagu täpsama? No ongi, et miks neid seda või olema, aga miks naks seda soovidoid? Sest näile nagu kohustus näiteks midagi maha võkta, kui tuleb avaldus, et näiteks see vikkub mingisugused, ütame, laulu, autorõigus on pealseli. Aga siis nad võtsid selle maha, et enampähem kui näiteks ongi, nagu näites pakkungi siin arutis ideavaatumust eenust, tuleb palju mingi video, aga tuleb maha võttu, tuleb peal maha, aga minu mõni vaataja tegi sellest ente laujutust koopa, et saaks õppu ei vaatud. Aga siin on kõik minu prodeeni. Aga muidu jääks see teli ja koop erendis alles mingi tiis peteemist pakka kuhu käsjudesse. Kui Google ise seda ei teeks ja laseks käsjida, siis 3. osaportel või nende nendel. Et Googles on kindlasti oma anne keskustas selle maha võtta, aga kui ta ei kontrolli seda, et kuidas käsjutaks see kunanat käsid kustutult, siis ta annab seda kontrolli oma ka seda kõra 3. osaportel. See on pidevselt võtta. Aga kas ongi seda kontrolli neil vaja? See oli lihtsalt üks näite, et see ei kruugi nagu kõige peamine olla. Teamine pohjuus, miks nad saad teha ta oda, on minimaaliseerite, ku palju anmeid on üle interneti vaja saada. Et see anne maht lihtsalt oleks liiga suur muidu. Aga see ei lähega seda, aga see ei ole lihtsalt ISP-käsj. Või malik, aga see ei kruugi. Ma ei tea selle täpselt põhjust, miks ta tehniliselt oleks suurem problem, kui ISP-sad isedevalt. Pigeme, et nad tahad kontrolli oida, nad võib-al tahavad saada mingit tarkvarja ostada, mis paremin oskap seda käsjimist teha. Võib-al see ei ole ainaid käsjid, nii maid ka kui tagi optimeerinud, mis mingisuguse kvaliteetiga näiteks videosid edastat resa kasutajal. Et neil on tarkvarja, mis põhjumatsalt sõpselt sõpselt erosasuttsiooni või mingisuguse pitk reibi vastavad sellel, et mis kasutajal koordioon. Ma täpselt ei tea. Aga saad selle kõrta juhtu lugele, kui see on uidros. Jätame ülejäänud teemat siis pahele, kuna ma arutasime, et pärast seda oli mu servismest tema. Saate siin viltinud ka vaadata, kui ma ühtpan seal lõpu. Oli kõrse tomaduse, millest ma räägin siin järgune nädal. Järgmises praktikumiseks see näda arendam edasi oma mikrotenesta põistrakendust ja teenata täiesti pilvepõiseks. Olge sellega ettevaatlik, ärgele järg, kes seda liiga kauaks jooksma. Aga seekord on nõu, et anna te meile teada, mis on teie webi link oma rakendusele. Põhimiseks, mida teht, saad ka mulle e-mail pärast esitalist ja ma kiiresti vaatun selle webi linki üle, et ta töötab ja sanan tagasi, et võite maha võtta. Võisil ma hinden osaliselt teie laenduse ette ära, et ta töötab ja siis pärast seda ütlel saada maha panna, sest te panete üles konteinerid, te panete oma kaks aapid konteinerid ja kauaks see maksab, et seda ei saada asuta jooksma jätta. Et see kauaks läheb pärast maksmani, et parem on, et pärast esitamist meie kontrollime kiiresti üle, sest te saadu tagasid, et saad ta ma rakenduse maha võtta. Ma võib olla ei hinda teie praktikumilaendust ära, vaid vist sanan peale pead, et see osa teil on korrekke ja siis praktikumil jõuenda vaata kiden teie poodi üle, aga esialgu me lihtsalt anna tagasilt, et teie rakendust saad ka võtta seda maha võtta ja siis paned see hinjate enam kõik viipi kadutama. Ja järgmine loeg siis toimub eksami korralduse loeg, kus ma seletan, kuidas see toimub hakkab ja rääkin ka üle selle näite küsimused ja on selle konsultatsioon, mis teie saada küsimusi küsida ja siis teises osas teeme sellise aine kokkuvõtte, kas räägime, et temad üleminest tähendada ei ole taega ja võtta me kokku sellised eedised ja puudused kõik teemade kohta. Võtta me kokku ja võib-olla mõned teemad peale aega jääb, rääkime nagu üle, aga kuna tänaseks toonadust ei natuke väeg, siis teasalt katame, kui siis mõned teedised ja puudust teeme selle rikmasjile. Aga ongi siis kõik tänaseks, kui küsimusi ei ole ja see praktikum siis on viimale, et järgmine nädal enam praktikum ei toime. Taan!

---------Loeng 14 - Aine kokkuvte ja Eksami info.txt--------

 Tere, tulemast viimase loengusse. Tänna rääkime eksame korraldusest loengu teisel poolel. Aga loengu esimesel poolel teeme üle aime teema kokkumõtted, mis ka on selline natuke rääkises seovatus. Mis teema on, me edes tulevad sellist teema üldime ülevaardele teanistest teemadele. Varesemalte olemme rääkime terineotest mikro- ja pilvetehnoloogid arktitektuuridest. Ma kann atukene loengu alguses toon veel mõned näinud, et nende arktitektuuridest. Rääkime üle mõned mustil, aga suurem osa esimeses osasest loengu läksist teemade kokkumõttele. Siis ta vaatame üle selle eksame korralduse reeglif. Ülda etse oleme eksame korralduses muutnud võrades esimesel loenguga, kui ta on esimesel loengusmaihmise. Ja kenu üle ka näite pishimuseks, mis tegelikult on olemas kodu lähele, aina kodu lähele, nii et need midagi väga uut, sõidesemate see ole, võib-e, et neid slideid lahavad üles, saate uuesti neid vaadata, aga näite pishimuseks on kodu lähele liigult juba olemas. Aga siis iga rääkin, et millisega vastuseid mina ootame, kui ta lähe näitad mende vastamisele. Vastamises suuesti mõnda mikro- teenost arktitektuurid mustrit ja võib-e, ka natuke pilvekortekstis, et kui me ei ole juba praktikumisloonud sellise täiesti pilvepõise mikro-teenost rakenduse, ning tegelikult ei ole kõik nii komponent veel kasutmusele võttud, aga selline kütiline mikro-teenost arktitektuurine rakendus, eritellisena appis arname rakendus näed lihti välja selline, et meil on lihtsalt selline klientis. See klienti tarpvara võib olla fontaine, mis sooksad kusagi. See võib olla nii miski appi klientid, kes kasutavad meie mikro-teenostseks või appisids. Meie kontekstis me hoiame oma konteeliseltise saartilise tisuna, mis asure saartlik app service või asure saartlik application teenusel. Ja need jaavastud ja maatame kvalit, mida me siin ülespannime, et tegelikult jahaks kasutavad teile, kui me vaatame kasutlendibrands, et kasutajad ja kasutajate broussereid teaksid üle selline Content Delivery Networki käte saadale kasutavad teile. Kasutavad te broussereid, siis õmbavalt, et need jaavastud ja haata veel failid. Siis alla webist ja asurets serverid näib sellise Content Delivery Network kaudu, et võimaldades lende failid ja võimalikult kasutavad teile ja lähedalt tohumisela, et saaks pigem vilve teenust paka optimeerida, et alate ei tõma keskustseks anme hoidlast või anme keskusest, vaikse nii lähedalt kui võimalde kasutatavad. Ja siis võimalde jookseb frontend kasutajarutist ja kui kasutavad teile nupudel, siis käibid jaavastud ja jätu kasut, millega kutsutakse välja mingida appu metodid. Asures on sisseheidadud selline appi gateway, meie appid, mida me üles seame teenustele on nevad saavad, et need on hostneimid ja üle sellise keskse asure appi gateway teenuste, et hostneimile tulevad ATTP päringut suunatekses edase õigritele, containerestele, kusagil asuresees. Ahas olis me saame isekonfigureerida need appi gatewayvõi siis, kui me tekitame oma appi kusti kuberneeteses või oma serverete peal, siis tavas me saame ise oma appi gateway ülesseama. Tavasalt kasutades näite, m.g. nixit, m.g. nixit, selects või mõnudu besta arkvara, Gadji vist on kõikks näendas, need on päris palju, et selliselt appi gatewayvõi preveest proxy, et kasutadaksed, et internetest tulevad päringut, siis suunata edase õigritele teenustele. Meil on kõik sisse logimine, piltit, nagu ramadud allatõmone kõik on nagu avalik, et meil nagu enaldiselist sisse logimist ei ole vaja, et meeldam, et suvaliselt kasutavad saavad meie rakendust kasutada ramadud allatõmat ja nügega, mis võib-olla ei ole hea ja selles haines võib-olla ma tuleb, et mõtlen sellepäele põdas siia, et sisse logimine ka veel juurda panne, et me seda ramast röörida, kuidas seda mikro-teenostada asjame lehteda, aga see on üks näid asju, mida meie mikro-teenostave rakendust ei ole. Et isteme enaldiseliselt mingisuguse teenuste kalduse kihi ka, et kuidas see hallata või leida. See ei ole tihti probleem nagu pilves, kuna pilves servistis kaveri ei hallata teievalt tere, aga näiteks kui päris näete, sest tihti peab panama teenustele hoidid nimed ja siis liiklusi ja teenuste vahel märpima, et millise sisse tullama teenuste nimel linnise kontainereslikkast ümbersunat, et see pige on toimub, kui peab keskselt ja alapäe teiepol, aga kui peab reeldises natuke lisad öötega, ma sa lähen, et sa ei ole teha. Ja siis on mingisuguse päliseid mängisid teenuse, mida kasutad meie puhul on, et asura ja file storage akoundid või mingisuguse tannebaasid, et osad teenused kasutad mingi päliseid teenused. Manest teises haid, et me oleme nägisid video teenuse kasutad, et saada SMS teavite siin, siis video, aga see on aga mault väline teenus, mida mikro teenuse kasutavad, et mingit selle funksivaasut partole. Ja appi keitvi andu sinna mustered ja paneme siis väljismaaima, et meeltidu mahele ja meie mingit mikro teenuste mahele, et see kesks vahepealise kihi, kes vastutav sellest, et milliselt ja milliselt suurad, siis sa tulevad pärilid kuhu suurata. Ja see tada meie mängisid tegelikult teist pead jääta, kus asuvad mingisugused appid. Ja tegelikult väga starti teitvedi kasutamistime frontendi kirutama tegelikult kahe mikro teenuse adressi, et raamatu otsingu adressi ja raamatud halduse adressid on eraldi ULL-id, eraldi hostneemid, et meie tegelikult ei koonda seda kahti mikro teenuse, nagu üheks hostneemid väljaskutvaadates, aga näid asured asemel me saaksime teha edasi suuremised, et paneme näid oma raamatud üldise rakenduse hostneemia, siis automaaltelest suurama vastavad, misugust saavad otspuksile, et tuleb päril, et kui on raamatu toitsingu, otspuks saavad ühele appile, kui on raamatu toitsingu, otspuks saavad teisel appile, et meie appi tegelikult kasutus oli võttud, et ka koondaks nagu kõik appid ühe hostneemid ahapäitub, niimoodi, et kasutai näeks näbis oma jalastrit või Hateme rakenduses või Moabidi rakenduses, et mis suurmist appid mis nimega kasutadaks, et sa appi kaid peale aisteleks ära peita. Aga appi kaid peale on teised sellist functionalselt sisse heitadud näiteks. Amazonis saab panna kõik, mikro teenusest rääkima, JSON dokumentistruktuurid, et ta võtab vastu JSON struktuurid, aga kui me talame, et mindisugune rakendus näist mobiliis oles võimene XML saata, siis Amazonis saab ka konfigureerida, kuidas XML ja JSONi vahe konverteerime automaatsil käib, et kui on mingi vajaluse, et teatud klientid saaksid JSON asem jahe xml kasutada, nii saab appi kõik või ära peita, kes nende korbaatid automaatsi konverteerimist. Amazonis on see täärist nii kasutada liidesest ja webist konfigureeritav, et saab sellise JSON ja XML templatele uue, mis on kõik põlmiseks vajalik. Kui näites, on mingi väline klient, kes tahab liidesestada XMLi appil ja teid on appi ehitadud jahe jahe sellisele JSONi, ja siis teid teada, kuud uud appi teidama hakkamäe saate, et Amazoni appi kõik või tasemel muudatud juba teha. Siin on teelüks samas kui inti senne visulatsioon, et meil võib olla ka mingi speciaalne metod, me tahame, et kasutaja saaks välja kutsuda mingi appi metode, jahe sellise suurema funksionaalsude mingisubuse tootostmine. Aga tootostmiseks on väga välja kutsuda kolme teenust jälestud, kui servisaal, servis V ja servis C, aga me ei taha, et kolme teenust kutsuks välja kasutaja HTML lähelt või JavaScript või mobiirakenduses, ja me ei taha, et kasutajad teabseks kolme erinead mikrotelist, et siis appi peete tasemel saab ka teha see mikrotelist väljakutsuda apprepetioona, et defineerid, et kui tuleb jätud otspultile päril, siis kõigevalt kutsutaväile mikrotelis A, siis mikrotelis B, mikrotelis C ja P ära, et niimoodi käividataks kolme mikrotelis kasutajad, et kasutan näed, et see kutsutaväile ühe metodi, aga siselnud seal kutsutakse väljakutse kolme erinead metodikustuse järele, et kui kõik on edukad ja ühtekerrad, et ei tule, et siis viimase ja teenuse väljakutse ja väljumpäe tagas kasutale saab ka teha sellist mikrotelist aga kaotareid, et defineerida logite, et mis järekoreid ja mindiselt nekrotelist tuleb väljakutsuda. Sõna saab teistmoodi ühe teha, et me saaksime teha lihtsalt ühe mikrotelise, mis oma korda leid kolme mikrotelist väljakutselud, aga mõnigult on parem, kui me saame sellist väljakutselolgiturt defineerida pilved asemel, niimoodi et me ei pea oma tarkvara selle, aga selle läks loom hakkama, et asures on ka selleks eraldi logic apps ja Amazonis on eraldi step functions, kus ka saab seda pilved aseme defineerida, aga mõnigult tehaks seda ka appi kõitveid teenusest otsenud. Üks asi, mida me ka me ei ole selles aeges vaatanud, on selline eriti kuperneetises kasutuses olev selline vuster, mis on kõrval kärv või sidecar indiskeeles, kust me loomme kuperneetise konteinerime poodid ja me loomme oma sellise logika või pisas logika konteinerisime sisse, mis näiteks implementeeri midja. Aga siis tegi pajaadus, et me sooviksime mingid lisadvuksinaasust sinna mikrodenduses juurde panne. Me soovime, et automaatselt tõmataks alla mingid konfiguraatsiooni failid või uue koodid kustki kitis ja automaatselt muudetaks mingid faili systemis, kus me ei ole rakennus osub. Meist tegib küsimude, et kuidas sa implementeerida. Kas me peame, et see koodi muutma, et koodi akaks ise pollima kusaköötafaili või ta ainult teedab, et ta saab meil faili lugega ketta, ja me paleme selle kuperneetisest poodidisse kõrval konteineri, mille üleks on ongi kusaköötafaili poolida mingid muudatusi ja uueldada leid faili systemis ilma, et me peaksime konteinerile või pood, miden aga restarti tegema. Ja siis ongi võimalik, kui peame teise konteineri kõrvale panne teised konteineri ja implementeerida mingisugust kisafoksionaalist. Siin on näiteks logifailide puugi saatmine, võrgu võenduste kripteerimine, sertifikaatide haldus. Kõik sellist asju saan panna meie mikrotenusiste mitte, koha nii muudas või lisakonteinerite lisamseva, kelle on õigus samat failisest feeminaga muuta. Ja näiteks meie teenus teed endale restarti, või vaatame meid sertifikaadiofaila, näiteks kledi sertifikaadiofaila kuske kaustas. Ja siis on kõrval teene konteiner, mis valmista vette ja või tõukab meid uusi kledi sertifikaadiofail alla iga natk saadaga. Kas siis põks seda suhi programmiseed, aga et me ei hoia asju mälus väga pikkad, sest muidumelt midu päeval võib olla võib olema? Ja, sellised juul jaht tõest, et me ei toivse sellise juul, nagu hoilda asju mälus, ja me ei toivse sellise juul võib pole kai eeldada, et kegid, et meil restarti iga natk saadaga, poid pigem meie parkorop peats olema võimelne refreshida mindi kausta näiteks. Ja tiftis aga on, et meil on näiteks mingisugune kledi sertifikaadiofailide kaust ja meie rakendus, siis lissalt refreshimsta kaust ja vaatab, et see saa eksisteerid ja ta ei eelda, et tal on nagu jooks mis ajal mällu loedad kaustusisu ja siis ta ei nõud märvust vaatab, et see paail eksisteerid on nüüd. Ja tiftis ja takasutavad ka niimoodi, et paljas saikas ja välise tühenduse ja mikrotenuse vahele, niimoodi, et mikrotenuseid ei pea välis ta tühenduseks mitte midagi. Tema näiteks kuulab sisse tulevad välikult mingi porti peal, aga mingi teine kõrval, pärud, konteiner, sest koolitsib sellest kõrvas krypteeride sisse tulevad tühenduse ja saab kripteerimise panna ka kõrval konteineri halata. See on siis service mesh list kui paneele keses kasutuse. Ja miks see nagu hea on, on see, me saame oma sellise konteineri Tarkvara demoa lihtsama ja meid kõrval kärvud tihti ole Tarkvara, mida meie entame, vaid see on iga kindist avatud lähtekooliga projekteid, miski sest võtta. Et me tõstame üle, et Tarkvara, mis oskab setil kaatavalat, me võtame Tarkvara, mis oskab logifile huumi saata, me võtame Tarkvara, mis oskab kitist pollida ja need komponenteid tihti tulevad kiin juba valmis oltate box lahendustes, mida saab sinna kõrval list panna ja installida ja siis meie ei oma mikro teneest midagi implementeerida tälle. Aga atuke seda tuleb arvestada, et meie mikro teneest on paru saama, et vahepeal ei tuleb võib-olla mida, keda põstada. Meie ka kasutasime suuresti selles ainest lähenev, et kui me jagasime mikro teneest kaheks, siis neid kaks mikro teneest kasutasid sama anduas. Selle ka väite oht, et kui näite üks mikro teneest midagi muudab ja teine mikro teneest on sama lajal ka midagi muudab, et neid ei ole väga isale eeritud, kuna nad mõjutaad üks teste läbi selle hanmebasis struktuur. On kui küsimist, kas igal mikro teneest on oma hanmebasis ja tema on ainult, kes on vastutan näiteks raamatulte failide haltuse eest. Ja ükski teine otsa hanmebasis raamatult sisu ei muuda, raamatulte list ei muuda ja kui on vaja raamatult alatamata, siis neid küsimid eesemikro teneest ja kõik raamat. See on üks polnus ülesne liimas praktiutumist, mis me natuke muudime, et enam ei oleks raamat otsinud, kui mikro teneest lõigust otsa hanmebasis raamatulid võtta, vaid ja teha küsima üle appi teised mikro teneest, et anna mulle raamatul sisu ja tema anna küsimist raamatulidee või anna mulle raamatult nimekiri. Ja siis me peame ainult ikkuna teereme jõuja mikro teneest ja see, et kuidas hanmebasis raamatulida nimeküia saada, kuidas raamatul sisu saada. Ja siis on see äri loogika täiesti eraldatud, et me ei pea ikkuna teereme siin mitu kord, et kui ma muudame ümber kosmust, asure file storage ase, me katsutaan mingi teist hanmebasi, siis me peame kõikki teist mikro teneest seda muudma, et kuidas raamatulide failiast käette saada. Ja siis on see loogika parem nii eraldatud, aga mõnikõttel lihtsam enitada appisid ja niimoodi, et me annan õigused, et mitme mikro teneest saada hanmebasi lugevad, siis nad ei ole hea, mida jõu üle võrkul oma vahel pärinud tegema, et saad otsa hanmebast asju vaadata, et mõnikõttel see on vajalik ikkagi, et me jagame hanmebast, mitme mikro teneest ohjadud. See on kõikki teist, et see, mis aal on, on oma hanmebast, see, mis tead oma hanmebast, aga see on lihtsam see, et teed hea, et tead hea, aga me annan õigused. Ja siis nad saad kiireli andatada ühe. Ligi, ja see on kadulik siis, kui on väga keerukad, täikest mingi pärinud, mida TNC ja TNC teevad, et siis ei ole ka hea, et igakoltu TNC jooksevad, on vajaga TNC pärinud teha, ja järgituse on viitum pärinud, meil on vahel pärinud teha, on ikka võib palju pärinud, et me ei tee ülega kaasa võrfu liiga palju pärinud, et siis annan mõlema ligipäe su sama hanmebastile. Võib-pal on siis hea, kui ainult üks näites kirutab ja aga mõlemad poemaatud, et vähem konflikte tegid. Ja me võime ka sellist mikro teneest ja näile kutsus, aga keerist vaadata kaad kahel viisile, kui meil on näiteks mingisugune teenus, mis tead väljakutsuma, võib-pal saab palju selgiks. Nüüd see on meil mingisugune teenus, kes loob uue kasutaja. Kasutaja loomise on vaja võib-pal aga teistest kolmest teenusid ei olegi muundud. Näiteks, kui me loome kasutaja, siis see kasutaja loomise teenus, siis ütleb väljate point 7 sile, et tuleks looa mingisugune baas, konto, 5000 punktiga uuele kasut. Või siis, et tuleks saata kasutajale sunum. Ja et tuleks ka veel, ja et tuleks ka kasutajale sunum saata e-mailideid, ja siis tuleks ka mingisugune post, näiteks mingisugune väike näite product saata ka kasutala kojuet tervituseks, et me saadaan mingisugune komite ütleks sellist ma ei tea, mis seal on, aga. Aga siis on see teenus, kasutajat loomise teenus nüüd vastutab kõige sellest, et tema päris väile kutsuma need asjad, ja siis tegib see probleeme, et see on väga sõltu. Mis toimub siis, kui näiteks loyalty point sellise maas, kas me saada kasutajat looa? Kui failid, näiteks selle loyalty point teenusele pärin, kui saad mene, mida ma peaksin kasutajal loomidele tegema? Kas kui tegib pausile panema, kas seda mitte tegema, et kui ta sõltub sellist asjad, et ta peaks välja kutsuma midagi, et kas me saame lootsa, kas me saame siis eeldat, et kasutajal loomine õnnestus, kui me ei õnnestud, näiteks loyalty point service teenuset väljakutsu. Ja selline orkesteerilne, kus üks teenus on vastutav, et ta kutsub mingis järgiselt teenuset väljateeg, mingiselt tegevusi, et see tegitab, kas just pudelik aalata, tegitab äga suuret sõltus mendevaal. Mõnesmõttes on võimalik tegelikult kasutada pigem koregraafia lähene, mis orkesteerilja tööte kultud, et meil on või orkestaator, bändi ees, kes kõigil näitab, mida teha, koregraafia on pigem see, et meil on nelid tansijad ja nad ise tansivad ja keegi juhi näid keskselt, et on pigem hajutatud juhtimine, kus orkesteeril on üks orkesteerilja, kes juhi mingiselt tegevusi koregraafia, nad pigem tansijad isel eevaad midagi. Ja mikro tehnosta maailmast on see, et me loome kasutaja ja me loome kas sõnmuse, näiteks kuski rääbitiselt, loodi uus kasutajal. Ja me paneme need teisele kolm teeluseid lihtsalt kuulaama need sõnmuseid. Ja nad ise otsustavad, et kui midagi teha, kui on uue kasutajal loomise sõnmus. Ja nüüd enam, nagu see kasutaja loomise sõnmus, teelusei peab üksse teada, mida peaks veel tegema kasutajaloomisel, kas peaks mingi tiimeli saab maailmite, kas peaks midagi muutma, lõveliitipoints tehnost oli mitte. Tema lihtsalt loob kasutaja ja tegiselt sõnmuse uus kasutajaloogi. Ja kes igares ole huvitatud selle sõnmuse, ta kuulatast nad uutni sõnmusi kas olul, see kas siin andre, vaid siis sõnumite järegulisemõal. Ja sellega me ei enam, ei teha see tehnost teadma, mis ju toimub pärast kasutajal loomist kui lega muuja. Ja see vähendab ka sellist, nagu onse kahe teeluste vahelist suhtkuse vajadust ja ka seda, okei, see oli maastunud seda uuen, et kasumub kas see teeluste taks uuesti mida korda, mitte korda ta täht seda kordama, kas ta peaks seda kordama jääma, nii on ei edasi. Et mõnikord on parem selle tõttu tegitada nagu tööde järekorralt või sõnumite järekorralt ja tegitada sellised sõnmused, kus sa sõnmusted asemist defineerid, et teadad sõnmuste, kuhul peaks ningid operatsioone veel välja kutsma. Ja see vähendab sa sõltuvust nendel, näida mikroteenuse oma vahelist sõltuvust. Ja võib-alas siis siin tuleb defineerid, et siin jääb see sõnmus alles, kuni teadud stüntid, kliendid on seda sõnumit välja kuulanud, kui vägidi seda teha, me võtame seda sõnmus ja tekitame kolm järekorda, näiteks FANAS, XENG ja ABIL ja nendes kolm järekorda jääb sõnmusta alles, kuni üks kliend vähemalt tuleb ja kuulad, et võtab neid ära. Me saame seda järekorda alles jätta igavesti, kuni reaalse tuleb ja keegi seda sõnmus tööte matkad. Me saame karanteerida selliselt sõnmuste kohele toeneutalist. Ja tulevõib, et sa andra kolme järekorda asumud, et näid sõnmuste sõttuvad. Ja selled on tõetud istiga mikroteenosta vahel kasutadeks näid tööd ja järekordud, agi sõnumit järekordase teenusele, et tead nii otsa sõntuvust ja neid mikroteenuste vahel. Mõneb ka rakke, kui sa näid, et siin on üks õppsele ästi tüümpiline abstraktne mikroteenuste näide, et ei ole nagu päris näide, et siin on ka kasutatud näideks kahva sõnmuste järekordasid. Defineerida eventid, et kui näid, et ma mõtlen, kus see algus võib sa oled, kasutada näideks. Kui sa oled, mida nii on shopping karti ja hakkab ostma, et soovib osta, ja siis restaabi vaat kuuluda saab sõnmuse, et siin on ka kahtatud, et sõnmuse, et shopping kart on nüüd valmis ja pärutav valjendat pae nupu. Ja siis ordeplasement teenus hakkab välja kutsuma meedlada, et miks on vaja teha, et kontrolliv inventorist kas üldse on neid aiteleid, mida ostasab taha. Kui kõik on olemas, siis saadab pärin kui payment meenus, et kontrollide kas payment läheb läbi. Ja samasajast kui õnestub siis inventori kontrolli ja payment läbi, ja siis ta tekitab, et uus ostmine on nüüd tekitad. Te kirutab amme baasi, et salastada küsivalt, et on ostetud midagi, ja ka tekitab sõnmuse, et üks ostmine on nüüd tekinud, et nüüd tulaks ostmidele sealt ataisa läbi teha. Aga siia amme ka kirutub, et see oli edukas ja ostmine on algraportutud. Aga samas tekitab ka ilendi. Ja siis teise teenuse, kes saavad teada, kes saavad mingiselt tegeluse teha, talas seda, kuus ostmine on edukas, näib, et shipping teenus kuulab neid sõnmud siia, kuulab, kõste peaks tehti teha uue kohale vahvetamise. Reporting teenuse on ka sinna tulata, et kui on uus ostmise event, siis ta ka võib-al ta mingis reporting amme baasi ka kirja panne, et kuna sa ostmine on toimus. Ja inventori ka võib-al ta ei tekitab mingiselt eventid, et siit tuleb inventorid ostmine toimus, tema võtab nüüd aitelemita, mis saadas inventorist maha, võib-al ka publisseerid, et siin on nüüd on vähem aitepeid, või näites aitemeid enam ei ole, ja siis on mingiselt teellimiste event tekitutakse, kus nile kolmandas osapooled peaks need aitemeid juurda teelime hinnat. Ja siin on see näite, et kuidas me saame osa asju teha aasumkronse taustale. Teetud asju me tahanu koha teha, me tahanu kasutelva asjate, et ostmine on edukas, aga teetud asja võib-al toimusab pärast poole, nagu et see on teha koha ütlema, et nüüd keegi hakkas sinu asju koku panema ja teelimust läbi liima. Sellest, et see võib toime teed, et see võib toime teed, et nädal aapärast, et teatud tüutmus ilmuseks, sa ei tea nagu koha ärava, nagu vastama klientid, et klentsapõib võib hiljem. Shipping teeluse käest, siin mitte kolmanda oda poolt, te kaulutuu, klentsapõib võib tead, et temal on aga poos, et seda kohal toivad. Uuperi näite on ka siin, et siin on ühtav arktikel, kus on kolm, neliselist hästi võialiku näite, et kui suure tasut seda on mikropeastel üle, nii läinud. Uuperil kunagi oli selline monolit, seda kunstalt juba uuedaholist monolit, kunandal oli palju väliste teenustele, sest adaptorid monolit sees, kas monolit on sellist viik loovika ja siis on nii teelat adaptorid, mis suudstas väliste teenustele, aga seda neid oli raske skaleerida miljonitel ja niljonitel sõitudele, et korralikult partitsioneerida andme, et näite paljuda monolit replikete valjel ära. Et see on läksid üle mikropeenuste peale, aga kui nad läksid suhtsalt vanamamu, siis selle laali on väga mikropeenuste standardeid, kuidas lua hästi mikropeenuseid. Ja siis neil tegis senne olukord, et neid olid tõesti tuhandeid mikropeenuseid ja nad proovist näiteks visualiseerida mikropeenustu vaheles suhtlust. Ja oligi tekkis nii palju legasi mikropeenuste, et tehti uued versionid mikropeenustest sinna mikropeenuste võrku ja see arvitektuur läks nii käest ära, et nad ei saanud enam visualiseerida, mis nüüd see jooksab, kui sa aga serveritse ja kuidakata oma vaja suhtedavad. Aga siis nad hakkasid standardiseerima, nad ise oli ka osaliselt nende mikropeenuste standardiseerimis lähenemistese, kuidas paremini monitoride, kuidas paremini aru saada, kuidas hästi mikropeenuste töötavad. Kui me loome alternatiivse mikropeenuste, et kuidas arusada, kas see mikropeenuste parandab neil olukord ja võitte, siis agati väga rangaist mõõntma mikropeenuste meitlikõi näiteks. Rikki talvus, dokumentatsioomi, tase, hõutus, stabiilsus, eskaleeritavus. Ja kui niisid arengustiimid tegid uuega tõst mikropeenuste, siis nad nõõtsid, kas uus mikropeenus, kui ta töölepana, et see näedab, et kas ta parandab mindist mõetlik, et kas ta reaalselt ka midagi paranaks tegi või siis teib kogu arvitektuurikeerujasemaks. Ja mikropeenuste uuega, siis siis pididki rangel parandama neid ja mindi üle natukene loobilisema mikropeenuste partirektuurile pigem seliste metsiku mikropeenuste metsahagel oleks konkreetselt ütame mindist onne 9, 10, 16 rangel mikropeenuste tüüpi ja nende mikropeenuste sees võidid olla mingisugused alteratiivselt inklaratatsioonid, mingisugused replikaadid, aga et ei tegid seda alukorda, et on see mingi rangel mets. Pige mindi sellise lähenemise peal, et jagati nagu valgkondadeks, iga valgkonna sees võidid olla mõned alternatiivid, et kui meil on näiteks mingisugune payment mikropeenuste block, siis sellel alg aluele on vitu mikropeenuste, mis näedeks Google Pay paymentiga, Apple Pay paymentiga tegelevad või tegite kolmaldat aseme paymentiga tegelevad, aga nad propeerid nii oledi nagu selliseks. Et täpselt sama tüüp mikropeenuste, et see on nii, et neid pandid sama hapi, sama välin hapi, et siia võibolla kui ole tegid peest appiga, siis ei planne tassioonlada Eil peaks on on erinega väline, appi on taksed sama, et peestet mikropeenuste sallel payment appiga väljakord, siis meil on vältu ta, aga sisi meil poedat oledub erinega planne tassioonlid, erinega välista parteride oks. Ja siis tekis pigem hoomatav lähenemine või selle arvitetuur, et on pigem arvusad, et kui palju on erineva tüüpi mikropeenuseid ja kui te saad omavals uskidavad, mis on näide vahelesed standardi integratsioonid ja ei tekid enam seda olukord, et siin võib et siin võib olla 10 aperapiid, kui seda löölem, nad on erine ja rest upi näiteks, on see sellist. Ja enam ei pidanud sellist arhitektuuri oma ma. Kuigi see arhitektuur on palju keerukam, kui ta siin näed, kuna sa oled erinoalt, sellised ala mikro teinud, et see on oma ma erinoalt, kui erinoast jeles impenete eritus, siis vähed arhitektuuria ühelduste ja appide tasanel, appide standardüüte tasanel, on igeme, aga palju paremine omahtanud. Ja siis kui te rohkem võitab, et kui tähtsalt sa tegid ja võib-a leia te vitsi, kui ta sinna graafi rohkem sisse suumida, siis vaada ka jõu näid, viilt eestse. Aga mingil ajal jah, et need mikro teinud kasvuselt väga metsikuksed ka. Amazon Prime video ka mingi aasta või poolteste aasta pagasi, et nad lähevad mikro teinudsteist arhitektuurist samm tagasi ja kombineerilad teadud mikro teinudit tagasi kokku osalisteks monoliitideks. Ja nad on koopimeerida, kuid palju liiklust saavadakse nende mikro teinudste vahelselt. Olukorras tegelikult saavadakse kasvusel video, striime, pilte, frame, pilti frame, et siis tegelikult on parem vältida üle võrku suurde andne ka saavkust. Nema otsikades palju rahakoku selle, et natuke liigutasid arhitektuurit tagasi monoliitid suun. Aga järgimiseks räägime siis aine, teemaat ja kokku võtest. Räägime üles, et eelised ja puudused kõikin peamist aine teemaate kohta. Esimeseks olib siis hajusüsteemid. Hajusüsteemide eelisena võib kokku võtta niimoodi, et me ei pea enam koondama arvuntused arvuntused ühte sellises serverisse. Me ei pea ostma hästi kallid virtuaalmasinaid või habetseegest küsima. Tange meil on hiigesuud virtuaalmasina või server, kus on näiteks 2 terabyte nälu ja kus seda või 200 terabyte ketas näiteks ja 128 tuuma. Võib me saama arvuntused jagada sultsed lihtsasti hästi paljud arvutid teha lära. Meil on palju lihtsam halata neid rüistvarad. Kas te teate, kui me soovime ehitada pilves anmebasiserverid ja me ei saa hajusüsteem kasutada, et mis on maksimum virtuaalmasina suurud, mida saate asures tellida, kuid palju see maksma läheb. Ütleme, et me anmebasipuul meid huidam, et see ketta ruum, palju me saame failisüsteemis hoida anmebasifailet, et mis ja võiks see maksimum olla ühe virtuaalmasine kohta ja mista arvata, kuid palju see maksma oks kuud ninn. Kentaruumis Nii, ühega minda ikka ketta ruum, serverid roles maksimum keetan edasi kohta. perceptpay Se, ma renkkant kettaruumis, mitte, me hommal osates thirdskillam Friedcher Sam calling 30032 раскets H방as threatpiss Siin on murks ja tegev, koht sacked kora ka veid. Nüüd saaks tegelikult teha juba filebase põhise Anne base serveri, kus on 2 petabyte ruumi filebase Mälu jaaks muidlikk vähe Aga mis arvad, päris sa maksva kuus lähe? 160 000 Ja kusagi 260 000 kuus See on selled, et üks suuriamad serverid, mist vaatab 64 ketast Ja 400-800 CPU tuuma Ja ka mituterapeitimälu on 75 000 kuus Aga siis sa pead maksma kõik 64 ketajast Ja seal on 32-64 terapaitiselt pilveketat, mille kuutasu võib kolla kui 3000 eurokuus ühe ketakort Ja selle peale tuleb, et sa hakkad maksma miljoned eurasu aastas ühe virtuaalmasine Need on aga väga specialiseeritud virtuaalmasinad, et palju odabam võtta Palju väikse virtuaalmasine või konteinere ja oksletel arvud seal Sest siis ei pea kasutama kõike kallimad serveri ja kõik kallimad ristvora, mida pilvet ees pakku on investeerid Tee centraliseeritus on kaas, et me ei ole üstei pudelikaalad, mis üks virtuaalmas crashid Ja siis kõik läheb kätki, vaid meil võib olla üks 100 crashid On tähitse okei, et me kordame nii samu tegevõsi kusagli mõjal Resursside kasutus on ka lihtsam, et me saame jaotada erinevade ajustustemi komponentide, erinevade regioonide Vahele kasutatavad mõne regiooni lähedad, et saavad parema prahutuse Palju lihtsam kareeritavast, kui me saame komponente juulde panna Ja meil ei ole selled centraliseeritud kusagil Ja tõrkjekendus on ka parem, kui üks komponent, erite, kui me räägime replikate Ja siis üks replikat kätki läheb, siis teised replikates on jätkata päringute või operatsioonid Või andmetöötmase tegemist, et suudad jälle korra tegevõsi Ja kui üks näitas kätki läheb, siis teised tegutavad sest tähin üle Hilvega on kaasa tulnud virtuaaliseerimin, et me enam ei pida nii serverite Sotsa riistvara peale asju instaleerima Ja see võimaldas siis serverid tükkeleta väiksemat kütkideks Ja see tähendab, et kui me longisis kohe betavai nii ketta-rummiga server Et me kasutasid seda ainult ühe rakenduseaks Eriti ööselt, kui võib-lese rakenduseks väga palju jõudust ära kasutama Saaksime ta tükkeleta väiksemateks virtuaalmasineeteks Ja kasutada iga virtuaalmasineet erinema rakenduseaks Kasutatel, anda kasutatel virtuaalmasineet Kui me suuri arvutasid ei tee või kui me kogu ketta-rummile ära kasuta midagi Et me saame siis suuremat serverid jagata väiksemate tegevuste ja rakenduste jaoks ära Ja ühte serverse lihtsamid rohkemast pööma Virtualiseerime lihtsustas ka kesku andada kohantamist Et me saame teha virtuaalmasinete piltides koopeid Me saame jooksvasti virtuaalmasinest, mida üks administraatore on ettevalmistamud käsurea Kault on äiteks teha kõik koopeja liibutada kusagi mujale Et näiteks administraatore peab üks kort valmistama ette meile mingiseltse virtuaalmasina Kus on kõik väärgud asjad istal eritud Siis me teeme sellest snapshoti Ja tulevikust me saame sellest snapshoti uuesti kasutada Teeme sellest kistad koopeid, hästi tiiresti Et enam ei pea 10 korda sama tyüpi asja üles Ja ma vaid saame teha sellest üks kort koopeja Ja tuleks need koopeid põldu See on siis lihtsam kontainerit ja poolmõde teha Ja virtuaalmasinel on võimalta, et see on lihtsam Selle tõttud me saame seda koopeid teha Me saame ka liigutada nii koopeid kõngi mujale Et see live migrationid on pildlasti enam peadsa Et toadud väga hästi Et saate näiteks öel, et soovite virtuaalmasinels liigutad teist tüüpi ristvara peale Et näiteks rohkem mõnu saada Siis see nüüd tähadal on koivud taustal Nüüd peakse jooksavad virtuaalmasinels snapshot Liigutadaks snapshot ära Panaks seda teise pool tööle Siis panaks see eesjälge kinni Ja suunotakse liiklus ümber teise IP-aadressi peale Tead kasutada ei kõugigi väga mõdegi märgata Et kõikki läks Kuigi tüsti nii kusapone väikse põrkjad tegivad Ja kui saame liiklus ümber suunotatse Aga näiteks Ülikooli pilvest saate ka virtuaalmasinels Öelda, et ma saan taaks rohkem märu Ja siis tõetataks teise virtuaalmasinels Kõikki teise teise teha pärjade Ja ühtis, et kui me kasutame virtuaalmasinels Siis viis tõra lihtsam jälgides Me saame jälgide, nagu virtuaaliseerimist ase Ja väljas pool operatsioonisisteeme Saame näiteks ketta välja pahetada Ja kui me saame jälgide, nagu virtuaaliseerimist ase Ja me saame jälgides, nagu virtuaaliseerimist ase Ja väljas pool operatsioonisisteeme Saame näiteks ketta välja pahetada Ja me ei pia, nagu virtuaalmasinel Sees, midagi see läks muusma Virtuaalmasinel seese peasikid teha, et ketta Välja pahetada Serveri sijadistudist vältavõid, et see on äkki lihtsamad Ja me saame miselt tarkvara Väljas pool virtuaalmasine tuuandida Või virtuaalmasine enda välja pahetada Ja systeemides ka on väri Varu koop, et tegem lihtsa Ja me saame lihtsalt ketastes koopeid teha Ja pärast aastal virtuaalmasine tändest On suhtseb lihtne Virtuaaliseerimise puuduselt erite alguses oli see Et jõudlus või ishaalveneda Tänapäevase pilveteenuste Ja pilvetehnoloogia arenguga on palju paremaks läinud Et ka Riisvara toeta rohkem Virtuaaliseerimist Aga alguses oli ka tõesti Päris hullem, eriti võrgujühendus osas Et aastatel 2010 Olit Virtuaalmasineid kõvasti aegusemat Kui hotzerberis asi pülesseadmine Ja tänapäevase on vähem problemi Eres Rakendist käilitame Võib-kall masina seis meie suol aga aegusem Ja kuna pilvesele Iga selle evituk rakendiseaks Vaja oma operatsioonilisteem koop Kuna oli virtuaalmasine koop Mis tegelikult nende linuksid juoksutamine Iga virtuaalmasine lisees vajas lisas ressursse Lisa mälu, aina lisega operatsioonisisteemi Endata inuksid juoksutamiseks Et see vajas rohkem ressursse Kui otsaja viisvara peal rakendist Otsaja üleks jalgre Aga see et sa ei isoleerida turvalisemul Olik kindlasti täh samatulse Ressursjade kulu Ikkagi piljatenusei hakkadik asjad On väga massivik Virtuaaliseeris sulid natuke uue kogut Nüüd on mõnikud raskem Leida Kui kultaketletel on server, kus on Nelivirtuaalmasinat, igas virtuaalmasinas on Mingisuse viiruse, kontrol või ruutkitide Kontrol, aga ruutkitid on Väljaspor virtuaalmasine, et esis virtuaalmasinas Või peitetud virtuaalmasinana Ei saa virtuaalmasina Seestada üleks leida Aga samas väljaspor ruut kasutane juoksut Juoksad protsasid mõnikud saavad Ika virtuaalmasinassega sisse vaadata Või asi ümber konfiguririda nii et Peatud ovud on palju keerulisemad Üleks leida Tuleb teha kontrollev väljaspor Virtuaalmasineid, nii et See palju lisa vajasluseks ja Nende virtualiseeriks takvarele Et leida sellises ohud üleks Ah, sellega mis See oli, et ARM arendav Serveri Protsessorid, mis Ristivare tasavati virtuaalmasineid Et siis ei teki seda problemi Võibalmikile valmisid Auksele Siin oli näite tuleg, et ARM arendav Vist kiitamist rupteerivad virtuaalmasin Aga järjest rohkem on just Ikkaselt kiipid ema plaadil, mis näiteks Automaaltselt transleerivad Virtuaalmasineid te melu aadresse Üle füüslise melu aadresse Nii et CPU ei pea seda ena misja tegema Ja sellest oto Ename ei ole ne virtuaalmasineid jaajuse Kettaste Kontrolleerite takvarele Seesame eraldi järjekorrad Nii et me saame eraldi virtuaalmasinest tulevad Kettaste päringid pana eraldi Järjekordades, et saab olnud Kes hoonitseb, et kõik virtuaalmasineid Saaksid mingi aja, et Ketta-operasioone teha ei oleks Nii et see virtuaalmasin, mis kõige Rohkem ketta-operasioone teheb Et temal on kõige prioriteetid Et tema võtab kõik ketta-operasioone Üle kere rohkem Ristvara soetab igasugused Ja kindlasti Kulteerimine ja turvalisus On ka seal väga väga täh Konteeneritefektiisus Eriti virtuaalmasineid ka kõik Ei ole enam vaja eraldi Operatsioonisisteeme Kuigi kui teie Panete üles uue konteenereid Ja teed uue tokkerepildi Teele jääb võib-al mul jääb Esimene kiht on uu puntu kiht Või älbpain kiht, et see on ka linuks Aga tegelikult seal operatsioonisisteem See on ajutakun, et komplekt Nendest tarkvarast, käskudest Faillistest, mis tavast operatsioonisisteemid Aga operatsioonisisteeme Eendevpotsessid ei jookse virtuaalmasinest Rohkem konteenereid on võimalik Ühes servoise ostatuda võidast Kui virtuaalmasineid tegab Kuigi tehaks ikkagi virtuaalmasinat Millest ees konteenereid jooksetud Et see vihtsalt selletõttu, et isoleerida Erinevat keskkonat, aga rohkem ära Kui on üle teenust pakkada Kaks klenti Siis on palena, et isoleerida Sellet asem, et panna ka näid eraldi Võib taalmasel Tama konteenerid ei pandu otsi Ristora peale, võib ikkagi mingi virtuaalmasinest Lihtsam on teisardada Kuna meil on tilt sinna, et Konteenereid tead indikusti registris Teine serverad lihtsalt registris Sellal alatõmata, aga võimalik Ka jooksvast konteenereid teha tegelikult pilt Ja see ympärri liigutada Et meil peab See on võimselt üks Tokker komit käsks, et läks teha Jooksvast konteenereid pilt ja see ära liigutada Teha komit ja siis Finite liigutub Lihtsam on uuesti jää kasutada Sest Iga tegevise koks ta tegib uuskiht Ja võrrateest virtuaalmasinega Me ei pea terveelt et ta kooplet tegema Virtuaalmasinapuul Kogu ruud talas, kui kõik on kiga paiti koope teha Tokkeripuul viis, vaidam viimasest Viis koope teha, siis niimoodi liigutada Ei ülehet tõmata siit registrist alla Et Ja konteenereid ka ka Kõvasti väiksemat avasat kui Virtuaalmasinad Ja siirus on ka Parem nii, et puultimise ja puul Sest ei ole vaja operatsioonisisteemi Ilesseada ja jookstuda virtuaalmasina Iga virtuaalmasina sees Era operatsioonisisteemi, lait Konteenernis me kõik käelidaan protsisse kõik Konteenernite peamised Sellise puudused, mis võib-olla on Naltukana otsintult puudused mõnes mõtteselt Või kõik midagi väljutua Rast keman nagakõr täialiku eraudatavust Sest viis virtuaalmasinad Parem nii eraudatavad, täiesti teevad Eraldi mäluolad Tänapäevas on ka tovetetud ristvara pool paremini Aga kui meid on Konteenernis sees jookse protsess Kelle on ruud kasuta õigused Sest tal on lihtsam Oma konteeneste välja Hübata võidadus virtuaalmasineasid Sees jookseval protsessiga Ja Ikkagi nagu See on ka üks poohju, et miks virtuaalmasine Kas tõks sama aegselt, kui tõesti on Vajalikte eraudatavus Aga lihtjaga see problem, et Kui konteenere, et tokkedkonteenere On halvasti konfigureeritud Sinna panaks see näiteks mingisukuna Tarkvara, et logeda logifaile Aga sellasega, et logifailide Kaustamountida, mountiteks selle Rurkavus Konteenere sees jookse protsessab kõikidele Fileidele väljas pool konteenereid ligi Ja õbula pääse pisi konteeneri Sellele sokkedfailjile ligi Ja saab teisi konteenereid jooksata See on väga lihtsa teha vigaasid ja alpa Millist see on lõiguselt õnnekse saab seda paremile hallata Cooperneetises saab keelata Et kui konteenere on pantud App nimeruumi, siin sellele nimeruumi See ole mida ühelikida lubatud Rood kasutada jooksata Elle mida üheleki luba konteenereid Väljas poolt kaustamountida Saab reegid pealabanna politikat Ei ole lihtsalt ka lubatud Peatud tegel või hülte Mingis nimeruumi jooksast kohsene See on ikkagi hakka Me ei taha sellised pirangid pana neid systemi namespecies, ja siis kui kelle, kelle onnestub, systemi namespecies midagi oksutada, siis see peab õnnestub see, aga persiis on võimalik pool netipe peale vanna. Mõnikord sa ei aitta administraatorete vastud, kui on halva administraatore, siis tema ikkagi onnestub, millega kaidki teha, aga tihti on probleemid ka siht. Kuulude kätte, et teil on asutusteltud kontinuusitekessal pipeline, mis võtab kitist kuberneetese manifestivs ja paneb serveris üle. Nüüd kudeste kaidselt selle vastu, et kit ei pane nii-kid imelik manifestivis, annab liiga palju õiguseb ja jooksutab niremiseid oheks jooksutada tähje serveris. Ja tegid sellist asju väga rasv kaidsta ja puhtal selletõttel teha efektiivselt tarkvaralendust lubataks sellised asju, et siis on väga rasvi kontrollida, et kellel on õigus, kiti möötsjuda mingisusust manifesti, kus mingid vead on sees, ja kes teaksab korralikult kontrolli nende üle, et kas sinna on paljud mingi root kasutaja õiguseb kuski konteineri, docker, beatfile ja need asjad. Et virtuaalmasinade pool on natuke parem kaidsta, kuna virtuaalmasina sees, midagi halba juhtub asi tihti ei saa virtuaalmasinast välja murda, aga konteinerid õiguseb päris hästi välja murda, sest konteinerid võimalda võimalda, võimalda on võimalda, võimalda on väga palju konkrubüreerida auke asjada konteineris issa. Päri näete, see manifesti tegel on võimalik, see on automaatt kontroleri? Jah, on võimalik. On võimalik panna, kui päri näete, see siis isse eradi kontrolleri. Näiteks on security operatore ja security kontrolleri, mis kontrolli jõuad iga uue manifesti üle. Ja nad kontrollid seda enne, kui Kubernetes, kes reasad neid poodil oma hakkam. Ja siis seal on siis kannikus, mitte kannikuga, ma unustin numera. Ja neid saad lihtsalt üld, et see ei ole korrekt manifest, kuna seal on lubatud uut kasutaja. Ja selline tarkvareks existeerib. Meil on üks Kubernetes aineemise, ma kistlikin tude, et peale mõelda, et sügisel, aga seal on jääb turvalisus aspektu üle. Kubernetes on võimalik sisse plug-inina panna päris väljasju. Ja tõesti on võimalik, kistad ka security policy defineerida, et mis on lubatud, mis ei ole lubatud. Ja on ka scannerid, mis canniivad iga imidžid, enne kui seda lubatakse kasutada. Ja vaatavad, et kas seal mingiselt vulnerability on. Et näiteks, kas seda tocker imidžid on ilmselt lubatud Kubernetes rasutus lõpeta. Ja et saavad tõesti vaatata tockerfailid ja näit layerikid läbi, et mis kasutad sees on. Ja vaatavad, et mis versioon on. Et näiteks, ei luba openSSL vanaversiooni. Et teab ole muu versioni, sest peerorid ei õnestud seda märgist lua. Kuna imidžis, mida kasutatakse, on liiga vanavaks versiooniks, kui sa on mõni pärne aukri. Et selles mõttes Kubernetes on hea, et seal saad peale väga västi teha. Aga sa administraatorid teavad, kuidas selle teha on eraltikusim. Ja see võib ka tegelikult, nagu sellise Kubernetes platformid suht keerukad teha. Mõnikult on lihtsalt keerukam arusaad, et mis kontainerid jooksevad, et see on vajalikud, et see on eba vajalikud, kas said reaasukavad, et see keegi on jooks määtnud. Nii indiselt Kubernetes poodid, aga on unnustavad maha võtta, kui pärast uurda ja siin on lihas mängid. Kui neid on sadu ja sadukontainerid jooksevad kuskil serverides ja klastrideses, kas administraatorid ja operaatorid saavad hea ülevaad, et mis on tegelikult vaja, mida peaks maalitma, mõnikult on arusaad, et kõik on vajalikud. Ja kas dokumentatsioon hästi kirjatev seda, mis tegelikult jooksma peaks. Ja arusaad, et mis on mõtetud, et meil on mõtepeaks emadada. Eriti kui neid mikro teemastakult tohukult palju, aga seda Uber näite puhud. Kus oli üks näite, kus kui Elon võttis üle flitteri, siis ta hakkas asju kindi panema. Ja üks asja, mis juhtus, oli võeti maha mingisugune teenus, mida ei teatud, mida ta teed mingi mikro teenus. Aga see mikro teenus oli selleks, et sealt kaudu frontendis oli mingi jahvaskri päring, mis selle mikro teenus kaudu midagi päris. Ja kunase mikro teenuse emadati, siis hakkas juhtuma see, et kõikides kasutete brouseritest hakkati tegema selle mikro teenuse aaldres vastu päringud, et kas saab jõhendada, kas saab jõhendada, kas saab jõhendada. Kogu flitteraks maha. Kõik kasutavad, kõikide kasutavad brouserid hakkasid teha alas sõrjistat akki printid tegema Twitteri vastu, et saad siit ohultud palju pümmekorta sekundud rohkem päringud Twitteri serveritesse, et kas see mikro teenus on olnud, sa mitte ja siis kogu sisteemi oksis mingiks saad koku, kui nõpuks laeti üles uus versioon sellest frontendijahvaskriptis, mis lõpetas näide päringud tegemiseks. Oli selleks huvikud valutatud. Ma täpselt ei mäletu, mis see mikro teenus oli, aga just see, kasutavad isegi hakkasid pommiktama seda serverit, kuna mingi mikro teenud enam ei tõna. Kupernetese on mind suurlade dokumentatsioonist nadel kogudud, et kuidas William Keeley selle kusmetsust ei tegud. Mõnesmõttes ei olegi, mõnesmõttes ongi, kupernetes iseheitad, niimoodi, et sellest manistestid on suurlast hästi loetavad, aga jah, et kuidas neid vädas kool kupernetese hästi dokumenteerida, ma pole kindes edas osas. Selles mõttes on palju parem, et virtuaalmasineid on kuhu sa pead scannima, et kui sa pead virtuaalmasineid, mis on sees, on kupernetse kuhu sa lihtsalt palju manistestid ja saavad aru, et see on võib. Kuidas nii, et kui saada manifesti ja agad sellest kukkit üldpi, ja aru saada neile asme? Visualiseerijad on tarkvarad, mis nagu neid kruppeeviivad, visualiseerijad värviivad manatalu, peabid idesa sulle, et parem üles oda. On tarkvarad, mis näitad, mis komponeidi millega suhtevad, et sa vaadad, et mulle on hapid. Ühtegi suhtlus viimase kolme tunni on suht, sellest hapid see ei ole. Seda sa näed, sest nagu dokumentatsioonid asjad, et sa tahad teada, mis on konteinersees, on pigem jahe manifestid, et sa oled tugele. Sa oled huvitatud millesti. Sa ei tea, mille ma seda sa aga sisse vaadad, et sa saaks manifesti tugele paruseta, mis on sees. Osa asi on peidetud, tockerfailide, konteinerse sisse, aga ka see on, et kõik layerid on tegelikult käsnud. Käskust saab lugelda, et nad ei ole mustatud. Black boxid sa ei näe, sa saad minna lugelda, et mis käskust, et mingisugune layer lua ja kogu tokeri, filo tegeliklu loeta. Kuigi sa ei tea pitkas, sest näiteks on veelis kooperitud mini ghost, sest seda kausta ei näe, et sellest mõttes kripti päris ei ole nähta, et tihti ikkagi midagi kooperiteks ja kuihtam fain kooperiteks, siis sa taakse liikud vaatama, et sa on kriptam fain ASMR-a. Aga ma olen kirjalis, et mis on tehtud, et see konteeril lua. Ta on suudseltaluu analüüsta, kas just inimesepot loetavaga. Kõik fäelik, et see on mõnna põttes olemas. Mikro-teelist ja kasutamiseeliselt on võimalde, et rakendustiseist pideva tarengutad võimalikult kiiresti muudatuse läbi viia ja miks see on hea, et muudatus on väiksta. Mida kiiremene saavud muudatused läbi viia, arendada, testida, testkeskkonnast käib itral testida ja production keskkonda panna, seda väiksemaid muudatused saavad olla. Väiksemate muudatuste pool on võimalik paremne mõõta, on võimalik paremne alusada, mis mõju nendel on rakendistile ja teistele mikro-teelistelel, mida väiksemad komponeerid ja väiksemad muudatuse tead, siis ta ette endustada onne, mis on näid muudatust mõjut. Kui võtame nädal aega midagi arendada ja pool nädalat testida, siis kahe nädal jaoks on väga palju asju muujal ka muutunud, teistele muodulitele, teistele takvara osades ja siis on väga raske, kas ju väga raske, ma ennustada, mis juhtub, kui ma selle uuenduse üles. Ja saab see pidevat pooltatavast, pidevat testistavast ja saavad kiiresti juurduvata neid muudatused. Kasutatavad kiireni tagasel ja saadad, kes muudatuste muu juhu on, tegitab nii terroveid või ei meeldi kasutatavad, et siis ei raiska kahte nädalat arendust, sa läks aru saab, et see midagi ei tööta või midagi on valasti tehtud, märkab ka igasete ja muidaks ja kiireni. Mikro-teelistel pool saab teha igalat teenuseb isu või väiksema, ta on niimoodi, et ta lihtna aru saada näite suuntele töötaned, et saab anda praktikondil ühe mikro-teenuse tuuri, kuidas see töötab, ja arenda seda paremaks või tee alternatiiv erlangis, püt võtab püütle mikro-teelistese erlangis ümber, et kui neid mikro-teelist on väikse, see on lihtsam teha, ja kasutajui või arenda ei pea hooma, et mis on kõik, see on neide mikro-teelist ümber olevad asjad, et saab neid tükk haval niipad arendada ja võib-olla arendad ei pea ki, olema ekspert kogusisteemile vaid, nad on eksperteid mingi väikse tükki osa üle, ja kui neid on täiesti eraldi jooksvad asjad, siis ka oma läpakas on neid istama ülesseada, et ei proovita kogu Uberi lahendust oma läpakade ülesseada palju raske. Arenduskeskandades ei käi importi üli suuri projekte, nüüd on projekti näiteks mingilt big data mapped, juss või Hadu projekti oma e-klippsi või Intelligensio importide, siis sa võtab sulle peale pool hünda aeg, et ikkas asjad sinna haladamada näidenis, ja siis tegid kärra, et kuna väga palju teile on mingi suurluseb, native library siit tule kaasa, et mis talad ära kui tõrge. Et siis monolitik projekti on kõikki väga terograal. Teele, et isa alustad jooksvus Kiinalini, et viib võta nii pala aega, kuigi terve, Mikro, teel, et see on kui selle rakke, et nii on ülesseadnud ja ta aegas olla, kui näid on hästi palju väikse tükke, mis talad üks järjel ülesseada, plus üks tükku ootab, kui ne andakas on üle, et enne, kui teid on ülespanaks, sellised sõttuvud võib ka aegis ota. Parem, mis ala eritas, nii kõrral, et kui mingisugud SMS-i saadnud selle teedus, kik otevus kaktki on, ja me ei kasvud otsa orkestreerimist, vaid nagu koregroofi ja lähenevist, siis meil on täits okei, et me teeme kasvuda ära ja poole tunnikast, kui teedus tagas üles tuleb, siis saadakse SMS. Aga otsas, et midagi kasvud näite loomineleks kakki ei lähe, meil see teatud asjad on natuke te leid, hiljemu tainuad, aga üle, et saad jätkata töötamist. Teatud kohad võib-alt olla pudelik aelad, et meil peab olema kasvuda teed loomis ja mikropeerust töötas, selleks, et SMS-i saakse saada, kuna me ei saa muidu sõnmust, et kasvuda loodud, aga aga sellisele eritavad, et kui midagi kaktinad, siis üle, asjad üle, et teeduseb lihti võibad jätkata töötamist, aga siis lihti olev selle, et see rakendab mõneselt see vähel näite teanoloogia võlga, kui teanoloogia võlg puudutab ainult ühte komponenti näites, et me tegime mingisuse mikropeerusem püütalist vanasti aeglene, tuleb, et juba tuleks vaetada ümber arendada näite kerlangi peale, ja kui me seda otsud, et teeme, et arendama ta teise keele peale ümber, siis see ei ole niisult võlg, kui me saame teda teha kas ühe mikropeerust tasemel või mikropeerust tasemel tükk haval, et me ei pea võtma kuuda aeg, et mikropeerust ümber kirutada teise keele peale, ja siis nad alles töölepanna, et kui me saame seda tükk haval teha lihtsam, vähempea tehnoloogilis võlga, ja kui ta mõjutab väiksemaid obekte ja väiksemaid teenuseid, siis onneks on olnud üksikult võrad väiksemaid. Tehnoloogi võlg on see, et kui meil on vajalik midagi uuendada, aga meil ei ole veel aeg, et saa või raha selle teha ja lükka mõne tulevikku, et mingiselt muudab, et see näiteks synkroontse, suhtsele tasumkroontse peale mene või püüten asemel erlaendu kattuda, midegis elid, et me paneme selle endale kirja, et me taaksime seda tulevikust teha, aga me ei vee seda ei see, et siis annad võlg, et me plaanime seda tulevikust teha ja meil on lihtsalt kent, tahab menegi tähtsalt funksionaasust ja me peame selle enne ära arjada, nagu ei võta nigi backlogist asjumi, et on selline backlog või võlg, et mida tulevikust võid seda siin teha või vajalik, aga mida ma koha ei ole teha, lükkan selle kulaid. Ja see võimalik, et siis eriline tehnoloogid kasutavad saama ühele mikrotenuside panna, Poskas anda baasi teisele, Eskul anda baasi kolmandele, mingiselt teist tehnoloogid kasutada. Mõnes kasutada erlaendu ja mõnes kasutada püütenid, et vastavad vajadusele või soovitele saama ja kasutada tehnoloogid. See on mõneselt sohtlik, et kui mingiselt teingsop valitad, et me teeme püütenis, aga tegelikult püütenis ei olegi iga päran teha, võib-kui oleks jää, ikkagi standaardsed panna, et see on võib-kui kõik, kes mikrotenus on sikkagi kasutavad sama keelt, et siis saavad teised tiimid asju ülevõtta, uue töötad, ei pea erlaendu õppima, et midagi tegema hakkab ta. Et selles mõttes, et need tehnoloogia valikud, kui neid teha liht väga suualisest, meid võib-kui oleikus tehnolooga võlge suurendada, aga see võimalus on olemas, et saame kasutada need annebasi, mis saab iga oktimaasama teadad tipi tegevast jaaks. Tähtis meil on JSON dokumented afeksivine, siis saame JSON annebasi kasutada, aga me tahame teha JSON annebasi peal väga keerukaid join ja aggregatsioonipäringud, siis väng tohi JSON annebasi kasutada, kuna tegil saan halvaad viitsinud anned aggregeriumseks ja analyysimiseks, need siis peab saada keskulisne annebasi kõik pärutuma või mingit nõuespele annebasi, mis võimaldeb siis aggregatsioonidega, et saab valida kõige sodiva ma tehnoloogid vastavalt mikroteeasioon vääbasel. Eliti siis, kui iga üksik mikroteeasioon on oma annebasi. Puhutuses mikroteeastapuul, meid ka tänab ka etsime, et mõnikõttel on raskem aru saada kogu suuresta arkitektuurist või komponente on palju nagu uuperjubugul näite solid. Vaja tegeleda teenostumalise sulktusega, nende võib-olla kriteerilise kaitsimisega, võib-olla ka mõõdbise, kui efektiivse on ja testimisega. Kui meil on üks mikroteeasio, me ei saa ennud seda mikroteeast üksite testida, me peame ka integratsiooniteste tegema. Pärinud, mis vajavad, mitme mikroteease järjestiku väljakutsumist või nende agriteerilis, et on tihti palju keeruisemad, et me ei saa, me peame väljakutsuma teise mikroteeanisega ja nende tulemusid parsime, siis järguse mikroteeanisega väljakutsuma ja peame halda, mingi pigased, mis tekivad, et näiteks, kui üks mikroteeanise vasta, kovame ootame, kovame kordame neid pärinud, võib-olla päris keeruliseks muutida, sest palju mikroteeaniseid hõlmavad tegevused. Kogusüsteeli võib olla aegas juurutuda, kui need palju tükka, mida ta pülesseadma, ja kogusüsteeli testimine ja silumine tifakumine on kirkal. Te pealt ei üles leidma, et kui kasutasad pea, kus, millises mikroteeanise, millises mikroteeanise replikasse, miga teha reaest tekis, nii et tihti ongi nagu põhimiseks, raskem tifakumine ja selleks on parem kasutaselist kesksed logide kogu ja logide halde analisaatoreid ja tresimus ka, et oleks lihtsam üles teht, et kui üks kasutas on pea, et siin näiteks kasuta annab teile oma päringu idee, ja te saate mingisse keskuse logise, mis süsteemi selle päringu idee sissepanna ja kui te saaksid kõik logik, kõikides mikroteeaniseid ühtekohtakoku ja võib-olla visualiseerida üle aega, et see on lihtsam üles teht, et kus need asuvad, aga selleks kistid tulla parem, aga platsaam sellised, et reissimine on ühtse võimalik, et see on see. Ja võib-olla ka suurem resursside kasutus, kui meil on hästi pole väikse komponente monoridide aseemalt, siis tegelikult haiusalt me taame igal, et ikkagi teelduse on ikkagi mingisuguse mõistliku maksimum mälu ja CPU aja ja muut limitiid andad, kui nad hüpavad nad üles poole, et siis nad ikkagi saaks oma asja tehtud, kui mingi kasutus läheb plakke, siis me tihti ikkagi anname kõigile näitele natuke lisamälu, lisavajadus ja kui seda hakkakeeb teha kogu systemiga, siis põled monolidiga, et resursside kasutus olla palju suurem kui monolidiga puhul. Ja teetud olukord, et sa võiatki monolidiselt hakkamist et olla efektiivsemat, eritoosu olukorras, kui on vaja kasutada jääbki aga mälu või selumeid saata tihti ikkagi teelest puhul, sest sellise lokaause võrku haadat, et päringutte tegemine või üldse päringutte tegemine üle võrku põredas, sellega, et me loomem äluskundi väärpusi on alati aeguse. Seda on tihti vajalik skaleerise jaoks, kui meil on 10 miljardid kasutajaks, me ei saa monolidid väga hästi kasutada, aga üksid päringuist jääbkultu aegusem olla ja monolidid puhul võib-olla, et saaks me ühele kasutada kiiresti vastata, aga kui me kasutame hajusot lähenemist, siis need päringutte ikuvad mikrotenuste vahel ja kõik see võrku 11. paegi, et meil on mingislused minimum latensus, mida meil ruudi saada saavutada, et reale sisteemit, mis peavad kohe vasta milisekundte jooksul, need võib-olla mikrotenuste ei kasutada, et selle tõttu, et see ei võimalda kiiresti kohe vastata päringuttele. Pilve toist rakenduste eliselt on võimalda võimalda või paremini sellise teenuse resursse teli ja te juurdu reaal ajas. Kui me loomem, et neid prakotype, siis käime ikka tavaselt sellist esialtsed ette maksud kuuduvad, et me saame näist asure app service kasutavad tasuta, kuni meil ei ole liiga palju kasutajad ja kui meid ei huvit, et meil ei jääb mikrotenuste, et jooksmaga öösel, et see jooksad siis, kui on päringud ja see on päringud ei ole, prototipid arengusest me saame teha nustsevts kasutasju ja ette maksud ka kuuduvad. Sellesmõttel, et kui meil kasutajad ei ole, maksama kuul lõpus, et kui me saame kasutatemnuda ja nad kasutama hakkavad, siis me saama kuul lõpus arve, aga me ei tea nagu ette ostma või ette maksma asja veest serverite ostmiseks. Kist on lihtsam, kui me kea ise serverite ülessead, ma ise installeerin takvara serverite pealt, ma ei saame lasta asure lissalt konteneerid ostmada või ettevannustat virtuaalmasse toostuda, et see võib olla lihtsam asja ülessead, et saame asule lööda, võtge minu püüstal takvara minu kitist ja pange üles ja kui meist mingit iga agend, siis enam on tööd. Aga eks te näete ka praktiku, mis olete näinud, et tisti tegimalt mingi peaks, kui kasutad ja siis teie näidid kordas. Palju kohadadud pilme teenuseid on eriti Amazonis. Existeerib näiteks teenus, mis teie roboti namipeeer, mis takvara jaoks kõneid erid robotid jaoks kolmde ruumid ja kõneid näid üks tuhad random ruumi ja siis lased teie takvare seal ruumis namigeerida, ja nende teg robotid mitmes ruumiist uhandas, see on nõnestus või mis ta keskkumist aega võiks jellistad. Või väga imelik teenuseid, mis existerivad. Näiteks teha selle antenus, et te saate panna oma video streami ja lased aga joost treenida, millised on objektid, mis liiniga liiguvad ja siis see ise õppi ära tuvastama mingit objekte, mis näevad väga testugust välja tavalistas objektele, keskkumistest. Võib-olla mõned selle teenuseid, mis existerivad, mida saad kandutada. Ja järjest hakkam, mida see juurde. Kuna aga ammu käisin, olid konverensid, kus Amazoni web servises pille arenda käis ja räägis, ja näende lähenemine pille teenuste implementeerimisele on see, et kui tuleb üks käring kletidelt, et tavad mingi pille teenust, mis teevad seda isse pere. Ja siis vaatavad, kuid palju seda kasutab hakkala. Kasi teda ei olnud, jah, teed keetavad selle alasi ja rohk meedas ja arvan. Ja see oligi näende lähenemine, neil oli palju raha, ta tatsik populariseerid oma pillida ja nad said arendalise tööle panna ja see ei ole suur kuru. Nii tegid lisabe eruselt ja sellel tõlt on Amazoni sadu ja sadu unikaalskime teenud. Ja saab juurutada lihtsalt teenuste kasutad lähemala läbi näende Content-Delivered Networkid või APES platformed, et meil on suudselt lihtne Eestis uua rakendus ja panna see näiteks sualisest pilve keskuses üles, kus meie kasutad on lähemal, kus me saame uue klendi ja me ei pea minema kuske linnu. Ja see on kõik, et meid on kõik, et meid on kõik, et meid on kõik, joo leют seen on vaid sobre viimale pootselday. needing ja viimailendsiliimine on koonditusi jıyorpr difícilinat Natus Man daha pl Hope mind sulti korraska. Võin, et ca sõummalt tegavad defects ja toohideid nägemustid neid Bitover전 soon. Sa talletanan,ombideid on meil linnus Gramfunelilipanõbr Kemком pracaviida turtle ja palju ei saa seda muud. Amasöönis on rohkem valikud erinevate virtuaalmasinadtypid üle, et seal saab maksata hästi kalli, täst võimsad servoilis Ristvara eest. Amasöönis saab ka tellida, et ma saav soovin terved Ristvara kasutada, et ühegi teise kasutavad virtuaalmasinadid ei taviselt joosta, kes ma lihtsalt maksame rohkem. Aga see võib suhtsalt kalliks minna ja meil ei ole jahe nüüd nii palju kontrolli Ristvara enda üle. Ja kulusid võib olla väga raske hinata, kui me jahsutame virtuaalmasinad, me võib olla teame. Kui meil on püme virtuaalmasinad, jahsutame aastat, saab palju see maksma läheb, aga kui ma hakkame mingil nanofuksioone kasutama, siis see maksme sõltub kasutad arvust. Aga üks kõik, mis pilved eenuese puhul sõltub tihki hind sellest, ka palju almeid allatõmatakse, et te peate maksma iga teravai teest, mis pilvest allatõmatakse teie klientide puhul. Ja kas te teate, ette, palju see järgine kuul on üleärgine kuul? Palju see maksma läheb, kui te näele servisot teie rakenteid vastaväeht? Palju see maksma? Niiht ja raske endostada, mis need pinnaad võib olla. Ja ammeta konstituatsiootiseks kaalt on see lihtsalt kaaguna, teile ei ole kontrolli selle üle. Ütleb te näiteks, te juhude tullub kasutada, ütleb, et kustaga kõik minu onmed ära. Teie lähete ütleb, et Amazon, kustaga kaust ära S3. Kas sest kaustas on vägapusega? Kas te teate, kas on? Teinilisest te võibolla teile kiisab sellest ütlet, et Amazon, et kustaga kõik selle kasutada anded ära või kustaga kõik see kaust ära. Ja siis on Amazoni vastutuda, et kas nad anded on kustatud mitte. Aga teie poolt väga ei ole võimalik lihti asi kontrolli, või kas mingi back-upid on kustatud, kas kusakile existeeriat midi fileid. Ja suure arvu arendate kasutate puul on tildiga probleem see, et te arvate õigus, et Amazonis midagi teha. Ja tegata päris keerurilne andatäpselt õigusid, et meil on lubata ainult peatud asjipeha. Sest see juurdepeasupoliitikete haldamine on sellik ülikranulaarne, et seal on väga väikselt võimalik andamigi õigusi. Aga siis hea ei ole kontrollid, aga sa ansite nelle õiget õigusid, mist kõik on pahelik, mingid mikrodades ülesseada. Või siis vastupid, et te jahna teie iigavale õigusid, et nad saavad mingi pipp toamaseid ja võimavad jooks oda pitkoine. Nii tead, milliks sellist. Et itki ongi raske kontrollida, mis kasutatavad, kui palju õigusid on, aga seal on piisavad õigusid või nii ka palju õigusid. Ja mis juutub, kui kele, kui on õnestud pääsalt teha adutuse pilna kontole ja panna mingi pitkoin mainaj, et sa tead öelda. Vajal see teil maksma läheb. õnneks Amazonis ja näidid skiratud, et maksimum 100 metallmasineid või võimalik jooks oda. Kui teid, kusin nendega, et see juutub, sa oda tõnahtama ka. Kes jälgib seda, et see on mirekõi valesti tehtavid? Valesti asi jookne jäädalt. Aga viimane teema on siis Exami korraldus. Exami leht või selline näite Exami küsimused on koduläel olemas, et saate ka sealt vaadata. Exam toimub siin samal ajal. See ei ruugi alu samas ruumi. Nii et esimene Exam on 122. Ja teine Exama 144. Et ruumid on teised. Aga nad toimub sellel loend vajal. On siis kakve nendalapärast ja kolme nendalapärast. Ja te peata palju nendest pärast. Ja järeleksim on ainult nendele, kes ei tulnud varasemal Examine või ei saa üle 50%i kokku ennest. Nendegenele on pea 50%i praktik, mis juba koos. Teid on üks punkt, et Examid kogudani. Et teie aaks ei ole väga tähtis. Aga järeleksimid ei saa ka hinnet paranduda. Kui te saad hinte e-kätte näiteks, siis enam järeleksimid ei saa tulla et eet paranduda. See on kõikides aine, kes saad saada vaadata. Ja see on siis 12. aega. Need, kes teid lopputöid piisad mõlemast ajast. Ja teid, kes teid lopputöid, ma saan ka näiteks 5. juunid nende Examid ülevaadata, kes hakkadud aates 16. kaitsma. See jääb tegelikult 500 aegi, et 7. ja 8. lõputöid kaitsda. Väga kiire, ei pea nagu kiirustama koha. Eksame siin ära tegema, kui te soovide lõputöid kaitsda. Tegelikult sooviste teine aegi. Piisad võib-oad ei saa 6. juunid kaitsda oma lõputöid. No tahavad, mis 42 tundi enne aegi sindaseed. Examid kvalifiseerimiseks peab olema esitatust 80%i praktikumi lahendustest. See ei tähende 80%i punktidest. Aga me samase ei loe 0. Kui te esitatud tühja sippi või vale praktikumi lahenduse, siis saata 0 punkti ja sellise lihtsalt ei piisaa. Peab olema mindi punktid kogutud, et minna kirjas ja 80%i peale. Aega esitatud tohjumused, kuni eksame algus, me võtame ikka vastuga hilineid asju, et ei tegikse olukord, et hilineid seledada tegsamal ei saa. Aine hilnad kaponetist, et jagame pooleks. Võib-oad ei saa. Praktikumi lahendust analogist 50%i aines ja eksamana 50%i aines. Tulemuste leht, kaks näitama seda, et kui te olete mingi punktid praktikumid saanud, et kui paljuta sellest 50%ist on, et see punktide ja praktikumio argute korrutiseid alati ei lähe 50 näks täpselt kordani. Ja teeme sellest skaleerins, et meil ei tead 4 teist praktikumist. Meil ei tead 4 teist praktikumi, annad siis 140 punkti kokku või 12 praktikumi 10 punkti, annad 120 punkti kokku ja 120 punkti skaleerid 50%iks, et üle 50%i tuleb eksam. Ja aines lägimesest peab siis üle 50%i kokku kogume võib. Ja teed, et saada. Eksamireeglid on kirjalik paperi eksam, et ei toonu muudlis. See on sellest ammatud raamatud eksam, aga selle arvutult, et telefon ei tohi raskema. Et selle muundatuse ma tegin see aasta, peene aasta juba hakkas probleeme tekkima, et kik hakkas kasutama chatjppid. Ja ma osates, et ei see Soomi teha seda eksamid nii palju raskemaks, et nendele, kes chatjppid kasutaksid oleks raskem, nii et ma pigem install keel on sulle arvutult teile telefonide kasutamise, siis ei pea eksamite tohutu raskemaks tegema. Ja mind pigem huvitavati rohkem, kui hästi te ainate teemadast aru saate, mitte seda, et kes te oskate mingis kusid keerukkai, loogika probleemi lahendada peas või chatjppi teega. Ja ma ka ei ju pealasundida, et võib chatjppi teega, aga ma pigem heevaks sulle arvutult te kasutamise. Aga te võite kasutaka märgmai raamatud, prindistud materjalne, et kas slideid välja prindida või pigem ärge nagu tohutud palju slide välja prindiga, tapate liikavalt puid, aga te võite ka luge tuudis, et palju chatjppid nii puid tapab nii, et võib-al meie lahendada on isegi parem. Aga ja, et pigem teist kendal mingid märgmäd ja valige slideid, mida te välja prindida, et ärge niis tohutud palju välja prindiga, aga kui te võtad läheb nii raamatud, te teete oma märgmäd ja võite näid materjalega omavalj agada, et näidiks keegi valmistab ette mingid märgmade, siis teine prindid ka endajaks välja, aga ei tohi nagu töö ajal omavahe suhelda või kosta teha, aga ja selline paperi materjalid on okei. Keskus on 90 minutit, nii et ei ole pikk exam ja on kolm exami küsimust, et kusti 30 minutit, eksam küsimust kohta, 90 küsimust, sellest senaariumi põhis, et nad ei ole nagu faktiküsimust, et neid peab jääb asjub meelde jätma, te võite küsida minu, kas mida tähendab, mingisugune term, loend vajal, et ei mäleta, mida tähendab midagi term, ja ma võin teile selgitada terminoloog, et ma midagi, mida te ei mäleta, te võiti sellised küsimust küsida, et ei pia asju pähe õppima. Aga kui te soovite, tege meelde, et tehtek meeltnud endale. Siis kodu lähele on siis kolm küsimuse näikete, jo ühel teksamilt, siin on üks näite, kus te peate ised senaariumi väldi mõtlama, üks näite, kus teile abbeksed senaarium ja siis sellest senaariumi pakka kaks viimud. Siin on viimust selle ennest senaariumi pakka. Esimene näite on siis, et hajussüsteemide mikrodemist põhjelsta rakendust, et saanimisel on võimalik kasutada erinev liisene hajussüsteemide komponentide vahelise suhtlustse ente mittelemised. Siin on küsimust, et millist tüübi suhtlust võiks sellest senaariumist kasutada, aga põhjeliselt te peate ise mõtlama välja kirjeltama ühted senaariumid, kus te ei ei hidankonele soovima, ma ei ehekkiisem kasutada komponitide vahel otsasutluse, et te teed mõrreelest jäädete jäärekordade kasutad. Ja mingid senaarium, kus tegelikult oleks otsasemme synkroone suhtlus hattu PRS-jaadil efektiisev või sopivam, kui jäädete jäärekorras, kus sõlumid panasi jäärekordeid, siis neid jäävad sinna ootpele, kui keegi ei tugematse. Ja te peate siis kirjeltama ühted senaariumid ja siis natukööne lisama argument, et miks teie hinan, kui rest on parem kui teedat jäärekordad. Ja küsimus võib olla ka vastuvidi, et miks teedat jäärekordad on parem kui rest. Ja see küsimus eeltab, et ta ise oskat, et senaariumid välja valida. Ma olen neid küst seda tüüpi küsimesi vähem kasutanud, kui järgmest näedad, kus ma ised senaariumi panen. Ja et ma teen sellised küsimus, kus ma isepakun meile senaariumid, kus ta ise ei pea senaariumid välja mõtlama. Aga see oleks siis üks näile. Teistelt kaks küsimust on sellel senaariumi kohta. Siin pakkusin välja välja senaariumi. Teid palka vidu firma, mille eesmärk on välja töötada ja käivitada tarkvana, mis võimaldab kasutatel üles laadida videoses. Selleks, et välja otsida videodest erinev tseene, milles leidub kasutajende nägu. Et näiteks keegi üles video, mingisest ürit just, et soovide enastalt välja leida. Siin tuu firma saavib aeltas tuua pilve, kui siin teedus näed kasutat, saavad svedi kaudu oma video üles laadida. Ja nende jaoks on tähtis voidu kulusid kokku alguses prototip eetemis ajal. Aga samas on soov, et hakkandis oleks võimalne hiljem skaleerima kiiresti, kui järsku mingi üritbis ajal näiteks. Toimub Eesti laulubidu ja siis kõik kasutatakad kohast ja kasutamad enastalt leida. Et siis võib pole korraga västi võidu video, et saad võiteks üles pohjapäära stil laulubidu. Siin on kaks eest küsimust ja need jälle puudutavad nende ainate temaid. See on teine küsimuse, millist kõipi anmebaasid ja kasutusel võtaksid. Kas resaltioonist võitivärdust, dokumentipõist või veegude perekonna. Mis oleks kõige mõistlikum, selleks, et vajustada sellist videos, kui teid trakere, mis sa olema saan loodud pitte. Neist te peate arutlema, mis on nende erinate lähennemiste elistile puudused. Ja tõhjendama, miks just see teie poolt valitud lähennemist on parem ku alternatiivid ja võrteva vähem tühe alternatiivida. Siin vastusa võib pole liiga lihtne, et kus teika videosed hoiaksid aga, nagu ohjelmist sellised küsimused tuleb. Teine küsimus täpsatesame selle samal senaarivi kohta on, kas te soovitakse kasutada virtaalmasinaid või konteinereid sellist rakennistakomponentid ülesjaadmiseks. Ja siis ka sellest senaarivi kontekstis arutlega oma valikud ja kasutavad eeliselt puutuseid, nii pohjad, et miks just te valitatakas selle või selle ja mis on probleemid selle teise ära lähennemist kape. Ja kui on sellist küsimused, siis te peate arutlame sellest senaarivi kontekstis ja mitte nii nagu üldisalt, et virtaalmasinad on paremad mingis teises kontekstis ei ole õige vastus, et te täksete just pareman. Just teid videode haltuse, piltide haltuse, kulutekoku hoitmise, skaleeridis konteksti, et see on siis keegi tähetsam. Ja tähendastud see eksami tuleb minu pohjaliselt senaarivimid ja sellist küsimused, kas tuleb, et teid tuleb arutleda siis nended senaarivimid kontekstis, millised valikud on paremad või halvemad ja kaata maidu teemasid, mis on loohendudest kaed või mida te oled praaktiikimeist proovid. Siin on küsimus, kuidas on poonuspunktid ja kas need annavad läveendi ja ma ei ole väga range olnud, et kui tudeend, kes kogu poonus üles sanate tõttu 51 punkt ja tõesti väga ei taha eksamid tulla on Eestist väljas, et siis ainuke range kriteerim on see, et te peate olema eksamele rekistreerunud, et ma saaks hinde sisse panna ja kui te saate eksamid 0, siis ma ei hakkanud, ma et te peate eksamid vähemalt midi puhju koguma, et saab teoreetustid isegi ilma eksamid ka kesika ei etahav. Aga jah, et lähevad, kuna lähevad on ainult praaktikumi laenduste esitamine, siis selles mõttes ega ta väga ma, kui seda 28 % ei põjutu, kuna ta ikkagi ühe praaktikumi sisuna see poonus selles sanat. Aga tõesti, et kui on mingi olukord, et jääda aigeks ja tõesti ei saa kuuaegu ühelki eksamide tulla, siis saab ka 51 punktiga läbi nii, et eksamele ei tulnud. Kuidas punktid rakenduvad? Teie võib-ole ei näe, et hinnate lähte hästi, kui te saate praaktikumi eest 10 punkti, hinnate lähte, siis poonusülesanat annad plus 2 sinna juurda. Aga midegi selistindama, võib-olla oleks pidanud esimese loon, kui see on rohkem ette tooma, aga jah, see poonusülesanat annad natuke poonuspunkti juurde, aga neid väga palju ainate see oledma ka viimases praaktikumi tein, jah, poonusülesat juurde, hea natsutada seal ei olnud, aga väga palju ta ei teie indete ei parandas, sest neid on kuskil 45 tükki, kui kui kus tükki komputervaine peale, neid tootub palju jälle. Kes kelle ka näeme küsimest? Et nad samad näite, et senaarimide küsimest on siis kodul ära kolmas, saate vaadata ja võite siis suulipik autu küsida, kui teil vees tekivad küsimest X-a, nii kohta näiteks, mis materjale tohi kasutada, aga tohjumust kõikki printitud materjale tohi kasutada, aga siis ärge suure kärugas ja tulga mõistliku arvu kõik. Meil ka oli eena aasta, kus me lubasime ainees süljaharvudid kasutada ja siis üks tuden kirutas terve eksami süljaharvudist, kes sääkis palju jõutusel ja chatboti. Aga selleks siis ongi kõik, et mind rohkemast ei näe, kuna see nädal uut teemat ka praktikumise alavets ma vasta saalt läbi kõmmi, nii et edu teile ja loodan, et saanja liide ea kus huvitab ja eks võtbalu näeme kuski teiste saanjatas tulevikus. Oda, et saanjal kasutada. Ah, eksame kõna, teie fietad. Aga lõpetame siis tänakse ära, kui rohkemist ei ole. Tänan!