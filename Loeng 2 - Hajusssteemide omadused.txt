 Aga alustame siis pihta tere tulemast teise loengus hajussüsteemide ja webi teenuste arjandusainest, kus ma mõnikord ja vaheta niid järekordasid. Aga täna on siis teine loengus me jätkame hajussüsteemide teemaga, et räägime hajussüsteemide omadustest ja natukka räägime lõimedest, kuna praktikum on konkreetselt lõimede programeerimisega seotud. Ma enne nädal juba natukka alustasin seda teemat, et räägisin teile, mis asjad on hajussüsteemid ja mis on nende omadused. Räägisin natukka hajussüsteemide ja tüüpidest ja näidetest ja ma korraks näitan näid veelkord ja käime natukene detailsemalt sisse selle loengu jooksul üle, et räägime natukene hajussüsteemide kõige tähtsamad omadused, et see võib natukene liiga abstraksseks võib-olla jäeda, aga sellega aine raames näites, kui ma hakkame iljem tegelema pilve, tehnoloogijaga ja pilveplatformidega, siis tegelikult on hea teada neid baasomadusi hajussüsteemidel ka, sest pilved ongi ühed suured hajussüsteemid. Ja räägime siis natukene mitme löömeliste protsessidest ja lõimedest üldiselt teises loengu osas ja põhimõtteliselt, kui te olete seda teemat kattud näiteks operatsioonisüsteemides või Java programeerimise aine samuti, et kui tas Java lõimi programeerida, siis see on suhtelat sarnaane protsess või suhtelat sarnaane teema ka siin. Hajussüsteemid, hajussüsteeme on hästi erinevaid. Tänapäeval, nagu meil minna loeng mainisin, võib väga paljusid rakendusjuvi käsitleda, kui hajussüsteeme. Tavalsed veebirakendusad on üles ehtatud sellised mitme kihilisena, et meil on mingit kliendi päringud sisse tulas meie süsteemi. Sisteemi ees on tavaliselt mingisugune päringute ja autor lüüs, mis jagab sisse tulnud päringud siis kas erinevate regionide vahel ära ja ühe regionisest erinevate serverite vahel ära, et hajutada neid kasutada päringud ja saada hakkama rohkemate kasutada päringude töötledmisega, kui üks server suudab hakkama saada. Siin tavalsed on selline back-end-tyüpi serverid, mis võtavad vastu näiteks Http päringud ja siis vastavad kasutavad päringutele. Ja tihti, kui tegemist on rakendustegmis, mis hoiavad mingit enamisandmed, siis need serverid omakorda siis ühen tuuvad kuskil anmebaasi ja need anmebaasid on tavaliselt eraldi serverit tään ülesseatud, et tekibki kohe selline loomulik hajussusteem, mis võib-olla back-end serverid omavahel ei ühendusti võtada, nad ei suhtel omavahel, nii et nad on pigem nagu selline suur süsteem eraltatud kihtidesse, et igal kihil on oma roil ja sest selle kihi seees replitseeritud, et saaks skaleerida, kui palju serverid tegelev siis ühe ülesandega. Ja kui anmed te mahtunud ohut, siis on vajaga hajutada rohkem seda anmebaasid, et tekitada seda hajus anmebaase, et näiteks seada üles mitu lugemiskoopjad Postgres anmebaasis, niimoodi, et me saame anmed lugeda siis näiteks kolmest serveriks korraga ja nende anmed lugemine hajutada siis kõigi rakendusserverite või back-end koopjate vahel ära, et nad, et anmebaas ise oleks selline pudelik ael. Aga see on omakorda suustelt keeruline tema ja ma räägin sellest võib-olla hiljem. Võib-olla ka tark kodu, kus on igasugused sensorid mingisugused mikrokontrollerid, mingisugused aktuaatorit näiteks, mis teevad uukseluku lahti või mis akna teevad lahti või muudavad kütte võimsust. Need on omakorda mingisuguses lokaalses võrgus, kes suhtelad omal ja nende koostööd võib ka vaadata, kui hajussüsteeme, et saate defineerida, et kui on liikumist selles ruumis, siis lüüdita lamp sisse. Et sellist asju võib sisse ehitada lampi Ristvarasse tarkkars. Ongi lamp ja lampi sees on kohe sensor, mis tuvastab liikumist ja paned tööle lampi, et sellist süsteemi ei oleks hajussüsteem, kuna kõik on ühes Ristvallas sees, ühes rakenduses sees. Aga kui meil on liikumist sensor seinapel ja lamp on siin ja nemad pead ülevõrgu oma vahel rääkima mingi protokolli kasutades ja oma vahel suhtlema, siis on see rohkem juba hajussüsteemi mood ja kui terve maja või korrus või korter on ühendatud niimoodi. Siis on kategoriu juba sellise mikrokontrollerite või väikest arvutete põhise hajussüsteemiga. Ja ma elm, kui träeksin ka näedast igasugust arvutuskriidides, kus võib olla. Siit on natuke raska näedata. Võib olla nagu mitu ülikooli, kellel on oma sellised arvutus klastrid nagu meie ülikoolil ja nad on ülevõrgu ühendatud ja kui meil on teadlased näiteks, võib olla. Teadlased näiteks või tudenkit, kes soovad suuremoodi arvutadesi teha, kui ülikooli arvutuskeskus lubab, siis saab ühendata sellised lokaalsed klastrid globaalsesse kriidi niimoodi, et saab töid saata siis mitme ülikooli arvutuskeskustesse sama aegselt ja kokuda kokuned tulemused paljudes tasukohtubest. Sellised ülevõrgu ühendatavad, kül lokaalsed asuvad klastrid, aga globaalsed ühendatakse ja see tekitab isegi mitme tasemelise hajussüsteemist. Lokaalselt võib-eva, et neid serverid olla ühendatud hajussüsteeme, aga siis näud on nagu ka üle interneti ühendatud siis suuremaks hajussüsteemiks, kus on väiksemat hajussüsteeminik koondamine suuremaks hajussüsteemiks. Ja kõik pilveplatformid on saa-moodi hajussüsteemid, kui teie saate logida sisse näiteks Amazoni webi lehel ja saate sealt kaudu akata põhimõttel küsima endale virtuaalmasinad, siis seal taustal toimub väga palju erinevaid tegevusi. Alate sellest, et luuaks virtuaalmasin, luuaks kuski mujal näiteks webi ketas, ühendatakse see webi ketas virtuaalmasin, aga mis jooksad teises serveris ja konfigureeriteks see kõik keskond ümber selle, et teie tegelikult ei näegi, mis seal taga on. Ja tänapäeval tava kasutad ei näegi. Teie näed ainult seda, et on mingi load balanceri IP-adress ja hostname, aga teie ei näegi, mis seal taga on, kas on üks server, kas on 10 serverid, kas on 100 serverid ja veel vähem näete anmebaasi. Teatud olukordadest võite näha, et te näete erinevata serverid IP-adresse, aga tihtise peidetakse täiest ära. Ja see koormuseaotur, kas seda saab teha väga mitmel tasemel, alate sellest, et Eestist teie küsite, kus asub Facebook, et lähete Facebooki adressile ja TNS vastab teile, mis on selle Facebook-adressile vastav IP-adress. Ja see, millist IP-adressi teile näidata, seda saab TNS tasemel konfigureerida, niimoodi et Eestist tuleolla päringulle näedataks näiteks, ma ei tea, Soomes asuva anme keskus IP-adressi, Saksamalt tuleolla päringul Saksamaanme keskus IP-adressi, et saab juba TNS päringud tasemel jaotada päringud erinata anme keskuste vahel. Enne, kui need teie päring üldseühtik alme keskusesse jõuab, et ka sellist TNS-i tasemel saab jaotada, et kuhu tegelikult liiklus üldse saadatakse. Ja sellisel juhul Facebook'il peab olema erine oma servered siis kõigis nendes anme keskustes. Väga palju põhjusõidav, miks on vaja hajussüsteeme alates sellest, et arvutusresursside koonamina on efektiivsem. Ja see on üks motivatsioon ka pilve arvutuste puhul, et kui iga asutus seab üles endale oma serverid oma kontoris, siis nendel on täis kontroll nende serverid üle, aga kui need kasutad pilve, siis on suur firma, kes hoolitseb suurte arvu Ristvararresurssidest. Ja see on mõnes mõttes efektiivsem ka selletõttu, et siis peab olema ühes asutuses võib-olla suur tiim, inimesi, kes need haldavad neid servered. Aga ka elektrikasutuse mõttes on näiteks efektiivsem jooksutada ühte suurt serverid ja kasutada seda maksimaalselt ära, et sellisil juhul ühe suure serveri elektrikasutus on tõenalselt palju väiksem, kui nüüd 25 väiksema serveri jooksutamine, kelle kõigil on vaja jooksutada siis kõiki Ristvarat, niimoodi Ristvarakoondamine iseenest on juba efektiivsem. Ja anmeti arvutus võib-susud laialjäägamine ka, et arvut saa moodi, et tegelikult kui me koondame ühtekohta, sest see üks koht võib ka natukene problemaatilseks muutuda, sest kui midagi juhtub selle lokaalse võrguga seal, siis meie ei saa kõik kasutad, kes seda ühte serverid kasutavad, siis nende ühendus kaub ära või nad ei saas kasutada, kui selle server kokku jooksud. Siit tegelikult saa moodi koondamine on hea, aga koondamine ainult ühtekohta, mis võib katki minna, ei ole ka kõige paremini, et tegelikult on saa moodi hea, kui need koondatud asukohti on palju ja nad on geografiliselt ära jagatud, niimoodi, et Eesti kasutajad saavad rakendusi kasutada niimoodi, et rakendusid jooksevad Soome, Anme keskuses ja Saksamalt tarid kasutajad saavad kiiresti parema kasutusmugause, kui need hajussistemi komponidi, mida nemad kasutavad, on nendele lähemal, et kui see hajussisteem ise on jagatud sellisteks erinevateks regioonideks, mida saab kasutada, siis lähemal olev kasutajad saavad võib-al sellest kasvu, kui nad ei pea väga kaukel ühenduma. Ja see on põhimustat samamist ees centraliseeritus, et ei oleks olukorda, et kõik Annmed oleks ühes kohas, et kui midagi juhtub, siis Annmed läks kaduma. Eesti ka tegis selle tõttu, ma tegin mitku palju aastat tagasi otsus, et võik Eesti riigi teenused võiksid olla hajutatult ülemaailma, sellase, et natura ainult nagu tegis Tallinnas, et kui keegi ründab Eestit, et siis Eesti riigi teenused jätkuks isegi, et selline konsultatsioonide. Ma isegi unustan ära, mis see täpne Annagas on. Kui meil on konsulaadid välismaal, siis panna konsulaatidesse ka Annmekeskust, väikse Annmekeskused, et saaks hajutatud riigi teenused näedevaale. See päris kunagi nagu käipele ei läinud, aga tehaks ikkagi seda, et meil oleks mitu Annmekeskust, Eesti riigi pilv näiteks ehitati ka kuskil kaheks aastat tagasi. Ja algus oli selle üks Annmekeskust, nüüd on selle kaks Annmekeskust ja tegelikult oleks hea luuga üks Annmekeskust, mis on täitsa Eestist väljas pool, et oleks selline Eesti riigi pilv, kus Annmed oleks ka alles, siis kui Eesti Annmekeskustega midagi juhtub. Resursside kaug kasutus on tähtis, et meil on kaks annemäärg, Resursside kaug kasutus on tähtis, et ei oleks ainult see, et sa saada ainult samast kontorist Annmetelil ligi, vaid saaks üle internet üks kõik kust vajatus on, et rakendusi kasutada. Ja väga tähts on jõudlus, haujusüsteemide see on suhtselt lihtne skaleerida, sest kui meil on monoliitne rakendus, kuidas te resurssijuurde panete. Tavaliselt teete suurema serveri ostat ja panet liigutat oma rakenduse suuremase serverisse. Pilvesmonoliitsele rakenduse saab võib-olla dynaamiliselt suurema virtuaalmasina anda, aga sellised haujusüsteeme, kuna ta on ehitatud niimoodi, et teil on palju komponente, siis sellise veebi haujusüsteemi puhul on lihtne rakendusserverid lihtsalt juurda panna. Öösel näiteks kasutajate ole, panema end ühe app-serveris ja päeval võib siin näiteks viis olla ja nagu pühad ajal, jõulud ajal näiteks meil võib-olla on hästi palju kasutajad ja siis meil võib 25 serverid seal olema. Et see suhtselt lihtne on skaleerida haujusüsteeme, mis onki ehitatud selleks, et seal oleks sellised haujusad komponente ja see natukene suunab sellele pool, et sellised komponente lihtsam lisada ja emaldada, kui hakkata ühtemonellise tarkkora skaleerima. Ja tõrkke taluvus on ka, et kui meil on haujusüsteemis koosad paljudes komponentidest, siis võib-olla ühe komponenti koku jooksmine, mis jooksab ühes serveris, ei mõjuta kogu süsteemi eriti, kui meil on teenused replitseritud, et teenustest ei ole ainult üks koopja kusagil serverisvaid, näitas võib-olla jooksab mitu koopjat ja siis samuti on nagu sisse tulevad sonumid või päringud, nende kolme serveri vahle ära jagatud, siis ühe serveri koku jooksmine ei mõjuta kogu rakenduse tööd. Et mida rohkem on komponenteja, kui need komponenteid on niimoodi kooperitult ülesseatud, niimoodi et kolm koopjat näiteks jooksab erinate serveride peal, siis kahe serveri koku jooksmine tähendab, et meil vähemalt üks koopja neid veel ales. Teatud olukordades ei saa, on vaelik rohkem, kui pooltekoopjate alles jäämist on, selliste hajus algoritmida puhul, kus on vaja, et omaval hajusalt töötavad komponentid valiksid endale näiteks suure pealiku või et sellise lühul on tegelikult vaja, et alles jääks üle poole komponentide, niit kui meil on ainult kolm replikat mingist teenusest, kes oma vahel pealiku valivad, siis on tähtis, et kaks jääksid elu, et kogu süsteeme elu jääks. Aga siis saab näiteks viis jääda üles ja siis on vajad viis-kolm jääks elu. Aga et kui meil on palju erineid komponente, siis võib-olla selles kohaselt ei tekise Törkketaluvus, meil on vaja, et need komponentid oleksid replitseeritud, et samades komponentides tolguse logimisesüsteem või ANME-bass või mingisugused rakendusserverid, et meil onks ka vajad, et oleks replitseeritud, aga häius-süsteemidiga on seda tihti parem võimalik tagata kui monoliitsüsteemidiga. So, ümane-bass jäädud, et viis jääda maha, aga võib-olla sellest rakendusserid, maha ei ole tanda vahel jääda üle, et meil on tohtomasti sühen takas uur, et neid soomeid mulle on, et Euroopa see on ükslades vahel, Amerikas on siis viis teist, ja Asjas on siis neljub, Euroopa jääse ma teist vahe, aga mul sens tõet, et Euroopa on üle asja, kui sa ei või ta, et Iitma ja Sallvea. Sellise liuhtudele on võimalik teha ka ümper suunamisi tene stasemel, et sul reaalselt sul ei suunata kui sinu Tarkvarav, Riisvarav ja sinu arvuti klienti arvut, et näitek laptop teeb päringu, et kus asub see hostname, ja TNS ei leiagi ühtegi serverit, mis sellele vastab, või vähemalt on eelmised päringu terrorid saanud, siis ta võib switchida ümber täiesti teise regioni ja hakkata siin suunamaasjasse, et see on ka võimalik. Aga ka see on tegelikult problemaatilne eriti Amerikas, meil on näiteks olnud, et inimesi läheb Amerikasse konverentsile, ja proovivad Tartu ülikoliserverit ligi pääsada ja ei saa, et jutee.ee ei vasta. Ja mis siis juhtus ongi see, et tegelikult on internet ei ole nii ühendatud üheks internetiks, kui ette kujutada võiks. Reaalselt on tegelikult mitu paraleliselt võrku ja teatad võrkudes ruutimine Amerikast Eestisse ei töötagi, kui vahepeal ei ole cashi loodud ja on vajalik tegelikult näiteks Googlei, Fiber võrkust ümper suunata välis interneti ja ümper suunata Eestisse ja esimest päringu teid prugigi töötada kuni mingisugust vahepealsed. Ma räägin sellest ka natuke ilisemata slaidides, aga võib juhtuda, et täiesti normaalne päring ei saagi vastus, kuna TNS ei oska suunata õigessa kohta ja esimest päringu teid töötagi. Ja, aga esimest päringud võib täitsa fählida, kui ruutereid ei oskagi ruutida orekstsas kohtad. Ühe definitsioonina on hajussusteeem autonoomset arutas elementida kogum, mis paistab kasutale ühe situsa süsteemina. Ta ei ole suvalist arutas elementide kogum, vaid on autonoomsete niimoodi, et need komponentid, mis on neil on, on suhteliselt sõltumadad üksteisest, et nad ei prugigi tegelikult väga teada, mis on teised komponentid ja kudas teised komponentid töötavad. Ehk autonoomsed arutas elementid Eesti keeles võib neid nimetatakse sõlmedeks, Ingliskeles tihti nimetatakse näitek snoodideks. Mis võivad need arutas elementid või sõlmed olla? Nad võivad lihtsalt olla serverid või arutid, kriistvara kusakil, mis oskab jooksutada tarkkura. Nad võivad olla ka processid, et nad ei pea konkreestalt olema terve arvuti, kes on hajussüsteemi osa, vaid selle arvutis jookse üks process on selle arvut või selle hajussüsteemi osa ilma, et server arvuti nagu üldiselt oleks. Teised tarkkura teenuse, mis jooksevad näiteks TNS teenus kusakil jooksevad kolla arvutus serveri osa või mida arvutis serveri või hajussüsteemi osa. Serverid arvutid eriti serverite puhul, mida me eeldame on see, et me saame nendese ühenduda, et me saame neile päringud teha, et neil on mingisugusid IP-aadrisid, neil on mingisugusid portid lahti, et me saame sinna kas sõnumid saata, HTTP päringud teha, aga meil võivad olega sellised, et see on nagu nutitelefonid või sensorit, kuhu tegelikult ei saa otsa ühenduda, et me ei saa temperatuurisensorisse ühendada küsida, mis on temperatuuriväärtus üle lokaalse võrgusin Tartu ülikoolis, et võib-olla saab see mikrokontroller, kes on draadiga ühendatud temperatuurisensorisse saab küsida, mis on temperatuuriväärtus, aga meie peame siis ühendama mingisuguse serverisse, et küsida mingisuguse sensoriväärtus. Sellised sensorid või nutitelefonid ja muud seadmed, kes pigem käituvad sellise klientina, et nemad ise võtavad ühendust teiste hajussüsteemide komponentide, näiteks serveritega, ja saadavad siin anmed või siis küsivad, näiteks, et kas minu ajaks on midagi mingi töö teha, et asjade internetist ihti ehitadakse just sellised seadmed turvalise seda tõttu, mis ise ühenduvad kuskile asjade interneti platformi ja küsivad, kas minu ajaks on mingisugust operatsiooni, et näiteks mulle võib-olla mikrokontroller, kes tegeleb selle lambi sissele ülitamisega, aga ma ei taha võrgust seda kätte saadavaks teha, ma ei tee ühtegi IP-adresse vii porti lahti selle mikrokontroller jaoks, aza mikrokontroller ise ühendub siin majas olavasse IOT-anmebase ja küsib, kas minu ajaks on uut operatsiooni, ja seal, kui ta küsib, kas minu ajaks on operatsiooni, seal on lambi sissele ültamise operatsiooni, seal on lambi välja ültamise operatsiooni ja seal on lambi sissele ültamise operatsiooni ja seda peab võib-olla ise otsustama, kud asjad need kolm operatsiooni siis teha, kas kohe korda ma oledas sissele ülitada või ainult kasutada viimast. Sellised seadmed on pigem nagu kliendid, kes teised sõlmed siin haussysteemist nende ühendust otsa ei saa, aga nad on ikka haussysteemi osad, mis võtavad ise ühendust teiste komponentidega ja suhtlevad nendeega. Et tihti ka asjad interneti platformides, sensori anmed liigutatakse anmebaasi kuhugi, niimoodi et teised haussysteemi komponenti saad anmebasist küsida, et mis on keige viimane temperatuuriväärtus, et ei piaga sensorid otsa olema ühendatud, et keegis sensori käsid otsa küsida. Sellal ma mõtsin autonoomsed, et nad on ise seisvalto otsustavad, kudas nad käituvad, kas nad võtavad ühendust kellegiga või kas nad võtavad vastu mingisuguseid sõnumi teistelt või nad pigem töötavad klientidena. Ei ole et hihti sellist kesksed kontrolerid, kes kõige üle otsustab, vaid nad võivad ka olla sellise mitte keskselt orkestreeritud süsteemina, aga oma vahel koostad tegev haussysteemide süsteem, kus on nagu rohkem korjografia, et iga üks tansib oma moodi, kudest ta soovib ja kokku ehitetakse nendest selline haussysteeme. Ja ühe situsas süsteemina mõeldakse seda, et kui meil nüüd on kasutajad, kasutaks võiks olla selle haussysteemi kasutam lihtne. Ei peaks olema olukorda, kus mina tahan näha temperatuurid, siis ma põnnu ülesotsima, kus on sensor, ülesotsima, mis on selle sensor IP-adress ja küsima selle sensori käest võib-olla mingi speciaalse rakenduse kaudu, et ma nüüd kasutan MQTT rakendust, et nüüd sensorega ühenudust võtta, saata sensorile operatsioon või saata sensorile sõnum või otsa ühenudada sensori MQTT serverisse ja kuulata, et mis on sensoriväärtused. Et selliste rakenduste ehitavalaks suhtseb keerulne, kui me peame teadma kõikides individuaalsades komponentides selle saajussüsteemis ja nende ka oma rakendust ühenudust võtma. Et parem on ehitada selline üks situsas süsteem, millel võib-olla on näiteks anmebaas ja mul on õigus anmebaast anmeid vaadata. Ma saan anmebaasist küsida, mis on sensorid ja vaadata, et sensorides on 40 temperatuurisensorid ja ma küsin anmebaasist, mis on selle temperatuurisensoriväärtus. Ja lõp kasutale võib-olla näeb see välja nagu pikem sellise tavalise veebirakendusena või tavalise mingi tüübi rakendusena ja minu eest on peidetud tegelikult ära, et ku palju sell riistvara komponent on, kus nad asuvad, kui seda infot vaja ei ole ja kuidas ma nagu nende ka ühenudust võtan, et ma ei pea teadma, mis on protokollid, on mikrokontroller ja sensor vahel, kas on Moot Park, kas on NQTT, kas on mingisugune traadi ühenudus ja et klient ei pea sellest mitte midagi teadma. Temaaks on mingisugune lihtsustus tehtud, etteiks veebirakendus, mille kauduma saan nüüd selle hajussüsteemiga suhelda ja tegeleda, et üks nagu eesmärk ongi siis tegelikult ära peitas ja keerukus kasutad eest, sest muidu on nende süsteemide kasutamine väga keeruline. Ja kasutai prugigi aru saada, et tegelikult on hajussüsteemiga tegu, et tema näeb ainult anmebaasi, etteiks. Meil võib olla siis täiesti centraliseeritud rakendus, mis on mingi mononitrakendus või anmebaast plus mingisugune rakendus. Meil võib olla selline hajutatud sõlmeda kogumik, kes teevad oma val koostuda, ka mõned on sellised kesksed kontrollerid või keskkled managerid, kes võib-olla haldaud oma komplekti sensoritest või oma komplekti teistest hajussüsteemide väiksemates komponentidest niimoodi, et võib-olla kasutaja saab ühenudust võtta peamise serveriga ja siin serveri kaudu see server pakub mingisugus liidest olguses haatate pealiid. Meil on siis sellise liides või mingi muu liides, näiteks MQTT, pidame käsina aines vaatame ja sellega autu saab kasutaja kõik infokätte. Võib-olla meil onki, et meil on eraldi sellised väiksemad klustrid, näiteks eraldi kaks kuberneetes klustrid, mis on oma vahel suhtlevad, aga kasutajal näed välja nagu üks kuberneetes kluster, aga tegelikult seal on peidusmitu. Võib-olla täiesti deesentraliseeritud hajussüsteemid, need on näiteks igasugused blockchain lahendused, kus iga sõlm selles võrgus, hajussüsteem võrgus on võrgne olem, et oma vahel ei ole ühtegi pealiku, vaid kõik teavad koostujad ja kõik võib-olla valivad endale, võib-olla nad ei pea esikult pealiku valima, et kõik ongi võrtsad, et sa võid suvalise noodiga ühenduda ja tema kas samasugused päringuid teha ja tema võib-olla suhtelad peistene noodidega, aga otsaselt ei ole pealiku, kellege ühendustaks võtma. Et selliste süsteemide pool võib-olla siin olevad klusterid peavad endale, klusteris olevad komponentid peavad endal pealiku valima ja siis kas teised hajussüsteemide komponentid suhtelad pealikuga või klendiid suhtelad pealikuga, aga selliste peastide etseentraliseeritud hajussüsteemide pool ei peagi pealiku olema. Kas te teate, mis on sellistes Bitcoinis näiteks viis kuidas valiteks see pealiku? Kui on täitsa selline olukord, et meil on kõik omavõls võrtsed, aga üks nendes saab õiguse teha järgmine blockchain, ehk otsustada, mis transaktioonid lähevad järgmise blokki. Põhimiselt ja, aga kõik teevad seda samahaikselt kõik proovioot pealikuks saada. Isegi mitte kõige pikkem, aga konkreets teatud arvu nulle peab olema, et ta ei ole olema kõige pikkem, ta peab olema esimene, kes sinna juuab või esimene, kes raporteerib. Et mõnes mõttes Bitcoinis on loteri. Kes võidab loteri, saab pealikuks ja sellele on õigus. Ei ole nagu, et me valime omaväl, kes pealikuks saab, vaid kõik mängivad loteriid nii kaua, kui üks nendest võidab ja siis see saab pealikuks. Ja mõnes mõttes see väldib seda, et peab kui tege valima, et kui me ei usaldada tegelikult ühtegi node sellest, et kui ta seda teha, siis see hashite arvutamine on selline hästi hajutatud mitte usaldust vaja, loteri, mida saab samahaikselt mängida. Ja võltsida on seda väga raske, sest võltsimiseks on sellal arvutus resurssivaja, siis ei ole isegi vahet, kas sa proovit seda võltsida või mitte, sest nii on sellal arvutus resurssivaja. Et kui oleks suuelne kokum võrdselt node, siis ma oon püks genereerida näiteks pilves endale 10 000 sellist hästi väikest serverid, kes proovivad mängida valijaid, aga kui iga üks nendest vajab tegelikult samal palju arvutus resursse, siis ma väga seda teha ei saa. Ma saan aga sest ei ole mingid kasu. Ja see ongi siis selles definitsioonis olev autonoomsalt arvutusel entidikogumid. Siin meil pigem on ainult üks. Oosaliselt centraliseeritud hajussüsteemides on näite sõlmede tüütä ja mitmesugused ja mõnedel on rohkem õigusi võib-pal ajutuselt, kuna ta on valitud tealikoks, aga teatud süsteemides on kõik siis võrdselt. Ja iga arvutuselement on mõnesmõttes sõltumatu ja peab olema sõltumatu, kuna ikku ja nagu füüsiliselt erinevad seadmed sinne on oma lokaalsed kellad, et mis hetke aeg on. Meil on oma mäluala, neil on oma resursid ja neid on raske niimoodi keskselt juhtida ja üks selline erinoos ongi, et meil ei ole globaalsed kella ja hajusalgoritmid pead selle ka arvestama. Nad saavad seda proovida teha, aga nad ei saa seda nagu 100% paika, et sal alati jääb natuke epa täpseks. Et isegi, kui sa proovid ehitada hajusüsteeme, kus nagu on tähtis, et kui korraga jõuab kohale kolm transaktsiooni, mis nendest ole esimene, näiteks sa tahad, ühest bankakontost tahetakse raha välja võtta ja sul tulub sama aegselt kolm päringud, siis mis nendest tegelikult reaalselt päris elus enne tehti. Seda on väga raske nagu tarkvaratasemel otsustada, kui sul on kolm päringud, mis jõuad kolme erinaate Riistvarasse ja kõigil on oma kellad. Saavad küll kellad synchroniseerinud, aga sa oled teinud seda võrgu päringud ta põhjal ja see ei saa kunagi nagu 100% täpne olema. See on see suhtsalt suur probleem sellistes hajusalgoritmides, kus nagu on tähtis mingite sünnmuste järekord, on hästi tähtis. Mõned hajusrakendustapuul ei ole üldse tähtis. Kes enne modifitseeris mingisugust postitust või on sama kasutamodifitseeris oma postitust kolm korda, see on ka mõnes mõttes oluline, aga vähem oluline, kui mingisugut bankakontot rahaväli võtmene. Sa mõted kellad? Ma ei ole päris kindel, aga see on nagu viga ise võib-olla natuke isegi see, natuke tähtsam, et just see, et kui sul on kolm samal aegsel toimud sünnmust, kas sa saadnad järjestada õigis järekorrad ja siis väga ei ole tähtis võib-olla. Kui sa ajaa sünnmus on väiksem kui täpsus, siis see on nii päris arvutussysteem, aga seda võib-olla isegi nagu rekordida ei olegi võimalik nii täpsult. Ja samas on tähtis, et kogu see systeem sõlmeda kogu, mingi töötaks samamoodi oleneval sellest, kus ja millal toimub kasutaja ja systeemi vahele suhtlusid. Kas kasutaja ühendub siis siia või ühendub opis siia, see haussysteem täks töötama samamoodi või siis siin, et kas kasutaja ühendub siia, ühendab siia, siis kogu selle haussysteemi kasutamine võiks sa olla täpselt samasugun, et ideaalis võib-olla kasutajai tohiks ikkagi aru saada, kuhuda on ühendatud. Ja siis on küsimus, kui läbi paiste peaks olema see hajutadus, kas lõp kasutaja tohiks näha, kus täpselt arvutusse toimuvad, kus on kus, kus läbi paiste peaks olema see hajutadus, kas lõp kasutaja tohiks näha, kus täpselt arvutusse toimuvad või peaks nende eest olla mära peidetud, nangu ideaalises haussysteemis võib-olla kasutajai tohikski midagi näha, aga päris elus ei ole vajalik otsaselt. Ei ole mõte, et ästi palju ressursse ei uurde panna või kui tästi keerulis tarp erahitada selle, agaks et kindlasti kõik asjad ära peita kasutajajast. Ja rakendaseaoks ei tohiks olla olulne, kus anmed täpselt saavlastatakse. Kui meie ühendume, siis küsime mingid anmest sellised haussysteemist. Kui anmed asuad seal, siis kindlasti nende kopeerimine siia võib-olla võta prohkem aega, aga kasutajajaks ei tohiks sellest midagi väga muhtuda, võib-olla väike latentsuse erinevus ja kõik. Kui me tahaksime teha haussysteemi täiesti läbi paistvatuks, et me tahame mingil põhjusel karanteerida, et ei oleks võimalik aru saada, kus anmed asuvad siin võrgus, see olks see suhustselt keeruline, sest kui asuad siin, võib-olla juhavad anmed 10 millisekondiga kohale, kui asuad siin, võib-olla juhavad 40 millisekondiga kohale, nii et vastavad latentsusele me saame kasutada saab teada, et kas anmed on kaugel või lähedal, kas me peame sellel ära peitma. Kui meil on nõu, et selle peaks ära peitma, siis me võib-olla peaksime kogulatentsuse panema automaatsal 50 millisekondi peale ja panema kasutada ootama 50 millisekondi, et enne, kui tanmed saab. Aga mille aaks meil see vajalik on, et kui meil rakendusel tarkvaran mingid sellist nõu, et ei ole, et see ei ole mõted ka lisatöö teha, et tagada sellisid omadusi, kuna teil on rangelt vajalikud. Aga see, ja anmedest on tihitiga peidetud see, kas sellest anmedest on mitu koopete või mitte, see ka ei ole tähtis, nagu kasuta jaaks. Ja see võib mõnikord ka natuke probleemiks tekida, et teie näiteks saadate Facebookile sõnume, et te soovete kõik oma anmed kustutada. Facebook kustutab anmedvaisid ära, ütleb, et teil on kõik anmed kustutatud. Kuidas te teate, et nad on kõik kustutatud? Ei, nad kui teiste kustutavad, aga kuidas nemad saavad kontrollid, et see on kustutatud? Nii on kõva ketas. Nii on virtuaalmasinatest backupid, igasugustest ketastest eraldi backupid, vanakatkilainud kõvaketas kui kõrvale pandud, ära on tead, et uue kõvakettaga, kui keegi tühendad seda kõvakettast. Kuidas sa tead, et anmed on täiesti kustutatud, siesteemides, kus ongi anmed replitseerimine, backupiminine hästi tavalne tegevus. Reasade ongi tegelikult väga raske karanteerid, et mitte üheski serveris ei ole kuskil kooped sellest anmedest. Ja olukorraga, kus meil sellised võrgud järjest suuremaks kasvavad, et kui meil on selline süsteem, mis on tõenalises, et ketas sinn kõrval läheb üks kord näiteks kahe aasta jooksul, läheb üks ketas kõrval. Aga meil on 500 ketast, siis üks ketas, iga ketagohta üks kord kahe aasta jooks läheb ketas katki, ja mida rohkem ketad on, siis seda tõenalises emand ome üks ketas nendest läheb katki. Jah, aga sul tekib juba probleem, kui üks ketas läheb katki, et selle komponentiga tekib koheproblem. Kui sul see komponent on replitseeritud, siis võib-olla mingi probleemi ole, aga... Jah, aga see süsteem, mille see ehitat, peabki olema siis võimelne selliste väikeste viga tege hakkama saama, et sa ei saa ehitada süsteemi, mis jookses kokku, kui üks komponent, üks ketas läheb katki. Jah, nagu sellise läbi paistluse mõttes, et kui meil on ühtne ja samalt situssüsteemis peab olema, nagu kasutel mitte aru saadov, et ta on hajussüsteem, või kasut ei piaks nägema näid resursse, mis seal taga on, siis selliste rikete peitmine kasutajeev, et see on pea võimatu, et kasuta saab vea kasutaja, kui sa vea proovit kasutajast ära peita, siis kasutajal on tegevast, et kasutajal on tegevast, et kasutajal on tegevast, et kasutajal on tegevast, et kasutajal on tegevast, et kasutajal on tegevast, et kasutajal on tegevast, et kasutaj kasutajajab ootele, kuni sa võib-olla uuesti päringu vastusse tale saadad, et nii ta märkab, et midagi on katki, kui asjad hakkavad feilimani, et selliste rikete ja nende taastumise peitmine võib-olla võimatu kasutajast ära peita, sa võid panna kasutajarega viieks minutiks ootele, siis saadad õiget tulemused, aga kasutaja saab aru, et midal eks valesti, miks ta viis minuti tootas. Ja selliste haiussysteemide sellised viis põhiomadust ongi resursside jagamine läbivaistvust, transparensus, millest me praegu rääksime, aga vaatame ka neid tüüp, et mis tüüp peal läbivaistvust meilt võib olla vajalik haiussysteemides tagada. Haiussysteemide avatus, et neid oleks võimalik mugavalt kasutada pea üks kõik, mis rakendusest, erinevalt sellest, mis programeerimist keelt või mis platformist, kas me kasutame Raspberry Pi-bjalt seda haiussysteemi või oma telefonist. Törke kindus, et elaks üle üks kõik, mis vead, mis tekivad süsteemis ja skaleeritavus ja paralelsus, et oleks võimaline skaleerida, et kui meie haiussysteemide kasutajad arv hüppelised kasab, et haiussysteem saaks selle kakkama. Resurssid jagamine, aga mis on siis resursid? Resursid võib oleks kõik, mis haiussysteemil on vajalikud olgun, et kas mingisugud failid, olgun, et arvutas võimsus, olguse salvestusruum. Meil on vaja nagu kõikite kasutata anmed salvestada niimoodi, et need oleks kasutatavad ja mida rohkem pilte salvestaviks, mida rohkem videot salvestataks, meie haiussysteem saaks ikkagi selle ka hakkama. Resursid võib olema anmed, mis on salvestad anmebaasi. Võivad ollagi igasugused failid, näiteks HTML-failid, mida kasutatavad ülleslaadida, nad soovid oma kodulehel näidata seda HTML-faili. Igasugused pildid, videod, et näiteks ma räägin sellest rohkem järgeste slaidipeale sellised anmedte jagamise võrgud, mille eesmärk ongi anmed teha võimalikult lokaalselt kätte saadavaks kasutatele, et näiteks kujutakette YouTube'i, et kui YouTube'i kõik videot täksid Amerikast kohale tõmbama, et kui palju interneti bandwidth'i on vaja, selleks tagada maailma internetiselt, et see võimalik oleks. Ja ka teenused endat, et kui meil on mingisugused teenused, mis on vajalikud selleks, et kõik hajussüsteem töötaks, ja meil vaja, et ka need teenused oleksid jaotatud siis kõiki nende asukohtade vahel, kus meil hajussüsteemide kasutajad on. Ja et ei ole, ei tekiks seda olukord, et teatud teenused on hästi aeglased, kui nad asuvad ainult ühes kohas. Jah, see aeglus sa võiti vaadata, et kust, kes seda aeglust mõõdab, et lõpkasutavadast on aeglene, kui pildi allatõmbane võtab hästi kaua aega, et kas on latentsuse tõttu või se on selle tõttu, et anmeda maht on suur. Jah, aga latentsus on kõululine, et kui anmeda hästi väikse, siis läbilask võime ei progültse tähendada, et ikkagi ootad suusted kaua aega enne, kui nad anmed kohal jõud. Jah, tihti selline sisu kohale toomise võrgud ongi ehitatud selleks, et kui meil on rakendust, mida me näiteks Eestis ehitame, aga meil on kasutad Australiast, et meil ei ole võib-pall kasutada Australiast või kogu üle maailma, et kui nemad kasutavad oma süle arutist, siis meie rakendust, et siis ei peaks anmed tõmbama Saksamaalt või Amerikast, et tekiksid sellised kohalikud anmed nende sisse, et meil on kasutad. Nii, et see on sellist anmed, et mida kõige tehedemid kasutatakse. Tavalliselt on need mingisusvusid pildid, mingisusvusid videod, kas või HTML-failid, et kui kasutaja proovib meie veebilet kasutada, see on kusajag, et vaja alla tõmata näiteks frontend JavaScripti-failid, ja see ei ole hea, kuna tästi kauge lasuvad ja näid tõmatakse eriti olukorras kasutada hästi palju. Ja selleks ongi sellised content delivery networkid, kus automaatselt tuaks anmed, mida kasutatakse sealt asukoast sinna asukoha lähedala. Ja seda tihti tehaakse pilvedes, et nendeiks Amazonis saad defineerida, et kuhu on lubatud teie kaustasasuvad anmed liigutadad, mis regioonidesse, ja kas te tahad, et oleks automaatne selline anmedliigutamine sisse lülitatud. Sest see nõuvab tegelikult mitmekordsed anmedtes alvestamist ja võib teile rohkemaksma minna ka. Et kui teie sojate koopet anmedtes kõikidas anmekeskustes ja need anmekeskus on kuus, siis te peate kuuskord rohkemaksma. Aga kui see toimub tõnaamiliselt, et ainult need anmed liigutadakse, mida reaselt kasutatakse, siis ta ei lähed äle nii palju maksma. Ja üks kõige klassikalis, ja määne näite ongi Google Edge Network, mis osaliselt ehitati YouTube jaaks valmis. Et kui Googlil on anmekeskuseid päris palju, aga põhimst tasu, nad Euroopas, üks Soomes, Amerikas, üks Lõuna, Amerikas, mõned Aasias. Nüüdseks kui te vaatate seda kaarti, siis seal võib olla rohkem, kui te lähete Google Edge Network veibi lähele. Aga need on ainult sellised põhi-Google ehitatud anmekeskused, lisaks asuvad, ma üppal räägin sellest järgmise slaidil. Lisaks asuvad sellised vahejaamad palju rohkemates kohtades, mis on ligi lähedased suurtel riikidele, kus on hästi palju elanikke. Siis Google ehitab sellised oma võrgu ja välis interneti vahel sellised jaamad, kus on ka väiksemad anmekeskused. Ja neid asukohti lisaks nende lülemistel on siis rohkem ja seal ka käsitakse YouTube videosid, niimoodi kui Lõuna Afrikast vist YouTube videosid vaatatakse, siis ei tõmata neid kuskilt Afrikast väljas poolt. Ma aidan üks, vähemalt üks selline vahepealne station. Ja see on nagu teine kiht. Esimene kiht on siis Google anmekeskused, teine kiht on sellised vahepealsed jaamad ja kolmas kiht on partnerfirmad. Siin ma kaegu siin saan sisse suumida, ka üks on Tallinnas. Tõenaselt Teliass, aga ma ei ole 100% kindel. Ja see on nagu kolmas kiht, et Google ise ei lupa näiteks YouTube videosid käsida Teliall. Et lihtsalt ei luba, et kuna nema tahad otsustada, et kuna käsitakse, kuna video eemaltatakse, et kui nema saavad mingisuguse, ma ei tea, take down requesti, siis et neid saaksid kohe selle maha võtta ja ei tekikse seda olukorda, et nüüd ma peavad Teliaga rääkima, et Telia selle käsji maha võtaks. Et nad tavad 100% kontrolli selle üle, et kuidas käsitakse nende sisu. Ja siis nad ongi nii paljutekohalik teenuspakujatega teinud lepingud, et nendes teenuspakujatega Annemekeskustesse on lubatud panna Google serverid. Ehk siis Google ostab ja viib kohale siis Google serverid kõik, keda sa on nende asukohtudesse ja need appid on tihti nagu suurte linnade või väikeste rikide juures. Ja kui teie vaatad YouTube videoid, esimes korda Eestis teie vaatad, siis tõmatakse kuskilt näiteks Soome-Anne keskusest või teisest jaamast, siis Telia serverisse see video ölesse, siis teised, kes pärast teid vaatavad, siis tõmatakse see video Telia keskusest. Aga selliseid võrk, kes saab kasutada üks kõik, mis sugu se sisu jaaks, aga peamiselt oli see vajalik just selle tõtta, et YouTube videoid ja vaatamise maht oli nii suur, et interneti bändvit ei elaks seda ülepõhimõtsult. Või siis läheks liiga kalliks Google'l maksma, või siis Google võtakski interneti üle, et teised teenusid oleks tohutult aeglased. Kõik olema dublitseeritud. Kui teie loota konto, siis tavast ütlet, et kustel ootavalt masina ma loon näiteks virtuaalmasina Soome'es, ma tekitan endale pilve kausta, kus ma panan anmed, ma loon selled näiteks Soome-Anne keskusest. Ja seal saate konfigureerite, kas see asub ainult Soomas, Anne keskusest või autonetiseks. Ja Content Delivery Network'i saab see oleisigi rohkem tünnaamil, et te saate registreerida teatud Anne neteks pildid, et nad oleksid Content Delivery Network'i poolt teie kaustast võetud ja Content Delivery Network'is registreeritud. Ja siis hakkataks automaatsalt neid liigutama, siis kui vaja läheb. Kui kasuta läheb teie veepi lehele ja teil on link, seal selle linkitakse. See link on nagu natuke üldin, aga ta linkib näiteks Soome, siis kasuta läheb selle linkile ja selle hostname'i põhja alt, et teie kaustast võetud. Ja siis on kõik, et teie kaustast võetud, et teie kaustast võetud, et teie kaustast võetud. Ja siis on nagu natuke soome, siis kasuta läheb selle linkile ja selle hostnamei põhja alt suunateks ümber, kus Content Delivery Network isa otsustab, et kuhu suunatakse see bäring, mis tõmbab selle faili alla ja sinna on loogika sisse eidatud, et kuidas see toimub. Ja sellisel juul tegelikult nendel linkidel peavad olema piisavalt üldsed adresid, et nad ei ole IP-specifiliselt. Ja siis on nagu võrgus, interneti võrgus ruuditakse õigesse kohta, kus see IP asub, aga peab olema mingisugune kiht, mis otsustab, et millist IP-et tegelikult kasutada ja kuhud see bäring, faili alla tõmata kuhuda reaalselt suunata. No siis, no siis teed, et siis juulikool saad ülve liga? Jah, aga sa ei taha nagu teha koost, et kõikida ruudritakse mõgailmas, sa tahad ikkagi, et see toimuks nagu sinupold kontrollitavalt asemel ja DNS-issa saab saa teha, et sa saad kirjutada DNS-i kirjad, kus sa mõned sellised reeglid sisse ehitatad, et kudest see suunamine toimub. Ja selled oto pakutakse ka sellised pilve-TNS-teenuseid, et sa saad Amazon pilves ees isedefineerida, et kudest see ruudimne käib ja kui TNS bäring jõub Amazoni, ja siis kontrolliteks ka sinu oma reegleid, mida sinad nagu selle TNS-teenuse eest oled tünnaamise tefineerinud, et sa saad nagu ümber kirjutada need Amazoni-TNS-i reeglit sinu ressurssideaks. See teema on suhtseed keerulline, et ma ei usod, et me seda aines kattame. Läbi paistusest ma natuke rääkisin, miks see üldse tähtis on, on tihti nagu keerulline, hea te näidete ka kirjeldada, aga üldiselt üks põhjus võiks olla näidikse, et me ei taha, et meie kasutad liiga palju teaks päris riistvara adressides, näidiks kus nad asuvad, mis sportid on, mis siipeadressid on, et võib-olla natuke kaistada rönnetavastu reaalselt see väga ei aita. Aga tihti on nagu erinevad põhjused, miks me tahame, et kasutad ei saaks teada täpselt, kus ja ku palju ressursse asuvad meie hajussüsteemis, see on tegelikult hea nagu peita ära kõik hajussüsteemide siseelu ja struktuur ja arhitektuur kasutajad eest. Näiteks juurde pääsu transparentsus või peidab ära nagu anmedes alvestis formaatide juurde pääsu meetodid erinevused. Kui anmebaas kasutab chasenit või kasutab SQL sellasemel või kasutab midagi muud, siis kasut ei toheiks selle pärast oma nagu päringud muud makata. Kui ühes anmebaasi hoiame chasenit, teise anmebase SQL, siis peaks ikkagi olema üks liidestus, mida lõpkasutavad kasutavad, et me oledaks lihtne näiteks mingisugust frontend rakenduse ehitada või et kasut ei peaks nüüd õpima erinevaid formaat, et meil alaks nagu lõpkasutavad üks konkreate formaatia, mis iganes formaadid meil reaalselt hajussüsteemis tegelikult kasutused on, on nüüd ära peidetud. See on hästi loomulik, et kui te infosüsteeme designid, et aga nagu üldiselt vaatates on see tähtis. Asukoha transparentsus, et tegelikult kasutaj ei pea teadma, kus tähtselt asukast asub Soomean me keskuses või Amerikan me keskuses, et tema näeb võib-olla globaalsed aadressi sellele pildile, mida alla tõmataks, et kasutale ei ole tähtis teada, kus asub. Teatud olukorras võib see tähtis olla, näiteks Euroopa nõuab, et anmed asuksid Euroopas, vedid siin anmed, siis võib-olla on hea, kui hajussüsteem näitab, et reaalselt kasut ka Euroopa anme keskuses, et isegurli panevats, et näiteks Soome aadressid, siis kasutad usaldavad seda rohkem võib-olla. Et see on ka sellene mäljakas vaheadus võib-olla. Kas ta reaalselt on või mitte, no võib-olla erinev küsimus. Aga põhimõttel saab ikkagi jälgid, et kuhu paketid lähevad. Võiks ka ära peeta selle, kui mingisugust resursid taustal kolivad teise asukohta, et selled oot ei peaks näiteks serveri aadressi või midagi muutuma, et me kasutame üldist IP-aadressi ja ka taga on serveri lokaalne IP, kuhu ümper suunataks ja see lokaalne IP võib täitsa midagi muud olla. Et igasust replitseerimise transparentsused peita ära see, et ku palju mitu koopjad on resursidest ja et täiesti on võib-olla, et pilv või näiteks hajussüsteem saab isesuunata ühtendendes kolmest koopjast ja kasutaj pea sellest mitte midagi teadma. Et on ka hea peita kõik tõrk, et kasutajat eest ära, muid on jälle hakkavad teiega ühendest võtama, et saad ma teile sõnumeid, et miks midagi katki on, server läks katki, et peita lihtsalt need erorid ära ja kasutajale saata seele pärin kovastus uuesti ja aga mõni kord jälle on hea, et kui midagi katki läheb ja tahad, et piisavalt kiiresti teada saada, et midagi katki läks, millegi pärast teie monitori mõnest ei tööta, siis loodate, et kasutajat teiega ühendest võtavad, et siis mõni kord on jälle hea panna vea teatesse informatsioon, mis oleks kasulik teile, et kui kasutaja teiega ühendest võtab, et seda infot näidata, et näiteks. Üks viis on see, et kui te näitate kasutajale, mis on päringu ID, siis seal võib olla kasutaja teie tõetajatele, teie firma tõetajatele, et neid saad näiteks monitorimisest selle ID-ka kõiks seotud logid ülesotsida. Et kui teie kasutajat, siis tracimist ja panete iga hajussüsteemi komponenti, logis originaalse päringu ID, siis teie töötajad võib olla ei pea kaevama logides nii palju. Et nad ei pea teka ma lisatööd, et okei, mis oli kasutane imi, kas ma tean, kus logides oli, mis aaja perioodisse võis olla, ei pea käsitsakama nagu kaevama logid, vaid lihtsalt saab teha lihtsa päringud. Selle kasutaja päringu ID-ka seotud logid vaadata ja siis võib olla mingile administraatorene palju lihtsam ülesleida probleemid, et sellise juhuse võib olla on hea teatud asju näidata kasutatele. Et kui neid ole mingi probleem, nad võtavad supporti kaud ühendust ja küsida nendat, et palun saadki meile ka teie vea teates olev päringu ID kaasa. Ja mõned muud on ka samaaeksus, et transparentsus ja skaleerimise transparentsus, et kasutate, tegelt, et ei pea sellekohta midagi näge käema, et kui skaleerimisega tekivad mingisugust probleemid või peita ära, et resurssi kasutavad samaks, et mituosa poolt. Et teine kasutaja kasutab ka sama virtuaalmasinat, et kasut ei peaks sellest mitte midagi teadmat peites ära kasutate eest. Ja täieliku läbi paistest peidame kõik kera kasutajat eest ei olegi vajalik, et võib-olla vajaks ka sellest lisaresurssi, et ma rääksin ka ühe näitene sellest, et kasut ei näeb, tegelikult seda latentsuse põhjal või päringu vastuse iiruse põhjal, kui kaugelt nendanme näiteks tulid. Et seda peita tihti oleva vajalik ja ei ole mõte, et nagu lisakulu ja keerukamad süsteemi ehitada selleks, et seda kudagi peita. Ja see on viimast punkti maja just katsin elmise slidipel. Et see transparentsuse võib-olla raska arus oda, mikse see on nii reaalselt vajalik on, aga palju sellise kasulikum omadus on avatus, et süsteemi saks panna kokku suvalisest riistvarast, suvalisest, no mitte päris suvalisest tarkvarast, aga et saks valida erinevaid tarkvarast, et ei oleks te piiratud targvara valikuga. Et oleks hea, kui riistvara on avatud, et lisaseadmete lisamine või komponentide lisamine ei toeks ole rask, et meil ei oleks kasutuses mingi hästi speciaalseid, ma ei tea, kõvaketad, mis ei ole et avakõvaketad või midagi sellist. Et riistvara oleks võimevõi progameerid, et võib-olla ei peaks tellima kogu uusi riistvara komponente või oleks siit nagu üldisemad riistvara komponentid. Ma ei tea, kas see on just hea mõtta, aga näiteks kasutada raspberry piisid või midagi, mis on saadaval kogu aeg ostetav kogu aeg. Ja tegil raspberry pii oligi pahepeal probleem, et mingi aeg, poolteste aastat ei olnudki ostetav, üldse. Kuigis tal on ka sellised alternatiivset seadmendid igas klonid. Ja tähtsam on võib-olla just see tarkvarjan avatus, kuna täna veel riistvara on vahetatav hästi suhtsalt lihtsast, et enam ei tehta väga speciifilist riistvara eriti serveritele. Aga tarkvarjan avatus on ka tähtis või kõige tähtsam, et oleks tähtis, et teil, kui sellise hajussustemi arenda, oleks lihtne uute, lisahomaduste, lisamoodulite arendamine, teenuste lisamine, et kasutadaoks avalik programeerimis liidaseid, näiteks, et appid, mida ehitadakse vastavad võib-olla respetifikatsioonile, on kasutusel näiteks Open Appi või Swagger spesifikatsioonid, mis defineerid ära, kuidas seda appid kasutada. Et kui te annate mingisugus selle parteril ühes, andat teile uus moodul ehitada, et siis oleks hästi lihtne nendale aru saada, kuidas liidestada täie hajussustemiga, et te tekiks seda olukordad, et nende aks näistikeeruline uute moodulite loomine. Aga protokollid võiksid olla midagi sellist, mida te ise välja mõtle, aga avatud protokollid, igasuguset TCP-d ja MQTT-d või AMQP-d, selleks, et sõnumid vahetada, sellase määlet teha mingisugune custom, sõnumite struktuur ja midagi väga unikaalsed väljamõelda, et ei ole mõted tihtijed. Et standaardsed protokollid on tihti piisavad selleks, et peab kõik ära teha. Et selline suhtlus ja annete vahetus teiste teenustega ja süsteemidega oleks hästi lihtne, et tänapäeval tarkkura valimisel vaadateks, et mis suurist integratioonid eksisteerivad, kas on võimalik näiteks integreerida, ma ei tea, Slackisõrumeid saata, kas on võimalik monitorimisega integreerida. Kui on tarkkura, millel on väga vähe välised integratioone, siis võib-olla seda valiteks vähemad. Kui on tarkkura, kasutaja peab liiga palju väli arendusi küsima, et mingisugusel liidestusi teha anmebaaside või anmehallikadega, siis tegelikult see on väga hästi suur lisakulu. Et kui teie lahenduseks on igasugusel avatud protokollid ja programeerimist liidest, et olemas, siis on palju lihtsam liidestuda. Ja kõik süsteemid, mis on siis hajus komponent, hajussüsteemide osalt, peaksid vastama nendele paikapaandud liidestele, mis iganas nad on, kas nad on mingisugud apid, et nad vastaksid selle, nad oleksid võimalised oma vajal koostud tegema üle nende liideste protokollidega ja võiks olla suhtse lihtne liigutada näid hajusrakendusi teistele platformidele, et ei tekiks seda, et te peate rakendust ümber ehitama, kui te lähete näiteks mingile teisele ristora peale, et lähete AMD 64 armi peale, et siis peate kogu sisteemi ümber ehitama, et see olega hea. Ja üldiselt vastavalt teelmistel, et oleks lihtne laiendada uusi moduleid, uusi võimalise juurde ehitada. Ja me katame aines just seda avatud programeerimist liidest ja protokolle, vaatame ja praktiku, mis teeme ka selle läbi open upiga, mis on nagu Swaggeri standard. Swaggerist välja kasv on selline natuke üldiselt standard. Ja paralelisus on tähtis hajussisteemite jaoks, et võimaldada kõrgemad jõudlust ja hakkama saada, kui kasutat arv või päringut arv kasab. Hea või ideaalne oleks, kui N-protsesoriga sisteema annaks, kuni N kord sa jõudluse kasvu, et me saaksime näiteks protsesorid lihtsalt juurda panna kas suuremad virtuaalmasinad, kas lihtsalt rohkem servereid, kus on kokku agregeeritud rohkem protsesoraid. Ja hajussisteem, võib-olla ma natuke seletasin seda valest, mida ma tahitsin, nagu sellest slaidile üldad, et kui meil on sentraliseeritud monoliitne sisteem, siis me tavalt saame selle panna ühel servere tööle ja siis me oleme limiteeritud selle maksimum protsesoreide arvuga, mis üks server on võimaline nagu toetama. Näiteks meil siin Arvuti teaduse instituudis on serverid, kus on 256 tuuma, sellised suuremad serverid ja mitu terapaitimälu ja ka pilves saab serverid, mille on hästi palju tuumasid, aga see on ikkagi limit, et sellest üleminna ei saa. Aga hajussisteemis me saame üks kõik, kui suurta arvu tuumasid tegelikult kasutada, kui me on võimaline lihtsalt kasutama paljuset arvuga, kus igal arvutil on m tuuma, siis me saame n arvutid võtta ja saame mxn tuuma ja kasutada oma hajussisteemis. See võimaldeb me skaleerida rohkem, kui monolitne sisteem võimaldeks, sest monolitne sisteemi jaaks mone limiteeritud rist voraga. Aga hajussisteemis me oleme limiteeritud nagu serverid arvuga. Tihti küll on, et me teaduse sisteemis on kõik, et me saame mõtta arvutid, kus on mitte arvutid, kus on arvutid, kui on arvutid. Ja siis me saame sisteemis, et me teaduse sisteemis on kõik, et me saame sisteemis, kui on arvutid, kus on arvutid, kus on arvutid. Kes me teaduse sisteemis on võimalik, et me teaduse sisteemis on arvutid, kus on arvutid, kus on arvutid. Ja siis me teaduse sisteemis on arvutid, kus on arvutid. Ka teaduse sisteemis on kõik, et me teaduse sisteemis on arvutid. Ma olen oma arvut minu arvut, mis olen oma arvut. Sitemis on kõik, et me teaduse sisteemis on arvut. ja muut probleemid tekivad, mis panavad meil piirit sellele. Superarvutid tänapäeval on ikkagi arvutiklastrid põhimõttel, kus on tohutul arvul, cpu-usid, mälujakp puusid, ikas arvutse on näiteks 1,4 gpu-ud ühendatud. Nääiteks Lumisuperarvutis Oomes on ka midagi sellist, mida meie hapetsekeskus ka heitas koostöösteitega. Ja meil on tavalselt hästi palju kasutad, kes sama aegselt kasutavad seda sisteemi nii, et kui nende arv kasvab, siis meie sisteemi peab olema võimalne sellel üleelama. Palju serveri protsessid töödavad sama aegselt, iga reageerib osadele nendest klientide päringutele ja samas paralelisest tulemad oma probleemid pealmised synkroniseerimisega, et kui meil on 10 000 kasutad, kes kõik anmebaasi midagi kirjutavad, siis selle kirjutamise skaleerimine on üks väga keeruline teema tegelikult. Kui meil on üks anmebaas, siis on lihtne, aga kui meil on anmebes jagatud mitmete noodide vahel ära, siis on suurstseid keerune probleem, kuidas synkroniseerida kirjutamist. Ja skaleerituvast tegelikult tähendab seda, et mitte see, et me saama ainult hakama sellega, ku kasutad arv tõuseb, vaid ka me oleksime võimelised seda tegema tünaamiliselt, et mitte raskama arvotusresursse, näiteks me saame virtuaalmasinat kinni panna, kui need enam vaja ei ole, et me saaksime neid arvotusriistad vajadusele. Ja süsteemi kasvatamine, et kui meil on vaja 10 või sadakorda rohkem kasutajad toetada, siis ei tohiks kaasa tuua targvara muutmise vajadust, mis mõnikord võib täiesti loogiliselt tekida, et kui meil ei ole üks anmebaas enam hakama ei saa, siis me peame oma süsteemi ümber disainima hajusa anmebaas jaoks ja tegelikult see ei ole hea, sa ei võib väga väga kalliks minna. Skaleerimist ongi, skaleerimisel ongi tihti nagu takistavad tegavased, kui meil on mingisuguse teenused, mis peavad töötama sentraalsed, et ainult üks server, siis nad muutuvad pudelikaalaks. Kui meil on mingisugune keskne anmebaas või anme kogu, mida me ei saa mingil põhjusel hajutada, siis ka see tekib pudelikaalaks. Ja kui meil on kalgoritmid, mis vajavad kõikid anmeda kokku kogumist, et teha mingisugus arvutusi, et mis ei ole võimelised nagu hajusalt anmed peale arvutama, niimoodi et mingisugune arvutus teaks kolmest serveris erald ja siis tuvaks see tulemised kokku ja arvutatakse midagi, et kui see ei ole võimalik, siis ka see muutub pudelikaalaks. Ja on ka vajalik, et ükski masine ei sõltuks täielikust infos kogu hajusa süsteemikohta, et see ole hea, kui meil ühe arvutimäru peab olema nii suure, et ta suudaks kõik anmed kõigi hajusüsteemide komponentide kohta kokku koguda, et parem on, et ta sada päringud ja lasad teistel mingit tööd teha, et ei olaks vaja kõik anmed ühte kohta kokku koguda. On hea, et masinat teeksid otsused ainult kohaliku informatsioone alusel, see ole alati võimalik ja tihtis ei ole võimalik, aga sellised süsteemid olev palju skaleeritavamad ja efektiivsemad, kuna teid ei pea palju suhtlema teistega, et lihtsalt päringutel vastata. Ja ühe masinatõrge ei tohiks blokkeerida kogu rakendase algoritmitööd. Ja hajusüsteemide pool tegelikult ei tohiks eeldada globaalse kella olemas olu. See võib parandada seda, et sul ei ole võib olla vajadust kesksete kellaserveretega sünkralliseerida. Aga ma ei ole kindel, kas oleks piisolt täpne, et sul kõik vajadus oleb ära täidetud. Aga võib-olla küll, jah. Põhimõtteliselt niise töötabki, et meil on kella ajaservered, kus sünkralliseeritaks, aga siis ongi see kogu probleem nende täpse ajamõtmisega, ku kõu päringut võtavad aega. Mul ei ole väga aega, et sa tead tänna rääkida. Ma lähen natuke kiiremini, et ma räägin seda skaleerimisest ka veel lohkem pilvetehnoloogia loengus, ja ma jätan näite skaleerimise osa praegu natuke vahele ja lähen lõimete juurde. Ja tõrkkel kindlusest me ka tegelikult siin juba rääkisime, arutasime. Mõned sellised eeldusid, mida ei tohiks teha hajussüsteemide kohta, on see, et võrk on töö kindl, et ükski ruuter, switch maha ei lähe. Võrk on turvalne, et kelle, kelle ei õnnest võrku serverte vahel pealt kuulata. Võrk on homokeen, et meil on alati täpselt samad ruuteri tarkvara kõikida sõlmedes meie hajussüsteemide komponentide vahel. Või et võrkus ei muudeta midagi liigutada ümber, või et võrkuslatentsust puudub, et lokaalsus võrkuslatentsust ei ole, et seda ei tohiks nagu järiti väljas pole lokaalsud võrku. Samut teid ei tohi eeldad, et me võime üks kõikku palju anmeid saata serverte vahel. Ja samut, et kulu anmeidetransportimise puhul on nüll, eriti pilvetehnoloogipuulse ei ole lihtsalt tööne, te peata sellest maksma. Ja et ühel süsteemiadmistraatoril on täielik pilt kogu võrku kõikki teha hajussüsteemid üle, et see tihti ole võimalik, kui see hajussüsteem tõesti olegi täiesti väike. Ei saa eeldada, et üks administraator teab kõike kogu võrku kogu hajussüsteemi kohta, et ei tee kunagi viku või midagi ole muutunud vahel, mida on teinud teine administraator. Ja siis viimane teema, mida te ka praktikumis läbi proovit on, lõimed. Räägime natuke sama asja, mida räägite operatsioonisüsteemid aines. Teil on sa aine ära olnud, ja keval sügisel. Kes ei ole operatsioonisüsteeme võtnud? Kõik on võtnud. Ma eist proovesin ka selle eelduse aineks panna. Ja räägime natuke lõimeda mudelist natuke veel üle ja räägime lõimeda valsi. Nõtukas veel üle ja räägime lõimeda valsi sümproniseerimisest ja kuidas on lõimed implementeeritud. Mis on üldse process? Process on täitmisel olev prográm, et ei ole prográm, mida ei ole veel käivitetud. Pärast programi käivitamist tegi process, mis on hetkel, kas ootel, kuni talle antakse prozessoraega ja reaalselt saab midagi käivitada või ta siis töötab hetkel või ootab näiteks. I.O. taga, et meil kirjutakse mingit file, et ootab, kuni file kirjutame on lõtanud. Ja processil on oma processi hetke olek, mis hoitakse kusagil rekistrites, et näiteks, mis on muutujate hetke väärtus, mis on seotud hetkel toimuvu arvutusega ja mingisugune käsul oendur näiteks, et misuguse koodi instruktsioon juures praegune käivitus hetkel on, mida praegu käivitetuks. Ja lisaks on mälus isu koodiseksioon, kus on selle processi programi kood, anveted seksioon, et mis anvetal mälus hetkel on ja magasin, et mis on hetkel täitmisel käsujärjend, et kui sügavalt on endes programi käskudes hetkel on, et kui üks programa käivitab teise metodi, siis selle programi mäluvajadus kirjutaks magasini ja siis hakkataks järgmis programi järgmiskäsku käivitama. Kui see käsk käivitab teise käsu, siis ka see kirjutaks magasini ja loodakse selle käsuka seotud andmed rekistrisse. Ja kui see käsk väljastab, siis see käsu tagastab mingisuguse tulemuse, siis see käsk sellest käsust väljastataks ja võetakse eelmine täite meetod, siis magasinist ja hakkatakse seda täitma, et see on nagu senne rekursioon, et mis hetkel on täitmisel. Kui mingisuguse meetodi täitmine tagastab, siis tulad tagasi juba teelmisse meetodisse, mis selle meetodi käivitas, nii et seal magasinis hoitakse seda jõud. Ja samast programmist võib olla käivitetu mituprocessi, et kui te näiteks käsurealt käivitat jaava käsu mitukorda, siis iga jaava käske teab jaava processi, mis taustal taetab. Igas protsessori tuumas, et kui meil on arudis neljiprocessori tuuma, siis seal saab juoksida korraga ainult üks protsess. Hyper trading on natuke teine asi, et tegelikult sama aegselt te jookse sama kahta protsessi korraga. Need lihtsalt on niimoodi ettevalmistatud, et nende vahel vahetumina on hästi kiire. Ja kui meil on protsess, mis jookseb hetkel protsessori tuumas ja mingil põhjusel peab vahetuma selle protsessi vahelt teisele protsessile näiteks, see protsess hakkas kirjutama midagi ketale, siis meil ei ole mõtled oodata, kuni ketal kirjutama lõppend, siis me võtame protsessori aja sellest protsessilt ära ja paneme sellest tuumas käima mõne teise protsessi. Või siis meil on vaja käivitada mingisugune operatsioonisüsteemi sisemine käsk, siis me ka paneme hetkel oleva protsessi pausile ja paneme käima opisela operatsioonisüsteemi protsessi, et seda operatsioonisüsteemi protsessori käsku täita. Ja kõik iga kord, kui me peame nimoodi protsesside vahetuma, nende vahel ära muutma, kes hetkel saab protsessoriaaega, et keda hetkel täitetakse, siis kogu see konteksti vahetus võtab aega. Ja see on hästi vähe aega, aga kui seda tehaks hästi tihedalt, siis see on kogu siis on nagu ajakulu, et me peame rekistrites väärtused ära muutma, et mis on hetkel käivitatava protsessirekistri väärtused, peame näed mälukirjutame uue protsessi rekistri anmed mälust siis tagasi või ja tagasi sinna rekistrisse kirjutame, siis ta käimo panem, et see kõik võtab natuk aega. Et kui meil on üks protsess, mille on üks lõimsees, siis ongi, tal on mingisugused mälualas kood, anmed, failid, failid on tavalselt failipidemed, et mis on need avatud failid, mille kaudusab nende failidega selt lugeda või siis sinna kirjutada. Meil on mingid rekistriväärtused ja meil on see stack, et mis on see kood, nagu pointerid ja mis on need eelmiste käskudega seotud, sisendid, väljundid, anmed, kui me saama tagasi hüpata, kui see praegune käsku on täidetud. Aga kui meil on programmis kolm lõime, siis need lõimed saavad iga lõimseb endale unikaas makasini ja unikaased rekistriväärtused, mis hoidakse mälus. Aga nad jagavad omavahel koodi, anmed ja faili, mis tähendab, et nagu on natuke efektiisen, kui teha kolm koopet protsessist, sest me peame oma korda tegema koopet ka koodist anmedest ja failidest. Nema saavad jagada põhimõtteliselt omavahel koodi, faili ja anmed mälus. Muidu, kui me läks kolm koopet, kolm protsessi igal üle on oma koop ja anmedest, me peame kui tegist synkroniseerime need anmed, et teene protsess ei saa esimese protsessi mälus lihtsalt midagi lukeda, aga lõimede puhul saab nad saavad samamälu ala kasutada siin anmedes synkroniseerimiseks. Kui see on implementeeritud, siis see on teatud olguridas võimalik, teatud implementatsioonidus. Aga lõimede puhul on sa automaatsal jagatud ja üks lõim saav kirjutada teise lõime anmed, kui sa ei ole lõime anmed, nad on tegelikult protsessi anmed. Ma magasini kohta juba rääksin, et igal lõimel on oma magasin ja see täitmis järekord, eestikelles tihti pinu mitte magasin. Ja igal lõime täidetaks täpselt samamoodi, aga kui protsessi ja ühtel lõim olaks täidetaks järje pidavalt ja kogu mälu on jagatud lõimeda vahel ja lõimeda vahel, sest mälu kaitsata ei ole, ja protsessi tivaal on defaultina mälu kaitse ja peab siis tõesti luba ma, kui midagi on. Ja kui meil näiteks on, kus meil nagu protsess algas, siis esimene ütleme meetod, mis käivitati, selle anmed on siin, see meetod käivitas teise meetodi, selle anmed on siin, see meetod käivitas kolmanda meetodi, selle anmed on siin ja siis selle praegusel käivitatava ja siis meil on pointter, et kus hetkel selles magasinis on nagu programmi täitmine, et siis võetakse selle hetkekäivituske seotud anmed, aga kõike elmised nagu meetodit ja anmed tuleb ka alles hoida, et me teaksime, et kui see väljupäe tagastab mingi väärtused, siis me saame siia üpata ja siit magasinis laadida mäluvahelikud registriväärtused ja muutjeteväärtused ja et oleks lihtne hästi kiiresti üpata elmiste täitmiste sammudele. Et kui te saate stack trace'i pythonis, et mis on need meetodid, mis käivitad üks see järel, siis põhimiselt see ongi sellest magasinivai stacki nagu logi, et mis oli need käsud, et et ihti saate pythoni väljondis, et näetiks vaadat, et see käs käivitade sealt realt, see koot käivitade sealt realt ja see koot käivitade sealt realt, et saate tagasi vaadat, et mis need kõik elmised meetodite käivitused olid ja ma luulis, hoitakssegi need anmed samamoodi. On erinevad lõimede mudelid, et meil on nagu riistvaralised lõimed, näetiks meil on 4 tuuma või meil on kasutajatasame lõimed, et meil on pythonis loome, siis näetiks, mis siin on 7 lõime ja tuuma lõimed on siis nagu lõimed, mille jaaks on riistvaraline toetus, et need sama aegselt käivitad, et meie protsessor oskap siis sama aegselt 4 tuuma lõime käivitada, et 4 asja korraga juhuksutada. Ja me peame kudagi need kasutajalõimed, mida meil on oma pythonis, siis jagama ära tuuma lõimede vahel, mida siis operatsioonisüsteemi kärnel tead ise, jossu ta ise, kui te sa tead. Et sellise ühe tuuma ka arvutipuhul meil siis ongi näed lõimed jagatud, miks ta ei tööta? Meil ongi siis näed lõimed jagatud ühe tuuma vahel, on sususti tefektiivne, kui meil on täpselt samapalju lõimi kasutada tasemel, kui tuuma lõimesid, et me saameki juhuksutada siis neid neljas erinas tuumas, aga pigem on tavalselt see, et meil on mingisun arv füüsilisilüü lõime, mida meie protsessor toetab sama aegselt juhuksutada ja siis meil on kasutapolt defineeritud, et meil on näiteks 60 lõimeline puul võiks selline krupp lõimesid, ja me lubame oma tarkvaras käivitada siis teatud tegevusi 60 tükki samahaegselt kasutada lõimedes. Lõimede hea küllk on see, et see parandab reageerimeskiirust. Kui me teeme ühe lõimega programmi, siis tegib see probleem, et kui see program võtab ühendust näiteks lokaase võrgukaudu teise protsessiga, siis ta tihti peab jääma ootele, kuni ta saab vastuse või kui ta kirutab file, siis kui ta ei tee seda asukroonselt, siis ta jääb nagu ootele, et kui fileist loodud anmed on käes. Ja see oota aeg on tegelikult hästi halb ja lõimedega saab seda parandada, et kui mingisugune protsessi käsk peab jääma ootele, kuni ta saab anmed failist, siis kui ta on erinev lõim, siis me saame ta pausile panna ja teised lõimed saavad jätkata tegevust. Näiteks me saame igale serverisse sisse tuleva HTTP päringu panna tööle erinas lõimes ja kui mõni neist jäb ootele, kui saab anmed anmebasist kätte, siis see ei mõjuta seda, mida see program saab samal aegel teha. Et suhtel lihtne ongi kogu käivitus, iga erineva sisse tuleva HTTP päringu käivitus teha erinevates lõimedes. Et siis kui ootele jäävad, siis me saame ikkina listat protsessi ootele panna ja käivitate järgvis lõime. See teab paralel programeerimise hästi mugavaks, et me saame maateks jagata 64 plokiks ja panna iga ploki töötluse erinas lõimes tööle. Ja siis me laseme protsessoril või operatsioonisüsteemi Kernelil koolitseda sellest, et kudest on nende lõimede vahel vahetub. Ja me ei pea oma koodist tegema seda, et mis järjekorras me jahat käime panema. Me defineerime lõimede tasemel kuske neli tööd ja laseme protsessoril neil oma aega vahetada nende vahel. Meil on võimalik siis jagada resursse nende vahel nii mälu kui kootiala, et meil ei ole vaja mitut koop, et sellest samas koodist mälus hoida. Me hoiame kokku jagatud resursside osas eritsele mäluala puhel, et me ei ole vaja 64 koopet teha sellest mälust. Tisti küll ütleme, et kui me teeme ühest maatreksist 64 väiksemat protsessid, siis võib-olla iga üks hoiapainud ühte ploki 64-st mälust, niit võib-olla mäluala on nelj vähem, aga meil on ikkagi efektiisem olla või omale üks mäluala ja me ei pea aga koopet tegema siis erineetlast asjadest. Kõik anmed, mis nad peavad olema täpselt samad nende lõimede vahel, siis neid ei pea dubliceerima mitme protsessile. Või vähemalt meil on see automaat, et me peab siis hakkama eraldi luba anma. Ja see võimaldeb ka siis, et meil on võimeline mitut protsessorid ära kasutada ühe progammist, et kui meil oleks ainult selline program siin, siis ilmal lõimed, et ta väga raske panna kahte protsessori tuuma seda sama programmi täitma. Aga me jagamegi oma protsessi lõimed, siis me saamegi kasutada sama programmi, sama protsessi jaoks nelja lõime, kui meil on rohkem, kui meil on rohkem, kui nelja lõime selle protsessi sees. Aga lõimeda vahel lülitemane endised lisakulu. Lõimede silumine, debugging on keerulisem, kuna raskem on aru saada, et mille sa problem tekis, kuna te näete, et problem tekis programmiga mitte, et mis suurlise lõime, kes sa tekis. Ja kaob isolatsioon, et kui mingi lõimd kirjutab vale, et anmed üle ja jakatud mälu alal, siis võib kogu program katki minna, selledatud, et tegelikult ei oleks pidanud seda ala ülekirutama, et teab teise lõimetöö katki, kui ta midagi valesti ülekirutab. Et lõimede kasutamisil on ka mitu viisi, kõige tüüpilisem on jakaja töötaja mudel, et meil on üks lõim, mis käivitud ja see lõim loob teisi lõimesid ja kui lõimede oma töö lõpetavad, siis see sama lõim väljub. Et keegi, kes otsustab, mida teised lõimed teevad ja kuna teisi lõimi lua, et näiteks meil on sisse tulevad 10 pildi töötlus ja see peamine lõim loobki siis 10 teist lõime iga pildi jaoks ja oota, kuni nad töö on lõpetand, ja siis isegi väljub. Et see on selline nagu jakaja töötajad, et ta luaks selle, kui töötaja lõimesid iga kord, kui mingi lisatöö tuleb. Meil on nagu veebi serveri lõim, mis loob iga sisse tuleva päringu töötlemise jaoks uue lõime ja kui see päringu on töödeltud, siis too lõim väljub ja peamine lõim saab uusi lõime juurda teha. Meil on kallameeskonna mudel, et meil ei ole peamist lõime, et me automaatselt tekibki näiteks lõimede hulk ja nad teevad omaval koostööd, aga otsasalt ei... ja kõik lõimeda võrtsad, et ei ole üste peallik lõime, kes teisi loovab ja teisi jälgib, et meil lõimed luvaks iga ainult siis, kui midagi on teha ja otsasalt ei ole pealik, kui nende vahan. Nii, et lõimed võib olla ka nagu... Meil teki piltitöötloss, ongi esimene lõim ja ta tekeleb ka end selle piltitöötlosagi ja väljub ja iga piltikohta teketaks uus lõim, nagu... et meil ei olegi nagu sellest üste lõime, kes teisi lõime loob, et seda saab teha nagu selt lõimede koopeerimise stiilis, et selle asemel, et me tekitame lõime, kes teisi lõime loob, me nagu spoonime ki koha nagu lõime iga kord, kui mingisugune progammikäivitust tekib. See ei ole kõige parem näite, võib olla, et... Ja meil võib olla kor konveijermudel, et me loome viis lõime, iga lõimde täiesti erinaat tööd. Esimene lõim alati tekeleb mingisuguse esimese ülesandega ja meil tekeb selline kas pipeline või konveijer, kus me saadame anmend nagu läbi viiest lõimest ja iga lõimdeb natuke erinevaja ülesande. Seda tihti väga ei kasutata lõimedet asemel pige, siis kui meil on viis erinaat progammia, me striimime nagu anmendnele progammides läbi. Ja selle aseme, et me lõime lõimeed loome kuskult pealiku progammist, me võib olla ei taha, et meil oleks 10 000 lõime. Mis juhtub, kui meil tulebki sisse korra, ka 10 000 kasutada päringut, kus me siin tõesti loome 10 000 koopjad mingisugustest stäkkidest ja asjadest. Võib olla me tahame, et maksimum oleks 20 lõime samaheikse töötavad, siis me saamegi luua sellise tred pooli, kus me defineerime, et maksimum lõimed alv on 20. Ja kui tuleb meil sisse uus töö, siis me külb defineerime, et see on lõim, aga teda ei panda nagu tööle enne, kui meil on nagu vabaresursse sinnd selles tred poolis või lõimede krupis. Et saab piirata, et kui palju lõime, sit ametlikult on nagu selle protsessoripolt järekorras või ootel. Ja tihti, kui meil on vaja koostad teha, et meil ongi siis oma vahel koostad tegevad lõimed, ja oma vahel koostad tegavad lõimed, siis kui meil on vajalik, et nad kirjutaks mingisugust, et alasid mälus üle või et nad oma vahel anmed jagaks, siis tegelikult tekivad palju probleemid, et kuidas seda teha õieti, ilma, et anmed tegiks mingisugust race kondisioneid, et kaks lõiveproojad samal ajaks, et mingit väärtust ümber muuta, et näiteks proovivad teha korrutist või plusoperatsioone, ja et ei tekiks seda olukorda, kus meil olev väärtus sõltub selles, kumb lõim enne kohale jõudis, et seda vältida. Või siis see, et meil on näiteks mälus olev lõim, kes loeb mingi mälu väärtust ja tahab seda plus kaks teha, aga sellel et enne pärast lugemist panaks seda pausile ja jäärimekord, kui ta eluärkeb, siis ta tead plus kaks sinna. Ja nüüd ta panaks se pausile, teine lõim tuleb ja loeb seda väärtust ja ta lõnestab koha see väärtus ära muuta, siis panaks see tema pausile ja panaks see esimene lõim uuesti tööle ja tema lõnestab plus kaks teha. Siis see tulemus ei ole korrekne, sest esimene proovist teha plus kaks, aga vahepeal see väärtus, millel eda plus kaks proovist teha, korrutati kahegi ära ja see tulemus ei ole jälle mõige. Et see tulemus siis sõltub selles, kumb lõim, mis hetkel pausile panaks ja see ei ole hea, kui tulemus sõltub sellistest suvalistest protsessori planeerimise poolt tehtud otsustest, taaks seda vältida. Selleks toetetakse sellised atomaarsed operatsioone, et me loeme väärtustid suurendamada kaks korda ja teine lõim ei ole samal ajal lubatud mitte midagi teha. Me karanteerime, et sama protsessi sees mingisugune lõime tegevus oleks atomaarne, et teiste lõimetele ei õnestuks seda mälu ala näiteks üle kirjutada samal ajal, kui see lõim tegeleb sellega. Selleks saab defineerida igasugused kas kriitised seksioonid, kas kasutada selliseid lukke. Ma järgmise slaidil natuke räägin selle kohta. Et me tahame vältida seda, et mingisuguse väärtuse arvutamine ei sõltuks ajastamise või planeerimise tegevustest. Ja selleks on vaja erinevaid synkroniseermisprinciipe. Erinevaid prinsiivid, mis on kasutus, on näiteks muteks, ehk luk, et ainult üks lõim saab korraga sellest lukust mööd. Meil on koodis selline objekt ja on karanteeritud, et sealt edasi saab ainult üks lõim korraga. Teistid jäävad selle muteksi taga ootama, kuni see üks protsessi alt väljub. Kui meil on olukord, kus me tahame tegelikult lubada mittmel protsessil, näiteks puf, ütleme, meil on ärääi ja mei ärääi pikkus on 4 ja me tahame lubada, et 4 lõime saaks korraga sinna väärtuse panna, aga me ei tohi lubada rohkem kui 4, siis me saame teha sellise semafori, mis lubab näiteks kuni x lõime või kuni 4 lõime sinna ära lelikikorraga, et nad saavad siis kõik appendida sinna listi või äräse uusi väärtusi, aga ei saa rohkem kui 4 appendida, et muidu kirjutateks alakerit mäluala näiteks üle. Meil võib olla ka selline spetsiaanel lugemis ja kirjutusnud luk, et suvalne arv lõimi saab lugeta stava väärtust või muutujad, aga ainult üks saab korraga kirjutuda. Need, kes tahad lugeda, saavad lukust edasi, aga kui keegi tahab muuta, siis ainult üks saab korraga proovida muuta seda muutujad. Monitor on spetsiaanel lukku, saab panna if-else-kondisjon, et kas ootab lukku taga, kuni mingisugune kondisjon on täite, et näiteks ootab kuni list on tühi või ootab kuni list on täis ja jääb ootale kuni list on täis. Ja see võib olla ajatab ka, et kui meil on erinead roolid, et mõned on kirjutad, mõned lugead ja mingi lugea ootab, kuni list saab täis ja jälle siis loeb ja siis teed sellega midagi jätu. Näiteks ootab, kuni maatriksi kõik arvutus on tehtud, maatriks on täis, nüüd ma hakkan arvutus tegemalt ja samal ajal teised saavad kirjutada maatriksisse väärtusi. Ja meil on ka võimalik teha kriitilise region, et mingi block-koodist märkida koodis kriitiliseks. Seda tehaks selle programeerimiskeeltet asemel, et ainult üks lõimsab sinna kriitilise regioni või meetode, et sa siseneda ja teha kogu selle meetode lõpuni ja teistel lõimetele selle laajale ei lubata sinna regioni minna, aga lubataks teha teise asja samaegselt. Et see on selline pikem, siis nagu matalasem programeerimise keeletasemel. Ja on võimalik ka ilmalukkud, et läbi ajada, selleks tuleb kasutada erinevad automaalsed operatsioone, mis on toetatud siis kerneli või procesori poolt. Ehk meil on võimalik teha näiteks test and set, fetch and add või compare and swap. Ma ei ole sadak protsentikindu, et ma õigestine ei tõna määletan, aga test and set on mõte, et me seame mingisuguse väärtuse mälus plus kaheks ja siis... Ei, me seame mingisuguse väärtuse mälus näiteks kaheksaks ja me saame tagasi, mista eelmine väärtus oli. Ja vastal selle me võime midagi edasi teha. Et selle asemel, et me ütleme plus kaks, me näiteks loeme, mis see väärtus oli ja et see oli kaheks. Mission Waffa astupidi, see on järgne operatsioon. Et võimest, et me seame mingisuguse mälu ola väärtuseks ja fetch and add on see, et ma suurendan mingisugust väärtust kahe võrra ja vaatan, mis see väärtus oli. Et see on see õigem, et ma proovisin seda vist valesti selle, et kui me soomem plus kahe teha, kas me ei duvitab, mis see väärtus oli. Et me ei pea ise otsustama, et kui väärtus on kaheks, siis me paneme sinna kymmen. Kui väärtus on ükst, siis me paneme kolmdeest. Et see pigem operatsioon teed plus kahe ja annab meile teada, mis see väärtus enne oli. Et see väldiv seda, et me peame lukema ja suurendama, kunne me tahame lihtsalt suurendada, aga me ka teadaksime teada, et mis see uus väärtus on. Et siis kui me teame plus kaks ja meile tagastadevik väärtus oli kaheks, siis me nüüd teame, et see uus väärtus on kymmen. Et me ei pea ette teadama, mis on uus väärtus. Meile piisab selles, kui me ütleme, mis kui palju seda suurendada, aga me ikkagi tahame teada, mis see uus väärtus on, näiteks oma algoritmi jaaks. Test ja set on, et siis see on selleks, et me seame väärtuse kymmneks, kui ta praegi on kaheks. Ja see on selleks, et me loome, saame teada, et väärtus on seitse. Ja me teadame, et me teadame seda ühekseks seadistada, aga meie operatsioon seadistab ta ühekseks ainult siis, kui tema väärtus oli seitse. See tähendab seda, et see feiliib siis, kui see väärtus, mida me muutu tahame ei ole see, mida me eeldameta oli. Võime luke, et ta oli seitse ja siis automaarnu operatsioon kontrollib, kas ta on seitse, siis muudad ühekseks. Ja me saame siis tagasi tulemuse, kas meil onnestus operatsioon või mitte. Ja seda tähendab, et ühelgi teisel lõimel sama laal ei onnestu seda muutujad mälus ära muuta. Või seda väärtus mälus ära muuta. Kompeerias vätbi ma etkel vist ei mäleta, et palun uurige ise, et mis ta täpselt oli. Ma võin proovit seda mällu või uuesti mäletada, aga praegu hetkelist ei mäleta ja aeg sa potsa. Selle nädala praktikumis siis te hakate praktikumegi piste. Te programeerite ühe sellise väikse kasutusloo ja hakate kasutama pyütonis lõimesid. Esialgu implementeerid seda ilmalõimedeta siis lõimedega ja siis lõimede grupiga. Ja selleks rakenduseks hakkab olema selline raamatute halduse süsteem, kus me kasutame Kutembergi raamatute repositoorimid ja teie kirjutada programmi, mis tõmbab Kutembergist alla raamatuit teatud ID-väärtusega. Et seal on hästi palju avatud vabasid tasuta raamatuid ja esimene meetod, mida ta loote, on lihtsalt tema ülesanani, et raamatut alla tõmata. Ja me loome ka praktikumil lõpus, synchroniseerimis ülesandes ühe teise metodi, mis siis lisaks sellele, et raamatut alla tõmatakse on eraldi meetod, mis loeb raamatutest raamatust, mitukorda mingi sõne eksisteerib ja me jagame sellel sõneotsimise erinate lõimeda vahel ära. Me saame kümbe lõime panne samat raamatut raamatust mingit sõneotsima, nima, et oma vahel tead koostada, et kokku arvutada, ku palju kokku oli neid sõnasid selles raamatus, mida me otsisime, et kas raamatus 211 oli siis sõna Estonia, mitukorda. Ja seda teaks siis lõimedabil. Et esims osas me tõmbame raamatuit alla erindes lõimedes ja viimas osas me synchroniseerime raamatust mingisugus sõneotsimist. Ja järgmestest praktikumides me hakkame seda kasutuslugu, mis on hästi lihtne, nagu edase arendama, tegema sinna rohkem sellest funktsionaalses juurde ja mingi hetk saadistame ta apiks, mingi hetk saadistame ka ta pilves üles, et meil tekib selline hästi lihtne raamatute halduse tarkvara, mida me igas praktikumis natuke edase arendama või teeme teatud asju teist moot, et näiteks kasutame erineid anmebaase või kasutame erineid viise komponentide vahelseks suhtuseks. Ja me teeme ta sellise mikroteenuseks lõpuks, et meil tekib mikroteenuse põhine hajussüsteem. Ja järgmestest loohen, kus ma hakkan siis andmetes rohkem rääkimad, räägid siis andmete vahetusest hajussüsteemides, kus siis pigem lõimeda asemel on program juokseperinevata protsessi täna, kes on oma vahel nagu sõltumadud või rohkem sõltumadud, kui lõimeda. Suumist küsimusi ole, kas kelekil on küsimusi, läksime natuke küll aaja. Tänan.