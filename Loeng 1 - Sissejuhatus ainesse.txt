 Tere tulemast siis VB Teehnosti ja hajussüsteemide arenduse ainesse. Minu nimi on Pelle Jakovits. Ma olen siin instituudis hajussüsteemidelektor. Annan seda ained, see on nüüd juba kolmadad korda. Annan pilve tehnoloogia ained, mida me oleme annud, ma ei tea, 10 aastad juba. Tegelen ka praktika korraldusega, nii et te olete võib-olla minuga kokku puutun, siis praktika ained raames. Ja õpetan ka kuberneetes ained, mis on pigem, nagu ma kistritudenkitele sügisse mestriis. Ja see ainegi tegime kuskil kolm aastad tagasi just selled tõttu, et ma olin praktika koordinaatore ja ma nägin, et tegelikult meie pakka tudenkit, kes lähevad praktikale, siis nendale ei prugi olla piisavalt sellised appide arenduse ja üldiselt hajussüsteemide teadmisi, kui nad lähevad praktikale itefirmadesse. Et siis tihti, et meie tudenkit pidi hakkama appisid õppima nagu sellise praktika või töö alguses. Ja kui me vaatasem, mis ained instituusisse eksisteerevad, siis oligi hajussüsteemida ainu oli midagi, mis oli ajalooliselt täiesti pakka ain, aga kuskil viis-kuus aasta tagasi ta muutusa ainult ma kistritasem aineks ja natuke teoreetilse maks. Ja nüüd pakka see olnudki sellist hajussüsteemide teemasid ja veepi-teenuste osa katab sellist appide arendust plus pilvedehtnoloogiat. Et. Midame. Täna räägime ja mis on selline aine üldine eesmärk kongi, siis sel näe, siis sissejuhatus hajussüsteemide olemusse, mis üldse on hajussüsteemid, kudas neid defineerida, kudas neid arendada. Sissejuhatus veepi-teenuste arhitektuuridesse. Veepi-teenuste alma peamaselt mõtlen just veepi-appisid. Sissejuhatus pilvedehnoloogisse me hakkame kasutama sinna aines Microsoft asure pilve. Teil on ligipääs üle teie ülikooli konto, et saate sisse logida, saate aktiveerida oma sellise student subscriptioni, mille abil saate väikse hulga krediiti ja lihtsalt saate ligipääsatelun õigused ülikooli asure kontos siis asi üles seada. Aga see aina on hästi praktiline, ma küll loengus siin räägin tausta teemadest ja tuleb ka eksam, mis on selline tööreetilne eksam, aga pool ainest on täiesti praktiline, kus üks ühelä siis loengu teemadega te praktikumides loote rakendusi. Alkuses siis sellise mitmelõimellised rakendused siis hajussüsteemidele on siis veepi-appid enne ja siis pilverakendust enna. Ja te saategi siis kokemuse selliste mitmelõimelliste progammide loomisest, hajussüsteemide loomisest, kus mituprozessi töötavad koos tööna, et saada oma valges sõnumeid või vahendavad andmeid erine halviisidel ja siis aina teisel poolel peamiselt just veepi-appidega ja pilvepõhiste rakenduste loomisega, nii et õppite, kui kui üles pilves oma loodud rakendused ülesseada efektiivselt. Ja aine kodulest on siis korsesportaalis, nagu kõik meie instituutid teised ained, et selt leiate siis loengu slaidid, loengu salvestused, kõik praktikumiuhendid ja seal hakkab olemasel peamine info näiteks, kuna me plaanime teha eksamid, mis on eelmise aastate eksamite näited, et saada vaatata, millised eksamid tulevad. Loengu ülekandid teeme küll suumi ja tekib ka videosalvestus, mille panen üles paaripäeva jooksel pärast loengut ja praktikumid toimuvad siis samal päeval kell 4 ja järgmisel päeval kell 12, kus meil on õppeassistent, kes teil praktikumis aitab. Aina alguses ma ka olen praktikumis, vaatan, et mis probleemid meil võib-al tekivad ja natuke haitan õppeassistent, aga üldjuhul juhendab teil praktikumis õppeassistent. Aga praktikumi ja materjald on sellised kirjeldavad, mis võib-al küll ei jõtla teile krikki ette ära ja lähevad aine jooksel natuke keerukamaks, aga põhimõttelneid saab iseseisvalt läbida ja otsaselt väga palju nagu õppeassistentilt võib-al ei ole vaja, aga kindlasti on parem neid teha praktikumis kohapeal, et kui vähegi mingi probleemid tekivad, siis saate kohe õppeassistenti küsida ja raiskata vähem aega kodus üksi pusides, kui te proovite neid kodus teha. Väheselt eeldus, et tudenkitel on see, et teil võiks olla pyyton teadmised. Me arendame peame sellest pyytonis oma sellised hajussüsteeme, veepi-teenuseid, pilve-teenuseid ja peame sellest kõik materjald on pyytonipõhimised. Teil võiksid olla mingisugused kit kasutamise baasoskus, et me ei pane teid meeskondades töölet-meris konflikte oma vahel lahendama, aga põhimõttel kitivahepeal kasutame päris mitvas kohas, sest see on üks peamise, et viis ja kudas hästi lihtsasti pilves pyyt on rakendus ülesseada, et sellasele on midagi käsitsi teha, me saame lihtsalt panna kitti ja üelda azurale, et võta sit tarkvarasid kitlist ja pan üles. Sellest operatsioonisisteemide alusteadmised on kõik head, et oleksite operatsioonisisteemide aine läbind, kuna me hakkame Linux käsurida kasutama päris mitvas kohas, me hakkame tokeri asju tegema ja et kui Linuxi teadmised ei lütse, siis natuke keerukam sellel aine läbimine. Päris palju teeme küll teie oma arvutis, aga me paneme teie arvutis ISL ja tokeri ja muud oisad tegelikult ka sellest, et aru saada, mis on dockerfail, siis tegelikult on vaja baasteadmisele, et Linux käsur jaast, sest dockerfail onki põhimselt Linuxi käsur ja käskude kirjeldamine tokerfailis küll teise struktuuris. Loengutes on plaanis siis rääkida pärast tänast loengut hajussisteemide olemusest ja definitsioonist, erinevatest hajusprogrammide, omavaheliste suhtluste viisidest alustatest teadete edastusega. Me siis kaugt protseduuridega ja siis selliste webi protokollidega nagu REST. Peamiselt me kasutame RapidMQ-t jaadet edastuseks ja loome sellist HTTP appisid, et teile näidata RESTi, aga pärast seda tegeleme ka selliste webi teenuste standarditega, et kui te ota kusakil praktika käigus või kuskil mujal projektis kasutanud swaggerit või open appid, siis me loome oma open appi spetsifikatsiooni ja genererime põhimõtteliselt serveri koodi ja implementeerime meetodit seal koodis ära. Vaatame ka pilvetehnoloogite kohta, mis on erinevad pilvetehnoloogimudelid. Räägime, mis on virtualiseerimes ja konteinerite erinevused. Ei ole, et konteinerid on lihtsam virtualiseerimine, vaid need erinevasad väga fundamentaalisad. Räägime natuke ka anmebaasidest pilves ja hajus anmebaasidest üldiselt ja aina viimased teemad on selliste mikro teenuste, nanoteenuste ja tarko arhitektuuridega seotud teemad, kus me lõpuks paneme ka oma loodud rakenduse pilve, täiesti pilvepõiseks rakenduseks, nii et ta kasutab pilve anmebaasi, pilvefailisüsteemed, pilvefailisüsteemed, pilvehoida ja jooksebki täiesti ja on disaniitud täiesti pilve jaoks. Ja viimane selline teema on EXAM-i konsultatsioon, kus EXAM tavaselt toimukas ieteiskymnedal või kueteiskymnedal nädalal. Peame selleks, et tudenkit, kes lõpetavad oma õpingud ja teevad lõputööd kevadel, siis saaksid aine kiiresti arvastatud. Praaktikumide sisu proovib neid teemasid jälgid üks ühele, selletatukat äna, nagu sellel nädalal praaktikumi veel ei ole ja praaktikumid hakkad pihta siis, kui me võtame ette esimese hajussusteemide teema järgmine nädal ja räägime lõimedest ja hajussusteemide processide synchroniseerimisest ja siis praaktikumis proovite läbi, mit me lõimelise püüt on rakenduse loomist. Praaktikumid toimub kohapeal, et suumi meil praaktikumide aegal kasutuses ei ole, et ei saa üle suumi vaatatamist toimub praaktikumis, kuna sa tegelikult segab õppeassistent, et ta peab samal aegel ruumis tudenkit aitame ja siis tekivad küsimused suumis ja siis on raske nagu jälgida, mis mõlemast toimub. Aga me seame üles eraldi sellises Suulipi keskkona või üle kasutamane instituudi Suulip keskkonda ja seal saate küsida abii, et näiteks jäädte pärast praaktikumi kodus midagi lõpetama ja saadute hättas, siis saate Suulipi kaudu abiküsida ja see on selles mõttes hea, saate ka 11 aidata Suulipis, et kui teisel tudenkil on mingi probleem tekib, siis saate ise kiiresti aidata enne kui mina või õppeassistent juab teid aidata. Ja toimud siis tänakel 4 ja omme kell 12. Praaktikumi teemad on üks ühele loengutega. Nii et me alustame lõimmedest püütonis, aga me mida me teeme on me võtame tegelikult ühe kasutuslo, milleks on selline suhtselt lihtne raamatute halduse süsteem või appi ja me võtame selle kasutuslo ja implementeerime selle esimeses praaktikumis osaliselt. Järgmises praaktikumis teeme natukes seda edasi ja kogu praaktikumide käigus me arendame järjest edasi seda ühte kasutuslugu. Et alguses teeme ta lõimmedega selliste raamatut alla tõmbamise, siis teeme ta teatete edastusega selliseks hajussüsteemiks, siis teatete edastusasemel kasutame RPC-d, kauprozeduurne nende kahe hajusa komponenti vahel. Neljandes praaktikumis me teeme ta ümber webi appiks, et siis saab post ja get request saata, et seda meie rakendust kasutada. Pärast seda teeme ta natuke ümber, et ta ei ole nagu nii käsitööna tehtud appi, vaid kasutab open appi spetsifikatsiooni, et märata ära kõik need appi endpointid ja metodid ja metodid ja sisendid ja väljundid, et ta oleks nagu dokumenteeritud appi, nii ajalda. Pärast seda paneme ta meie appi pilve platform üles, siis me paneme ta sellise pyütun rakendusena, aga järgmises praaktikumis me teeme teemast konteineri, võisigi mitu konteinerid, nimut, et me saame konteinerina jooksutada teda oma arutis ja pilves. Ja pärast seda hakkame anmeid oidma pilveanmebaasides, sellasemele, et anmeid oida nagu lokaalsena failidena, siis võtama anmebasid kasutusele asures. Siis teeme ta natuke ümber, et on nagu ühe konteiner asemel teeme temast nagu mitu mikro teenost, mis on ama vahel suhtlevad, saarnastelt tegelikult nendele teadete edastusele ja kaukprotseduuridele. Ja pärast seda teeme ka frontend juurde sellele mikro teenusele. Et see frontend hakkab olema hästi lihtne, lihtsalt nagu selline basic õpetus, kuidas luua JavaScript frontend, mis suhtleb meie loodud appiga. Ja automaatsal, siis kui kasutakse klikki mingi nuppe HTMLis, siis kutsutakse appi meedodeid välja. Ta nii väga ei õpeta teed, kuidas häid frontende luua, vaid pigem õpetab seda, et kuidas frontendid üldse töötavad, et kuidas nad seda appi meedodeid väljakutsuvad tõnaamiliselt ja kuidas nad need appipolt tagastatud anmeid kasutavad siis HTMLis. Ja pärast seda, kui meil frontend on olemas siin, siis hakkame natuke laiendama seda meie rakendust, et lisaks kahele mikrotenusele teeme ühe sellise nanoteenuse juurde, mis konverteerid tekstiilised ramatu fileid ümber PDFideks automaatsal, et iga kord, kui uus ramatu file anmei base lisatakse, siis kutsutakse välja selline asure väike nano funksioon, mis on osaliselt ei sisaltu meie mikrotenuste sees, vaid on nagu välinne selline nano funksioon, mis käivitatakse tõnaamiliselt sünnmustapõhiselt, kui vaja. Ja viimases praktikumis me võtame kõik omal oodud komponentid, kaks appi, konteinerid, frontendi ja selline nano funksiooni ja anme base ja teeme nad kombineerim nat koku nagu üheks selliseks pilve paketiks, mis ongi nagu selline üks pilvepõhine rakendus ja kui me varasemalt oleme testinud, võib-olla nende sellist komponente, siis lõpuks paneme ta täiesti pilves tööle sellise pilve rakendusana või pilvepõhise rakendusana kui ingliskelle sõjata siis cloud native application. Ede ongi sest, et kõikid asi praktikumid, et teed töötame edasi selle sama rakendusega, et siis te näete, et kuidas erinevaid lähenemise anme basi teaks, verinad lähenemisi hajussüsteemide kontekstis kasutada täpselt sama kasutusloo raames. Praktikumid oleks kõige parem lahendada enne järgmislooingud lihtsalt selletõttu, et siis te olete selle teema praktiliselt läbinud enne kui te järgmist ja reetselt teemat kuulama tulete, aga selleks, et nagu 100% punkte saada, siis põhimõttel teie tähtaeg on järgmise praktikumipäev. Ma. Soovi viitesadat kodutööd hakkada hindama mai lõpus või juni alguses, et me ikkagi sunnime teid jooksvalt neid esitama, et kaeguse nii on, et ei saa lubada täiesti lõpus kõike praktikumi järgiteha. Ette sa vika esitada ja et võid kohe praktikumi jooksvõi ära teha ja ära esitada ja kõik, et ei paha kui te koota ma nad alat. Olen, et paridusel kokemust on nende tehnoloogitega, et siis praktikumis jõub täiesti valmis nende ka. Me ei avalda need järgmise nädalab praktikumi materjale enne, kui see praktikum algab, et kuna me ise vaatame näid üle ja parandame uuendama materjale, siis teoreetiliselt saate minna selle sama aine eelmise aasta korslaslehele ja vaatata, mis näid ülesandad eelmine aasta oli, aga ei ole mingid karantiid, et see on täpselt sama aene. Meie midagi muutub. Ja võib juhtud, et te jääte väga hättakuna asures nüüd töötab midagi natukas teistmoodi ja me peame kogu praktikumi ümber tegema. Ainehinde komponentid on siis see, et te saate 50% praktikumidest, kui teete kõik praktikumis ära, esitata ära, saate täispunktid, siis aines on 1% puud, et saada aines läbi. Eksam annab samuti 50% aines, ja see on selline teoreetil eksam. Seal on kolm küsimust, mis on sellised senaariumi põhised küsimused, et ei ole faktiküsimused või ei ole muudlidest, et pigem selline lahtise senaariumiga küsimused. Saate vaadata aine kodulehelt, et mis näite küsimused olid. Mul on mingi 2022 aasta eksamin näite küsimust olemas. Eksamine saamiseks peab esitama vähemalt 75%, ehk vähemalt 10 praktikumilahendused, hakkab olema, kes 13-12 praktikumi peame selled öet, et esimene praktikumi jääb ära. See ei nõua, et te peate saama 75% punktidest, vaid, et te peate esitama 75%-i lahendustest. Nad võib-ead olla ka osallid poolikud. Ja nagu teisteis ainates ka, et siis on vaja 51% kogu ainest, et saada vähemalt tee, ja siis see hindamiskala on täpselt samamis teisteis ainates. See on midagi väga erilisti ole. Praktikumilahendused ei ole krupitöö, ehk te peate iseseta tegema, ei tohi teiste tudenkite koodi kopeerida. Kui te jääte hätt, ei saa lahendatud, siis pigem küsige abisulipi kanalis või küsige õppejult habi vajaduse saama aidata teid koodikirutamisega. Et kui midagi on, et siis saame teile viidata, mida seal teist moodi teha, et lahendada. Mõni korda on mõned tudenkit lihtsalt kui kui kui kui kavandavad väga keerulise lahenduse, lihtse lahenduse jaoks, et saate kindlasti praktikumis habi küsida. Te saate lahenduse ei teid teiste õppilästega üliõpilästega arutada, aga teid tohi anda teisele tudenkile oma koodi, et nad koopeeriksid teie koodi. Kuna ülesende tuleb ise lahendada, see ei tohi olla krupitöö. Esiteks see tuden, kes koopeerib koodi, siis ei õpi selle käegus kõikitead mis ise ja teise problemina, et kui meie märkamajhindamisele ka teise problemine, ja teise problemina, et kui meie märkamajhindamisele kaks tööd on hästi sarnased või täiesti samad, siis mõlematel tudenkitel tegi problem, mitte ainult sellel, kes koopeeris. Põhimõttel tehke töö ise, ärge jaga oma lahenduse koodi teistega, kui teie sõber vaja pabi, siis aidaketa ta andke tale vihjeid, aidaketa progameerida kas või näide, andke tale üldised juhiseid, aga ärge laske tal koodi koopeerida. Kui te kasutate mõnda veebialikat või näiteks chat-cpidid, siis viidake sellele, et muidu tekib sama probleem, et kaks tudenkit leiavad täpselt sama hallika veebist, et midagi implementeerida ja siis kood näib täpselt sama välja ja siis tekib ka probleem, aga kui mõlemad viitavad, et ma leidsin mingisugus osalise lahenduse kusagelt veebist, panate lihtsalt koodi kommentari kus linkiga, et me näeme, et te olete kusagelt muidat lahendus leidnud ja siis ei tegi probleem, et teine tudenk teie pealt koopeeris, vai te mõlemad olete koopeerid kusagelt muidat, et siis seda probleem ei tegi. Ja kui kasutate chat-cpidid, siis on teie endu otsustada. Selle ain eesmärk ei ole teile nii väga programeerimist õpetada. Meie huvi on pigem kõik need erinemad pilvetehnoloogia hausstüsteemide lahendused ja kuidas neid efektiivselt kasutada. Ja kui teine natuke vähem mõppite püütu, onid kuna kasutadat chat-cpidid, siis on teie enda asi, aga ma kindlasti ei soovita kasutada chat-cpidid. Kenerida kõik kood ja siis mängida lihtsalt testijad, kas töötab või mitte, kas töötab või mitte. Et see muutub selleks puzzle mänguks, et proovite ja vaadata, kas see lahendus töötab või mitte. Sela asemel, et ise proovite selle lahenduda ja õpida selle käigus. Palju parem, et õpite ise nullist apisid designima, sest see on tegelikult suhtsev lihtne. See kood, mida me siin ainees loome ei ole väga keeruline kood. Ja sellest apide ja haussystemide loogikast aru saamine on palju tähtsam, kui mingi koodi valmis saamine, mis on keeruline. Et see loogika, mida me oma kasutus loos implementeerimine on suhtsev lihtne. Et ei vaja mingi erilisi. Me ei hakkagi erilise algoritme või erilisi keerukaid anvestruktuur katsutuma. Esialgse tegsemäead on 28. mai ja 4. juuni. Võimalik, et ma liigutan seda 4. juunid natuke hilisemaks, et anda teile rohkem aegat õpida. Aga praeguse seisujärgi jääb ta umbes selliseks. Need on mõlemad tegelikult enne lõpudüöda kaitsimisi. Nii et tudenkit, kes soovad lõpudüöd kaitsistaksele kevadel, saavad valita näiteks lihtsalt 28. mai. Ja siis jääb umbes pooldeist nädalat esimeste kaitsimistene, mis hakkavad vist rähedest pihtu. Eksam toimub koha pealt teltas. Ta on kirjalik, aga ta on avatu draamatu, avatud interneteksam, et saada süljaharvutud samal alal kasutada. Aks kirjutada paveri peale, et ei ole muudlidesse, kus ta muudlise kirjutada. Aga see on huvitav aine, kus see nõuab käsitsi kirjutamist paverile. Saada natuke arjutada. Jah, õnne, nagu siin ei ole koodi kirjutamist, see on pikem nagu selline, et senaariumi põhiselt teoreetsed küsimused. Ja kestvus on siis 9 minuutit eksamil ja 3 küsimust, nii ettele jääb niivadi pooltuindi iga küsimuse kohta. Ja näiteeksami küsimused on see Hanna kodul. Kas teil on korralduse kohta mingit küsimusi? Kõik sealga. Kõik see sama info on ka kodulehel olemas, aine kodulehel, et leedatse selt üles. Kui te märkat, et mingit kuub päevad on teised, siis andke teada, ma ootan üle. Meil toimub niimoodi, et me kooperime elmisevasta kursuse, lähme sinna, muudame kui kuub päevad ära. Ja alati võib mingisugun asi kaha silma vahel jääda, et kusakil on midagi muutmata. Aga kõik aine materjallid ja praktikumid ilmuvad sinna. Järgmise nädalaj praktikumi alguses paneme üles selle linki praktikumi materialidele ja siis saates avada. Ja seda kasutam hakkata, kui te näete, et see linki taga on mingi lehtmis küsivtel parooli. Tegelikult see tähendab, et me oleme ära peitnud selle materialid kuni praktikumi alguse nii, et siis oodakka lihtsalt kuni praktikumi algab ja tehekki refresh ja siis see parool ka parvasalt. Aga väga lühitelt siis ma kirjelda siis need kolme peamist aine teemat. Hajussüsteeme, webi-tenuseid või webitehnoloogid ja appisid ja siis pilvetehnoloogid. Ja nagu siseulisemalt räägime näidest hajussüsteemid olemustest ja omadustest ja definitsioonidest järgmises loengus. Aga mis on siis hajussüsteem? Tänapäeval on võib-olla lihtsam küsida, mis asi ei ole hajussüsteem. Sest peab kõik asjad on tänapäeval vähemalt mingil märral hajussüsteemid. Kas või täiesti tavaline rakendus, mis teie arvutis jookseb, mis tegelikult ei oia ühtiga arvutist väljas pool, võtab ühendust tõenaselt automaatsalt väliste sisteemidega selleks, et näiteks kontrollidega, kas on mingid uuendusiga, kas on mingid sõgused anmeid vaja alla laadida. Tänapäeval tegelikult ongi peab kõik hajussüsteemid. Aga selline huvitav loogika, mida kasutada hajussüsteemi ära tundmiseks on you know you have a distributed system when the crash of a computer you have never heard of stops you from getting any work done. Et kui teie kasutad oma arvutis rakendust, aga kui internet ei ole, siis rakenduse tööta või rakendus töötab, aga mingi et ta katkestab töö, kuna internet siis teda midagi ole kätte saada. Ja tänapäeval ka päris palju rakendusi. Isegi kui nad on hajussüsteemid, siis nad on võimalselt töötama ilma, nagu interneti ühenduseta puhtalt selle töötu, et muidu ei saaksid keegi kasutada arvutis olevad tarkvara, kui internet ei ole. Aga reaaliselt kui interneti ühendust tuleb tagasi siis tegelikult võib päris paljud tegevasi toimuda taustal, mida teie ei näe. Kahjuks ei ole, sest üks asi on replikseeritud hajussüsteem, kui sul on lihtsalt mitu koopjat nendest teenustest, et sul on okei, kui ainult üks nendest on kätkastav, ei kasutatav, aga näiteks kui sul on anmebaas ja sul on api ja sul on frontend, üks kõik, mis nendest ära kasutab kaop, siis sa ei saa seda rakka kasutada. Et see on pigem selisel olukorral, kui sul on hajutatud anmebaas, kui sul on anmebaasi servereid on kolm tükki ja on täitsa okei, kui üks nendest ära kaop. Et sellise liul, ja, aga need on pigem sellised replikseeritud mudel hajussüsteemides, mis onki ehitatud selleks, et olla tõrke kindel, kui üks server ära kaop. Et sul on igast frontendi konteinerist on sul kolm koopjad, igast backendi konteinerist on sul kolm koopjad ja igast anmebaasi noodist on sul kolm koopjad. Ja siis tõesti üks kõik, mis ära kaop jääb tööle, aga kui üks nendest kolmest kihist ära kaop, siis ei tööta. Ja väga üldiselt võib defineerida ka nii, et hajussüsteem on autonomse te arvutite kogu, mis oma vääli ühendatud arvutivõrku ja mis on varustatud integreeritud keskkona loomiseks vaheliku tarkkoraga. See on väga üldistatud kirjaldis, mis tegelikult väga palju jütle. Ja täna päeval me enam ei tegele nii väga arvutitega. Te näete ka kes selles aides, kui me lähme pilvetehnoloogia peal, et näiteks, mis asi on serverless computing. Kas keegi oska vastata, mis on serverless computing? Päris mitte. Seda on väga palju rakendatud just sellistes kaardi rakendustasüsteemides, kus sul tegelikult näiteks, et Google Maps töödabki, JavaScript rakendasik sinu arvutis. Aga serverless on tegelikult natuke midagi muud. Pikemada siis, kui ta töötab serveris, aga sa kunagi seda serverid teine, see tarkkora arendaja, kes selle tarkkora kirjutab ka kunagi serverid teine, et kirjutatud tarkkora niimoodi, mis töötab, mis jookseb kusagil pilves, aga ei ole määratud, kus serverist ta jookseb. Ja ta on serverite vabakood, mis jookseb kusagil pilves, ta füüsiliselt jookseb serveri peal, aga ta on disaanitud niimoodi, et siin kunagi ei huvita, mis serverist ta jookseb. Kunagi ei eksisteeri serverid, kus ta kood asub, vaid sa kood pikem asub näiteks mingisuguses file repositoriumis või natuke isegi ettevalmistatud konteinerina, aga ei ole teada, kus ta jookseb, enne kui teada tegelikult käima panaks. Jah. Ihtsalt on serveri. Jah. Aga kusutaks seda serverless. Aga see on huvitav nimi, mis tegelikult ei ole õige, samamoodi õige mõeliks seda kutsuta function as a service, mis on palju kirjeldavam nimi, et on pyytane funksioon, mis käivitatakse kusagil pilves, aga sa ei tea, mis serveri peal ette, et ta jookseb ühe nende serverite peal, siis kui vaja. Teine näite on NoSQL serverid, või NoSQL anmebasid, millest me ka pilvetenoloogiaosas räägimad. Suur osa NoSQL anmebasidest toetab SQL-li. Mis on ka see huvitav, nagu, definitsioon, et mis on mitte relatsioonilist anmebasid, osa nendest toetavad relatsioone, osa nendest toetavad SQL-li, aga ikkagi neid nimetatakse ja tihti nagu mitte relatsioonilist üks anmebasidiks. Ja siis tegibki tegelikult väga selline keeruline hinat, et mis asi on üldse hajussusteem ja sellised võib-olla rangemad piirid on, et nendel komponentidel, serveridel, nendel processidel, processoridel ja peame seda just riistvaral, neil ei ole ühist kella. See tähem, et nad tegelikult ei jookse sama ema plaadi peal, neil ei ole ühist kella, nad ei ole synkroniseeritud. Ühel processil võib olla ajatempel täitsa teine, kui teisel processil, kui nad samal alal jooksevad ja oma vahel synkroniseerivad. Kui ma näiteks kaks komponenti anmebasil, kus on kaks anmebasi serverid ja te peate otsustama, kui ma panen paraleliselt kaks objekti anmebasi, kumb nendest ennekohale juab. Olukorras, kus kahel serveril tegelikult on täiesti eraldi kellad ja täiesti eraldi arvutatud timestampend, kui kui tagi püüsilises maailmas üks jõudis ennekohale kui teine, aga nende kahel serveri on erinad kellad, siis ta ei saa kui tagi karanteerida või ei saa hästi karanteerida, et kumb siis tegelikult on. Kui kui tegelikult ennekohale jõudis, et pigem mõeldaksik hajussüsteemid ala sellised süsteeme, kus on eraldi sellised masiinad või sõlmed võrgus, kes omavahel koostud teevad ja need sõlmed on täiesti sõltumatud üks teised selles osas, et neil on oma mõlu, oma protsessor, oma loogilinaaeg, mida nad oma püüsilise kella põhjal arvutavad ja sisteemid ei ole ranges synkronis, nii et sa ei saa tegelikult usaldada, sa ei saa usaldada, et kui üks hajussüsteeme, node või sõlm arvutab mingi ajatempli, et see on korrektne globaals ajasuhtes. Hajussüsteem pigem ongi selline kogum sõltumatud sõlmi või arvuteid või riistvara, mis paistavad kasutajale ühe tervikliku süsteemina, et teie lähete mingile veebiaadresile, hostemile kasutada seda, et tegelikult ei tea, kas seal taga on üks konteiner, üks server, 100 konteinerit või 10 000 serverit ja konteinerit, et te seda ei näe, et kasutajal teist ole see täiesti erabeidetud. Teatud olukorrast võib-al näete, et te lähete veebilehele ja siis vaadate kuhk sellest Chromei logist, et kuhu tehti appi värengud ja vaadate, et mida meil IP-adresile appi värengud tehti, aga siist te tegelikult ei tea, mis selle IP-adresi taga on, kas on reale server, kas on lihtsalt router, kas on mingi sugunne appi lüüs või appi gateway, mis tegelikult suuna veda siit 10-le teisele serverile. Et ta küll osa sellest on nähtav, et ta ei ole üks server, aga selle siseminestruktuur on erabeidetud teie. Ja tegelikult ei ole piirangud ristora kogus, et ku palju servered on YouTube'l, mitu servered on YouTube'i taga. Kui teie vaatad YouTube'i videot, kust tõmatakse alla see video? Kui see tõmatakse alla Amerikas suures tanmekeskuses, kas internet elakse lüüle? Kogu internet tegelikult läheks umbe. Ma soovitan sulle otsida Google Age Networki, et see on globaalne infrastruktuur, mille Google on ehitend, Google on ehitend selleks, et oleks üldse võimalik YouTube'i kasutada. Ja teie, kui tõmbate video alla, siis ta võib tulla Amerikast, aga ainult esimest korda, kui keegi tartus vaatab seda videot. Et Google on endal Tallinnas üks yhed serverid, kus kõik käsitaks ja kõik YouTube'i videod, selleks, et Eestist ei peaks Amerika serveredest videosid alla tõmbama. Ja Google ei lupa näiteks telijal käsida Google'i videoid. Et nad tahavad 100% kontrolli selle üle, et kui inimesed vaatavad mingit sisu, et siis ei oleks mingi cash, mingi kolmante osapoole cash, kes otsustaks, kas näha uut videot, vanavideot ja mingid vanu kommentaare ja uusi kommentaare. Sest Google on teinud nagu lepingud kõik maailma suurimate interneti teinuse pakkujatega niimoodi, et neil on õigusad nende anme keskustesse panna Google'i serverid just selleks, et nad saaksid optimeerida YouTube videoatevaatamisi. Ma võib-olla räägin sellest jääregmisel loengus rohkem. Sellest Google'i võib-olla pilvetehnoloogia loengust agelikult. Miks on vaja üldse hajussüsteeme? Miks kõik süssteemid tänapäeval peak on hajussüsteemid? Ongi selleks arvutusresursside koondamine, et palju efektiisem ja odavam tegelikult kasutada, ehitada hästi suuri pilva anme keskuseid ja kasutada neid selleks, et pakkuda resurss firmadele, kes nüüd oma tarkvarasel ülesseavad, kui see, et iga firma seab oma serverid. Et firmadele võib see mõnesmõttes natuke kallis olla, suhtelat kallis olla, aga energia- ja arvutusresursside kokkuhoiju mõttes on tegelikult palju odavam, nagu koguda Riistvarra resursid kokku ja pakkuda seda paljutale kasutatele. Teenusele niimoodi, et sa saad ühe suure füüsilise serveri peal pakkuda hästi palju sellised virtuaalselid väiksemat keskondi ja kasutada kogu selle serveri võimsus ära selleks, et tarkvarasel peal jooksatada, kui see, et sul on üks. Igal rakenduse jaoks on üks suur server ja siis võib-olla 30%-i või 10%-i või 80%-i sellest Riistvarrast ei ole, nagu kasutust leidev, et lihtsalt istub selle ei tee midagi. Ja et on võimalik anmeid ja töid jaotada ära paljude asukohtada vahel, niimoodi, et on palju efektiisem, kui suur hulk lente need anmed allatõmbad, et ei ole pudeli kaelu, et üks server peab siis kõigega hakama saama, vaid saabki anmed lihtsalt hajutada hästi paljude serverite vahel ära. Ja kui meie vaatame YouTube videoid, siis see tuleb Tallinnast, mida ei tule soome anmed keskusest või tule Google Amerika serverist. Ja samamoodi meie rakendusta puhul, et kui meil on start-up Eestis, kes loob rakenduse hästi palju, akatakse Aasias seda rakendust kasutama, siis on parem, kui need anmed ja tarkvarva liigub kuskile Aasi anmed keskusesse ja hakkatakse sealt neid kasutatele kohale toimetama mitte nagu Eestiserveritest või näiteks isegi Saksama anme keskusest. Ja et oleks selline üldine decentraliseeritus, et mis juhtub siis, kui meie lokale anme keskus kokku jookseb, kas me peame siis kudega hakama neid asju liigutama teise anme keskusesse, või need hoitakse juba niimoodi, et kui üks kõik, mis anme keskus kokku jookseb, siis koha on olemas koopjad asendusteenus, et teises anme keskuses ja meie kasutat võib-ale ei märkagi, et midagi kahtki läks. Aga see esimene arutusresursside koondamine ja decentraliseeritus natuke läheb oma vahel vastuollu, sest alati ei ole võimalik või ei taha maksta sellegest, et meie rakendused töötakseid hästi paljudes erinatse anme keskustes. Et on juhtunud, et kui see suur kokutud, anme keskus kokku jookseb, siis väga paljude asutust ja rakendused lihtsalt enam ei tööta. Microsoft Azure-s oli paar aastat tagasi niimoodi, et üks süsteemiadministraator kirjutas ruuterisse vale konfiguratsiooni ja ruuterise enam ei saanud sisselogida. Ja ruuter enam liiklus tõdasi suunanud. Ja tekki siis probleem, et kõik on harjunud üle webi, süsteeme haldama ja ei saanudki midagi teha, pidikohale kõndima ja ruuterisse sisselogima üle Ethernet kaabli ja siis ära parandama. Aga selleks pidi uuksest sisse saama ja uuksel oli turvallisest peal, et suurvalne administraator ei saanud sinna sisse kõndida. Ja see võitis pool päeva aega enne, kui keegi jõudis sinna ruuterisse juurde kõndida, kelle ole ole õiguses, et ruutarit hallata ja siis ära parandada. Ja terve Anme keskus asures ühes Amerika regioonis oligi maas pool päeva. Selle tõttu. Ja kõik nat rakendused, mis ei olnud teesentraliseeritud, siis ei töötanud. Öldse, et oleks võimalik resursse kaug kaugelt kasutada, et oleks võimalik siis tagada selline kõrg käiteldavus või asjade kokku jooks misel automaatne nende asjade parandamine või selline fault tolerant singlis keeles, et kui midagi kokku jooks, siis kasutad ei märkagi seda. Me seamegi Anme basist üles mitu koopjat, me seamegi appist üle mitu koopjat, niimoodi, et kui üks server kokku jooks, siis kasutad seda lihtsalt ei märka, et nad võib-olla üks või kaks või kolm kasutad märkav, kelle sessioon oli sellele hetkel aktiivne ja nemad saavad vea teat, et midagi enam ei toimu, aga põhimõtteliselt tagada sellel olukorrad, meil on hajussiste niimoodi, et kui ükski sõlm või server kokku jooks, siis tegelikult meie kasutajad sellest mitte midagi märka. See on tegelikult rohkem tõrked alus. Ja jõudlus osas, et me saaksime süsteemes kaleerida, et kui meil on tänna 10 kasutajad võib-olla meile ühes servist viisab, omme õhtul on 300 kasutajad, kas meie üks servisarv saab selle kakkama. Et pilves on suhtselt lihtne või siig automaatne skaleerimine, niimoodi et kui meie paneme oma appi üles, Asure App Service teenusene alla ja aktiveerime skaleerimise, siis vastavalt sellele, ku palju sisse tulevad päringud, vastavalt sellele, ku palju ressursse meie rakenduse konteehner kasutab, ja asure pilve teenus automaatselt lisab sinna ressursse juurde lihtsalt selle tõttu, et see kasutusmugavus või päringude latentzus oleks piisavalt väike ja tänapäeval pilves saab seda teha automaatselt ilma, et administraator ise peakski väga selleks midagi tegema. See on toku oleneb, kas te kasutate virtuaalmasinaid, kas te kasutate dockerid või kuperneetes konteehnerid või kasutate pilve põhiseid teenuseid, kus te seda üles ainult oma püütenrakenduse või java rakendused. Igal ühele on natuke erinev selline viis kuda seda skaleerimist defineerida ja kõike keerulisem on virtuaalmasinate puhul, kun on see nõub tegelikult virtuaalmasinaloomist ja see tavast võtab natuke aega põrreldes teiste lähennemistega. Et siis olekski võimalik samast appist ülesseada võib-a tuhat koopjad, mis töötavad 500 erinat serveris ja kogu liiklus nende vahel ära jagada. Hajusarvutitest on ka klasikaliselt teoria põhjal erinevaid tüüppe, et meil võivad olla sellist hajusarvutit, mis me seamegi ülesed väikse klastri arvutitest, aga kui me seame nad üles täiesti eraldi seisvete serveritena, siis nad on suhselt epaeffektiivselt, kui on vaja luua sellist ästi arvutusvõimsaid või ästi suuri arvutusi võimalisi superarvuteid, siis pigem prooviteks natuke rohkem integreerida neid arvuteid ja serverid, et tegaks isegi süsteeme, mis jagavad oma vahel mälusid, niimoodi, et selle aseme, et meil on 10 serverid, mille ligal on 32 gigabaitimälu, me loome hajus klastri, kus on küll 10 serverid, aga neil on 320 gigabaitimälu ja nad saavad nagu tarkvarast adresseerida kogus seda 320 gigabaiti, niimoodi, et nad kirjutavad programmi, mis adresseerib suvalist aadressi sellest suurest 320 gigabaitismälust, aga füüsilist on ta ikkagi serveritevajal peal ära jagatud, et sellised jagatud mäluolukarad, mida tegelikult on natuke lihtsam programe kirjutada, kes lihtsalt kasutavad hästi suurt mälu, kui kirjutada programe, mis peavad nagu arvesse võtma seda, et sul on 10 erine tarvutid, kui sa tahad rohkem mälu kasutada kui 10 gigabaiti või 32 gigabaiti, siis kui on 32 gigabaiti, sa pead hakkama sõnumeid saadma serverite vahel ja pead hoolitsema seda, et kus asuvad andmed, kas nad asuvad andmed, arvutis üks, nad peavad asuma arvutis kaks, selleks, et arvutik kahes asuv protses saaks mingisugust arvutusi teha, et siis võib-olla peab liigutama mälusoloid andmed nende kahe serveri vahel. Need, kus on jagatud mälu, nagu ristvaraliselt või vähemalt loogiliselt, need on nagu jagatud mälusüsteemid ja need, kus me lihtsalt ühendame 10 arvutid oma vahel, et hakkama hajusarvutis tegema, siis need tihti kasutavad sellest teadate edastamist, et me saame näiteks teha suurte maatriksid arvutusi, jagada maatriksid plokkideks ja igale serverile anda siis väike osasest maatriksist, aga siis, kui me tahame, et üks protses näeks mingi teist maatriksiosas, nad teadad neid maatriksid plokka oma vahel jagama. See on sellised klassikalised sellised paralel arvutused, mida tehaks näiteks MPI või teiste sõnumit edastuste, tehnoloogete abil. Me võime ka ülesseada sellised klustrid, kus selle asemele, et me teeme nagu otse hajusarvutusi tegitama sellise tööde järekorrad, et kui meil on arvutusklustrid näiteks haapetse keskuses ja meil on tudenkit, kes soova jõuad mingiselt pildi töötlusi teha näiteks GPU-tega, siis tudenk paneb oma käsu, mida tahab jooksutada järekorda ja siis on kuskil tööde järekora Haldur, kes võtab järekorrast uusi töid, siis otsustab, millise serveri peal see töö käivitada, kus on GPU-t, käivitab need ja paneb tulemused tagasi, kas kuskile anmebaasi või kuskile filesystemi kirjutab need väljundfailina, neid tulemused, siis see tudenksab hiljem vaadata, kas töö on valmis ja läheb, vaatab oma kaustast, kas sinna tekis väljundfail ja saab seda rugeda. See on tukkagi lihtsam viis, et me ei pane kohe nagu 10 arvutid oma val koost, et otse tegema, vaid kasutame need selliste tööde käivitusena. Ja siis, kui mul on suur selline maatriksid arvutuse üle sanna, et ma ei pane 10 protsessi sama aegselt tööle, aga ma jagangi sellel arvutuse 10 väikseks tükiks. Et mul on üks task, mis tööte päras esimesed 10 000 rida maatriksist. Panan selle järekorda, siis tekitan uue task, mis tööte päras järgmised 10 000 rida. Paren ka selle tööte järekorda, et ma jagan nagu oma suure arvutuse selliteks väikesteks tükkideks. Et võib-olla maatriksist tasamele piltide töötlus on natuke aru saada, et me tükkeltame pilti väikesteks tükkideks ja töötame need kõiki tükke eraldi väikeste töödena. Ja kui meil ühe Tartu ülikooli klastrist ei piisa, siis me saame Tartu ülikooli ühendada teiste ülikoolite ka kokku selliseks kriidiks, et meil on paljud ülikoolide oma vaheline klastrite koost kokkulete, et kui minula mingisugune töö, mis võtaks minul kuuaega aega näiteks teha, et ma jagan ta küll 10 000 väikseks tööks, aga nende 10 000 väikse töö tegemine lokaalsest klastrist võtaks kuuaega aega, siis ma saan need tööt saada opis sellises suuremase tööte järekorda, kus sealt tööte järekorast, siis võetaks ja otsustataks, mis ülikooli klastristse töö käivitada. Senne laajäändus, et meil on mitmed klastrid ja siis me saame ka tööd teistest klastrides käivitada, on see, et ajal oliselt olnud ülikoolide superarvutite või suurarvutite keskuste kriidid. Ja tihti on siis kõike arvutid või serverida oma vahel erinevad, võib-olla meil on sellises Intel ja Nvidia serverid ja siis teises ülikoolisena AMD ja AMD CPU-d ja GPU-d. Siis võib-olla hajussüsteemid meil opist tehtud hästi väikestest süsteemidest, et meil on mikrokontrollerid kusagil majas, et siin majas on ka mingisugused 15-20 mikrokontrollerid, mis tegelikult ei ole nii väga väikselt, nad on pikeb sellised, mis kontrollivad seda ventilatsioonisüsteema, mis kontrollivad päiksepaneele katu sell, mis kontrollivad akkusid, mis kontrollivad CO2 tased sinn, nagu uurivad CO2 tased sinn kuskil väljund toru. See on CO2 sensor, mis mõhda palju väljuvasõhus sellest ruumist, et CO2 tase on ja kasutab seda, et seda ventilatorit, kus ta nüüd sinna asub, kireminne tööle panne kuvaelik. Ja on siis sellised sensorvõrgud, et meie majas tegelikult ongi suur hulk sensoreid, kui te oled te näinud seda dashboardi sinna samas seinataga vist üks tubansi vahel, mis natuke visualiseerid need majanmed, siis need majanmed tulevadki siis lokaalsest sensorvõrgust, kus on palju kontrollereid ja palju sensoreid. Autodes tänapäeval on suured kännvõrgud, kus mitmed mikrokontrollerid autode sees oma vahel suhtlevad ja jagavad anmeid sellise car area network kaudu. Ja no seda reaalselt väga ei kasutata, aga sellised võib olla ka, et kui on mingi meditsiini rakendus, siis panaks see inimesi ja külge palju erinele sensoreid ja mikrokontrollerid ja panaks see need oma vahel lühendus, et ühe sensori põhjal siis võib-olla muudetakse mingi teise aktuaatori või sensori käitumist. Neid nimetateks selliseks SART-süsteemideks või ingliskeles embedded system või need on mitu nimed, aga et ingliskeles on kolm või neljinnime nendel. Hajussüsteemidel on palju erinele komponente, aga see peamine on ikkagi need sõilmeld või arvutid, kes teevad viivad läbi mingisugust arvutusi, olgu need mikrokontrollerid, olgu need mingid suured serverid, kus ma ei tea hetkel, mis on SART-ülik oli kõige suurium server, aga mõned aastat tagasi oli server, kus oli 512 tuuma ja vist 4 terabyte mälu, aga võib-olla nüüd on palju rohkem terabyte mälu. Asures võib rentide serveri, mis maksaab kuskil 50 000 eurot kuus selline server, kus on see hint tuleb peame sellest GPU-dest ja hästi paljute ketastest, ketaste kasutamisest. Kus saab kasutada tihti, noh, kas just tihti, ma ei tea palju on, et kasutatakse, aga saab kasutada hiigel suurte SQL-anmebaaside loomiseks, kus mälude maht on 500 terabytei näiteks, ongi arvutis 500 terabytei RAM-i. Ja võib-olla mitte 500 terabytei, vaid saab luua kettasysteeme, kus salvestusruumi on 2 petabytei anmebaasiaks näiteks. Aga lisaks arvuti teendal on ka kõik need võrgud, mida kasutatakse nende omava lühendamiseks. Meie pigem kasutam Eternet võrgke, siin aines Wi-Fi võrgud, kõik need ruutereid sildad. Tänapäeval prooviteks jäärest rohkem arvutusi seostada ka ruuteritega, et ruuterid oleksid targemad, et näiteks Cisco toodab ruutereid, mis on vist iOS-ruutereid, ja sama nimis Apple'il. Aga mille mõte on, et võimalik on jooksutada funksioone, siis ruuteri reistvarab kõrval või peal, selleks, et selle jooksutada näiteks mingisuguselt võrgu funksioona või teha mingiselt anme töötlust ruuteri seadme peal, enne kui need anmed lahkuvad majast või mingisugusest majate kompleksist. Et on võimalik vajadusel ka arvutusi teha ruuterte peal, et seda nimetakse hoog komputinguks, mida ma räägin natuke hiljem pilvetehnoloogia loengus ka. Et kõik need vajaduse sõendused lisaks on tähtsad hajussisteemide puul ka, mis transportiprotokollid on kasutuses, need samad procesid, mis jooksavad ja teevad läbi hajusarvutusi, et meil võib olla kogu hajussisteeme ehitatud riistvara ühendamise peale, kui me loome näiteks sellised jakatud mälusüsteeme või siis me teeme seda ainult procesid etasemel, et riistvara ei teha nagu teistest arvutus, sest pitte midagi ja procesid jagavad, saadavad sõnumeid üks teisele, et siis me teeme seda hajussarvutus ainult procesid etasemel. Et siis meil on hajussisteemis ölmede komponenteid vahel lihtsalt loogilni ühendus, et nemad teavad üksteese IP-aadresse näiteks ja võtad ühendust ja riistvara tasemel ei ole mingisugust hajussisteemi nagu ehitatud otsaselt. Iga suuristed hajussalvestusüsteemid ja annmebaasid, et me soovime hästi suurt mitralatsioonist annmebaas üles seada, kus me saame sadu terapeitte või petapeitte annmeid hoida, või me näiteks tekitame võrguketta oma virtuaalmasinete vahel, niimoodi, et üks kõik, mis proces kettale midagi salvestav, siis kohe teene proces näeb lihtsalt see neid samu file, et üks kõik, mis serveris nad asuvad, saavad päriteks ketta tasemel file, failide tasemel oma vahel nagu hannmeid jagada, et sellase meil, et ülevõrgu sõnumeid saata, siis toimub automaatne ketaste synkroniseerimine, siis filesisteemi tasemel hoopis. See ei ole küll kõige parem viis, kud as annmebaase luua, aga see on üks võimalus, kud as neid luua. Igasugus muud süsteemsed resursid, süsteemi teenused, lõimed, filei pidemed, valdkonna speciifised rakendused ja ka muud teenused. Üks kõige tähtsam muu teenus on just see sama viis, kui ta hajusalt töötavad serverid saavad oma vahel kella synkroniseerida, on siis Network Time protocol serverid, kus server saab minna küsida teise server käest, mis on praegu aeg. Aga see on väga keeruline probleem tegelikult. Okei, ma soovin kahe serveri vahele aega synkroniseerida. Nüüd need kaks serverid lähevad ja küsivad sama välise serveri käest aja. Aga kud as sinna saad olla kindel, et võttes arvesse internetilatentsust saabumise aja arvutamist ikkagi lokaalselt, et mõlemad serverid kolmanda osapoole päringute põhjal ikkagi synkroniseerida oma kella korrektselt, et kud as seda karanteeride saab. Ja kui täpne sellatentsust mõõtmin on? Ja siis on ka küsimus, kui täpne sul kella vaja saad on, et kui täpne, kas millisekonda on piisavalt täpne või mitte? Mõned sistemiid tänab ole kasutad ka nano sekondeid, näiteks InfluxDB default on nano sekondeid kui reaalselt ma ei tea miks, kui peamaselt ülevõrku ikkagi sinna annaid saadetaks. Haajussistemeid on ka erinead mudelid, kud as neid ehitada ja kasutada. Kõige lihtsam on klentserveri mudel, kus meil on mingi server ja meil on klent, kes seda servered kasutab ja võib-olla meil palju klente, kes seda servered kasutab. Muster on siis selline, et klent võtab ühendust serveriga, klendid kõik teavad, kus server asub, aks klendid võib-olla oma vahele teha, kes on teised klendid. Ja klent teab päringuserverile ja server vastab sellele ja server ongi ehitatud selleks, et teenindada mingisugud päringud, mis tulevad klentide käest. Ja klentie ei olema kasutaja, klent võib-olla lised rakendus, klent võib-olla front-endi rakendus, mis teie browserist töötab ja saadab päringud ülevõrku. Ja keerukamad hajussüsteemid saab klentserveri põhja lehitada niimoodi, et kõik klendid on ka serverid. Et sul ongi iga sõlim, kes selle saajussüsteemis osaleb, tema pakub mingis teenus serverina ja teised klendid ühendavad tema ka kui serverisse, aga see sama tarkora võib-olla ka klent teiste serverit vaatest, et võib ka tekida selline server-server mudel, kus kõik on klendid ja kõik on serverid. Meil võivad ole ka selt keerukamad mudelid, kus me kasutame hajus objekte, et pyütanis me tekitame objekti, mida meie kasutame, et võite kujutada ette kui klassi. Ja klassil on oma muut tõed, oma väärtused ja meie pyütan tarkvara saab küsida, mis on selle objekti hetke väärtus. Ja hästi lihtne programeerida, meil on lise klass, klassi objekt ja me küsime selle klassi objekti väärtust ja kutsume välja selle klassi objekti meetodeid. Aga see objekt ei asu meie serveris. See objekte asud tegelikult kusagil muujal pilves teised serveris ja lokaalselt me programeerime tarkvara, kui lihtsalt küsime, et mis on objekti väärtus, aga taustalt toimub objektide vahel synchroniseerimened. Kui mingis teised serveris see väärtus ära muudetakse, siis toimub synchroniseerimined, kõik teised serverid saavad ka teada, et se objekti klassi muutujate väärtus muutus ära. Ja kui meie lokaalselt muudam selle objekti väärtust ära, siis automaatselt synchroniseeritakse selle objekti olek ka teised serverides. Ja siis ei pea nagu mõtlema selle peale, et kus asub server, kelle ka ühendust võtan. Ma lihtsalt programeerin või kasutan selle objekti appid, et mingid meetodeid välja kutsuda, aga ma ei tarkvara kirjutades, ma ei tea, kus sa täpselt asub, ma ei pea mingite teiste serveride ka ühendust võtma. Ja kogu see klentserveri mudel või sõnumite saadmine või ülevõrgu ühenduse, peidetakse siinnago objekti sisse ära. See töötab sellise taustal. Et tema peamine eesmerk on peita ära klentserver mudel või anmedel synchroniseerimine, siis programeeria poolt käest ära, et programeeria ei pea selle ka enam tegelema. Hausobjektide sissemini implementatsioon oskab saanud synchroniseerida, siis on neid natuke lihtsam programeerida. Siis on pigem server-servered, kes omab seda objekti, see käitab sellegu objekti serverina ja teised klendid saavad seda objekti väärtusi muuta, arvatest, et ta on tagilikult lokaalne objekt, aga tagilikult on synchroniseeritud objekt, mis asub teoreetist kusagil muhev. Aga kõige selline tüüpilisem võib-olla rohkem selline klend-klend mudel on hajusarvutustse eriti teadusharvutustse ja kriid arvutustse on selline teadetele orjetne eritas suhtlus, et meil töötavad 16 prozessi soovid hajusarvutusi teha ja selleks et anmed jagad on nad saadaad üksteesele sõnumid. Põhimest peab-u nagu e-mail, et need anmed on nüüd teised ja sa tead, et process 2 tahab need anmed, et sa saadaad processile kahele sõnumi, et need anmed on muutunud. Aga tänapäeval pigem kasutatakse sellist lähenemist, kus meil ei ole nagu otsa teisele processile sõnumide saadmist, vaid kasutatakse selliseid loogilisi huvi grupe või selliseid postkaste. Et selle asemel, et saada sõnum processile 2, te saadate sõnumi postkastie, et näiteks, mis on maatriksite postkastie, saadate oma maatriksina postkastie ja siis üks kõik, mis teene process on huvitatud maatriksite väärtustest, nemad saad kuulad seda postkastia lugeada neid sõnumid. Kuna nende implementatsioon on natuke selline üldisemel lihtsam, siis see on nagu parem, kui otsaselt vaja teadmine, et ma pean saadma sõnumi processile 13, et te lihtsalt saadate sõnumi kuskil aadresil ja teised, kelle on sellele aadresil ligipääs, saavad nende sõnumidele ligi. See on ka esti palju tänaväl kasutuses mobiiltelefonide tarkkoras, et kui teie panete appid tööle oma telefonis, siis selle asemel, et appi ühendub kuhugi, serversi hakkab anmed pollima, ta teeb sellise, kuidas saadada, ta tellib anmedtele ligipääsot, et on huvitatud update sõnumidest või ta on huvitatud, selle kasutajale saabunud sõnumidest on huvitatud mingitest üldistest sõnumidest ja ta subscribeib või tellib teatud postkasti või teema ka seotud sõnumeid ja tekib nagu subscription kuskil serveris ja iga kord, kui anmed tekivad serveris, mis on seotud selle subscriptioniga, siis nad suunateks ja sinna ja siis suunateks seda siin kasutajale või sellele rakendusele, mis sallel telefonis jookseb, et selle asemel, et halatad, mis on need täpselt kliendid, kes hetkel on nagu kuskil jooksamas mingis telefonis, kasutatakse selliseid vahepealse nagu postkasti, et viska sinna sõnum ja see sõnum tuoks see kohales õigele kliendile, kas see kliend ise pollib need sealat või siis jääb kuula ma neid, et kõik need push notificationid ja tänapäeval need mustrid anmedte kohale, et toimetavise mustrid töötavadki sellist postkastide põhjal või sõnumite järekordade põhjal. Ja selle me ka mängime läbi, kas teises või kolmandas praktikumis. Ja suur anmedte töötluse puhul kasutatakse selliseid kuvitavad hajusobjekte, mis kui tavalsed hajusobjektid on ütlema, et ma kasutan hajusobjekti meetodid, et midagi väljakutsuda või mingi tanmed muuta ja see hajusobjekt võib asuda kusakli mujal, siis hajus anmestruktuuride korral on pigem meil nagu anmestruktuur, näiteks mis on list või mis on mingi matrix või mis on mingi tabel ja me ei tea, kus asuvad tabel erinevad read. Et meil on suur tabel, me saame teha mingi tarvutusi tabeli põhjal, aga iga tabelirida võib asuta erineva serveri peal. Et tegelikult nad tavalselt asuvad kõik blokkid enam, aga võite kujutada endale ettesest hiigel suurt hajusad tabelid ja need tabeli blokkid on jagatud täiesti erinevate serverite vahel, aga teie saate teha SQL päringud selle tabeli peal, saate tulemased kätte, aga te ei näe, et kus reaalisalt need anmed asuvad ja kuidas need päringud tegelikult läbi viakse. Et sa oled näiteda nagu Apache Spark RTD, mis on nagu pigem lihtsalt list, Apache Spark DataFrame, mis on nagu Python Pandas DataFrame või siis SQL tabel ja neid on väga saarnast hajusobjektidele, aga nad on nagu sisemiselta ära jagatud ja paraliseeritud. Sellised suuremad hajusobjektid põhimõttel. Ja neid väga palju kasutatakse sellised suurarvutustes ramistikes nagu Hadoop ja Spark ja Big Data anmed teed öödleks. Ja kuna ma ütlesinki, et tänapäeval on pea kõik asjad hajussusteemid, siis lihtsalt näid, et taval internet, World Wide Web minge postime lehekülele või Telfi lehekülele avage webi konsool. Vaadake, mis teile laetakse, kui te seda lehel refresh teate. Eriti hea, kui te seda esimes kord avate, siis ei ole käsitud midagi ja lugega, mitu päringud tehakse, kas Telfi või postime esi lehe laetimisel. Te näet, et neid on tõenest mingi sada või kaksada päringud tehakse taustal. Kõik neid pildid ja kõik neid sisu ära laadida. TNS, E-postid, kõik on hajussusteemid koha algust peale. Igasugust interaktiivselt suhtust programmid, võrgumängud, peer-to-peer võrgud, blockchain võrgud. Ja tänapäeval peab kõik infosusteemid ehitatakse sellist hajussusteemid. Meil on üks või rohkem anmebaasi sõlmeserverid. Meil tihti on back-end-appi konteeenerid või serverid ka palju, et saaks hakkama suure arvu klientidega. Nende ees on tavasalt mingisugune ümper suunaja või liiklusepalanseeria, kes siis otsustab, et millisele serverile päringud edasi saata ja klientide käestu ole västi palju päringud. Ja kogu süsteeme onki ehitatud niimoodi, et meil on ühel tasemel mitu replikaati teatud süsteemist, mis meil vaja on. Ja meil on mitud aset, et eraldada see loogika või arvutuste tegemise anmebaasi moodulist. Et need oida täiesti eraldi, et me võime kõik need appi konteeenerid ära tappa ja anmetega juhtu mitte midagi. Ja me saame suvaliselt muuta nende appi serverite või appi konteeenerid arvu vastavalt vajaduslad, kui palju meil on kasutajad hetkel kasutamads. Öösel võib-olla me jätame ainult ühe elu ja kesed päevavõib pühadajal võib-olla meil on sadatükki neid sadaserverid jookseb. Et selline lihtne mudel, kus on võimalik skaleerida. Ja kui meil on hästi palju anmeid, siis me ka skaleerime siin või vähemalt replitseerime selleks. Me saaksime teha ka samast SQL-anmebasist kolm koopjat saata anmete uuendamise päringud ainult ühtekoopjesse, et karanteerid, et kunagi anmed ei salvestata sama aegselt ei muudata ühtegi väärtust. Aga me saame kõik SQL-päringud, mis anmeid küsivad, ehkä ainult pärjivad, jagada siis kolmeseerver vahel ära, et kiirendada anmetel lukemise kiirust. Et seda tihti tehaksse Postgres puhul näiteks, et kiirendada anmetel lukemise kiirust. Ja, et sellise liul peab aksepteerima, et teil on selline English keeles eventual consistency, et ta on natukes aaja pärast korrekne. Ja see on täitsa okei rakendust jaaks näiteks mingisugune Messages Board või Facebook, et siin väga juhvite, et kui kasutavad, sa aru me ära muudab, et sinu annad koha samal sekondi seda muutust. Siin on oks on okei, kui see tuleb minuute aaja pärast või kahe sekondi pärast. Et sellistest systeemid on seda itse okei. Ja teiste, me nägem selest ka ühes loon, kus Pilvetenoloogia nende hajusannapaised juures, et kuidas siis karanteerida seda, et kui annmed muutetakse, et siis ükski järgmine lukemine ei anna enam vanu annmed. Ja paljemel aeg on. Natuke velan. Üks viimased teemad on siis tegelikult see on teine teema, üks teema on veel. Webiteenused. Mis siis on tänapall webiteenused? Ongi põhimised hajusüsteemid, mida saab suvalisest webiklendist välja kutsuda standartse protokolle standartse rakenduse kaudu. Põhimised kõiki webiteenused saab browserist välja kutsuda. Kül ketmetodeid peamiselt, aga saate ka postmetodeid teha. Tarkvara, mis pakub üle interete ligipäesu erinevatele, tarkvara teenustele ja resursitele läbi standartsete webiprotokollidega. Ehk põhimised tarkvara, mida saab kasutada täpselt sama protokolli kaudu, mida te kasutad teie browser. Ehk ongi standartne Http protokoll ja kui meie teeme mingi hajus rakenduse, me ehitame selles seliselt, et saaks sama Http protokolli kaudu seda kasutada ja ei piaks mingid erilisi protokolle välja mõtlema, et seda kasutada. Ja põhimõttelselt meil võitki olla mingi suure arvutus ja sama moodi, kui me näiteks postimees mingi lehekülj alla laeme või kuskil, ütleme foorumis, uue postituse tekitame, võime sama moodi tekitada uue hajus arvutuse, piltitöötlus arvutuse, siis sama protokolli kaudu. Ja siin ongi näiteks, et Google Translate teie lähete Google Translate lehele ja tõlgite midagi, aga samuti võib teie mobiilis olev rakendus kutsuda välja Google Translate veebiteenust selleks, et samamoodi tõlgimist välja kutsuda. Ja teie saate kirjutada Python rakenduse, mis samuti Google Translate kasutab selleks, et küsida Google Translate, et mis see eestikälne lausa on ingliskeeles. Ja tegelikult ei ole vahet, kas seda teie browser või teie Pythoni rakendused samat protokollite kasutusel ja täpselt samasuguse metodi saate saata sinna oma Python koodist, et ära automatiseerida see sama protsess, mida te teete webi browser ja webi lehekülj ja kaudu. Et see ongi suur osa need asju, mida teise teise browseri kaudu teha, saaks seda ära automatiseerida mingi skriptiga, et tehke sa samasi ära. Või siis piltide väiksemaks tegemise teenus või reditis sõnumikirjutamine, et samamoodi kui teelete rediti lehele ja kirjutad uue sõnumi, saaks seda lua Python skripti, mis kirjutab selle uue sõnumia ja saadab selle sinna. Põhimist sama apimetodi kaudu. Ja. Miks on webi teenuse tähtsad ongi see, et oleks lihtne luua rakendusi, mis oskavad üks teisi välja kutsuda, ükstese metodid välja kutsuda ja ei tekiks seda probleemi, et on meil hästi palju erine protokolle ja kui me loome rakenduse, mis soovib, kas Google Translate teha ja reditis see teises keeles midagi kirjutada, siis sellise tüütun rakenduse kirjutamine hästi lihtne, et kutsume välja Google Translate metod ja kutsume kõik. Kutsume välja Google Translate metod ja kutsume välja Reddit metod ja ongi skript olemas, et seda oleks hästi lihtne teha. Et siis üks peamine eesmärk ongi, et üks kõik, millist rakendusest oleks võimalik neid kasutada ilma, et me peaksime õppima erineva protokolle ja et meil rakendusest oleks sellised platformi neutraalsed, et meil peaks erinevate platformi teaks asju erineval tegema ja et oleks programeerimis keeles sõltumatud, et meil ei ole niimoodi, et tüütan näiteks tuetavüüste protokolli ja siis me ei saa teist programeerimis keelt kasutada, et kui meil ongi selline standaartne hea protokoll nende haussisteemide veepi teenuste metodite väljakutsumiseks, siis on seda võimalik teha üks kõik, mis programeerimis keelest ja üks kõik, mis viisil. On ka sellised standaardid, mis kirjaldavad ära, kuidas need veepi teenuseid kasutada, niimoodi, et oleks nad arvuti loetavad, et oleks võimalik automaatselt genererida tarkk vara ja mis oskaks kohes neid teenused kasutada, et ei peaks olema ainult programeeria, kes läheb ja vaatab, millis need metodit on ja käsitsi programeerib midagi, vaid oleks võimalik ka seda programeerimist ja protokolliit, et kasutamist ära automatiseerida. Siis ajal olised on kasutusel olnud selline asi nagu VSTL enne selliste Http ja Rest Appi populaarseks saamist. Tänapäeval seda kasutatakse ka näiteks Eesti XT puhul päris palju, kun ajal olised seda kasutust on, mis kasutab sellist, kus kasutatakse peamist sellist SILP-protokolli, kus kasutatakse XML sõnumide struktuuri, mis on natuke keerulisem. Aga tänapäeval on palju populaarsem Http protokoll ja selleks on standaard, mille nimena Open Appi, mida me siis ka. Neid standaardeid me vaatame öhes loengus ja on praegu toonlist ühe näiteks Http protokolli kohta. Kes ei tea, mis on Http? Te kõik olete Http'ed mingis ainees kasutan näinud. Http onki selline hästi lihtne viis, kuidas veebis alla tõmata resursse muuta, resursse pärida. Resurs võib olla siis veebileht, resurs võib olla mingi pilt, resurs on põhimõtteliselt mingi tüübi dokument, aga ta võib olla ka tegelikult mingisugune metod, mille välja kutsume. Http on suhvõi vähe operatsioone, mida saab käivitada. On ket mingi resursi alla tõmbamiseks, put resursi loomiseks või muutmiseks, post uue sellise resursi või alam resursi loomist, et näiteks post uus sõnum, post uus image, post uus kasutaja, et uue resursi loomine ja te liitad siis resursi kustutumine. Ja kasutadaks sellist server klientläheneemist, et meil on server, server juba mingisuguna aadress, mis serverid teatud tüübi resurssa, näiteks pildid või HTML-leht või mingisugune üldine resurs ja ketiga saame seda arvussursse alla tõmata putiga muuta, postiga uue luua ja teletiga kustutada. On ka mõned teised metodid, mis on kasutuses, nendest ma räägin siis appi loengus natukka rohkem, aga see ongi sinna lihtne lähemine. Ja tegelikult, kui on ainult nelja metodid, mida kasutada, siis on suhtseb lihtne teada, kuidas tarkora looa, mis oskap need resursse kasutada. Ja see resurs võib tegelikult olla ka midagi natuke abstraksemat, näiteks mingisugune funksionaalsus meie hajussusteemis, et me soovime uut arvutus, vana arvutuses staatust vaadata, siis me saame teha ketpäringu selle arvutuse aadressil, arvutuse aadress võib olla näiteks mingisugune slash arvutuse, slash 617, et see on 617 arvutus ja ketpäringu ka me saame alla tõmbama alla info selle arvutuse kohtad, et arvutuse kohtad, kas arvutus on tehtud, kas arvutus on veel tegemisel, kas arvutus on järjekorras, et ei pea olema nagu selline nii-mell ta ette kujutada füüsiline resurs, võib olla ka selline loogiline või virtuaalne resurs, et mingisugune arvutus, mis kusagel käib, ta võib olla mingisugune kasutaja, et me ketiga saame tõmbama alla selle kasutajainfaaanmebasist. Putiga loome uue kasutaja, postiga muudame kasutajanmed ja te liidiga kustutama kasutajära, et see võib olla üks kõik, mis anmebasiresurs või veebiresurs nagu pilt. Ma rääkin sellest natuke ühes teises loengus, selle vahe on see, et kui meil on näiteks kasutate list, siis uue kasutale listi alla uue kasutaloomine, aga siis me ei saa anmed muuta, siis me kasutame putti olemas oleve kasutaja aadressi peale, et näiteks user slash 312, et saata uued anmed selle kasutajakohta, et ta ümber muuta. Aga teatud olukurras võib ka putti kasutada loomiseks, aga on loodud ka selline natuke täpsem spesifikatsioon või standaarde, et kuidas HTTB-t natuke selgemine kasutada, et mis on lubatud, mis ei ole ja see on restful, mis on põhimselt täpselt sama appi ja protokollis HTTB, aga ta paneme natuke rohkem regleid selle peal, et mida sa võid kasutada, mida ei või kasutada ja ma rääkin sellest ühes järgnevas loengus. Ja siis viimane teema, millest ma tahtsin rääkida, on pilvetehnoloogia, et kui meil on nüüd võimalus luua listasti hajussusteeme webi teenuseid, siis kuhu me paneme nad üles, ne oma hajussusteeme webi teenused, kas me paneme oma server üles siin ülikooli või oma start-up kontari nurgas, või vähem tegelikult taaksime, et oleks lihtsam resurssede hankimist teha, et kui meil öösel või sellel nädalal on ainult 13 klienti, kes meie start-up rakendus kasutavad, mis juhtub siis, kui järgmine kuul meie start-up saab hästi populaarseks ja meil tuleb 10 000 kasutajad, kas me, kui palju meil võtab aega uute serverid ostmine ja kohale toimetamines, ülest panemine, tarkkura sinna instaleerimined, see kõik on nagu aega nõudu tegevus. Palju lihtsamalas, kui me saaksime küsida, et antke meile 10 serverit ja me saaksime ligi pääsu kahe minutikane 10-le serverile ja saaksime oma rakendus sinna instaleerida käima panna, et saaks nagu kiiresti arvutusresursse teile ligi pääsu. Pilvetehnoloogi ongi see idee, mis on täikest kui hästi vana idee aastast 1969, et miks mitte pakkuda arvutusresursse täpselt samamoodi kui elektrit või vett või teore järgmobiiliteenust, mis tegelikult enam ei ole väga selline utiliit-teenus. Me kasutame arvutusresursse ja kuhul lõpus me saame arve selle põhjal, kui palju me mälu kasutasime, kui palju me ketta ruumi kasutasime, kui palju me prozessori aega ära kasutasime ja kuhul lõpus saadab keegi meile arvet, et nii palju peate maksma selle eest. Ja me ei pea selle peale ette mõtlema ja me ei pea ostma arvuteid, servereid ja neid ülesseadma, vaid me saame need lihtsalt kasutamakata ja meil on selline lõpmatute resursside illusioon, et kui ühe aasta pärast on meil 3 miljonid kasutad, siis meil ei oleks vaja nagu liiga palju tööt selleks teha, et võib-olla sadakorda või tuhadkorda või kymmetuhadkordas kaleerida oma resursside vajadust. Ja tihti pilvetehnoloogikaud on võimalik saada ilma ette maksuta arvutusresursse, tihti isegi tasuta, et kui teile on oma start-up, saate minna näiteks Azuresse või Google App Engine või Amazon pilve ja panna mingi prototüp üles ja see ei lähe mitte midagi teile maksma. See hakkab teile maksma siis, kui reaaliselt kasutad, aga teie rakad just kasutama, et testimise ajal või prototüpimise ajal ei prugis üldse mitte midagi kasutada, sest tihti on pilvedes selline päevased või kuused, koutad või märad, et kui te nendest märadest üle ei lähe, siis te ei pea midagi maksma. Et sellised vabatasemad, et alla selle jäädes, et kui ei kasuta piisavalt ketta ruumi, siis ei pea maksma, kui ei kasuta piisavalt interneti, broadbandi, armet allatõmbamise, siis ei pea midagi maksma, aga kui lähete nendest piiridesest üles, hakkab te maksma ja võite päris palju maksma hakkata. Pilved on muutunud ideaaliseks teenuseks selleks, et majutada veepirakendusi, kus teid kasutavad võib tulla üle maailma, et te ei tead, et kõik kasutavad on Eestist, ja te ei tead, nende kasutad arvu ette ära. Et saate lihtsalt elastselt oma rakenduste ülesseada, nii Eestis, no Eestis väga eestis te ei saagi, nii Saksamal, Soomes, Iiris, Amerikas ja siis ka Australias näiteks, et saate täpselt sama rakenduse lihtsalt ülesseada, et muudate läbi apikaudu mõned parametrid ära ja panaks sa teile konteeenerid ka Australiast öelda. Pilved tehnoloogis on mitu sellist mudelid, kõige klassikalis ja mülevaade on, et meil on selline tarkvaratenusena mudel, softwarase servis, kus lõp kasutavad teie rakendust üle browseri ja ei näe midagi nendest serveritest, ei päa midagi tegema, logijad lisse browseri kaudu sisse või tead uue kontoo ja hakkad seda kasutama. Tänapäeval peab kõigist tarkvarast on ka tarkvaratenusena versioon olemas, alates Wordis kasutatud Office 365i, kasutatud Slacki või te Slacki läbi browseri kasutada, kasutatud suulipid või te läbi browseri suulipid kasutada, kasutatud Zoomi või te läbi browseri Zoomi kasutada, et tänapäeval ongi tehtud väga paljudes tarkvarades ka see veebiversioon, et saaks läbi browseri seda lihtsalt kasutada. Pil pakub sellist kahte peamist mudelid, et luua tarkvaratenuseid. Esimene on seline riistvaratenusena või infrastruktuurtenusena, kus teile antakse ligipääs virtuaalmasinatele, et saate minna Amazonist küsida, antke mulle ligipääs 25 suurelle virtuaalmasinale, te saate ülevõrgun nendale ligi, saate kahe minutiga 25 virtuaalmasinat üles, saate üle SSH nendale ligi ja saate neid halda makata ja saate täielik kontrolli nende virtuaalmasinate üle, et saate valida operatsioonisüsteemia, et kasutada makata. Aga selleks on teil vaja siis võibolla selliseid operaatoreid, kes oskavad virtuaalmasinat halata, et võibolla teie start-up ei taha halata virtuaalmasinad, taab lihtsalt oma pyütun rakendust ülespanna. Selleks pakutakse erine platforme rakenduste jaoks, et kui te ei taha tegeleda madalataseme infrastruktuuriga, te tahate lihtsalt, et minu pyüt on rakendusjookseks kusagil, tahate seda esti lihtsalt iskaleerida, tahate, et see efektiivselt jookseb niimoodi on karanteeritud, et kui kasutatav arv 10 korda tõuseb, siis 10 korda rohkem resursse kasutatakse, et kõigil kasutatel on kasutusmugavus enamen sarnane, et siis saab kasutada sellist platforme teenusena, kus pakutakse teile näiteks võimalust, et linkige oma hithaa repositoorium, kui seal on rakendus, millel on veebiserver küljes, näiteks, kas ta on Flask veebiraamistik, kas ta on Vue veebiraamistik, kas ta on Vue, oma pigem mitte, pigem mingi server rakendus, kas ta on mingi sugun fast API rakendus või Java Spring rakendus, et siis pilve platform valmistab ette teile keskonna, mis oskaab neid rakendus jooksutada, skaleerida, halata niimoodi, et ta isegi tõmbab ise sellest hithaap repositoorium starkvar alla, paneb üles, kuski konteinerist panab tööle, teie sate linki, et teie rakendus osub seal jonki tööl. Ja saate konfigureerida, et mis on maksimum konteineritarm, mida te lubate igaks juhuks, et üle eelorvii läheks, ja siis pilva hakkab teil ka seda automaatsa, et skaleerima. Ja kui te loote oma rakendus oma serverite peal, siis te peate ise haldama serverid ostma, haldama võrku, salvestusmahtu, virtualiseerimist, kui te soovid ikkagi virtualiseerimist kasutada, peate ise instaleerima operatsioonisisteemid mingisugust vahepealsed tarkkorad näiteks, kas seata üles püütun 3,9 või püütun 3,12 keskonna, siis oma anmed ja oma rakenduse, kui te pilvekäest võtate infrastruktuuriteenusena, siis pilve teenuspakuja hoolitseb võrku eest, hoolitseb ketasteest, hoolitseb servereteest, hoolitseb virtualiseerimist, et ei saate võibolla valida operatsioonisisteemi, et ma tahan Centos virtualmasinaid, ma tahan U. virtualmasinaid, mis iganes Linux või Windows, veel Windows on ka toetatud, et mis iganes operatsioonisisteemi tahate. Aga ise peate haldama siis operatsioonisisteemi sisu, et näiteks, kui mingisuguses paketis, mida te instaleerite tekib mingi turva viga, siis teie olete vastutav selle eest, et õige laajalne uuendaks ära, et pilve teenuspakuja ei lähe teie virtuaalmasina sisse ja ei hakkak mingit pakete või tarkkora välja vahetama, kui on mingi turva probleemit, võibolla nad panate virtuaalmasin kinni opis. Aga siis te halad ise operatsioonisisteemi, mingisuguses vahevarasid näiteks Python keskondi ja siis on samut, et kui mingi Python teek ei ole turvaline, siis olete teie selle üle vastutav. Aga kui te kasutad näiteks platformi teenusena, selleks võib olla näiteks Google App Engine või Azure App Service või siis Amazonis on see Beanstalk Service näiteks, et siis teie ainult annate anmed info ja rakendusinfod näiteks, mis anmebaaside kasutate ja kus on rakenduse kood ja pilve teenuspakuja siis ise huolitsab nende keskondode eest ja operatsioonisisteemi eest ja nii edasi. Ja lõpuks loote, tarkvarateenus on rakenduse, kus kasutad enam ei tee mitagi. Ja siin see vahe ongi, et palju teil kontrolli on, et mida te tahad ise kontrollida, kas te tahad, eest Riisvara kontrollida, kas te tahad operatsioonisisteemi kontrollida ja keskonda kontrollida, või te annate nagu kõik need haldus ära pilve teenuspakuja le, annate ainult oma koodi ja võib-olla kirjeldata natuke, et kudas see koot peaks jooksma ja kui palju tead, et ka leidete saaks. Ja need vaatame ka siis aina raames läbi ja teete praktikumide raames läbi, et seda, no, enda arvutes võib-olla midagi seata üles, aga pilve kontekstis vaatame nii infrastruktuuriteenuse nagu iga platformiteenuse meile. Ja siis tänapäeval ongi, et pilve ja teenuseb muutunud nagu, te saate kõike teenusena pilvest küsida või teenusest kasutada alates mingite standme baasidest, webi mängude taustasysteemidest, et näiteks webi mängude multiplayer osa pakutakse amas, onist täiesti teenusena, et saate nende mingisugust gaming enginei kasutada niimoodi, et te piha seda ehitama. Firma võib, et näiteks blockchaini teenust võtta pilve teenuse pakuja käest niimoodi, et nad ise ei piha oma blockchain node, et serverite nüleseadma või et lihtsalt amas laanab neile need. Ma asinin õpet, et kui teenuse, nad pakutakse hästi palju tänapäeval, aga igasugust ka kolmde keskkonad näiteks, et te tahate ehitata uue roboti, targvara tahate testida seda robotid väga erineates ruumikonfiguratsioonides, et kas robot saab hakkama mööbli vahel liikumisega ja Amazonis on teenus, mis genererit teile 1000 erineat toak kolmde konfiguratsiooni ja panatate targvara jooksma, et saate tagas, et mitmes tuhandest ruumiste ja robot sai ilma millegile otsasõitmata hakkama. Et on selline teenus lihtsalt, eksist eerib. Igasugust media videoedastust teenused, et näiteks teete video striimi, mist ei soovi ühtegi video striimi, mis platformi kasutada, tahate oma mingisuguse firmale seda teha ja tahate sinna striimi automaalsit injektida mingil reklaame, eksist eerib selleks teenus. Igaid muud väga palju, mida oskate ette kuutata, eksist eerib Amazonis pilve teenus. Näiteks teil on tehas liin, lahedle ka pudelid või midagi muud, mida luakse. Te soovite masinõppe abil tuvastad ära, et misugust tal pudelid on tefektid, siis eksist eerib masinõppe teenus, mis saate töölepanna kaamere striimiga, nii et striimiteks anma, et vist pilve. Teenus vastab teile aja stambi abil vist, et misugune pudel näeb teistmoodi välja, kui teised pudelid, võib-olla selleks mingit efekt. See on valmis teenus selleks, et ära tuvastada natuke teistmoodi välja nägevaid asju, mida toodetakse tehas. Ongi teemat läbi, kõik need kolm teemat, ma räägin rohkem lahtikus näidetega järgmestes loengutes. Tänal idea olik, et ma natuke lihtsalt tutustan, mis sinna aine olema hakkab. See nädal praktikum ei ole, järgmest nädal räägime siis hajussüsteemide loomisest, programeerimisest ja lõimedest ja siis toimub lõimeda põhine praktika. Ja räägime siis natuke mitmelõimeliste rakendastaloomisest pyütonis. Ja miks pyüton on natuke halb nende jaoks, sest tegelikult pyütoni tava lõimeda ei ole üldse paralelisad. Ja järgmestes loengus räägime natuke rohkem hajussüsteemide omadustest, et praegu see või seada liikara, kui selleks kiireks ja lühidaks. Aga siis järgmest kord räägin täpselmalt äneed omadused lahti natuke rohkem nende hajussüsteemide kohta. Eest ka mitmelõimeliste programeerimise loomise kohta. Ja mingi hetk järgmestel nädal on ma lisan teid ka suulippisse, kutsun teid, kui te ei ole juba liikmed. Ja siis selle ka odu saab hakkata ka suhtlema väljaspol praktikumia loengu aega, et saate suulippis abi küsida, kui millegi hakkama ei saa või hättajäete.