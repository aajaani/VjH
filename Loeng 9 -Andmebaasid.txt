 Täna se loengu teemaks on siis hajus ja pilve-anmebaasid. Räägime natukene pilvetehnoloogiest edasi, aga tänane selline loengongi kombinatsioon anmebaasidest, pilvetehnoloogestest ja hajussusteemidest, sest me võtamegi fookuses just hajus-anmebaasid ja pilve-anmebaasid mitte nii väga tavaliselt esküel anmebaasid, aga põhimõttelikagi alustame sellest, et mis on üldse relatsioonilist anmebaasist ja mis on nende probleemid. Just skaleerimise vaate vinklist, et miks hästi skaleeritavate lanmebaaside puhule ei kasutada tihti tavaliselt esküel anmebaasid pilves. Ja lõpetame siis pilvetehnostega, mis ongi mõeldud anmebaaside jaoks ja praktikumidest hakkate siis kasutama oma raamatu, halduse, rakenduses anme toidmiseks, siis pilve-anmebaase. Esijal, kui me teeme sellest natuke lihtsamalt, aga eks te näete? Ja tänane praktikum tegelikult võidki oleks raskema praaktikum, aga eks seda vaatame, et teil tuleb oma se rest-appi natuke ümber teha, et põhjamasud peab kõikides meedodides, et sellase mele, et me hoiame neid raamatuid lokaalsed, siis nüüd panaks seda anmebaasi, ja me hoiame, kas seda jasonid põhimõttel anmebaasis nüüd, et kus hoidakse seda raamatuid nime kerja, kui ma jätin mõletan. Aga anmebaasi relationist mudelt, te ota kõik näinud, kas anmebaasid ainees, kas kuskil asutuses, kus te teete praktikat või töötate, põhimõttel anmet salvestavaks ta tabelina, kus tabelitas on kirjed ja tabelid tehaks see tavaliselt iga erinev oleme jaoks, et meil võib-olla näiteks olla kasutajatabel, siis on meil näiteks mingisugune kasutaja võtmetetabel, mingisugune kasutaja ostetud, ma tegime objektitabel, kui meil on mingi veebibood. Põhimõttel meil tekivad sellist erinevad tabelid, näiteks siin on customers, orders ja products, ja me tavaselt seome need oma vahel selliste välismõttelmedseostega, et see kasutaja, customer ID, customer staple on samamis, customer ID orders table ja siis product ID orders table on samamis product staple, et see loob siis otsased seosad endanemete vahel, mis on andes kolmest tabelis. Ja need on hästi ranged seosad, et näiteks ei prugigi olla võimalik teha uus order kirje, kui siia prooviteks kirjutada midagi customer ID ka, mida ei eksisteeri customers tabelis, et selledut tulemusel tuleb viga, et ei saa teha orderid tellimust kasutajale või klendile, keda ei eksisteeri veel klendi tabelis. Ja see panep peale teatud piirangud, me ei saa lihtsalt tohutul mahul anmeid sisastada näiteks orders tabelis, me peame enne hoolitsema, et customer stabelis on kõik kliendid loodud enne, kui order stabelis palju anmeid lisame. Meil peab olema synchroniseeritud ka anmete sisestaminud, kui me hakkame uue klendi anmeid sisestama order stabelis, siis see peab olema loodud customer stabelisse ja kõike seda tuleb arvessa võtta, kui me hakkame anme baase skaleerima. Ja ka anmete tüibid on määratud tihti väga rangelt, et kõik tulbad on siin näiteks Integer 64 või String 256 pikk või siis näiteks Float 64, et näiteks tüibid on määratud ja siis te saate vea, kui te proovete seda mingi teise anmeid sisestada. Et see anme baasi tarkvara, anme baasi engine ise siis kontrollid, et kuu see anmeid sisestataks, et näid rangelt oleks täpselt õige struktuuriga, kui anme baasis on määratud nende tüibiks. Ja tavalselt kasutatakse SQL päringud, et anmeid sisestada, anmeid pärita siis relationist anme baasidest. Ja siin on üks suvaline näide, mitte väga keerukast anme baasist, et kui te lähete töötama mingis siin firmasse, siis seal võib olla kõvasti rohkem tabeleid, eriti kui see on 10-20 aastat vanha firma, mis tegelebki SQL põhiste süsteemidega ja tänapäeval võivad, et SQL anme baasid ole palju keerukamad kui siin, aga mõnikord ma vaatan, kas siit seda võib-olla välja ei tule, et mõnikord tekivad ka seda süttyksed seosad, aga siin on pikemse orders, tundub olevat selline keskmine tabel, millega teised on seotud, et on nagu pikemseline puu mõnes mõttes, mis hakkab orders tealapoole. Et ma vaatin, et see on isendas. Jah, et see on selline... Huvitav tükkel siin. Ma olen ka seda mujal näinud, aga... Region is... Võib-olla lihtsalt seos nende vahel, et ja... Title, title of courtesy and region oma val seotud. Ma pole päris kindel, mis seal täpselt oma val seotud on. Ei pruugi olla, et see võib olla... Ma olen näinud sellist seeost, et sul on kasutad ja kasutajate tabelisab eer, kus on sõbrad, ja sõbrad on defineeritud nagu listina. Mis on hästi imelik, et relatsioonisandmebasis tavasad ei tee, aga ma olen seda näinud. Ja siis tegib endaga seeost, et saa seot ühe kasut oma sõprade, kes on samuti kasutajad, aga tavasad seda väga ei tohiks teha pikem. Peaks sellised seeos, et tegem äraalt ei tabelina. Ja sellist relatsioonistetabelite puhul on tegelikult keeruline otsustada, et kuidas neid skaleerida sellised andmebase. Et kui meil ühe serveri jõudlusest enam ei piisa, siis meil on tavasad kaks võimalust skaleerimiseks, et anda rohkem arvutusjõudlust, näiteks me viime oma office andmebasi pilve ja siis soovime pilves seda palju suuremast skaleeridad. Me saaksime teha vertikaased skaleerimist, millest ka ma aga natuke pilvetehnoloogia loengusist mainisin, et me lihtsalt suurendame ühe serveri võimsust, et paneme ta suuremast virtuaalmasinas tööle. Sella asem, et me anname teile neid 8 tuuma, anname 16 tuuma, sella asem, et aks 12 gigabaitimelu, anname näid 24 gigabaitimelu. Me saame alati andmebasi suurendada. Kas te ei oletu uurinud, mis on kõige suurend virtuaalmasina asures? Päris ja maksma läheb. Ütleme rohkem nagu sadatuhate eurad kus. Ma jääsi üksustel. Tegelikult on võimalik võtta hiigel suur virtuaalmasin. Me asures seal on speciaalsed virtuaalmasinad, mis on näiteks GPU-hevid või mis on CPU-hevid või mis on memory-hevid. Aga on võimalik ka annemabasi ehitada niimoodi, et võtta hiigel suur virtuaalmasin ja sinna ühendada kuni vist 64 kähendadele. Siin on viis kähendada. Ja ikka ketas võib olla mingi 4 terabyte. Või siin on 8 terabyte. Et see on pilve ketas. Sist virtuaalmasin ise võib maksida mingi 50 000 või 100 000 kus, aga ikka ketas läheb ka mingi 3000 000 kus maksma. Ja siis te võid arutada, et paljusel reaalsed maksma läheb ja tegelikult ei ole võimatul uur asures näiteks ühe petapaitilise ketta ruumi ka virtuaalmasini. Lissalt ei ole mingi 64 kettas, lihtsalt ei ole mingi 64 ja või rohkem ketast, mis on hästi mahukad. Aga see läheb tohtud kalliks. Selliste anmebasi veitamene, mis ühe virtuaalmasina peale on ülas eitatud, siis läheb väga, väga kalliks. Et tiedamine kasutatakse pigem, nagu horisontaalselt skalenimest, paneme rohkem servereid ja paneme anmebasi, siis mitte me serveri peal samakselt ööle. Ja me saame resursse juurdu panna sellekõpp, me lisame virtuaalmasinaid või lisame servereid. Ja see on odavam, et me ei pea võtma nii võimsaid virtuaalmasinaid, me lihtsalt võtame neid rohkem, nii et kolmkorda suurema anmebasiaks kasutama kolmkorda rohkem servereid näiteks. Ja see läheb kolmkorda rohkemaks. Aga siis me peame hakkama anmeid jagama erinevad serverite vahel ja tegib hajus anmebaas, tegibki süsteem, kus me peame nüüd ufolitsema hakkama, et kuidas anmed on, kas replitseeritud või... Kuidas anmed on jagatud nende serverite vahel. Ja relationaalis anmebasi saab samuti horisaantaalselt skaleerida, sellest ma lägin järgmestaslaadil nimetadaks Ingiske sardimiseks, aga no teist ka skaleeru väga hästi, et tekivad palju palju probleeme ja tihti tekivadki probleemid just nendest seostest anmebaasiid vahele. Kui me näiteks jõtame, et me jagame kõik tellimused kolme servere vahele ära, siis me peame otsustama, et millised tellimuse tähed ühte serverisse, millise tähed teise serverisse, millised kolmandase serverisse, siis me peame otsustama, kuidas seeotud anmed veste stabelitse hoitakse, sest kui me partitsioneeri näid hästi, siis võib juhtuda, et igakord, kui me teeme üks kõip mis select päringu, siis me peame kolme serveri pealt anmed kokku kokuma, et seda select päringule vastata. Ja meil olks palju kiirem, kui me ei peakse sellist kokku kokumist tegema, kui seda vaja ei ole, et teha lihtne select või join päring, et meil on tegelikult parem, et anmed tullada tähed tühest serverist, et siis seal on vaja näiteks võrgulinklust ja mälust, anmed küsimina on palju kiirem kui üle võrgu anmed küsimina. Ja selletur ta tegelikult tähtiselt partitsioneerimist tähti teha. Ja need kõik need relatsioonid tabelite vaheliselt seeoset teevadki siis tegelikult skaleerimise keerulisemaks. Kilustamine põhimise tehtab seda, et me võtame mingisuguse tabeli ja jagame tabeli mingisuguste tulpade järgi erinaeks partitsioonideks. Näiteks siin tabelis meil on customer ID 1-4 ja me paneme reegli paika, et customer 1 ja 2 läheb ühte partitsiooni, 3-4 läheb teise partitsiooni ja näiteks 5 ja 6 läheb kolmatase partitsiooni edasi. Ja siis me saame defineerida sellised reeglid, et mis anmed hoitaks esimeses partitsioonis, mis anmed hoitaks teises partitsioonis. Ja siis me jagame, et partitsioonid või eestikeles võib-olla kilud, anmedbasikilud siis erinevat serverite vahel ära. Ja siis päringute tegemisele, et kui on meil SQL-i, selleks päring, mis puuduta painud customer 1 või customer 2 anmeid, siis piisab sellest, et need anmed võetakse esimesest sardist. Ja kui need päring kõik kõik puudutakigi customer 3 või 4, siis võib-olla meil teises serversi olegi kõik ma vaadata. Ja samamoodi, et me võiksime vaadata, et kui meil näiteks employee ID on siin ja see tabel on siis seotud emploii teritoriis ja siis orderitega. Ka order tabeli saame partitsiooneerida siis emploi ID järgi, ka selle tabeli saame partitsiooneerida siis emploii tabeliga. Ja vastavalt meil võib-olla ei ole nii võimalik üleenused tabelid väga konkreestalt partitsiooneerid. See läheb palju keerulisemaks partitsiooneerimise tegemine, kui on tohutud palju oma vaja seotud tabeled. Kui meil aluks üks või kaks tabelid või, mida tihti tänapäeal tehakse, kõikite tabelidega kuidagi seostada üks konkreetne idee, et me igasle tabelisse paname emploi ID või customer ID, et me saaksime kõiki tabeleid partitsiooneerida. Seda ka mõni kord tehakse. Eriti tehakse mitte relatsioonlistus andme basidas, millest ma siis tänaka räägin. Ja kui meil tekikski see võimalus, et me kõik tabelid, customer ID, invoice item, kõik tabelid seeome, siis kõikite tabelisse paname customer IDid, see meil on palju lihtsam partitsiooneerid andmeid, sest me lihtsalt partitsiooneerimigi ühe idee värtuse kaudu või kaupa, mis kõikite tabelid tuseksisteerid. Seda mõnesmõttes nimetatakse näiteks ka STARS-skeemaks, et meil on andme basi keskel üks tabel, mis on customer ID, customer tabel, ja siis kõik teised tabelid on keskeliselt tabeliga seotud, et tegib selline täh või STARS-skeema. See võimalutab meil andmeid paremini nagu jakata partitsiooneerideks. Partitsioonideks me saame öelda, et me partitsiooneerime selleks customer ID väärtused ära näiteks 10 või 16 või 32 partitsiooni vahel ja hoiama neid näiteks siis 10 või 5 serinas serverid. Aga suvalisa andme baasi võtmine ja sellel ära partitsiooneerime et ihti ei ole väga lihtne või sikil võimalik, et seda tegelikult tuleb. Selle peale tegelikult tuleb mõelda, et kui hakkat andme baasi looma, andme baasi modelid loomat. Täiesti kasutusel võtta sellise suvalise mustrii asemel selline STARS-skeema, kus meil mingisugune ID, mingisugune muutuj on allalt igastabelis. Ja selleks, et oleks võimalik lihtsamine andmeid skaleerida, lihtsamine andmeid jagada erinat sõlmeda vahel hajussüsteemides, ongi siis SQL andme baasid asemel välja tuldude erinevate mitterelatsioonist andme baasid ja ka sellised hajussandme baasid või noSQL andme baasid. NoSQL on tegelikult väga halb nimi, sest te lähete vaatada, otsite noSQL andme baasi, leiate näiteks mingisugune kasandra kasutub SQL. Otsite mingi noSQL andme baasi, mis on... Mõnge on näiteks SQL kasut, aga mõned teised täitsaad toetavad SQL. Ja miks nad toetavad SQLi? On selletõttu, et SQL on hästi laialtaselt kasutuses, kui karem tead. Teavad, mis on SQL, kui me loovam mingisuguse oma päringu keele, oma andme baasi jaoks, siis me me kõiki kasvateid õpetame, kuidas sa tahak keelt kasutada. Nii et tihti, mitterelatsioonist, nii et isegi nõu SQL andme baasid, tihti otsustavad lihtsalt kasutame SQLi kasutus. Otsustavad lihtsalt kasutame SQLi ka. Et näiteks inflaks andme baas, kestibi andme baas, mis on ajaseri andme baasid, võid SQLi kasutu. Kui neil põhi päringu keel on teine, neil on näiteks inflaksil on kas Flux-geel näiteks, aga saad ka SQLi kasutada. Nii et tihti toetatakse ikka kest SQLi. Aga ei nõu SQLi tähelelikult tähendad pigem, mitterelatsioonist andme baasid ja visatakse seda näite relatsioonit tabelite vahel, et pohjumist et ei lubata sellised otserrelatsioon ja tabelite vahel. Ja kõiki andmeid vaadatakse, kui mitte seostatud andmetena. Ja nad on üles ehitatud, hästi tohutud lihtsal andme mudelile, kus meil on lihtsalt võtti ja väärtus. Meil ongi andme baas, kus meil tabelis on lihtsalt võtti ja mingisugune väärtus. Ja see on nagu see kõige madalat asemene, ütleme võib-pall-a valesti üelda, selline füüsilne andmesalvestuse struktuur, et andmeid oitakse tohimised võit ja väärtus. Ja miks on kasuliks? Sest võtme ärgim väga lihtne võimalik andmeid partitsioon eerida. Me lihtsalt tekida mingi hash-funktiooni, mis jagab võtmed erinevatesse partitsioonidesse. Näiteks hashime võtme ja siis kui hashi väärtus jagame siis näiteks kuue paketi vahel ära ja sellet tulemusana saab väga lihtsalt selle otsustada, et kudas me andmeid hoiame partitsioneeritult. Ja kui võtja näiteks ongi customer ID näiteks, siis me tegelikult väga lihtne on customerid jagatsi erinevata partitsioonide vahel ja erinevatesse serverite vahel ka üks süsteemis. Aga võtti väärtus on natuke raske aru saada, et kuidas seda kasutada. Tavalsalt need mitte relatsioonist andmebaasid panevad lisa skeemasid või lisastruktuurigas võtmesse või väärtusesse. Nii täna vaatame ka neid, mis need olemasolad andme mudelid siis on. Aga põhimiselt me kasutame mitte relatsioonist as andmebaasides, sest lihtsamait rankes struktuuritava, rankes keemata skeemales andmebaasi mudeleid. Ja nad on tavaliselt disainitud just kaleeritavust või suurt jõudlust meeles pidades. Kogu struktuur onki eitatud selleks, et oleks võimalik skaleerida andmebaas näiteks 100 või 300 serveri peale. Toetada rakendusi Facebook või Twitter, kus on kümmeid miljonid või sadu miljonid kasutajad, kes väga suur hult võipal igapäevaselt kasutab seda. Ja hajus andmebaaside puul meil on tegelikult vaja huolitseda, et kui me paneme andmebaasi 100 serveri peale üles, siis huolitseda, et andmebaas töötab isegi siis, kui üks põik, mis selleks hajusesteemis kokku jooksab, andmed tuleb synchroniseerida. Kui andmed on näiteks replitiseeritud kujul, et igast andmest on näiteks kolm kooped andmebaasis, et vältada seda, et andmed kadul lähevad, kui server kaob, siis ka peab andmed olema synchroniseeritud. Et kui ühes kooped ja andmed muutetakse, siis peab kõikides kooped ja andmed muutetud olema. Ja selleks, et jõudlust saada, meil on vaja sisse tula, et päringult siis jagada nende serveritevahel ära, et me ei saa tekitada ühte pudelikaale, et me saadam kõik päringult ühte serverisse ja üleent serverlist hoiaodanne. Et meil on vaja ka, et päringult jagatakse nende serveritevahel ära, et kiirendada andmete lugemist ja kirjutamist. Ja nad siis proovivad saavutada seda, et andmet on lugemine või ja kirjutamine on kiireld. Teatud hajus andmesystemid optimeerioid ainult lugemist ja kirjutamist ignoreeritakse, teeldatakse, et kirjutatakse harva, aga loetakse hästi hästi tihti. Et võib-al, et kirjutatakse sadakorda vähem, kui loetakse ja siis pigem skaleeritakse lugemist. Miks see muster on kasutus, on selle tõtud, et kirjutamist on palju raskem synkroniseerida, aga lugemist on lihtne synkroniseerida. Me kirjutame näiteks ühteserverisse, eest taustal toimub andmet ja replitseerime teiste serveritevahel, aga lugemist saavutakse kõikidesse serveritevahel. Näiteks tihti näid hajus, posk, rassandme, baasi teavad niimoodi, et üks server on pealik server, kuhul sunatakse kõik kirjutamispäringud, aga teised serverid siis serveri jõuad lugemispäringud. Enne, kui me lähme nende hajus-andme-baasi tüüpite juurde, räägime sellises teoreemist, agu Captheorem või Eric Breweri teoreem, kuna demo oliks selle autoreid. Selle teoreemi mõte ei ole andme-baaside kohtalt, on pigem üldised hajussisteemide kohta, et hajusarhutil või hajus-andme- baasil on võimatu sama aegselt karanteerida 100%-i teoreemide, et hajus-andme-baasi on tehtud, et hajus-andme-baasi on tehtud, et hajussisteemil, mis koosneb mitmest serverist, oleks võimelne sama aegselt pakkuda järjepidavust, kättesaadavust ja partitioneerimistaluvust või tõrkketaluvust. Selle teoreemi mõte on siis see, et me peame valima 2003-est. Aga mis asjad on üldise järjepidavust? Järjepidavus või ingliskeves konsistensi tähendab seda, et iga lugemisoperatsioon, mis saadad, klastris olevas serverisse, saab alati kõike uuema kirje või saab peateate. See tähendab seda, et kui keegi on just enne seda saatnud kirjutamisepäringu ja nüüd meie saadame lugemisepäringu, siis andmebaas peab karanteerima, et lugemispäring saab vastuse just selled uuendatud andme, mis just eelne päring ära uuendasid. Selle ei tovi, et me ei saa kõik uuendamisepäringu, et andmed kirjutad üle, siis järgmine päring, mis andme prog luge, täpeks saama kõige viimasad väärtused. Mida võib olla rastke saavutada, kui meil on 16 serverid, kirjutamispäring läheb esimesse ja sama aegs, et läheb lugemispäring 15. selle. Kätte saadavus või ingliskevesa veel afiliitit tähendab seda, et iga päring saab korrektse vastuse. Kui me saadame hästi palju lugemispäring, et me ei tohiks saada tagasi eroräid. Me peaksime iga sisse tuleb päring. Klientid tähts saama korrektse tulemuse. Loeb andmed, mis on andme väärtus. Kirjutab andmed ja ei tohiks tekida olukorda, kus mingil hetkel süsteemele kätte saadav. Akkab, et see erorid saadma ja ei tohiks tekida olukorda, et saadatakse erorid. Ja me ei saa kõik seda, et me ei saa kõik seda. Kõige keerulisem osa on see partition tolerants ingliskeles emision partitioneerimise taluvus. Mis tähendab seda, et kui... Ma mõtlen, kui seda selgitada. Võib-olla ma natuke joonistan korraks tafli peale. Aga zoomist meie hästi ei ole. Kui saame... Ma vaatun, võib-olla ma saan... ...seda. Kui meil on näiteks... ...kolm serverit... See on veel väga kirjubild sinna. Meil on mingi kliendid, mis saadavad päringud selle selle serverisse joonistamas ja klendi ka. Ma väga ei oska sõrmagi joonistaa. Kui meil on kõik kliendi, siis meil on kõik kliendi, et meil ei ole sõrmagi joonist. Ta mul oligi midu joon. Kliendidel tulevad päringud nendesse kolme serverisse. Törkketaluvust tähendab seda, et üks kõik, kui teid kolmene grupp partitioneeritakse mitumeks gruppiks, olgu see kas niimoodi, et meil on vasakul pool kaks serverit ja paremal pool üks server alles. Partitioneerium on tähendab seda, et võrgust grup A... ...ja grup B... ...ei saa enam oma vahel suhelda. Meil algusus oli anmebasik grup, mis koos näes kolmest serverist. Ja nüüd on grup A, mis koosab kahest serverist, ja grup B, mis koosab ühest serverist. Kui me jätkame päringutesaatmist nend kõikid nendesse kolmesse serverisse, et siis server peaks jätkama tööd ilma ühegi probleemita. Et server peaks olema kasutatav, või see kluster peaks olema kasutatav, kui praegu kasutate päringutesaatmine jätkub nendesse kolme serverisse, isegi kui serverid üks, kaks ja serverid kolme ei saa oma vahel suhelda. Ja see partitioneerium tähendab, et suvalne partitioneeriumne, et me võime näiteks 100 serverid jagata 50 ja 50, või kolm serverid jagata 89, et suvalise partitioneerimise tulemusena server peaks jätkama tööd. Ja see cap teorem, ma vaatame, kas ma siit välja minna, väga ei saa. Ma ei tea, kui tuli seda nõrkustutnuda. Aga see cap teorem siis tähendab seda, et ükski hajussisteeme ei saa sama aegselt karanteerida kõike kolme omadust 100%-lisalt. Peab valimaga siis järjepidavuse ja partitioneerimise või kätte saadavuse ja velability. Ja taval seda anmebasite puhul teaksab. Mõned anmebasid proovivad pakkuda ideaalselt jõudlust, et hästi skaleeritavad anmebasi, aga nad natukene annavad alla konsistentsiosas. Või siis mõned anmebasid... Mõned anmebasid siis proovivad pakkuda hästi sellist konsistentsiosas. Ja siis tähendab seda anmebasi, nagu transaksiooni teaksab, mingi bankasysteemid, mis tahavad karanteerida, et kui keegi on kasutaja krediidinumbri ära muutnud, siis kasutajale ei tohiks olla võimalust, nagu näiteks kaks kordased rahakulutadal. Kui rahanumber kontool ära muudetakse, siis igas järgmises ketväringus täheks olema kõige viiman väärts, et kunagi tohiks tagastada mingid vanakrediidiväärtust. Ja siis ongi anmebasid, kas proovivad karanteerida järjepidavust ja partitsioneerimist või siis kättesaadavast partitsioneerimist. Mõnesmõttes partitsioneerimne siin pigemma sõnastakski tõrketaalumus. Et üks kõik, mis juhtuks, et süsteemeleks ikkagi 100% kasutadad. Ja lahendused, mis keskenduvad, rohkem kättesaadavusele, mis tahavad olla ästi efektiised ja skaleerivad anmebasid, siis nemad kasutavad midagi, mida nimetadeks viivitusega järjepidavuseaks või eventual consistency, et anmed võivad jääda mingiks aegs mitte järjepidavaks, aga natuks ajaperast ja võib-pol nad karanteerivad, mis ajaperiod võib olla. Peab see, et järjepidavaks on järjepidavaks, et anmebasid partitsioneerivadki ennast kolm nurgal ühele tasemeled. Et need anmebasid, mis fokusseerivad konsistensile ja partition toleransile, neid on mongoDB, mis on Jason anmebas, hypertable, peaktable, retis, berkliDB. Anmebasid, mis proovivad pakkuda rohkem, on järjepidavaks, mis on järjepidavaks, ja tõrkketaluvust on Dynamo ja Cassandra. Dynamo on Amazoni pilve anmebas, cauchDB ja RIAG. Anmebasid, mis ei pakku tõrkketaluvust, need on piken nagu ühe serverised lahendused. MySQL, Postgres või Oracle. Kui me näedisime Postgresil, Postgres kukub maha, et ma ei saa järjepidavaks. Põhimõtteliselt üks server, kes on pealik, ja teistesse serverlite päringute saadmise tulemus, ei saa kui tegelikult karanteerida, et päring saab korreksed vastused. Kuigi võib-olla siin on natuke vale öelda, et pigem, ma ütleks, et see on võib-olla, et päring on päring, et päring on päring. Ja siis on päring, et päring on päring. Sa võib-olla kuskamasojad tegelikult põship Pilipantonala...... Aaa mõpinud kohotuseks jääniteth М referring wise on nüüd obedience sheet. Võib-olla siin on natuke vale öelda, et pigem, ma ütleks, see on ühen server・set lahendused, kui server maha läb, siis ei ole lahend Teen's kuskoskostamised kiireoresit. Sa assembling Saint. kui teiseks põhimõtteliselt seda tehaks igi niimoodi, aga seda tehaks on aktuke taustal. Mul vist selles loengus ei ole seda diagrammi, kuidas Postgres seda tehaks, aga põhimõtteliselt pannaks üles näiteks üks pealik ja kolm replitseeritud serverid. Kõik kirjutavist päringud läheb pealikuse ja taustal taajub protsess, mis pealikoole kirjutada tammed replitseerikad eestesse. Sulle ei ole suurt vahet, kas saadadaks kolm päringud kliendilt kolme serverisse või see toimub taustal. Parem on ikkagi, et sul oleks mingisugun taustaproces, kes karanteerid, et tammed on replitseeritud. Seda tegelikult Postgres hajusat tammepaasiid klastrite pool tehaks kea. Aga lihtsalt see protsess toovimad taustal, et me ei saada kõiki, vaid me saadame ühte ja seal automaatst replitseeritaks halati nii kiiresti, kui võimalik kõikidesse. Aga see tähendab, et see võtab aega, nii et sa ei saa ikkagi karanteerida 100%-list õiged järekord ei saegi. Et kirjutavist päring jõudis enne hanmepasi kui lugemist päring. Oli te lihtsalt kõik mul nõmida järekord? Jahaka, kas ta jõub kõikidese servietes sama järekoraga? Lihti tegijaltki probleemid mitte nagu ühe serveri vaatavinklist või just sellest. Aga see võib oma tekida, et on kui üks mõjest kalatatvaast näiteks, ma tegindin kõrra ka kirjutnese lugevise. Ja kuna see ei kõna teedimad järekordita, et kui mõe esimeses on juba käib, et ikka saan lugeveta vanaväärtust visel, kui me just kirjutusem. Jah, lihtsalt see, et kui see lugemine jõuab enne kohaliku kirjutamine, siis see on veel okei. Aga kui ta jõuab kahteserverisse erinas järekorras, siis pigemte peab probleemid. Ma ei tea, kas Moskan on hea näid, et väga tuua. Kui sul on üks järekord, siis sul on raske saata kahte näiteks kirjutamispäringud või kahte lugemispäringud. Nääid panaks see järekorda jõuavad samal aal ammebaase, siis see järekord ongi selline, nagu ta oli, nagu internetis kohale toimetasvõid. Aga kui ta jõuab kahteserverisse vales erinas järekorras, siis võib tekida see mitukorda rahakulutamise probleem. Et nagu üks server arvab, et rahavõib peab kulutada, teine server vastab, et rahai tohjel on kulutada, kui rahavõib peab kultatud, aga teine server vastab, et rahavõib peab kulutada. Ja sul võib selle tõttu olla, siis võimalik back-endist kaks korda küsida, et anna mulle raha või osta midagi. Et kui sa saad ammebaasist kahelt erinalt servelt erinal tulemuse, siis see ei ole probleem pige tegi. Et kui nad tulad ainult ühteservese kohale, siis see sama server ei vasta kaks korda erinalt. Aga ma peakse selle kohta võib pole näite tooma, et paremini selgitama. Viivitus aga järjapidavusek, eventual consistency, ta tähendab seda, et ma võib-olla näitan kiin visualtioon jänne, et kui meil on kaks anmebaasi või hajussüsteemi sõlme ja ühte toimub ühte saadatakse kirutamisepäring, siis tihtise synchroniseeriment toimub natuke hiljem. Et siin ei tea palju hetk on kasta millisekondides, mikrosekondides, mis iganes ühikudes, aga ütlem, et synchroniseeriminen jõuab nagu kolm ajoühikud hiljem toimub alles mingil põhjusel. Kas või see, et kirjutaman ise võtab aega, näiteks mingisugud indexet agututakse ümber mis iganes, siis samal ajal teisel ajan ühikud saadatakse lugemisrequest, mis proovib seda sama anmeobjekti lugega teisest serverist. Ja siis server jõuab juba vastata lugemise vastusega kiiremini, kui see synchroniseerimne kohale jõuab. Ja see tähendab, et see teise serverisse saadatud lugemine saab vastuseks vanad anmed, kuna synchroniseerimne veel ei jõuha ei ole jõudnud juhtuda. Aga seda nimetataksegi eventual consistency, alati toimub see natukas ajal, hilisemalt toimub siis see synchroniseerimene ja mingisugus aja ühikolguse siis kas sekundites, millisekundites. Pärast seda on anmed lõpuks järja pidavad, aga me ei saa karanteerida, et nad on koha järja pidavad, sest see alati võtab aega, kui me tegeleme võrguga, et kõik võrgupäringud võtab aega. Et siis need süsteemid vastavad, nad ei proovi ülekontrollida kas anmed on kõige uuemad, nad proovid hästi kiiresti vastata, et just pakkuda sest hästi kõrged jõudlust ja skaleeritavust. Ja eventual consistency onki, et me lubame mingisuguse lühikis aja ja võib-olla karanteerime, mis on selle maksimum pikkus, sellega ajaakna pikkus, et näiteks, et maksimum üks minut on inconsistent. Et siis need anmedbasiid, mis proovivadki, hajus anmedbasiid, mis proovivadki pakkuda hästi hea jõudlust hästi suurts skaleeritavast, siis nendel on viivitusega järjapidavas. Ja igas elme anmed muutuvad lõpuks järjapidavaks mingi aja järel. Ja siis see võimaldeb pakkuda väga madalatelt tentsust, sest me ei pea kontrollima üle midagi, et me saame kohe vastata lugemispäringul, et me ei pea kontrollima, kas anmed on vanad, me ei pea suhtlema teiste nõudidega selles klastris, et me saame kohe kliendipäringul vastata. Ja näiteks Twitteris meid ei huvita, võib-olla Twitter on vale näite, aga Facebookis meid ei huvita, et kui Facebooki posti kirutada, muudab oma postitust, et meie kohe millisekondite järele näeksime õiged vastust. Meid väga ei huvita, meid on okei, kui mingi minuti või 20 sekundi pärast alles näeme, et keegi muutis oma postitust. Võib-olla teatud olukordad, et see on alb, aga üldjuhul kõikid as-systeemides meid ei huvita väga, et kui anmed ei muutu koheselt. Teine omadus, mida mitte relatsioonilistes ja hajussüsteemides tavaselt on, võib-olla see slide on natuke vara, on agregeritusel orjenteeritus. Seda onneb seda, et prooviteks vältida vajadust anmeid joinida või grupeerida. Üks kõige kallimad operatsioone ka relatsioonistes anmebasides on just paljude tabellite, et joinida tegemine või anmed te grupeerimine, et raport ei tarvutada. Ja selle idee on, et siis näiteks me, ma hiljem räägin näiteks anmebasid tüüpidest, aga näiteks Chase-on anmebasides, et prooviteks hoida anmed, mida päritakse koos ühes Chase-on dokumentis või vähemalt samas partitsioonis, niimoodi, et nende anmed pärimisele ei oleks vaja anmed kokkuda kokku paljudelt serveriteld, et ei tekik seda vajadust, et serveritad oma vahel anmed küsima selleks, et vastata kasutatada päringuteled. Kui vähegi võimalik prooviteks anmed teenormaaliseerida, niimoodi nad ei oleks jagatud väga erinatasse partitsioonidesse. Näiteks üks võimalus on, et kui me teeme alati raporteid kuukauppa ja klendi kauppa, siis paneme ku ja klendi anmed alati samasse partitsiooni, samasse serverisse ja järgmise ku anmed võib olla mingi teises serveris, aga põhimised partitsioonime anmed siis samadesse failidesse või partitsioonidesse või samadesse vähemalt serveridesse, siis ku ja klendi kauppa, niimoodi, et sama ku ja sama klendi anmed ei ole kunagi erinatasse serverides. Ja see siis vähendab seda võimalust, et kui me iga kuudeme klendide raporteid, et raportide tegem saal me ei pea joinima anmed mitmest serverist kokku, et see nagu kiirendab tohutult tegelikult anmed pärimist, et kui me hoiamaanmed, juba kruppeeritud viisil. Mõnikord seda tehakse nagu otsa anmemudelid tasemel, ma kaan natuke toon selle kohta näiteid, aga mõnikord tehakse seda lihtsalt partitsiooneerimise tasemel ja mõnesmõttes sarditud SQL onmebasides samuti, teakse partitsiooneerimist just niimoodi, et vältida, et anmed on liiga laiali serveride vahel. Siin on siis näite sellises JSON anmebasist, kus põhimõtsed anmed, mida loogised hoiteks erinaates tabelites, näiteks SQL anmebasis meilaks credit card stable, order line stable, customer stable, order stable, siis on võimalik, et näiteks JSON anmebasis me hoiame sama klendi anmed kõik ühes dokumentis, et me paneme klendi meta anmed, klendi ID, klendi nime, samutib me tekitame näiteks JSON listi, me paneme kõik orderid ühte JSON alamlisti ja igakord modifitseerimisele kasutaja JSON dokumenti, kui kasutad, telib midagi uut ja isegi meil on võimalik näiteks credit card info panna samassa JSONisse, kui võimalik, et see kõige paremata ei ole, või vähemalt, kui ta krupteeritada, siis see võib-lega on okei. Et idea on, et me saaksime siis relatsioonis anmebasise erinaates tabelit, et info panna mitte relatsioonis anmebasis, mis on näiteks JSON anmebas, panna nadki samassa dokumenti või samassa kirjassa kokku, et vältid, et me peame tegema üle neljad abeli joini, me hoiame igi sama kasutajanmed koos, ja seda mõnikord teaksin mobiilirakendustes, et selle aseme, et ühe kasutaja kohta hoida palju JSON dokumenti, ja JSON anmebasis saab hoida ühte JSON dokumenti. See on kui mõnesmõttes võib-lega tüütu teile by-stab, et miks ma peaksin hakkama igakord JSON dokumenti muud, kui ma seda ridasid lisan või eemalden, aga see tegelikult hästi mugab, et ma saan appi kaudu küsida klendi JSONi, mulle kõik palju, kui ta andalt käes, ja ma ei pea eraldi päringu tegemad otsida erinatest kaustadest või dokumentidest, mis saan, et ma tahan, ja neid kogu kudagi võib-olla klendi brouseris kokku joinima, vaid mul ongi üks JSON, ja ma saan JSONid kirutada anmebasi, ma saan JSONid fetchida anmebasist ja ongi kõik, mis ma vajaan, et ma saan klendi idei järgi need JSONid fetchida, ühendada ja kõik. Ja partitioneerimisest ma juba rääkisin, aga põhimõtteliselt partitioneerimine ongi siis anmete jagamine, ütleme kas failideks või serverite vahel niimoodi, et need anmed, mida meil on tihti vaja koos hoida, on salvestatakse ühes serveris või isegi ühes failis, mõnikord on meil lihtsalt kasulik karanteerid, et anmed on samas failis, et siis piisab, et ketavad üks fail luge, et ainult. Ja see ongi põhimõtteliselt sama, mis killustamine SQL anmebasida puhul. Ja osad anmebasi enginid annavad kasutatele võimalus, et isedefineerida, kuidas sa partitioneerimine toimub, et saab näiteks defineerida, et kas partitioneerida, mis tulpade kaupa partitioneerida ja kuidas arvutada partitsiooni idei väärtus, et mis on partitsiooni identifikaaturi. Ja mitrerelatsioonist anmebasides tihti tuleb, kui kohe alguses anme modelid designimise käigus välja mõelda, et mis see partitsiooni struktuur peaks olema, et mis väljade põhjal me paneme paikat selle partitsioneerimise. See on niile nummade, et kui saab? Saab, aga see lihtsalt võib olla väga kulukas pratses ja see tähendab kogu anme tabeli ümber konverteerimist, mis saab toimuda samal ajal, kui see anmebasid on tööl, aga ta aeglustab kogu anmebasid, kui sa näiteks on 10 giga paiti anmeid ja sa taad seda ümber konverteerida, sest see võib sulle terve anmebasid kooma tõmata samal ajal, kui sa teed, et võib-olla ööselt teed, et see on okei. Aga teene asja on ka, et need eriti chase on anmebaside puhul, see võib mõjutada ka sinu koodi, et kui teadud olukordade saab teadud asju joinima klendii, brouseris, siis tõenast on saad, et sa kirjuta mingi JavaScript-kodi, mis sa tead, ja kui sa enam ei pea seda partitioon, võib kusulnud partitioon muutub, teoreetist võib su JavaScript-kodi vajam olla muuta. Ma pole päris sellest kind, aga see võib isegi koodi ka mõjutada. Ma pole päris kindel, kas sa oled korvata korraks? Ma enne juus öel, et pilve arutus, et sul onki teatab hulli nagu üks. Ia, et selles mõttes küll, sa aati näed seda klendi oma koodist, et ta nagu üks serveri ja sai näegi, mis seal taga toimub, et kas nad omavad suhtlevad mitte. Teadud päringud olisid aeglasamad, kuna serverid peavad päringule vastamiseks lugema, kas paljudest partitioonidest anmeid versus, et oleb ainult ühest partitioonist, mis on fiilid asemel võida, peab isegi teiste nõudide, kas anmeid küsima, et sinu päringule vastata. Ja sinna näed ains seda, et latentsus on teine või võtab kauema aega, et vastata sinu päringul. Sellisiljul kood oleks sama? Sellisiljul kood oleks sama, aga see natuke ole näeb, et teatud enginites nagu Firebase, Google'is, Google pilve või just Android, Firebase back-end jaaks. Seal võib sulle oleisid limiteeritud, mis sellise teha saad. Et sa näiteks ei saagi grupeerida anmeid, kui anmeid ei ole juba ette ära grupeeritud. Ja sa tead teha ainult mingisugus teatud limiteeritud operatsioon, et kui sa vaatad, et mida sa tahad pärida, seda võib-olla raske seletada, aga meil oli ühest projektisse problem, et tuden kasutas, Firebase ja eeldasime, et me saame raporteid hästi teha, aga lõpuda lõpuks anmei pasi on päringud, millega need raporteid teha ja mis tuli teha, et ta pidi alla tõmbama teatud hulga anmeid ja siis Javascriptis grupeerima neid ümber. See võib-olla on natuke teistukene probleem, mida sina sõnastasid, aga põhimõtsalt teatud olukordes sai kruugigi saada päringud teha, kuna anmei pasi enginite ei toheta seda. Aga tõesti, et kui see toimub ainult sissemisel, siis selisel juhul sa koodi muutma ei pea. Kui see toimub ainult taustal, anmete lugemin erineutest partitsioonid, erineutest serverid, siis tõesti see reaalselt sinukoodi ei toveks üldse mõetle. Siin on üks näid, et kui me näiteks on loogine struktuur, et me salvestame anmeibasi, tüübi nime, riigi ja mingisõlguse kuu ja aasta kombinatsioon, mis aastele, mis kuul see kirja toimus. Ja nüüd me taaksin raporteerida, siis kui mõetli mäljataan kuupäeva ja tüübi kaudu, et me taaksin iga tüübi kohta teha raportid. Ja me teeme mingisugune SQL päringud, kruppeeri anmed siis kuupäeva ja tüübi kaupa, aga anmed salvestatakse anmeibasi tavasalt mingite failid. Nii on teha, et anmed ei hige suured olla. Meil oitaks anmed erindas failides ja kui meil ei ole partitsioneerimist, siis tavasalt anmed suure tõenudse ka kirjutatakse kuupäeva järjest, kuna tõenudselt saabusid selle samal kuupäeval või vähemalt lähedal omale kuupäeval. Või vähemalt kuupäevade järjekorras, ütleme pandi anmed anmeibasi. Tavasalt anmed on enamväem sorteeritud kuupäevade järgi erinudesse partitsioonidesse, aga need tüübid ei ole kui nagu kruppeeritud. See tähendab seda, et kui me teeme päringu näiteks 2011 veebrorikohta, siis võib-olla meil õnnestub sultsed vähe partitsioone läbilukada, saada 2011 veebror annad kätte, aga kui me teeme 2011 veebror ja tüübi neljakohta mingi päringud, siis on suur tõenudses, et me peame kõik partitsioonid, kus on 2011 ja 2002 läbilukema, need võib palju partitsioon olla ja siis me peame nagu kõikides nendest näid tüübi annad välja koguma. See tähendab seda, et meil on vähev, siin aga näha, et see kaks tõtti on siin, siin, siin ja siin ei ole, et partitsioonid meil võib-olla puntumar peab, kui andmed tulad lugehti selle partitsioonid. Ja lisaks, kui kuupäev ei ole nagu see partitsiooni määraja, siis andme vasitea, misuguses failis on kuupäev. Et lisaks selle, et me määrame kuupäev on nendeks partitsiooniks, andme vasitelt meeldas selle mätpingu, selle partitsiooni muutu ja siis nende failide vahel. Et andme vasitelt teav, et siia ei pea maatsuma, kuna see fail ei ole seotud partitsiooniga, mille nimes või võtmes olnud justus kuupäev. Aga kui me kasutame nende kuupäev jaa tüüpi partitsiooneerimisel, siis andme vas hoiab andmed niimoodi, et ta proovib hoida võisigi karanteeriteks, et hoiteks andmed niimoodi, et samas failis on põhimõtteliselt need andme, et andmed, mis on sama tüüdii väärtuse ja sama kuupäev väärtusega. Võib-mist prooviteks või hoiteks endud samad andmed, mis on sama väärtusega koos. Ja sellisel juhul on meie päring pudetab vähem fail ja selle, kes andme basi engine saab kiiremini vastata meie päringkuttele. Läheme nüüd nende pilveplatformide juurde ja me räägime natuke kaar nende mitrerelatsioonist andmebasi tüüpidest, et pilved eelised on mõnesmates üldised, aga ka andmed, baside puhul, me saame lõpmatute resurssid ilusiooni, et teil on võimalik, siisiga amas on küsida täiesti hallatud andmebasi, kus teid ei piisagi teadma palju sellest serveri, aga on te maksata näiteks päringkut arvuest ja enam ei maksa serveriteest. Tihti teadud teelused me saame ilma ettemaksutada, kasutada, et väikse projekti, kuhul me võib-melle ei peaagi andmebaisest midagi maksma, kui nimeil kasutat ei ole. Olen, et andmebasi mudelist võib olla arvetus sellised mudelid erinevad, et mõnedes andmebased ja puhul me maksame serveriteest, teistest me maksame päringkut eest, et me saame teoreetised valida endale sopiva sellise hinna mudeli. Pilve teenused võimalde, et pakkuda rohkem skaleeritavad teenused, et amasõnist või asulest saab otsida andmebasi teenuse, mis skaleerib ised, meie peab selle pärast muretsemat, kuidas Postgres klastrisse serverid juhuda panne võimaldada. Ja mida minam õtlen, siis hajus andmebasi pilve teenust all on sellised hallatud salvestust teenuste pakkumised. Selle peal võib mõelda, kui salvestus kui teenus või storage as a service. Ja kui kiis sellist ametliku klasifikatsiooni väga eksisteeri, et see on ka natuke halb nimist taas. Ja nende eelis on see, et pilve teenuse pakkuja saab huolid seda kogu installeerimise, konfiguratsioonimise, ülesseadmise ja partitsioneerimise varukoopet eest. Et kui te võtate täiesti hallatud pilve teenuse, siis te ise ei pea halldama näiteks, et kui tihti teaks varukooped. Aga see natuke oleme ja me vaatame erinevaid tüüp, ja mida ainult neid, mis see tabakuad. Peamised tüübid, mis on, on sellised võtti- ja väärtusanmebaasid. Mõnikord nimetadeksene eka paket või ploobanmebaasid. Peamine põhjus selleks, et hoiteks anmet pigem sellist pinaarsete anmetena. Ei vaatata väga sisse, mis on anmetesiehemine struktuur. Nagu kui te SQL anmebaside puhulte näete, mis tulbaad sees, mis väärtsalt sees on, sellise ploobanmebaside puhul väga sisse ei vaatata. Hallatud SQL anmebaside me saame täpselt samad. Postgresi või MySQL või Oracle SQL anmebaside ka seda hallatakse pilve teenuse pakkujapolt. Või siis hallatud mitte relatsioonist anmebasid. Hallatud relatsioonist anmebaside jaoks on peamasest kaks tüippi. Üks on see lihtne, SQL serverid, et me ei saa klastrit nõudmisel, et lihtsalt Amazon paned meieoks ühe nõudilise Postgres anmebasi üles. Või siis paned üles klastri näiteks, et meil saavad olega täielikult hallatavad kilustatud SQL klastrid, et Amazon panedki meile üles näiteks Oracle SQL klastrid. Ja need erine teenused, mis eksisteerjad Amazon RDS, on selline, kus te isesate valida, et mis on see serveris olev anmebasi engine, et saab olla Postgres SQL või MySQL SQL server. Põhimselt see on lihtsalt teenus, mille abilte saada hästi kiiresti klastri üles seada. Ja siis on see, et ma ei saa klastrit, ja see on siis jaas Postgres SQL server ja Amazon saab teile üles, et ilma, et täksite ise haldama näid virtuaalmasinaid. Mitterelatsioonist anmebasid, neid on peamiselt sellist kolm tüpid. Kas võtiväärtus anmebasid, mis on hästi lihtsalt, võite ette kuhutada, et ma panen mingi anmebasi võtmeja väärtuse ja rohkem väga struktuuris ei olegi. Kui me peadetakse rohkem struktuuriga, võtme selle väärtuse sisse. Sellist anmebasid on AVS DynamoDB või Google Cloud Datastore. Teist tüüpi, mida me tänna vaatame, on dokumentipõiset anmebasid, kus panaks see mingi XML-file või JSON-file anmebasi, kus võtja JSON-faili nimi või JSON-faili ID. Meil väärtusas ära, et meil väärtas ongi üks JSON dokument. Näiteks AVS DocumentDB, IBM Cloud Ant, mis on KAUSTDB põhine, või see näiteks Google Cloud Firestore on selline JSON anmebasi. Lisaks on sellised suurda abeli anmebasid või veerkude perekondade või kolumnoorjantat anmebasid tüübid, kus üks peamiselt on veerkude perekondade tüüb, kus SQL-anmebasi on tavaliselt, relational anmebasi on tavaliselt ridade kaupas olestatakse, aga veerkude perekondate tasemel põhimatselt kombineeriteksse kõik teie tabelid SQL-anmebasis nagu üheks, tuureks tabeliks, mida nimedates kolumfämilii tabeliks. Ja selleks on peamiselt kas Sandra on üks kõige tuntumaid anmebasi, vabaavatud anmebasityppe, mis kasutab seda veerkude perekondade mudelid, aga ka Google Pequery. Amazonis on selline Amazon Managed kas Sandra teenus, mis seab teile üles alles ja kas Sandra Clustry. Ja nüüd vaatame need kolme tüüpi, et mis on siis need kolm peamist mitreraatsiooniste anmebaside tüüpi. Kõige lihtsam ongi võtiväärtus mudel, kus me lihtsalt paneme anmebasi anmeid, meil on võimalus saata kettspäring, et anna mulle mingit anmeid mingi konkreetse võtmega. Meil on põhimatselt selline postpäring, et pane anmebasi uus väärtus selle võtmega ja siis kusutamise päring, et kustuta anmebasis selle võtmega anmed ära. Ja teatud anmebasisid, see on rohkem võimalusi, aga põhimatselt võtiväärtus anmebaside mõte on olla tohutult skaleeri vanmebaas, aga hästi lihtsam anme mudelik, et panna ainult võtmega väärtusi ja lugeda võtmega väärtusi ja kõik põhimatselt. Ja väärtusesse väga sisse ei vaadata, vaadatakse, kui lihtsalt mingisugune väärtus, aga sa ei saa väärtuse sisu põheal väga pärida, et ainult võtmeta põheal seda anmeid pärida. Et näite, et on näiteks TainamoDB Amazonis, Riaq, Apache Ignite, ArangoDB, BerkeleyDB ja Couchspace, kui Couchspace on pigem selne Seishan anmebaas. Ja nad on hästi horisontsaasa skaleeritavad, sest me saame võtmed või kogu selle võtmet the namespacei agada tohutult paljute serverite vahel ära ja meil ei ole, kuna meil ei ole väga keerulisi päringu keeli, on ainult võtmet järgi võtmene, siis tegelikult saab hästi kiirendada anmetes lugemist ja anmebaasi kirutamist. Et anmebaasi lugemist ja kirutamist on tägelikult hästi skaleerida ja meil ei olegi nagu selle join päringu tohi mõtsult nii, et meil ei tekigi probleeme selle, kui anmed on erinudne serverite vahel jagatud. Ja see on üks kõige skeema vabamaid mudeleid üldse, et meid anme tüibid võib-olla väga ei huvitagi, tüib võib-olla üks kõik mida ja klienti ise hiljem selle anme väärtus, aga teeb, mis ta igasest tahab. Ja tüibilselt pakutakse sellest rest, liidastad, ketput, post ja elite päringud, et need anmeid muutasis anmebaasis. Ja anmete päringne võtme järgi ja kirutamine võib-olla väga-väga kiire olemb selles, ku palju serverid on, ku palju kettaid nende serverides on ja kui paljusaparaliseeritud on. Ja sellena hästi lihtsustatud visuoloatsioon ongisi meil on lihtsalt võtmed ja väärtasad anmebaasis. Aga teil tegelikult tegib kohan küsimus, kuidas ta siis ise disainiks ühtegi rakendust, mis selliks lihtsalt anmebaasi kasutaks. Et üks viis seda teha ongi peita loogika võtmes ära. Me võime ette kujutada, et meil on kasutajate tabel, kuidas ma kasutate infosalvestaks võtme väärtusena. Ma võiksin seda teha niimoodi, et ma võimast, et tekin tahan struktuurid oma rakenduse jaaks, kuidas ma väärtused anmebaasis valvestan, ma panen visa struktuurivõtmetesse. Et mul ongi näiges, emploii anmed, emploii tabelis esimene kirje ja selle esimese kirje, kõsteem tult, võldub mati. Ja see on kogu minu võtmi. Kui nüüd mina tahan pärita, anna mulle esimese töötaja nimi, siis ma otsingi emploii, siia panen töötaja ID, kool on nii siia panen, et ma tahan first name nagu tult pakette saada. Niimoodi saab tegelikult rätliteerida sellist relatsioonilist anme struktuurid võtgi väärtus anmebaasis. Ma tekitan ki omale struktuurid, et võtme esimene komponent, on siis nii-haldi, et näiteks näiteks olemi ID ja võtme kolmas komponent, on olemi tult või olemi mingisuguna muutuja. Ja kui ma tahan tegitada näiteks mingisugus mappinguid, saaks ka tegitada, et ma olen, ma teen seda pigem hiirega vist, et meil on payment kahe kasutavahel, kus meil on võtmeks panem, et meil on payment esimese kasutapayment, esimese kasutapayment ja siis selle makse suurus oli 10 000 ja samuti, et esimese kasutaja, esimese makse kuupäev on selline. See võib-olla on natuke halb, sest meil ikanaku väärtiseks küsimiseks võib-olla on vaja eraldi teha ketparing, aga võib-olla anmebaas tuetab mingisuguselt wildcard, et me saame küsida näiteks, Anna mulle, emploi, kool on üks, kool on staar, Anna mulle kõik võitmed, mis algavad prefiksiga, emploi, kool on üks, ja siis ma saaksin kõik sellega kasutaga anmed küsida korraga. Et see täiesti olevab, kas anmebaasi engin siis toetab sellised wildcard ja näiteks võitmed pärimisel. Ja see on üks selline lihtne näide, et kuidas saaks disaimida SQLi anmebaasi puhtalt võtiväärtus stiilis. Näiteks ka teene näide, siin üleval on Amazon S3, hoitakse file. Me võime üks oma eest pildi file hoida Amazon S3, aga kuidas me teeme nende pildi file-te vahel vahe, et me lihtsalt aname näile tee selle pildi file-ini. Ja Amazon S3'es pildi asukoht ongi unikaalne asukoht internetis, et meil on näiteks siis mingisugun HOTATEPES. S3, et ta on U.A.A. West 2 regionis või ava öelja piliidisoonis, Amazoni SE-s, ta asub mypaketis, mis on unikaalne, unikaalne nagu S3 container või kaust, see peab olema unikaalne kogu Amazoni selles regionid vähemad. Mypaketis saeks siis teerida kahel kasutel samas regionis, et see punan osan siin täiesti unikaalne väärtus. Aga siis sellest kaustavõi paketis Ees on tääristid suvalne file struktuur, et ma võin tekitele see kaustu ja ma võin siinna panna siis file.jpeg. See tähendab, et see on selle file identifikaator siis sellises võtti väärtus fileid annebasis ja selled täielik ID koosneb mittele talam komponidist. Esiteks, mis ava öelja piliidisoonist on, teiseks, mis unikaalne paketis on ja kolmandaks, mis on selle paketi T-failini, mis on selle file T selles paketis praegimaltselt. Ja kuna see on unikaalne identifikaator interetis, siis seda saab rakendustis kasutada selle file aadressina, kus selle file aadressi sees on tegelikult ka selle annebasi aadress, ehk s3.amazon.avs.com. Nii et kui ki, see võtti väärtus annebasi on hästi lihtsad, on palju keerulisemaid anne struktuur ja võimalik nendes nagu dublikkeerida. Ja s3 on mis siis üks nendes näideltest, mida ma juba korraks kirjeldasin, et jälgib täiest seda võtiväärtus anne struktuurikus võtmõde lihtsad fileid asukohad ja väärtus on selle filei sisu, ehk mis anne seles filei sees on, ehk file ise võimatsed. Võimatsed. Ja see võimalde, et see hästi palju anneid salvestada s3-le, ehk võimatsed teil piirangut ei ole, teil on lubatud küll sada paketid luua, sada on ikka asut paketid, aga vajatus seal saate õiguseid rohkem juurde küsida. Ja otsast anne te struktuurive skeemad see ei ole, et ta võite üks kõik mis file sinna üleslaadida, alguta textfile, videofile, pildifile ja nii edasi. Ja meie ise kasutama asures, siis võib-olla asure file storage akounti või asula blob storaged, Google Cloudis anda Google Cloud Storage, IBMis on Google Cloud Object Storage täpselt samasugunud kui S3. Kui te soovite vabavaralist, siis kasutage minnajood, et minnajoon tegelikult võimatsed Amazon S3 clone, et saate Amazon S3 teke ära kasutada selleks, et minnajoos saan meid kirutada või lugeda. Kui soovite anmed ära liigutada Amazon S3-st oma serverist, siis saad mini-io ülesseada selleks. Selles ma enam rääkisin, aga ma rääkin selles järgmises laidi peal. Amazon S3 on tegelikult ka tähtis, kuidas standmaid salvestate ja mis suurbust konfiguratsioonide kasutate, sest selle põhel takkata maksuma. Amazonis te maksate miinimum 30 päeva eest, nii et kui panate ühe fail üles, kolmeks tunniks, te maksate 30 päeva eest. See ei ole nii, et te maksate vähemseled. Kuna ta võtab ruumi, siis ongi selline miinimum tasu, on 30 päeva salvestuse tasu failid. Aga Amazonis on erinevad nagu salvestuse klasid, on S3 standard, intelligent hearing, standard infrequent ja siis S3 classier. Kui standard on standardne anmete salvestus, kus te taab reaal ajas näid anmeid kasutada, näeteeks te teete mingisuguse kaleriirakenduse ja kaleris panete otsa S3 linkid ja siis kui kasutad, läheb teie kaleri aades automaasut tõmateks ja pildid S3-st alla, et te reaal ajas soovite neid faili kasutada. Et siis saate S3 standardid kasutada. Standard infrequent tähedab seda, et te ei soovi neid reaal ajas kasutada, teeldad, et näid anmeid kasutad kord päevas, kord nädalas, näeteeks hoiate seal mingit anme, data sette, et teete anme tõetlust, teeldad piltitõetlust ja igasekk on neid kasutad. Et siis infrequent accessi ka tõttu saate vähem maksta nendest, kui reaal ajas kogu aeg ei ole neid anmeid vaja. Et pigem kasutad seda standard infrequentid siis, kui mingit teised pilved eenused kord päevas anmeid tõetlev on. Ja kolmas tüüp on S3 classier, mis on põhimest arhiiv. Et siin ei teanud, et saalvestada anmeid päevadeks, kuudeks, aastateks, et te ei saagi neid reaal ajas kasutada, et anmeid otsasalt ei ole kasutatavad suvalsel ajal. Ja võib võtta minuteid kui tunde, et enne ole anmeid teile ligi pääseda. Ja on eraldiga ver classier deep archive, et siia salvestatud failid minimum või nagu võib juhtuda, et ei saa kui 12 tundi anmeid teile ligi, kuude ütlet, et tahate need anmeid kätte saada. Ja siis te maksate minimus 180 päevas, et pool aasta eest. Aga miks need nii palju on? On selled ütlet, et Amazon tahab optimeerida, et kuidas need anmeid kasutatakse ja siin et salvestatakse erineval viisil. Ja teiega maksate väga erineval viisil, et kui te kasutate täiesti standaardsed anmetes salvestamist asure või Amazon S3-s, siis te maksate ühe terabyte anmetes salvestuseest 23,6 dollarit. Te maksate lisaks infopäringuteest, et kui te küsite miljon korda, mis failid on seal, mis on nende failide suurused, siis te maksate iga infopäringu eest, aga anmetallatõmbamine ei lähde teile mitte midagi maksma. Et te saate tasuta nagu anmetallatõmata. See on üks väga suur aga, eik tegelikult läheb anmeted alatõmbamine lisaks veel nad ka maksma, aga S3-ootsaselt ei küsid asut sealest, et te maksate põmst võrgu kasutamiseest. Teised poliitikat kõik on natuke odavamad salvestuse osad, näiteks S3-klassiärki parkhaivas teileb maksma üks dollar, kuus ühe terabyte salvestamiseest. Palju odami, 23 korda odami. Aga, see on suur aga, alatõmbamine maksak 20 dolar, teravadikolt. Ja te saate nagu kaua aega salvestada sinna ja lõpuks alatõmbamata, aga siis maksate nagu 20 dollar lõpuks. Ja ei tea, nad siis S3-klassiärki parkhaivi puhul Amazon saab kasutada salvestuseadmed, mis see peale olema ots võrgu ühendatud, saab kasutada neid lintkettaid, mille sa anmetest alastan odavam, aga need ei pea olema reaalast kasutatavad ja võtavad kui nii 12 tundi, et anmetel liigi pääsad või lõpuks. Ta võib-miseks kobeerivad anmet teistel seatmattel, et teile kättasad alg teha. Ja S3 infrequent accessi puhul, ma vaatan, kus sa asus. Mis siin? Ja siin te maksate kaks korda vähem, anmete salvestamises 6, aga siis alatõmbamiseest maksate 10 dollar, kui standardis oli alatõmbamiseet asuta, infrequent access on salvestavad odaam, aga alatõmbamiseest maksate. Põhimõtteliselt idean, et te saate anmeid salvestada pidemalt, aga alatõmbamiseid maksa, ja tegelikult standard on kõige odaam olukord, kus te kogu aeg on uuesti alatõmbate. Ükskald päevas tõmbate terapeid anmeid alas teha, ükskald päevas 10 dollarit terapeidikohta maksat, kui siit alatõmbate anmetsis. Põhimõtteliselt standardi puhude peaa anmete kasutamises maksama midagi. Mis siin pooleb kus toivad? See on siis, kui sa saadad info pärin, kui S3 listid kõik failid kaustas, küsid, mis on failid suurus, metaanmeid või metaanmeid küsid näiteks, mis tüübi failid on, et sul näiteks mingisuguna rakendus käib ja listib kasutale, mis pildid on kaleri kaustas näiteks. Et iga kord. Liselt seda, et rakenduse teist pämiks seda liiga palju, siis amas on kõib rahasel eest. Et see põhimõtteliselt treening kasutavad, et vali endale õige mudele, siis kasutat optimaalselt. Ja et teie teist kümmele. Ja, et pigem cashi, et siis sa ei maksa sellest. Mõnesmõtteliselt samas on liisa tulu, kui sa teed seda, nii et nendel midagi väga paha ei ole, et saad rahalist sellest. Aga, ja siis kindlasti on see, et kui kogu aga allatõmata, siis pigem kasutada ja SKM standardid ja maksda fixeeritud hinda kuus. Ja siis allatõmuses, ma peab maksma sest muiduvõib. Ja siis üks on, lisaks on, intelligent standard on see, et nii ise valid mudelid automaatselt vastavalt kasutas mustrile. Et siis sa ei päris ära otsustama, et kui teid ei pärit, siis jäljal muudetakse infrequentiks ja kui neid ei nagu suuesti tilti pärima, siis ta muuda võib automaatselt nataka siin standardi. Proovid karanteerid, et saate mõistliku hinnaku, kui ise ei soovina, ette otsustata, mis politikete kastutada soovite. Aga selle kohta peab kindlasti iseja rohkem lugema, et kui ta täpselt toetab ja muidu ei tea, kas ta kõige odomaks osutab. Miks see plasiira on, kui see plasiira nii parpaili, kui kui sa oled põttas? See on see vahe, et plasiiripuhul sa maksad poole aastaest minimum. Ja kui plasiiripuhul sa saad, plasiiripuhul nii parpailikult, sa maksad kui nii poole aastaest ja plasiiripuhul sa maksad kui nii kolme kuuest. Ja plasiiri almed hoiteks enam vähem sellist, et serverides, mis sa minutite või tundidega saadavad, aga Deep Ark Havis võtab vähemalt 12 tundi aega enne, mis oligi pääst. Võib sa ma kui nii kohastast? Jah, kui nii 12 tundi võib pole, ehk mitte minimalt. Ma arvan, et see on piigem kui nii 12 tundi. Ja Deep Ark Havis sa oodad näiks anmed, mida võib olla mingisugun riigiasutus nõuab, et sa alles oodad 10 aastad mingisugused kirjeid, aga sa ei kõnagi kõna kõik kasutada lihtsalt, kui hiljem riigiasutust ütlepead. Saada meile need anmed, sest sa küsid Amazonist, aga saad väga nagu odaavad. Võib pole need anmed, mida sa kõna kui planeerigi alla tõmatad. Igaks juhuks, aga mitte kõna kõna kõna kõna kasutada, sest sa näist odaavad. 1 dollar. Mul on väga võib, et kui tiis pigisaab, kui see siirti Deep Ark Havis, kui sa 23. tundi, siis sa odaavad kaks kord. Siin on siis 4 kord odaavad. No, et sa oled nii, mis on viinil vaja, et 9. päevad, siis see on 28. päevad. Siis on sulle odaavad seda võida ja sulle on ka kättesaljumt arvas odaavad. Jah, et kui sa plant stand, kui kuu aega oida, siis see ei ole mõted. No, kolm kuud oida, siis ei ole mõted Deep Ark Havis kasutada, aga hea oida, seal neid anmed, mida sa pead, nagu alles oidmaga ei tule kus kasutada. Kui pole mõid, kolm kuugul tiimurvasi või kõrvõi kõrvõi kõnala, kui isa standa. Jah, aga kui seal on koostus, et aasteid oida, siis... Jah, siis pead. Teine mudel, mis sisemisel samuti kasutab võtme väärtusmudelid ja mida te tõenastavate kõige rohkem kuulud mitralatsioonist anmebaasidepuul, on siis dokumenti anmebaasid. Ehk ei tea, nad me kasutame uuesti võti väärtusmudelid, aga väärtus on mingi struktuurist dokument, et me paneme anmebaasid asemel paik, et väärtus on alati XML dokument, aga tavast on ta pigem JSON dokument, ehk JSON anmebaasid siis. Rangemad skeemate struktuur ei ole, ta on JSON, aga me ei uvita väga nagu anmebaasi tasemel, et anmebaasi kontrolli, kas selle JSON sees on mingi teatud väärtused. Võib-al-a, ta nõuab, et seal oleks datetime ja ID JSON dokumenti sees, aga ülejäänud tulpad või väärtused või võtmed JSONi sees on nagu klendi või rakenduse määrata. Anmed päritakse, siis kas võtmekaupat, anna mulle teatud JSON dokument kindla IDga ja mõned anmebaasid tuhetavad ka päringu keeli, mis vaatavad JSONi dokumenti sisse. Näiteks MapRedus saarvasid päringud. Näitid on CouchDB, MongoDB, CouchSpace, Mongo, üks kõige populaarsemaid, kui osad vihkaad, mongod osatele meeldib Mongo. Aga üks kõige kasutatamaid on Mongo. Teavad te kõik JSON dokumenti näinud, aga siin on lihtsalt üks ilustreerimise näide, et milline see JSON dokument võib saamebasis olla. Põhimise, et me ei võib olla mitmed tasemelised JSON dokumentid, meil võivad lisaks sellele näitel olla ka mapid ja listid see, et meil ei pea olemada ühe tasemeline või kahe tasemeline. See on kahe tasemeline, JSON dokument võib ole ka viie tasemeline, kus on järjest rohkem alam JSON-aid sees. Aga kui ta vaatata selle peale, siis kui ta on ühe või kahe tasemelise, ta on tegelikult väga sarna põhimadsed SQL tabelile, et meil on tulbaad, business ID kategoris, city, open, leditud, longitud. Me saameb võimselt sarna tabelistruktuuriga JSON-is hoida, lihtsalt meil on võimalus kasutada alam JSON struktuuria liste ja mäpe ja muid selliseid. Meil on peamaselt vahekas on string väärtus, juttumärkiidega eraldatud või numeerilised väärtusad, aga opselt meil ei ole väga range tüüppe. Võib juhtuda, et ühes dokumentis on mingi väärtus string, teises dokumentis on sama väärtus integer ja anmebasikontrolli, et need oleks alati stringid välati integerid. Ja seal tulevad lihti vead sisse. Ja kolmas tüüp on veerkude perekondade mudelid, kus põhimõdselt me proovime saavutada sarna olukorda, nagu ma loen ka alguses näitasin, et igas tabelis on täpselt sama kasutada ID või mingiselt, kus võtme väärtus. Seda nimetadeks ka veerkude perekondade nimeks, aga seda võib mõelda kui tabelite gruppe. Veerkude perekond on enamam sama kui SQL tabelite gruppid. Anmed on salvestatud suurte tabelite struktuuridest täpselt nagu SQL-is ja veerud me gruppeerime nagu veerkude perekondadeks või mõnes mõttes tabeliteks, et meil on nagu tabelid ükstise kõrval võib selle peale mõelda. Veerkude perekond on loogilne veerkude grupp, mõnes mõttes sama aegimist tabel SQL-annebaasides. Meil tekivad sellised mitmed asemellised võitmed, aga ma sõle koht räägi natuk hiljem. Väga suur erinevus SQL-annebaasidesest on see, et meil on võimalik suvalisel ajal veergi juurde panna. Ei ole üldse eriline, et veerkude perekondade annebaasis on sadatuhad veergu. Mis on natuke imelik, SPL-annebaasisidile mõeldes, aga see on teatud kindel muster, miks seda nimadi teevad. Näite, et kõige tuntum on kas Sandra, aga big-tape-ol on hästi tuntud Google'i pilves. H-space-jakumul on ka vabavarralised annebaasisid. Kõige tuntum on kas Sandra. Kuigi kas Sandra ennast väga meerkude perekondade annebaasisks enami nimeta, ta proovib näita ennast on. Kui kasutatele lihtsalt SQL-annebaasina. Kuidas see töötab on umbes selline, et meil on põhimõtteliselt üleval on loogilne veerkude perekona mudel, kus meil on mingisugune olemon võitmaks, näiteks kas see võib oleks kasutaiide või asutuseide. Siin näiteks on kasutaiide ja kõik selle kasutajaga seotud annemed on ühes reas. Meil tekeb see hästi lai tabel, kus me paneme kõik sama olemiga seotud annemed ühele reale ja meil tekik ainult üks tabel. Aga see tabel on hästi lai ja meil tekivad kolm familid või veerkude perekonad, kus meil on tohutult saaran SQL-ile, et meil on kolm tabelid, nimete, kontaktite ja messages tabel. Põhimõtteliselt see ongi täpselt sama asi, et me paneme mis taabelid kõrvuti, me karanteerime, et igas tabelis on ID, mis on täpselt sama, näiteks kasutaiide ja kõik annemed igas alam tabelis on seotud selle sama kasutajaga. Meil tekibki selline karanteeritud ühe olemiga tabelid komponent, me lihtsalt nimetame iga tabeli kolm familiks, aga meil võib olla kahte tüüpi kolm familid või perekondi. Ühed on staatilised, mis on sellised tavaliselt staatsed annemed, et meil on kasutate anned, kus me hoiame kasutanime, eesnime ja perekonnime või kontaktid, kus me hoiame näiteks e-maili ja telefoninumbrid, aga meil lisaks on speciaalne tabel, mida nimetateks, dynamiliseks tabeliks, et näiteks messages. Ja selle idee on, et me saame siis ühe kasutapoolt kirjutatud sõnumid, panna kõik ühte tabelisse niimoodi, et nad asuvad ühen reaal. Meil tekibki selline võimalus, et neidest kasutajatellimused või kasutajapostitused või kasutaja mingisugused püsivald, pidevald tehtud tegevusad panna samas rita, ja kudas me seda teeme, et me tekitame näiteks messages tabeli ja see tulp messages tabeli sees on üks kirja, ehk üks, siin on täisest üks message, et messel tulp isa nagu message ID, ehk ei item one, item two ja nii edasi, ja selle tulpa väärtus on põhimestad sõnumise. Ja see idee on, et me saame siis kasutasab siia kirjutada, et 10 000 sõnumid, tegib 10 000 tulpa. See on SQL vaatas hästi imelik, miks me paneme tulpadesse, aga tegelikult füüsiliselt ei hoita neid tulpad, et füüsiliselt hoitaksa neid võtme ja väärtustana, nii ku nii, need ei ole vahet, et me nad niimoodi defineerime. Reaalselt hoitaksa anmed kõik nagu siin alumises tabelis on, et meil tekib selline anme struktuur, kus paremal pool valge tulpa on väärtus, ehk Chase Smith on võtijäväärtus anmebasisest põhimestad lihtsalt väärtus, ja kolm elmist tulpa on nagu kolmed asemine võti, et meil siis tekibki anmebasis võti a001 names, username ja väärtus on Chase Smith, või siis a001 messages, item 7 ja message 7 on väärtus. Meil tekib selline mitmed asemelline võti ja siis väärtus anmebasis. Põhimest, et anme struktuur, mida hoitaksa näites ketal failides, on pigem selline võtiväärtus anme mudel, aga loogiliselt on ta kasutatav kui tabel. Miks me seda loogiliselt tabelne kasutame, sest me tahame SQL kasutada, et me saame teha näiteks select from names, select names dot first name dot, ja select names dot first name, where id võrdub a001. Me saame SQL kasutada anmete päringute tegemisel, isegi anmete sisestamisel, et insertiga lisada anme-tannebaasi, aga füüsiliselt hoitaksa neid sellisel kujul, ja füüsiliselt tihti hoitaksa staatilised kolumnid, staatilised perekonnad ja tünnaamistist perekonnad täiesti eraldi partitsioonides. Ja tühe partitsioonid on neid, mis alati jäävad samaks ei muutu, eks staatilised, ja tünnaamistest partitsioonid hoitaksa sellistest failides, kus me kogu aeg paneme asju juurde. Iga kord, kui kasutajad uue sõnumi kirutab, me tekitame sinna uue sellise kirjet, poemist a001 messages, item n plus 1 võrdud message n plus 1, mis saad lisame appendime sinna file sõnumid juurde. Ja selled, et meil ei ole probleem, kui üheski tuulbaas on näiteks 10 000 värtustest. Tegelikult neid ei hoita tabelit enam ja ei teki sellist tühja, selled, nagu ei teki, et meil tühjad sellid või sellised tühjad blokit tabelis ei ole ütse probleemit, kuna neid füüsiliselt kusagile ei hoita. Et nad failis ongeliselt tühjad, et näid, et see ei eksisteri. Ja kas Sandra ongi üks näid, mis lubab kasutada SQL päringud, et sellises anmebase anmeid siestada ja pärida, reaalselt füüsiliselt hoitaksa need erinevalt, et ei hoita nagu savast SQL anmebaseid, et iga rida koos, vaid partitioneertaks siis nende perekondade kauppa erinevadest. Eri naates ja failidesse, aga see põmist anmebasei engin ise otsustakud, kuidas ta päriselt tahab anmeid salvestada ja partitioneerida. Ja nüüd me oleme jäägi lopetamas, et kõik see, millest ma rääksin, see ei tahe tähend, et teie ei peaks relatsioonist anmebasei kasutama, et kui teil on väike projekte, teil ei ole vaja sadud enam paite anmeid, siis teil ei ole vaja hiigel suuri skaleerioid anmebasei kasutada. Kui teile ei ole vajad, siis pigem kasutada tavalisi relatsioonist anmebasei, kuna ta on vanad proovitud ja testitud tehnoloogijad, et tõetad hästi. Ei teki seda probleem, et te võtate Firebase kasutusele ja siis kolm kuud hiljem saate aru, et teil ei ole ikkui võimalik agregeeritud statistise raporteid teha, sest anmebasei engin seda ei võimalda ja siis te peate kõik seda klienti arvutis JavaScriptis tegema hakkama. Et allad on paha mingid kogu kuu anmed jasonina ja siis hakkama JavaScriptis agregeerima. Nad on hästi optimeeritud jõudluse jaoks, kui neid mahuad üste serverisse, neid testkuhelis saab tegelikult oodata päris head jõudlust ja Postgres anmebasei saab ka näitele klastrin öeles jahdada. Ma arvan, ma jahes tuleviku looin, kus toon näite selle Postgres klastri kohta, kuna selle kohta tekis mitte küsimust. Range anmebaseide struktuur tähendab ka vähem vigasid. Ei ole võimalik nii palju vigasid anmebasei üldse teha, sest anmebase vastab teile insert päringule, et sellist anmebasei saa siesestada, kuna tüüt on vale. Ja vigasid anmebasei ei tekik, et tegijad viga vead rakendustes. Võimalik paremini vältid anmeda puudumist, sest saad öelda, et teatult ei ole lubatud nullina hoida, et ei või tühed olla ja saada karanteerid, et kui anmed on anmebasi pandud, siis nad ei ole katki. Vähemalt anmebasi valjade tüüpide ja anmeda puudumise vaatavinglist. Ja SQL anmebasidele võib olla ka väga hea jõudlus, kui anmed ma hood nälu, nii et te saate tegelikult võite saada palju parema jõudlus SQL anmebasei krasutamise puul, kui anmeda väikselt. Et teatud mitte relatsioonist anmebasid alati ojavad anmed kettal ja te ei prugigi saada väga hea jõudlus, kuni need anmed ei kasva västi suureks. Ja mitte relatsioonis anmebase pikem kasutada siis, kui anmede maht kasvab liiga suureks, kuna neid on lihtsam ja odaam skaleerida, kui anmedestruktuur ei ole et ära fikseeritud ja teil on plaan, et kogu aeg muuta, siis võib olla ka parem oida erinal mitte struktuur erimalt anmed anmebasis. Näiteks soovitegi roo anmeid oida, seison dokumentida ja näitek jahaneid konverteerida SQL tabelliteks ümber. Prototypine võib olla lihtsam ja kui ta niku nii appis kasutad, et seison dokumenta näiteks mingis mobili rakendustes, siis tiisti arendatele meeldib, kui võtad seison anmebase kasutusad, et ta lihtsalt panetegi seison anmebasi, fetchite seisoni anmebasist ja te hoiategi kõik vaelikud anmed ühes seison dokumentis. Et siis mõni kordongi lihtsam, et ei peagi SQL anmebasi ümber konverteerima päringud ja lihtsalt natuke tuleb mõelda selle peale, et kui palju te tahate tulevikus anmeid agregeerima hakata ja kui teie agregeerimise vajadus, et kujutad ette, ettele on palju agregeerimist vaja teha, siis vaadake dokumentatsioonia oolitsege sellest, et see anmebasi engine, seison anmebasi, mida ta valisite, eriti Firestore kuhul, et ta tooetab neid päringud, mida ta arvat, et tulevikus vaja olla. Et muidude lukkustat ennast seison anmebasi peale ja hiljem tekivad probleemid. Ja mitte relatsioonist anmebasi lihtsalt on ka rohkem avatud lähtekodiga, kui palju relatsioonist anmebasi on ka avatud lähtekodiga. Et pilves saabki lihtsameni valida endale sellise serveri, kui te vaja on ja siis vajaduse selle serveri suurust muuta. Iga nädal võite neid serveri suurust muuta, kuidel vaja läheks, et ei pea siis fikseerima oma füüsilist serverit. Nii esküell anmebasi, et kui mitte relatsioonist anmebasi tihti pakutakse teenusena pilves, et te saate vaba valida endale vajaliku, nagu teenuse ise ei pea virtuaalmasineid haltama ja kõik vajalik ülesseadma. Te saate ka tihti loota, et need hallatud anmebasi on hästi optimeeritud, et te ei pea itse ette teada, mis peaks Postgres konfiguratsiooni file'is ära olema muudatud. Et Postgres töötakse efektiivselt, kuna hallatud anmebasis seda tehaks ette eest ette ära, aga mõnikord, kui teel on vaja need asju ise optimeerida, siis jälle on probleem, et Amazoni teenuses teile ei võimalik olla tehtud asju konfigurata, mida te tahaksida. Aga siis te saate ka Amazonis SQL anmebasi ise virtuaalmasinas ülesseada. Lisaks täis hallatud anmebaside kuhul võib kas ka leerime teie peedetud olla, et te ei pea ise muretsama, et kas ma pea, see on üles piisalt suure virtuaalmasina või piisavalt suure krastri. Näiteks Amazon DynamoDB puhul on minimaalselt teie poosad haldust, te ei pea isegi annebasi versioonide uuenduste pärast muretsama, kuna te ei nägi need versioonia anmebasi halda ja isemudab need versioone. Ja tihtid ei pea isegi muretsama, et kas anmebas on piisavalt suur, et saate sinna lihtsalt rohkem anmeet salvestada ja Amazon skaleerib neid. Aga see täiesto olev, et kas te kasutate täis hallatud platforme või pool hallatud platforme. Pool hallatud platform on selline, kus ta Amazonid küside, et sealtki mulle üles SQL cluster kindlasuurusega ja siis võib-olla ei ole nii lihtna seda suurendada. Ja teid täis hallatud platformid võidad ka pakkuda ka sellist karanteeritud jõudlust ja te saate Amazonist teatud lubaadused, et kui neid ei täideta, et siis võib-olla saate mingi alla hindudusem midagi, et kui midagi juhtub, siis maksdakse osade, sest kuludas kinni. Näites Amazoni cluster maha läheb ja siis hiljem saate küsida nagu trahvi sellest, et miks Amazon ei töötanud, kui te olete nenega midagi kokkulepinud. Sellene nädala praktikumis siis onki pilve annepaase te kasutamine, et me muudame oma hdte appi raamatude halldusrakendus niimoodi, et ta nüüd hakkab asule annepaase kasutama. Kas on küsimesi? Aga lopetamis ära ja siis täna kahed uniberst on praktikum, et seekord võib praktikum natuke raskem olla, et soovitan rohkem kohal käie, kui varasemalt ei ole käinud. Et natuke rohkem on ise väljamalda, kui võrralte selline varasemalt praktikumi on. Nägemist!